{"meta":{"title":"Shaw","subtitle":"@hust","description":"积沙成塔","author":"Shaw","url":"http://example.com","root":"/"},"pages":[{"title":"All archives","date":"2021-09-03T03:39:45.000Z","updated":"2021-09-03T03:40:04.450Z","comments":true,"path":"archives/index.html","permalink":"http://example.com/archives/index.html","excerpt":"","text":""},{"title":"","date":"2022-07-15T07:39:37.754Z","updated":"2022-07-15T07:39:37.754Z","comments":true,"path":"book/menu.html","permalink":"http://example.com/book/menu.html","excerpt":"","text":"Home Changelog h Categories Elements Excerpts Gallery Post Hello World Images Untitled Link Post Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam justo turpis, tincidunt ac convallis id. Untitled Tag Plugins Tags Videos 中文測試 日本語テスト"},{"title":"All categories","date":"2021-09-03T03:22:06.577Z","updated":"2021-09-03T03:22:06.577Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"contact","date":"2021-06-14T09:40:01.000Z","updated":"2021-06-14T09:40:14.806Z","comments":true,"path":"contact/index.html","permalink":"http://example.com/contact/index.html","excerpt":"","text":""},{"title":"友链","date":"2021-06-14T09:40:37.000Z","updated":"2021-06-14T09:55:02.256Z","comments":true,"path":"friends/index.html","permalink":"http://example.com/friends/index.html","excerpt":"","text":""},{"title":"About","date":"2023-07-07T12:45:59.798Z","updated":"2023-07-07T12:45:59.798Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"邮箱：asdiop123321@qq.com； @华中科技大学 网络空间安全学院 Email: asdiop123321@qq.com ； @ School of Cyberspace Security, Huazhong University of science and technology"},{"title":"All tags","date":"2021-06-14T09:39:05.000Z","updated":"2021-09-03T03:22:24.928Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""},{"title":"","date":"2022-07-15T07:10:17.486Z","updated":"2022-07-15T07:10:17.486Z","comments":true,"path":"book/home.html","permalink":"http://example.com/book/home.html","excerpt":"","text":"More is different，宏观与微观的审视哲学，量变产生质变。 ​ ----Shaw的，一些记录，一些随手写。"}],"posts":[{"title":"(技术积累)AFL++ Instrumention for WAVM","slug":"【技术积累】AFL++-Instrumention-for-WAVM","date":"2023-08-03T02:47:05.272Z","updated":"2023-08-14T12:11:41.214Z","comments":true,"path":"2023/08/03/【技术积累】AFL++-Instrumention-for-WAVM/","link":"","permalink":"http://example.com/2023/08/03/%E3%80%90%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF%E3%80%91AFL++-Instrumention-for-WAVM/","excerpt":"(技术积累)AFL++ Instrumention for WAVM ​ 利用AFL++自带的compiler warpper对WAVM插桩，一些Bug的记录分析。","text":"(技术积累)AFL++ Instrumention for WAVM ​ 利用AFL++自带的compiler warpper对WAVM插桩，一些Bug的记录分析。 Instrumention cmake ../ -G \"Unix Makefiles\" -DCMAKE_C_COMPILER=/home/wx/Shaw/discrepancy_cases_study/compdiff/compilers/diff-cc-1 -DCMAKE_CXX_COMPILER=/home/wx/Shaw/discrepancy_cases_study/compdiff/compilers/diff-cxx-1 -DLLVM_DIR=/home/wx/Shaw/discrepancy_cases_study/compdiff/llvm-project/install/lib/cmake/llvm Bugs 1. AFL++崩溃 ​ 使用afl-gcc-fast编译WAVM，然后放到修改后的AFL中运行。程序每次都在total exec=14时退出并报错：“segmentation fault”，使用GDB调试发现如下信息： ​ 问题定位到differential_compilers()函数第一次运行diff forkserver时，其afl_fsrv_run_target()函数中使用的memset()函数： ​ 但这里的问题就是，如果本次测试运行指定了参数-y 0，也就是不使用diff forkserver，而在differential_compilers()函数中： ​ 错误原因：即使没有设置diff forkserver，这里还是会尝试运行afl-&gt;diff_fsrv[0]，所以后续对一块没有分配过的内存进行memset操作就会出错。这里属于是对代码边界条件的判断错误。 ​ 在differential_compilers()函数内加上条件判断，重新编译即可解决： 2. AFL++卡死 ​ 修复完上面的Bug后，使用如下命令测试CompDiff在新版AFL上的功能： ./afl-fuzz -y 1 -i /home/wx/Shaw/idea_test/libtiff/seed -o /home/wx/Shaw/idea_test/out1 -J \"out.file\" -- /home/wx/Shaw/idea_test/libtiff/tools/tiffcp -M -i @@ out.file ​ 发现其每次都在total execs达到200左右时卡住，然后显示如下错误： ​ GDB调试发现程序在第一次进入differential_compilers()函数就会出错，也就是trim阶段刚结束，正式开始运行时。继续调试，发现在主函数afl-fuzz.c中，afl_fsrv_start_diff()相关代码根本就没有运行： ​ 当程序运行到afl-fuzz.c的2189行时，查看其条件判断，发现环境变量AFL_SKIP_BIN_CHECK被设置为1，导致这里直接跳过了diff forkserver的初始化过程： ​ 这是由于之前复现WAFL时使用的环境变量AFL_SKIP_BIN_CHECK还留存在了同一个bash中，导致了程序直接跳过了部分代码。 ​ 并且，由于在diff-afl-forkserver.c中的read_s32_timed()函数中，从子进程读取时读出的长度是0： ​ 这是由于这里使用的是原生的afl-gcc-fast编译的程序，其插桩时还是按照198,199的文件描述符与forkserver通信，而在diff forkserver的定义中，其是从202开始的，diff 0应该从202开始与forkserver通信才对： ​ 错误原因： 1. 错误使用环境变量`AFL_SKIP_BIN_CHECK`导致diff forkserver根本没有初始化； 2. 没有使用diff as对target插桩，导致fuzz target使用了错误的管道。 ​ 故这里不要用原生AFL编译器编译的target，直接使用CompDiff提供的编译器编译的二进制文件即可： ./afl-fuzz -y 1 -i /home/wx/Shaw/discrepancy_cases_study/compdiff/examples/libtiff/seeds -o /home/wx/Shaw/idea_test/out -J \"out.file\" -- /home/wx/Shaw/idea_test/tiffcp -M -i @@ out.file 3. 按Ctrl+C后程序结束，但不返回bash ./afl-fuzz -y 1 -i /home/wx/Shaw/discrepancy_cases_study/compdiff/examples/libtiff/seeds -o /home/wx/Shaw/idea_test/out -J \"out.file\" -- /home/wx/Shaw/idea_test/tiffcp -M -i @@ out.file ./afl-fuzz -y 1 -i /home/wx/Shaw/idea_test/in -o /home/wx/Shaw/idea_test/out -- /home/wx/Shaw/idea_test/wavm run /home/wx/Shaw/idea_c_test.wasm ./afl-fuzz -y 2 -i /home/wx/Shaw/idea_test/in -o /home/wx/Shaw/idea_test/out -- /home/wx/Shaw/idea_test/test-instr -i @@ -b 4. Without wasm:检测不到discrepancy ​ 使用如下测试程序来测试CompDiff： #include &lt;stdio.h> #include &lt;stdlib.h> #include &lt;unistd.h> int main(int argc, char** argv) &#123; char buf[8]; if (read(0, buf, 8) &lt; 1) &#123; printf(\"Hum?\\n\"); exit(1); &#125; if (buf[0] == '0') // printf(\"I'm native one!\\n\"); // printf(\"I'm wasm one!\\n\"); else printf(\"A non-zero value? How quaint!\\n\"); exit(0); &#125; ​ 当buf[0]='0'时，原始程序和待测试程序分别会打印不同的内容，但测试过程中diff目录没有任何记录。 ​ 错误原因1：原生的binary不参与discrenpancy的比较，只负责引导fuzzing。 ​ 查看differential_compilers()代码（DiffComp比较-核心逻辑）可知，CompDiff先运行一次diff_forkserver 0,然后依次运行后续的diff forkserver，每运行一个就与最开始运行的diff_forkserver 0的结果比较，如果有不同就记录discrepancy。 ​ 故这里不能指定-y为1，不然只有一个diff forkserver没有办法比较，正确做法是指定2个，然后用上述的compiler warpper包装它。 ./afl-fuzz -y 2 -i /home/wx/Shaw/idea_test/in -o /home/wx/Shaw/idea_test/out -- /home/wx/Shaw/idea_test/test-instr ​ 这样就可以成功检测到discrepancy: 5. With wasm:检测不到discrepancy ​ 在修正上述问题后，将diff forkserver 0设置为native binary，将diff forkserver 1设置为wasm binary，并修改forkserver的out_file参数和target（将target变为wavm），程序可以成功运行，但是检测不到discrepancy。 ./afl-fuzz -i /home/wx/Shaw/idea_test/in -o /home/wx/Shaw/idea_test/out -- /home/wx/Shaw/idea_test/test-instr ​ 而且注意到在测试的过程中 ，.cur_output0文件（native binary输出文件）一直有输出，但.cur_output1（wasm binary输出文件）一直是空的： ​ 问题原因：wavm运行时间太长，导致程序运行diff forkserver 1时直接退出了。 ​ 这里将diff forkserver 1的运行时间延长10倍（也就是跟forkserver初始化的时间相同），即可解决： 6. last new find总是等于run time ​ 在测试过程中，发现输出的last new find总是等于run time，这就意味着每时每刻都在发现新cov：","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Fuzzing","slug":"Fuzzing","permalink":"http://example.com/tags/Fuzzing/"}],"author":"Shaw"},{"title":"(论文复现)CompDiff(二) 代码分析","slug":"【论文复现】CompDiff(二)-代码分析","date":"2023-07-31T07:29:55.805Z","updated":"2023-08-03T02:45:00.355Z","comments":true,"path":"2023/07/31/【论文复现】CompDiff(二)-代码分析/","link":"","permalink":"http://example.com/2023/07/31/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91CompDiff(%E4%BA%8C)-%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/","excerpt":"​ CompDiff与AFL++源码对比分析。","text":"​ CompDiff与AFL++源码对比分析。 Code analysis ​ CompDiff与AFL++源码对比分析。 1. 相关数据结构变化 1.1 struct afl_state ​ 在afl_state中， 相较于原本AFL++的数据结构，这里增加了一些变量用于处理多forserver。首先是增加了多forkserver数组diff_srv以及diff forkserver数量diff_num： ​ 增加了用于保存输出文件的指针output_file： ​ 增加了用于确定输出文件的flag_use_output： ​ 增加了用于对比输出文件差异的bitmap virgin_diff： ​ 增加了用于保存差异数量的total_diffs和total_diffs： ​ 2. 主函数——afl-fuzz.c 简要分析CompDiff与AFL++中alf-fucc.c文件异同。 2.1 afl_fsrv_init() ​ 在main函数开头，原生forkserver完成初始化后，接着调用afl_fsrv_init()完成对另外10个待测试forkserver的初始化： ​ 在这之前，afl_state_init()函数会将afl-&gt;diff_num设置为10，然后CompDiff就会初始化diff_num个forkserver，该由于该部分forkserver用于后续的比较，故我们称这部分forkserver为diff forkserver。afl_fsrv_init()函数与AFL++无异。 2.2 参数处理 ​ 在参数处理方面，CompDiff增加了-y与-Y选项: -y选项： -y选项用于指定diff forkserver的数量（如果不指定则默认为10），并将指定的参数存储于afl-&gt;diff_num中。 -Y选项： -Y选项用于指定输出文件的存储位置，该位用于将待测试文件的输出到用户指定的文件中（AFL++默认丢弃fuzz target 的输出）。 其设置了两个参数：afl-&gt;output_file = optarg、afl-&gt;flag_use_output = 1; 2.3 设置kill-signal ​ 在设置了主forkserver的kill signal后，将diff forkservers的kill signal设置为相同值： 2.4 设置fsrv.out_file ​ fsrv.out_file是需要传入fuzz target的参数，在设置完主forkserver的参数后，将diff forkserver的参数设置为相同的值： ​ 同时，增加了处理函数setup_stdout_file_diff()，其定义在diff-afl-fuzz-init.c中： void setup_stdout_file_diff(afl_state_t *afl) &#123; // 如果指定了fuzz target输出文件 if (afl->flag_use_output) &#123; // 打印相关信息 OKF(\"Using output...%s\", afl->output_file); // 分配字符串空间 u8* fn = alloc_printf(\"%s\", afl->output_file); unlink(fn); /* Ignore errors */ // 设置文件描述符 afl->fsrv.dev_stdout_fd = open(fn, O_RDWR | O_CREAT | O_EXCL, 0600); if (afl->fsrv.dev_stdout_fd &lt; 0) PFATAL(\"Unable to create '%s'\", fn); ck_free(fn); // 分配错误文件信息 fn = alloc_printf(\"%s/.error\", afl->tmp_dir); unlink(fn); /* Ignore errors */ // 设置文件描述符 afl->fsrv.dev_stderr_fd = open(fn, O_RDWR | O_CREAT | O_EXCL, 0600); if (afl->fsrv.dev_stderr_fd &lt; 0) PFATAL(\"Unable to create '%s'\", fn); ck_free(fn); &#125; // 设置每个forkserver的dev_stdout_fd for (int idx_com=0; idx_com &lt; afl->diff_num; idx_com++) &#123; u8* fn = alloc_printf(\"%s/.cur_output_%d\", afl->tmp_dir, idx_com); unlink(fn); /* Ignore errors */ afl->diff_fsrv[idx_com].dev_stdout_fd = open(fn, O_RDWR | O_CREAT | O_EXCL, 0600); if (afl->diff_fsrv[idx_com].dev_stdout_fd &lt; 0) PFATAL(\"Unable to create '%s'\", fn); ck_free(fn); &#125; // 设置每个forkserver的dev_stderr_fd for (int idx_com=0; idx_com &lt; afl->diff_num; idx_com++) &#123; u8* fn = alloc_printf(\"%s/.cur_error_%d\", afl->tmp_dir, idx_com); unlink(fn); /* Ignore errors */ afl->diff_fsrv[idx_com].dev_stderr_fd = open(fn, O_RDWR | O_CREAT | O_EXCL, 0600); if (afl->diff_fsrv[idx_com].dev_stderr_fd &lt; 0) PFATAL(\"Unable to create '%s'\", fn); ck_free(fn); &#125; &#125; 2.5 shmem ​ 在AFL中，afl-&gt;shmem_testcase_mode默认被置为1，setup_testcase_shmem()函数会为afl-&gt;shm_fuzz分配空间，并设置： afl->fsrv.support_shmem_fuzz = 1; afl->fsrv.shmem_fuzz_len = (u32 *)map; afl->fsrv.shmem_fuzz = map + sizeof(u32); ​ CompDiff在这之后会将diff forkserver的这三个参数设置为主forkserver相同的值： ​ 然后对所有forkserver进行共享内存的初始化，配置相关环境变量： 2.6 forkserver ​ 在AFL中，其会调用afl_fsrv_get_mapsize()函数来启动一个forkserver，这里会接着将剩下的diff forkserver也启动： ​ 最后，将afl-&gt;virgin_diff通过memset函数置为0即可： ​ 以上就是afl-fuzz.c主文件中的大部分改动（还有部分细节见源码）。 3. 初始化 afl-fuzz-init.c文件是AFL的初始化相关函数定义，这里描述了CompDiff与AFL++初始化方面的区别 3.1 In afl-fuzz-init.c 3.1.1 setup_dirs_fds() ​ setup_dirs_fds()函数用于创建输出目录以及其相关子目录（例如queue、crashes、hang等），并将afl-&gt;fsrv.out_dir_fd，afl-&gt;fsrv.dev_null_fd，afl-&gt;fsrv.dev_urandom_fd 设置为对应的描述符。 ​ 这里CompDiff在创建文件夹时，增加了对diffs文件夹的创建，其用于存储找到的discrepancy： ​ 接下来在往afl-&gt;fsrv.plot_file中写入字符串时加入unique_diffs信息： 3.1.2 check_binary() ​ check_binary()函数的主要作用是将fsrv.target_path设置为argv[optind]，也就是fuzz target的路径。这里增加了设置diff forkserver的相关代码： ​ 可以看到，这里需要对比运行的二进制文件的名称必须是filename+-+diff_num格式，故在实验复现阶段生成的文件名称是不能随意改变的。 3.2 In afl-fuzz-state.c 3.2.1 afl_state_init() ​ afl_state_init()函数的定义存储于afl-fuzz-state.c，相较于AFL++，CompDiff新增了：对virgin_diff图的空间分配、对diff forkserver的相关数据结构的初始赋值： 3.2.2 afl_state_deinit() ​ afl_state_deinit()函数用于移除并释放afl_state结构，这里增加了对diff相关数据结构的释放操作： 4. :star:DiffComp比较-核心逻辑 ​ DiffComp的核心逻辑存储在diff-afl-fuzz-init.c中，其关键比较函数存储在differential_compilers()函数中： // from diff-afl-fuzz-init.c // 比较不同输出 u8 differential_compilers(afl_state_t *afl, void *mem, u32 len) &#123; unsigned char first_cksum_out[MD5_DIGEST_LENGTH], cksum_out[MD5_DIGEST_LENGTH]; int bytes; unsigned char data[1024]; u8 keep_as_diff = 0; fsrv_run_result_t ret; // 如果使用了-Y选项，指定输出文件 if (afl->flag_use_output) &#123; // 设置diff forkserver的相关描述符 for (int idx = 0; idx &lt; afl->diff_num; idx++) &#123; afl->diff_fsrv[idx].dev_stdout_fd = afl->fsrv.dev_stdout_fd; afl->diff_fsrv[idx].dev_stderr_fd = afl->fsrv.dev_stderr_fd; &#125; &#125; for (int idx = 0; idx &lt; afl->diff_num; idx++) &#123; // 将这两个描述符置于文件开头 lseek(afl->diff_fsrv[idx].dev_stdout_fd, 0, SEEK_SET); lseek(afl->diff_fsrv[idx].dev_stderr_fd, 0, SEEK_SET); // 清空文件内容 if (ftruncate(afl->diff_fsrv[idx].dev_stdout_fd, 0)) PFATAL(\"ftruncate() failed\"); if (ftruncate(afl->diff_fsrv[idx].dev_stderr_fd, 0)) PFATAL(\"ftruncate() failed\"); // 将这两个描述符置于文件开头 lseek(afl->diff_fsrv[idx].dev_stdout_fd, 0, SEEK_SET); lseek(afl->diff_fsrv[idx].dev_stderr_fd, 0, SEEK_SET); &#125; // 将第一个diff forkserver的out_fd置于开头 // out_fd用于指向fsrv->out_file // 也就是传给fuzz target的参数 lseek(afl->diff_fsrv[0].out_fd, 0, SEEK_SET); // 运行第一个diff forkserver ret = afl_fsrv_run_target(&amp;afl->diff_fsrv[0], afl->fsrv.exec_tmout, &amp;afl->stop_soon); // 如果超时则退出 if (ret == FSRV_RUN_TMOUT) &#123; return ret; &#125; // 将这两个描述符置于文件开头 lseek(afl->diff_fsrv[0].dev_stdout_fd, 0, SEEK_SET); lseek(afl->diff_fsrv[0].dev_stderr_fd, 0, SEEK_SET); // md5 of first output MD5_CTX first_mdContext; MD5_Init (&amp;first_mdContext); // 从第一个diff forkserver中读取1024个标准输出 while ((bytes = read(afl->diff_fsrv[0].dev_stdout_fd, data, 1024)) != 0) &#123; MD5_Update(&amp;first_mdContext, data, bytes); &#125; // 第一个diff forkserver中读取1024个错误输出 while ((bytes = read(afl->diff_fsrv[0].dev_stderr_fd, data, 1024)) != 0) &#123; MD5_Update(&amp;first_mdContext, data, bytes); &#125; // 计算输出的哈希值 MD5_Final(first_cksum_out, &amp;first_mdContext); // md5 of following outputs // 运行剩下的diff forkservers // 从dev_stdout_fd读取其输出并计算哈希 for (int idx = 1; idx &lt; afl->diff_num; idx++) &#123; lseek(afl->diff_fsrv[0].out_fd, 0, SEEK_SET); ret = afl_fsrv_run_target(&amp;afl->diff_fsrv[idx], afl->fsrv.exec_tmout, &amp;afl->stop_soon); if (ret == FSRV_RUN_TMOUT) &#123; return ret; &#125; lseek(afl->diff_fsrv[idx].dev_stdout_fd, 0, SEEK_SET); lseek(afl->diff_fsrv[idx].dev_stderr_fd, 0, SEEK_SET); MD5_CTX mdContext; MD5_Init (&amp;mdContext); while ((bytes = read(afl->diff_fsrv[idx].dev_stdout_fd, data, 1024)) != 0)&#123; MD5_Update(&amp;mdContext, data, bytes); &#125; while ((bytes = read(afl->diff_fsrv[idx].dev_stderr_fd, data, 1024)) != 0)&#123; MD5_Update(&amp;mdContext, data, bytes); &#125; MD5_Final(cksum_out, &amp;mdContext); // 与第一次计算的哈希比较 // 如果不同则退出/继续比较 if (strncmp(cksum_out, first_cksum_out, MD5_DIGEST_LENGTH) != 0) &#123; keep_as_diff = 1; //break; &#125; &#125; // 如果发现discrepancy if (keep_as_diff) &#123; ++afl->total_diffs; classify_counts(&amp;afl->fsrv); simplify_trace(afl, afl->fsrv.trace_bits); // 检查virgin_diff 图是否有变化 if (!has_new_bits(afl, afl->virgin_diff)) &#123; return 0; &#125; u8 fn[PATH_MAX]; s32 fd; // 存储相关样例 #ifndef SIMPLE_FILES snprintf(fn, PATH_MAX, \"%s/diffs/id:%06llu,sig:%02u,%s\", afl->out_dir, afl->unique_diffs, afl->fsrv.last_kill_signal, describe_op(afl, 0, NAME_MAX - strlen(\"id:000000,sig:00,\"))); #else snprintf(fn, PATH_MAX, \"%s/diffs/id_%06llu_%02u\", afl->out_dir, afl->unique_diffs, afl->last_kill_signal); #endif /* ^!SIMPLE_FILES */ fd = open(fn, O_WRONLY | O_CREAT | O_EXCL, DEFAULT_PERMISSION); if (unlikely(fd &lt; 0)) &#123; PFATAL(\"Unable to create '%s'\", fn); &#125; ck_write(fd, mem, len, fn); close(fd); ++afl->unique_diffs; &#125; return 0; &#125; ​ differential_compilers()会在afl-fuzz-run.c中的common_fuzz_stuff()函数中被调用。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Fuzzing","slug":"Fuzzing","permalink":"http://example.com/tags/Fuzzing/"}],"author":"Shaw"},{"title":"(论文复现)CompDiff(一) 实验复现","slug":"【论文复现】Finding-Unstable-Code-via-Compiler-Driven-Differential-Testing","date":"2023-07-28T13:25:50.845Z","updated":"2023-07-31T11:03:24.321Z","comments":true,"path":"2023/07/28/【论文复现】Finding-Unstable-Code-via-Compiler-Driven-Differential-Testing/","link":"","permalink":"http://example.com/2023/07/28/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91Finding-Unstable-Code-via-Compiler-Driven-Differential-Testing/","excerpt":"(论文复现)Finding Unstable Code via Compiler-Driven Differential Testing ​ 对论文《Finding Unstable Code via Compiler-Driven Differential Testing》的过程复现+代码分析。","text":"(论文复现)Finding Unstable Code via Compiler-Driven Differential Testing ​ 对论文《Finding Unstable Code via Compiler-Driven Differential Testing》的过程复现+代码分析。 代码结构 ​ CompDiff的代码结构如下： ​ 其中，aflpp是以AFL++ 3.15a为基础魔改的版本，compilers用于生成包装后的编译器，examples包含了作者提供的两个待测试程序和其对应构建脚本。 实验复现 1. 生成包装编译器 ​ 从仓库下载代码，运行./diff-build.sh脚本： #!/bin/bash set -e #run ./diff-build.sh clean if [ \"$1\" = \"clean\" ]; then cd \"./aflpp\" CC=clang make clean cd ../compilers make clean exit 0 fi #build modified AFL++ 3.15a cd \"./aflpp\" CC=clang make source-only CC=clang make -C utils/aflpp_driver cd .. #build different compilers(10 by default) cd \"./compilers\" source build.sh cd .. ​ 该脚本会编译魔改版的AFL和compilers，compilers利用了AFL++提供的编译器包装器（warpper）生成不同配置的包装后的编译器： ​ 对于CC和CXX，各有10个生成，其分别对应用gcc和clang使用-O0, -O1,-O2,-O3, 和-Os5种优化选项，2×5 = 10。具体逻辑可见/compdiff/compilers/build.sh： #!/bin/bash # This is the building script for different compiler configurations. make clean if [ \"$1\" = \"clean\" ]; then exit 0 fi forksrv=202 id=0 compiler_id=0 for _ in $(seq 1 `jq \"[.][0] | length\" config`); do for config in `jq \"[[.][0][$&#123;compiler_id&#125;].configs][0][]\" config`; do export DIFF_CC=`jq \"[.][0][$&#123;compiler_id&#125;].CC\" config` export DIFF_CXX=`jq \"[.][0][$&#123;compiler_id&#125;].CXX\" config` export DIFF_ID=$&#123;id&#125; printf \"#define FORKSRV_FD $&#123;forksrv&#125; \\n #define DIFF_ID $&#123;DIFF_ID&#125; \\n #define DIFF_CC $&#123;DIFF_CC&#125; \\n #define DIFF_CXX $&#123;DIFF_CXX&#125; \\n #define DIFF_CONFIG $&#123;config&#125; \" > ./compiler-base/diff-config.h make id=$((id+1)) forksrv=$((forksrv+4)) done compiler_id=$((compiler_id+1)) done ​ 其中，FORKSRV_FD是对应在AFL中打开的forkserver中使用的文件描述符；DIFF_CONFIG就是对应的优化选项，例如-O1、-O2等；DIFF_ID用于区分不同的编译配置（编译器+优化选项），其序号在/compdiff/compilers/config中对应如下： ​ 在for循环中从config获取这些编译选项参数后，通过printf函数将对应设置写入到./compiler-base/diff-config.h文件中，该文件会被同文件夹下的config.h文件包含，并最终被diff-cc.c包装器引用，最终生成我们所需的10种编译器。 ​ 在后续的过程中，这10中不同的编译器将会用来编译待测试项目/文件。 2. 编译项目 ​ 这里以libtiff为例，用作者已经给出的编译脚本编译（后续可以写自己的）： ./diff-instrument.sh ./examples/libtiff/build.sh ​ 可以看到脚本自动下载了libtiff并编译，然后用上一步生成的编译器编译了10个不同的版本和一个原生版本： PS:由于作者给出的shell脚本都是直接从github仓库下载最新版的软件，最新版本的xpdf样例(2023.7.29)在我的虚拟机上存在QTso库不兼容问题，但这个bug不重要，故避免浪费时间见这里使用libtiff做演示。 3. Fuzzing ​ 直接运行魔改后的AFL即可： $ ./aflpp/afl-fuzz -y 10 -i examples/libtiff/seeds -o examples/libtiff/findings -Y \"out.file\" -- ./examples/libtiff/bin/tiffcp -M -i @@ out.file ​ 但其由于需要将程序结果输出到文件中，大量的I/O操作以及每轮需要运行10+1个forkserver，导致其速度还不如正常的1/10： ​ 当然，这是在虚拟机内跑的结果，实际物理机会略快一些，但不会快太多。 ​ ​","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Fuzzing","slug":"Fuzzing","permalink":"http://example.com/tags/Fuzzing/"}],"author":"Shaw"},{"title":"(论文阅读)★Finding Unstable Code via Compiler-Driven Differential Testing","slug":"【论文阅读】Finding-Unstable-Code-via-Compiler-Driven-Differential-Testing","date":"2023-07-27T07:43:41.893Z","updated":"2023-07-27T13:24:04.540Z","comments":true,"path":"2023/07/27/【论文阅读】Finding-Unstable-Code-via-Compiler-Driven-Differential-Testing/","link":"","permalink":"http://example.com/2023/07/27/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Finding-Unstable-Code-via-Compiler-Driven-Differential-Testing/","excerpt":"Finding Unstable Code via Compiler-Driven Differential Testing 时间：2023 作者：Shaohua Li、Zhendong Su（苏黎世联邦理工） 会议：ASPLOS（CCF-A） 开源：shao-hua-li/compdiff (github.com) Abstract ​ 不稳定的代码是指由于程序中存在未定义行为（UB），导致运行时语义不一致或不稳定的代码。编译器通过假设未定义行为永远不会发生来利用UB，从而生成高效但潜在语义不一致的二进制文件。实践者们在设计动态工具（例如sanitizers）来处理常见的UB问题时已付出了大量研究和工程努力。然而，目前的技术仍面临一个重大挑战，即如何检测那些超出当前技术范围的UB问题。 ​ 在本文中，我们介绍了一种名为Compiler-driven differential testing（CompDiff）的简单而有效的方法，用于发现C/C++程序中的不稳定代码。CompDiff利用了一个事实，即当编译不稳定代码时，不同的编译器实现可能会生成语义上不一致的二进制文件。我们的主要方法是检查相同输入上不同二进制文件的输出。输出的差异可能表明存在不稳定的代码。为了在实际程序中检测不稳定代码，我们还将CompDiff集成到AFL++中，这是最常用且积极维护的通用模糊测试工具。 ​ 尽管CompDiff的方法简单，但实践中非常有效：在Juliet基准程序上，相比于sanitizers，CompDiff独特地检测到1,409个错误；在23个流行的开源C/C++项目中，CompDiff-AFL++发现了78个新错误，其中52个已经被开发人员修复，而36个无法通过sanitizers检测出来。我们的评估还揭示了一个事实，即CompDiff的设计并不是为了取代当前的UB检测工具，而是为它们提供补充。","text":"Finding Unstable Code via Compiler-Driven Differential Testing 时间：2023 作者：Shaohua Li、Zhendong Su（苏黎世联邦理工） 会议：ASPLOS（CCF-A） 开源：shao-hua-li/compdiff (github.com) Abstract ​ 不稳定的代码是指由于程序中存在未定义行为（UB），导致运行时语义不一致或不稳定的代码。编译器通过假设未定义行为永远不会发生来利用UB，从而生成高效但潜在语义不一致的二进制文件。实践者们在设计动态工具（例如sanitizers）来处理常见的UB问题时已付出了大量研究和工程努力。然而，目前的技术仍面临一个重大挑战，即如何检测那些超出当前技术范围的UB问题。 ​ 在本文中，我们介绍了一种名为Compiler-driven differential testing（CompDiff）的简单而有效的方法，用于发现C/C++程序中的不稳定代码。CompDiff利用了一个事实，即当编译不稳定代码时，不同的编译器实现可能会生成语义上不一致的二进制文件。我们的主要方法是检查相同输入上不同二进制文件的输出。输出的差异可能表明存在不稳定的代码。为了在实际程序中检测不稳定代码，我们还将CompDiff集成到AFL++中，这是最常用且积极维护的通用模糊测试工具。 ​ 尽管CompDiff的方法简单，但实践中非常有效：在Juliet基准程序上，相比于sanitizers，CompDiff独特地检测到1,409个错误；在23个流行的开源C/C++项目中，CompDiff-AFL++发现了78个新错误，其中52个已经被开发人员修复，而36个无法通过sanitizers检测出来。我们的评估还揭示了一个事实，即CompDiff的设计并不是为了取代当前的UB检测工具，而是为它们提供补充。 Background ​ 对于包含未定义行为的代码，不同的编译器实现可能会生成语义不同的二进制文件。之前的研究 [47, 48] 表明，未定义行为可能会导致优化不稳定代码，即编译器优化可能会意外丢弃的代码。 ​ 如上图Line9的if语句尝试处理可能出现的整数溢出，该语句（offset+len &lt; offset）只有在整数溢出时才可能成立。但是，编译器可以在假设未定义行为从未发生的情况下进行任意优化操作，结果就是在clang -O2参数下移除了9-11行代码，在-O0下则不会。 ​ 一方面，这个问题会导致优化后的二进制文件出现安全漏洞，因为大量非法内存数据可能会被转储。另一方面，它破坏了代码的功能正确性，因为由不同编译器编译的二进制文件可能会产生不同的输出结果。 Contribution 我们提出的 CompDiff 是一种简单、直接但有效的查找不稳定代码的方法; 我们将 CompDiff 集成到AFL++中; 我们在基准程序和实际程序上对 CompDiff 进行了评估，结果表明，CompDiff 对sanitizer有明显的补充作用。 Examples Example 1: Invalid pointer comparison ​ 上图是CompDiff在Binutils中找到的不稳定代码样例，指针look_for和saved_start分别指向不同的对象。使用关系运算符对指向不同的对象进行比较是一个未定义行为，并且已有的sanitizer并不能对其进行检测，因为没办法设计一个合理的监测机制。 ​ 但CompDiff 可以轻松检测到这一问题，因为不同编译器实现对if语句的评估方式不同，因此会观察到不同的输出结果。 Example 2: Evaluation order of subexpressions with conflict side effects ​ 上图是从Tcpdump中找到的不稳定代码样例，第九行通过调用DP_PRINT函数来dump信息，并且该函数的两个参数是函数GET_LINKADDR_STRING的返回值。 ​ 首先，函数GET_LINKADDR_STRING使用静态字符数组缓冲区来存储生成的字符串，缓冲区指向的内存区域将在函数调用中共享。由于该函数有两次调用，第一次调用存储在缓冲区中的结果将被第二次调用覆盖。因此，在转储的字符串中，who-is 和 tell 这两个字段总是相同的。 ​ 其次，由于语言规范对函数参数的评估顺序没有限制，不同的编译器可能会以不同的顺序评估这两次 GET_LINKADDR_STRING 调用。如果我们分别用 gcc 和 clang 编译 Tcpdump，得到的两个二进制文件会以相反的顺序评估 ND_PRINT 的参数，从而导致转储字符串不一致。具体来说，clang 会从第一个到最后一个评估参数，即 p2 会同时转储到 who-is 和 tell；而 gcc 会从最后一个到第一个评估参数，即 p1 会同时转储到两个属性。 ​ 目前已有的sanitizer没法发现这个问题，要扩展sanitizer以支持此类检测，需要设计一个新的检查器，检查多个子表达式是否会对冲突内存区域产生副作用，但如何实现这样的检查器仍是未知数。 Example 3: Uninitialized memory usage ​ 上图给出了一个由于使用了未初始化变量而导致不稳定的代码片段。开发人员可能会认为，虽然变量l未初始化，但其初始随机值应在第 6 行被 is中的内容覆盖。然而，在 is为空字符串的情况下，变量 l将保持不变，然后，未初始化的值将用于剩余的执行过程，在本例中将打印输出到 ostream。 ​ 虽然MemorySanitizer支持检测未初始化内存的使用，其中未初始化值必须用于确定代码分支，例如，if语句依赖于未初始化值。为避免误报，它不支持示例中所示的情况。但CompDiff-AFL++ 可以检测到这一问题，因为： ​ 1）后端 AFL++可以生成导致变量为空的测试样例，从而使不同二进制文件中的 l不同； ​ 2）CompDiff 可以捕获不同的输出。 Model Workflow of CompDiff 找到一些自身完善的编译器Ci； 用这些编译器编译程序P得到多个二进制文件Bi； 找到一个输入集L； 在每个Bi上运行L，得到输出Oi，比较其异同。 :star:CompDiff-AFL++ ​ 在CompDiff结合AFL++的过程中，从一份待测试源码编译了若干个二进制程序，其中一个\\(B_{fuzz}\\)是用AFL自带的编译器插桩编译完成的，其就是正常使用AFL++时的工作流程，编译器（如afl-clang-fast）会在二进制程序中插入forkserver、覆盖率反馈以及可选的sanitizer功能。其余的二进制程序都是从待测试编译器中编译而来的普通二进制程序，为了快速运行，我们在其中插入了AFL的forkserver功能。 Instrumentation on ℬ𝑖 ​ 每个Bi由不同的（编译器+优化参数）配置编译而成，并对其进行代码插桩以实现forkserver，forkserver的具体机制见：(技术积累)How does AFL++ run a program? | Shaw (shawdox.github.io) Output examination ​ 默认情况下AFL++会丢弃待测试程序的输出，这里可以使用dup2()函数将其重定向到指定的文件，然后通过检查输出文件的checksum来判断是否有discrepancy。这里我们使用了AFL++支持的MurmurHash3哈希函数来计算checksum。 Bug-triggering inputs ​ 我们会将引发输出discrepancy的所有输入保存到一个单独的目录 \"diffs/\"中，以便将来进行诊断。与普通fuzzing中的崩溃触发输入类似，有许多输入会触发相同的错误，自动识别独特的差异并非易事，尤其是在differential testing的情况下。目前，我们依靠人工分析报告的差异来分流错误报告。 Evaluation 1. 测试环境 版本信息： ​ 在我们的测试中，使用了gcc 11.1.0和clang 13.0.1（当时最新的版本）作为测试的后端编译器，在每个编译器中都会测试-O0, -O1,-O2,-O3, 和-Os优化选项，故一共有10中不同的编译配置选项。AFL++的版本是3.15a。 数据集： Juliet test suite 23 个维护良好的开源 C/C++ 项目 对比： 3种广泛使用的静态分析工具：Coverity [40]、Cppcheck [12] 和 Infer [31]； Sanitizers：ASan、UBSan、MSan； 2. 测试结果 ​ 测试分为两个部分：在Juliet test suite上测试用于测试CompDiff的effectiveness；在真实的项目上测试其检测bug的能力。 2.1 Effectiveness of CompDiff in Benchmark Programs 与 CompDiff 相比，静态工具的false positive不可忽略，并且错误检测率相对较低。 CompDiff 可以发现许多额外的错误，是对sanitizer的补充； 与每种sanitizer相比，CompDiff 的bug覆盖率最高; CompDiff 会遗漏某些类型的错误; CompDiff 没有false postive。 2.2 The bug detection capability of CompDiffAFL++ in real-world software 在真实的C/C++项目上使用CompDiff，其直接利用其Unit test作为初始种子进行fuzzing： 小记 CompDiff文章的优点： 数据分析十分详尽，利用Juliet test suite测试其effectiveness，利用开源项目测试其发现bug的真实能力，并对其发现bug的能力、误报率、与其它工具的对比、不同编译选项的影响都分析的十分到位，图表清晰明了，分析数据详实，很有说服力； idea立意很好，通过examples很好的说明了为什么已有的工具没法解决一些未定义行为，而CompDiff可以，突出了其优点； [待更新]","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Fuzzing","slug":"Fuzzing","permalink":"http://example.com/tags/Fuzzing/"}],"author":"Shaw"},{"title":"(论文阅读)UTOPIA-Automatic Generation of Fuzz Driver using Unit Tests","slug":"【论文阅读】UTOPIA-Automatic-Generation-of-Fuzz-Driver-using-Unit-Tests","date":"2023-07-24T05:51:56.821Z","updated":"2023-07-24T06:55:42.832Z","comments":true,"path":"2023/07/24/【论文阅读】UTOPIA-Automatic-Generation-of-Fuzz-Driver-using-Unit-Tests/","link":"","permalink":"http://example.com/2023/07/24/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91UTOPIA-Automatic-Generation-of-Fuzz-Driver-using-Unit-Tests/","excerpt":"UTOPIA: Automatic Generation of Fuzz Driver using Unit Tests 时间：2022 作者：Bokdeuk Jeong、Joonun Jang（Samsung Research）、Taesoo Kim（佐治亚理工） 会议：S&amp;P'2023 开源：https://github.com/Samsung/UTopia Abstract ​ Fuzzing可以说是检测软件安全漏洞的最实用方法，但采用这种方法需要付出不小的努力。要想取得成效，高质量的fuzz driver程序应首先应当包含适当的 API 序列，以便详尽地探索程序状态。为减轻这一负担，现有解决方案试图通过从用户代码（即 API 的实际使用）中推断出有效的 API 序列，或直接从样本执行中提取 API 序列来生成fuzz driver程序。遗憾的是，所有现有方法都存在一个共同问题：观察到的 API 序列（无论是静态推断还是动态监控）都与自定义应用程序逻辑混杂在一起。然而，我们观察到，单元测试是由应用程序接口的实际设计者精心制作的，以验证其正确使用，而且重要的是，在开发过程中编写单元测试是一种常见做法（例如，超过 70% 的流行 GitHub 项目）。 ​ 在本文中，我们提出了一种开源工具和分析算法--UTOPIA，它可以从现有的单元测试中自动合成有效的fuzz driver程序，几乎不需要人工参与。为了证明其有效性，我们将 UTOPIA 应用于 55 个开源项目库，包括 Tizen 和 Node.js，并从 8K 个合格的单元测试中自动生成了 5K 个fuzz driver程序。此外，我们在每个内核上执行了约 500 万小时生成的fuzzer，发现了 123 个错误。更重要的是，2.4K 个生成的fuzz driver程序被Tizen项目的持续集成流程采用，这表明了合成fuzz driver程序的质量。为了让研究人员和从业人员更广泛地采用，我们公开并维护了所提出的工具和结果。","text":"UTOPIA: Automatic Generation of Fuzz Driver using Unit Tests 时间：2022 作者：Bokdeuk Jeong、Joonun Jang（Samsung Research）、Taesoo Kim（佐治亚理工） 会议：S&amp;P'2023 开源：https://github.com/Samsung/UTopia Abstract ​ Fuzzing可以说是检测软件安全漏洞的最实用方法，但采用这种方法需要付出不小的努力。要想取得成效，高质量的fuzz driver程序应首先应当包含适当的 API 序列，以便详尽地探索程序状态。为减轻这一负担，现有解决方案试图通过从用户代码（即 API 的实际使用）中推断出有效的 API 序列，或直接从样本执行中提取 API 序列来生成fuzz driver程序。遗憾的是，所有现有方法都存在一个共同问题：观察到的 API 序列（无论是静态推断还是动态监控）都与自定义应用程序逻辑混杂在一起。然而，我们观察到，单元测试是由应用程序接口的实际设计者精心制作的，以验证其正确使用，而且重要的是，在开发过程中编写单元测试是一种常见做法（例如，超过 70% 的流行 GitHub 项目）。 ​ 在本文中，我们提出了一种开源工具和分析算法--UTOPIA，它可以从现有的单元测试中自动合成有效的fuzz driver程序，几乎不需要人工参与。为了证明其有效性，我们将 UTOPIA 应用于 55 个开源项目库，包括 Tizen 和 Node.js，并从 8K 个合格的单元测试中自动生成了 5K 个fuzz driver程序。此外，我们在每个内核上执行了约 500 万小时生成的fuzzer，发现了 123 个错误。更重要的是，2.4K 个生成的fuzz driver程序被Tizen项目的持续集成流程采用，这表明了合成fuzz driver程序的质量。为了让研究人员和从业人员更广泛地采用，我们公开并维护了所提出的工具和结果。 Background ​ 最近，研究人员一直在探索一种方法，通过自动生成或合成fuzz driver程序来减轻library fuzzing人工集成的负担[12, 16, 18, 28]。他们通过随机推断源代码中的应用程序接口依赖关系[12, 16]，或通过运行时观察到的执行轨迹[18, 28]，为fuzzing制定了适当的应用程序接口序列。 ​ 更具体地说，最初的项目之一 Fudge[12]，侧重于从消费者代码中直接还原适当的 API 调用序列，其中 API 使用和自定义应用程序逻辑相互交织。后续项目FuzzGen[16]通过对整个程序进行分析，从多个消费者代码中推理出 API 的依赖关系，理论上可以产生合理有效的fuzz driver程序（即推断出有效的 API 调用序列）。尽管这些方法具有通用性和广泛适用性，但它们所依赖的用户代码却存在根本性的局限。特别是，混合代码最终可能会生成过于简单的 API 序列/语义上无效的状态（例如，在一个代码中分配，而在其他地方使用）。从消费者代码的统计聚合中推断有效的 API 序列和依赖关系，会产生刻板的情况，这对于寻找无效、不常见输入的模糊器来说并不理想。 ​ 与试图推断 API 依赖关系的现有项目不同，我们在单元测试 (UT) 中使用了准确的 API 调用顺序，我们观察到： 现有的UT明确表达了开发人员所关心的 API 的这种依赖性； UT检查library所提供功能的各个方面，其API（如内部API）多于消费者代码； 许多现有项目已经有了写得很好的UT--在来自 Github、Android 外部和 OSS-Fuzz的项目中占比73%。 ​ Contribution ​ 在本文中，我们提出了UTOPIA，利用各种技术，以自动化和可扩展的方式将现有的UT转换为有效的fuzz driver程序，UTOPIA背后的主要思想是： 利用UT的特定属性来揭示UT分析的复杂性； 执行root-definition analysis（一种新引入的技术）来追溯API参数的源头，以进行适当的fuzz input注入，从而保持开发人员所希望的程序间关系和数据流； 在fuzz input突变中反映对每个参数在其API内部可能产生的影响的分析。这样，UTOPIA 就能深入探索代码空间，避免因无效 API 使用而导致崩溃。因此，UTOPIA 可以提供一个push-button式解决方案，在没有人工参与的情况下自动合成高质量的fuzz driver程序。 ​ 本文的贡献如下： 我们提出了一种新的fuzz driver程序合成方法，该方法包含现有的单元测试，可自动生成fuzz driver程序； 我们利用 gtest 和 boost UT 框架，为 C/C++ 库实施了本方法的原型 UTOPIA，并通过经验验证，本方法可成功地将五千多的UT转化为 55 个开源项目库的有意义的fuzz driver程序； 我们报告了 123 个新漏洞，其中 70 个在责任披露过程中得到确认。 Model 1. 挑战 C1. 生成有效的API序列； C2. 生成有效的API参数。 ​ 在fuzz driver中，library不仅可以因为bug崩溃，也可以是因为API的不当使用（如C1、C2），这种崩溃会严重影响fuzzing的进程。 ​ 上图是一个用OpenCV库读/写raw data的UT，UTOPIA 通过对原始 UT 代码进行细微修改，将 UT 转换为fuzz driver程序，以便将fuzz input分配给被分析为API参数来源的现有变量。 ​ 上图可以观察到UTOPIA对UT所做的改动，其将一些常数值变为了变量以将其分配给fuzzer进行改动（文章里的说法真巧妙啊:cupid:） 2. 方法 2.1 生成有效的API序列 2.1.1 先前工作的问题 ​ 如果要像以前的研究那样，对任何特定的消费者代码进行分析，则应决定对消费者代码做分析的程序。 ​ 一种可能的方法是对整个消费者代码进行分析，从而提取消费者内部的整个 API 使用模式。但是，如果遇到复杂的消费者代码，其中有大量 API 调用分散在复杂的控制流中，提取的模式可能会变得臃肿。这会导致驱动程序调用数十或数百次 API 调用，由于来自众多 API 的输入空间过于臃肿，这会阻碍驱动程序的fuzzing工作。 ​ 为了避免这种情况，一种方法是限制生成单个fuzz driver程序时所需要分析的用户代码量（例如，先前的工作[12, 16]仅对同一编译单元进行分析，以提取库 API 调用的使用情况）。虽然这缓解了之前序列臃肿的问题，但由于一些必要的 API 调用存在于不同的源文件中，这可能会导致获取的 API 序列不完整。此外，从这样的序列生成fuzz driver程序可能会产生虚假崩溃。 2.1.2 我们的方法 ​ 以前的研究侧重于从任何给定的消费者中正确重建有效的 API 序列，与此不同，我们利用单元测试中编写的显式 API 序列，完全避开了上述 API 序列合成的难题。 ​ 使用UT有两个好处： 在UT中为每个测试用例明确构建库状态，这意味着在生成模糊驱动程序时无需进行应用程序接口模式推理或提取； 这与fuzz driver程序的目的是一致的，即每个测试用例及其所包含的API序列，都是为了测试库开发人员认为必不可少的库的特定属性/变量而设计的。 ​ 在我们运行的示例中，这种方法使我们能够在代码中保持所有的 API 顺序关系，因为我们不会改变任何调用。此外，由于UT只包含测试库特定属性所需的简短API序列，UTOPIA不容易生成臃肿的API序列。 2.2 生成有效的API参数 2.2.1 Inferring inter-API semantics ​ 有效语义的API之间的主要关系是： out-to-in: 一个API的输出是另一个API的输入； fixed: 每个 API 中的参数在所有 API 调用中都应相同； relative: 不同API的参数由同一值生成（x=f(y)；API_1(x)；z=x+g(y); API_2(z);）。 ​ 使用传统的程序内数据流分析方法，无法从一般消费者代码的使用中准确分析出应用程序间的关系，因为如果我们在输入fuzz input时不考虑程序间的数据流，就可能会忽略开发者的预期数据流，例如： var a = 3; b = func(a); Target_API(b); ​ 反之，如果只依赖程序内分析，则会将fuzz input分配给 b，而不是 a。另外，也可以通过API之间的参数类型别名来推断这种关系[16]，但无法确定它们是否指的是同一个对象。在这种情况下，生成的fuzz driver程序无法反映参数之间的 API 间关系。 2.2.2 Inferring intra-API semantics ​ 此外，还应考虑同一 API 中参数之间的关系，最常见的考虑因素包括与数组有关的因素： array↔︎length: 输入参数表示另一个输入数组参数的长度； array↔︎index: 输入参数是另一个数组输入参数的索引。 ​ 例如，Mat 类构造函数中的第一个参数（图 1 中第 14 行）要求与第二个和第四个参数中所述数组的大小相对应。如果对这两个参数进行随机fuzzing，驱动程序大多会导致故障（参数大小大于数组实际大小）或浪费精力更改未使用的fuzz input字节（参数大小小于数组实际大小）。 ​ 如果将 Fudge [12] 基于类型的模式匹配方法应用于这个示例，它将无法匹配第一个参数和第四个参数之间的逻辑关系，因为这种关系并没有明确地暴露在消费者代码中。虽然 FuzzGen [16] 的值集方法可以对应用程序接口的内部结构进行分析，但由于它推断的是单个参数的类型和值集，而不是参数之间的关系，因此在表示三个参数之间的关系时容易失败。 2.2.3 Detrimental input for fuzzing ​ 虽然不属于滥用API，但我们注意到，有些参数在不经意地进行fuzzing时，会降低fuzzing的性能。例如，如果某个参数用于内存分配或循环计数，过大的数值经常会分别导致内存不足或超时错误。虽然这些并不是虚假崩溃，但往往同样会阻碍进一步的模糊探索。 ​ 为了保持有效的参数语义，UTOPIA 保留了 UT 中的原始数据流，并通过静态分析找到注入fuzz input（即fuzz target）的位置以及它们应该如何变异（API 属性）。为了识别注入fuzz input的合适位置，我们定义了一个新的root-definition analysis，即用常量定义变量的赋值语句。通过只在root-definition处分配fuzz input，我们可以保留原有的数据流，并自然地遵循现有的应用程序接口间语义，因为应用程序接口参数之间的流动是不间断的。在图 1 中，UTOPIA 通过在root-definition（第 23 行）中分配fuzz input，将fuzz input传递给写原始数据（writeRaw() API）中的第三个参数 rawdata（第 31 行），在根定义中，rawdata 向量的每个元素都被分配了常数。 ​ 找到根定义后，UTOPIA 会根据从根定义中获取值的 API 参数的属性分析注入模糊输入（确定属性的 API 静态分析详见第三节 B）。例如，在 Mat 类的构造函数中（图 1 中的第 18 行），UTOPIA 推断出了数组↔︎长度关系，并将 dim 的大小（数组属性）分配给第 18 行的第一个参数（ArrayLength 属性）和第 17 行的每个带有模糊输入的元素。 2.3 使用单元测试的独特挑战 ​ 然而，简单地将 UT 作为消费者提供给现有方法并不合适，因为使用 UT 会带来自身的一系列挑战 (UT-C)。 ​ [……这里待更新，笔记着重了解fuzzing过程]","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Fuzzing","slug":"Fuzzing","permalink":"http://example.com/tags/Fuzzing/"}],"author":"Shaw"},{"title":"(技术积累)How does AFL++ run a program?","slug":"【技术积累】How does AFL++ run a program","date":"2023-07-23T07:14:56.830Z","updated":"2023-07-29T09:04:04.496Z","comments":true,"path":"2023/07/23/【技术积累】How does AFL++ run a program/","link":"","permalink":"http://example.com/2023/07/23/%E3%80%90%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF%E3%80%91How%20does%20AFL++%20run%20a%20program/","excerpt":"(技术积累)How does AFL++ run a program? 前提：使用AFL++对开源程序fuzzing。 ​ 当对目标程序插桩完毕后，在一次运行中AFL++： 如何准备运行的环境？ 如何获得程序的输入？ 如何判断程序是否崩溃/对应sanitizer是否触发？ 如何获取这一次的代码覆盖率并记录结果？","text":"(技术积累)How does AFL++ run a program? 前提：使用AFL++对开源程序fuzzing。 ​ 当对目标程序插桩完毕后，在一次运行中AFL++： 如何准备运行的环境？ 如何获得程序的输入？ 如何判断程序是否崩溃/对应sanitizer是否触发？ 如何获取这一次的代码覆盖率并记录结果？ Using child process ​ 使用Fuzzing最简单的思想就是调用execve()函数，其会加载新的子进程来运行指定的程序，设置好对应的运行环境。但这么做的问题是每次运行大部分的时间都在等待execve()加载环境、载入目标文件和库、解析符号地址等重复性工作上，这种重复的操作并不会为fuzzing带来好处，反而严重增加了成本。 ​ AFL中使用了一种巧妙的手段来避免引入execve()导致的时间成本增加，其通过代码插桩与fork结合的方式，让程序停留在合适的位置以将算力聚焦于非重复操作上。 1. Some functions exec 在Linux中，并不存在一个exec()的函数形式，exec指的是一组函数，一共有6个，分别是：execl、execlp、execle、execv、execvp、execve。execve()（执行文件）在父进程中fork一个子进程，在子进程中调用exec函数启动新的程序。 fork() fork系统调用用于创建一个新进程，称为子进程，它与进程（称为系统调用fork的进程）同时运行，此进程称为父进程。创建新的子进程后，两个进程将执行fork（）系统调用之后的下一条指令。子进程使用相同的pc，相同的CPU寄存器，在父进程中使用的相同打开文件。 二者区别如下： struct sigaction signal() &gt;void (*signal(int sig, void (*func)(int)))(int) 参数： sig：信号码，有以下几种： 宏 信号 SIGABRT (Signal Abort) 程序异常终止。 SIGFPE (Signal Floating-Point Exception) 算术运算出错，如除数为 0 或溢出（不一定是浮点运算）。 SIGILL (Signal Illegal Instruction) 非法函数映象，如非法指令，通常是由于代码中的某个变体或者尝试执行数据导致的。 SIGINT (Signal Interrupt) 中断信号，如 ctrl-C，通常由用户生成。 SIGSEGV (Signal Segmentation Violation) 非法访问存储器，如访问不存在的内存单元。 SIGTERM (Signal Terminate) 发送给本程序的终止请求信号。 func：信号处理函数指针，可以用预定义的SIG_IGN（忽略）、SIG_DFL（系统默认）、SIG_ERR（返回错误） sigaction() >int sigaction(int signum, const struct sigaction *act,struct sigaction *oldact) 参数： signum：要捕获的信号 act：接收到信号之后对信号进行处理的结构体 oldact：接收到信号之后，保存原来对此信号处理的各种方式与信号（可用来做备份）。如果不需要备份，此处可以填NULL 返回值： 成功时：返回0 出错时：返回-1，并将errno设置为指示错误 struct sigaction >struct sigaction&#123; >void(*sa_handler)(int);// 旧的信号处理函数 >void(*sa_sigaction)(int,siginfo_t *,void *);// 新的信号处理函数 >sigset_t sa_mask;// 信号阻塞集 >int sa_flags;// 信号的处理方式 >void(*sa_restorer)(void);// 己弃用 >&#125; sa_handler,sa_sigaction： 信号处量函数指针，和signal()里的函数指针用法一样，应根据sa_sigaction, sa_handler 两者之一赋值，其取值如：SIG_IGN 忽略该信号、SIG_DEL 执行系统默认动作； sa_mask： 信号阻塞集，在信号处理函数执行过程中，临时屏蔽指定信号； sa_flags： 用于指定信号处理的行为，通常设为0，表默认属性，它可以是以下值的按位与组合 2. Fuzzing without execve() ​ AFL的思路是： 通过对程序插桩，让程序在合适的位置停下等待fuzzer的指令 这时程序所需的运行环境已经加载完毕，但没有开始获取输入； 指定环境变量LD_BIND_NOW=1，当LD_BIND_NOW被设置为非空值时，动态链接器会在程序启动时立即解析所有的符号。这意味着符号解析工作不会延迟到实际用到该符号的时候，而是在程序加载时就会完成： // from afl-forkserver.c /* This should improve performance a bit, since it stops the linker from doing extra work post-fork(). */ if (!getenv(\"LD_BIND_LAZY\")) &#123; setenv(\"LD_BIND_NOW\", \"1\", 1); &#125; 相反，如果没有设置LD_BIND_NOW环境变量，动态链接器会使用lazy binding的方式进行符号解析。lazy binding是一种延迟符号解析的机制，在实际使用到某个符号时再进行解析和绑定，这样可以节省程序启动时的时间和资源开销； 这个合适的位置通常是待测程序的main函数。 当收到fuzzer的相关执行指令后，使用fork()创建子进程 fork()会对已经加载完成的程序创建完全相同的子进程副本，由子进程运行程序； 得益于“copy-on-write”写时复制机制，对进程的复制是很快并且隔离性很好； 在父进程中，会将新加入进程的 PID 转发给fuzzer，然后返回命令等待循环 ​ 当开启persistent mode后，AFL++ 会在单个fork进程中对目标进行多次fuzzing测试，而不是为每次执行都分叉一个新进程。这是最有效的模糊方法，因为速度可以轻松快 10 倍或 20 倍，而没有任何缺点，所有专业的fuzzing都会使用这种模式。 3. Deep into the code 3.1 AFL++的主体是afl-fuzz.c，关于forkserver，其负责的功能有： 在main函数的开头初始化forkserver： afl_fsrv_init(&amp;afl->fsrv); ​ 该函数对fsrv数据结构中的相关值进行了初始化。 启动一个forkserver： 首先，运行fuzz时会使用如下命令行参数： alf-fuzz -i input_dir -o output_dir -- ./to_be_test @@ ​ 在while循环中使用getopt()函数读取命令行参数后，(argv+optind)指针会指向./to_be_test。后续的代码会将afl-&gt;fsrv.target_path设置为argv[optind]，然后从input_dir读取完test case后运行： //from afl.fuzz.c // afl_fsrv_get_mapsize()函数会start一个forkserver // 然后返回这个forkserver的fsrv->map_size属性 u32 new_map_size = afl_fsrv_get_mapsize( &amp;afl->fsrv, afl->argv, &amp;afl->stop_soon, afl->afl_env.afl_debug_child); ​ afl_fsrv_get_mapsize()函数会首先调用afl_fsrv_start()，启动一个forkserver： //from afl.fuzz.c afl_fsrv_start(&amp;afl->fsrv, afl->argv, &amp;afl->stop_soon, afl->afl_env.afl_debug_child); ​ 该函数会检查相关管道设置，重定向进程的0、1、2号文件描述符，然后fork一个进程，然后这个进程execv targetBinary ，targetBinary中也启动的了fork（），相当于fuzzer程序是实际被fork程序的祖祖父进程。 forkserver设计 3.2 在forkserver.h与forkserver.c文件中，其定义了相关数据结构afl_forkserver： ​ forkserver的关键函数是afl_fsrv_start()： // 设置状态管道st_pipe和控制管道ctl_pipe if (pipe(st_pipe) || pipe(ctl_pipe)) &#123; PFATAL(\"pipe() failed\"); &#125; //last_run_timed_out 为 u32，以 4 字节数组的形式发送给子进程 fsrv->last_run_timed_out = 0; // fork出一个子进程 fsrv->fsrv_pid = fork(); // 若fork成功，则父进程即为fuzzer // 子进程即为目标程序进程，也就是fork server if (fsrv->fsrv_pid &lt; 0) &#123; PFATAL(\"fork() failed\"); &#125; if (!fsrv->fsrv_pid) &#123; // 子进程 // ...... &#125; // 父进程 // 若fuzzer从server中读取了四个字节的hello ， // 那么forkserver程序就设置成功了，如果没有， // 接下来的代码就是检查错误。 if (rlen == 4) &#123;//判断读取是否成功 OKF(\"All right - fork server is up.\"); return; &#125; 3.2.1 子进程—&gt;forkserver ​ 可以看到，这里fork了一个进程，在子进程中，首先设置该进程对SIGPIPE的处理方式： // enable terminating on sigpipe in the childs // 当一个进程试图向已关闭的管道写入数据时，操作系统会发送SIGPIPE信号给该进程。 struct sigaction sa; memset((char *)&amp;sa, 0, sizeof(sa)); sa.sa_handler = SIG_DFL; sigaction(SIGPIPE, &amp;sa, NULL); ​ 然后进行一些诸如内存、文件描述符之类的资源设置后（这里略）。在完成相关管道、文件描述符的配置后，afl_fsrv_start()函数会在子进程内使用setsid()函数使子进程独立，然后在子进程内直接运行待测试程序: /* Isolate the process and configure standard descriptors. If out_file is specified, stdin is /dev/null; otherwise, out_fd is cloned instead. */ // 创建一个守护进程 setsid(); if (!(debug_child_output)) &#123; // 如果没有指定debug_child_output，则 // 重定向文件描述符1和2到dev_null_fd // 因为dev_null_fd=-1，子进程将不输出 dup2(fsrv->dev_null_fd, 1); dup2(fsrv->dev_null_fd, 2); &#125; // 如果指定了out_file，则文件描述符0重定向到dev_null_fd，否则重定向到out_fd if (!fsrv->use_stdin) &#123; dup2(fsrv->dev_null_fd, 0); &#125; else &#123; dup2(fsrv->out_fd, 0); close(fsrv->out_fd); &#125; ​ 设置管道，并关闭一些不必要的管道和文件描述符： // 设置控制和状态管道，关闭一些不需要的文件描述符 // FORKSRV_FD = 198 // 198号fd用于ctl管道读操作 // 199号fd用于st管道写操作 if (dup2(ctl_pipe[0], FORKSRV_FD) &lt; 0) &#123; PFATAL(\"dup2() failed\"); &#125; if (dup2(st_pipe[1], FORKSRV_FD + 1) &lt; 0) &#123; PFATAL(\"dup2() failed\"); &#125; close(ctl_pipe[0]); close(ctl_pipe[1]); close(st_pipe[0]); close(st_pipe[1]); close(fsrv->out_dir_fd); close(fsrv->dev_null_fd); close(fsrv->dev_urandom_fd); ​ 如果LD_BIND_LAZY不为1则设置为1（原因参考上文）： if (!getenv(\"LD_BIND_LAZY\")) &#123; setenv(\"LD_BIND_NOW\", \"1\", 1); &#125; ​ 然后使用execv运行程序： // init_child_func == fsrv_exec_child fsrv->init_child_func(fsrv, argv); /* Use a distinctive bitmap signature to tell the parent about execv() falling through. */ // 运行失败这段代码就会执行 // 运行成功则不会 *(u32 *)fsrv->trace_bits = EXEC_FAIL_SIG; FATAL(\"Error: execv to target failed\\n\"); ​ init_child_func定义如下： static void fsrv_exec_child(afl_forkserver_t *fsrv, char **argv) &#123; if (fsrv->qemu_mode || fsrv->cs_mode) &#123; setenv(\"AFL_DISABLE_LLVM_INSTRUMENTATION\", \"1\", 0); &#125; // 运行target_path处的程序 execv(fsrv->target_path, argv); WARNF(\"Execv failed in forkserver.\"); &#125; ​ fsrv.target_path就是要fuzz的程序的地址，其经过check_binary()函数初始化。 3.2.2 父进程—&gt;fuzzer ​ 父进程会设置相关管道，并使用read_s32_timed()函数从子进程中读取信息，同时进行相关超时处理： /* Wrapper for select() and read(), reading a 32 bit var. Returns the time passed to read. If the wait times out, returns timeout_ms + 1; Returns 0 if an error occurred (fd closed, signal, ...); */ static u32 __attribute__((hot)) read_s32_timed(s32 fd, s32 *buf, u32 timeout_ms, volatile u8 *stop_soon_p) &#123; // 配置相关变量 // ...... // set exceptfds as well to return when a child exited/closed the pipe. restart_select: // 使用select函数阻塞进程，从readfds中读取信息 sret = select(fd + 1, &amp;readfds, NULL, NULL, &amp;timeout); if (likely(sret > 0)) &#123; restart_read: if (*stop_soon_p) &#123; // Early return - the user wants to quit. return 0; &#125; len_read = read(fd, (u8 *)buf, 4); // ...... if (likely(len_read == 4)) &#123; // for speed we put this first // ensure to report 1 ms has passed (0 is an error) return exec_ms > 0 ? exec_ms : 1; &#125; else if (unlikely(len_read == -1 &amp;&amp; errno == EINTR)) &#123; goto restart_read; &#125; else if (unlikely(len_read &lt; 4)) &#123; return 0; &#125; &#125; else if (unlikely(!sret)) &#123; *buf = -1; return timeout_ms + 1; &#125; else if (unlikely(sret &lt; 0)) &#123; if (likely(errno == EINTR)) goto restart_select; *buf = -1; return 0; &#125; return 0; // not reached &#125; ​ 可以看到，如果返回0代表出错，返回timeout_ms + 1代表超时。 ​ 接着判断从子进程读取到的信息的长度，如果读取到4字节的hello信息则代表forkserver初始化成功，父进程函数直接返回，继续执行fuzzer，子进程保留运行等待fuzzer指令： if (rlen == 4) &#123; // 错误/超时处理 if ((status &amp; FS_OPT_ERROR) == FS_OPT_ERROR) report_error_and_exit(FS_OPT_GET_ERROR(status))&#123; //...... &#125; if ((status &amp; FS_OPT_ENABLED) == FS_OPT_ENABLED)&#123; //...... &#125; // 如果forkserver初始化成功，直接退出父函数 // 因为子进程里设置了setsid，故其仍然继续运行 return; &#125; if (fsrv-last_run_time_out)&#123; // 读取超时处理 &#125; // 相关错误处理 // ...... ​ 注意到，forkserver与待测试程序之间的关系并不是两个独立的程序，forkserver是经过代码插桩以后的待测试程序，其可以在相关符号加载完成后等待fuzzer的指令，然后在循环中不断fork执行程序。 3.3 代码插桩 ​ 当forkserver初始化后，由于使用execv直接运行待测试程序，按理来说其应该直接执行，并不会有forkserver的功能。但在程序编译时进行了代码插桩，execv后的子进程其会在main函数停止，等待fuzzer的命令，具体的插桩分析见Reference:star:。 Get the input/output Dry run ​ 在将test case从input dir读取到afl-&gt;queue中后，进行正式的fuzzing之前，AFL通会对所有的test cases进行一次执行，以确保排除一些古怪的、有问题的test case，AFL源码中管这个过程叫Calibrate。对input_dir进行Calibrate的过程就是dry run。 ​ PS：可以通过设置环境变量AFL_NO_STARTUP_CALIBRATION来决定是否进行dry run。 1. perform_dry_run() 函数原型： void* perform_dry_run(afl_state_t **afl*) 来源：afl-fuzz-init.c 被引用：afl-fuzz.c 功能简介：对所有的测试用例进行模拟运行，以确保应用程序按预期执行。 ​ 首先，perform_dry_run()函数会遍历afl-&gt;queue_buf，每个queue_buf中存储着input相关信息。函数打开input文件，将其读取到一块内存use_mem中，然后调用calibrate_case()函数运行单个测试用例： // 获取文件名 u8 *fn = strrchr(q->fname, '/') + 1; // 打印文件名 ACTF(\"Attempting dry run with '%s'...\", fn); // 只读打开文件 fd = open(q->fname, O_RDONLY); if (fd &lt; 0) &#123; PFATAL(\"Unable to open '%s'\", q->fname); &#125; // 将文件读取到use_mem中 u32 read_len = MIN(q->len, (u32)MAX_FILE); use_mem = afl_realloc(AFL_BUF_PARAM(in), read_len); ck_read(fd, use_mem, read_len, q->fname); // 关闭文件 close(fd); // 运行case res = calibrate_case(afl, q, use_mem, 0, 1); ​ 在通过运行calibrate_case()函数对单个输入进行测试后，通过其返回的res对不同的结果进行处理： switch (res) &#123; case FSRV_RUN_OK: case FSRV_RUN_TMOUT: case FSRV_RUN_CRASH: case FSRV_RUN_ERROR: case FSRV_RUN_NOINST: case FSRV_RUN_NOBITS: &#125; ​ 总体函数调用逻辑如下： 2. :star:calibrate_case() 函数原型： u8 calibrate_case(afl_state_t afl, struct* queue_entry q, u8 use_mem, u32 handicap, u8 from_queue) 来源：afl-fuzz-run.c 被引用：afl-fuzz-init.c 功能简介：运行单个测试用例，排除有问题的样例。 ​ 这个函数是AFL的重点函数之一，在perform_dry_run，save_if_interesting，fuzz_one，pilot_fuzzing,core_fuzzing函数中均有调用。 ​ 开始时，函数会设置两个属性，afl-&gt;stage_name用以表示程序正处在calibration阶段，afl-&gt;stage_max是每一个测试样例需要运行的次数，如果设置了CAL_CYCLES_FAST，则为3，否则默认情况下为8。 afl->stage_name = \"calibration\"; afl->stage_max = afl->afl_env.afl_cal_fast ? CAL_CYCLES_FAST : CAL_CYCLES; ​ 接着，根据afl-&gt;stage_max开启一个for循环： // 每个运行stage_max次 for (afl->stage_cur = 0; afl->stage_cur &lt; afl->stage_max; ++afl->stage_cur) &#123; u64 cksum; // 将testcase写入到文件中去 (void)write_to_testcase(afl, (void **)&amp;use_mem, q->len, 1); // 运行样例 fault = fuzz_run_target(afl, &amp;afl->fsrv, use_tmout); // ...... // 通过trace_bits计算checksum cksum = hash64(afl->fsrv.trace_bits, afl->fsrv.map_size, HASH_CONST); if (q->exec_cksum != cksum) &#123; // 对比queue中的checksum和forkserver中的checksum // 如果发现不同，则调用has_new_bits()函数和总表virgin_bits对比 hnb = has_new_bits(afl, afl->virgin_bits); if (hnb > new_bits) &#123; new_bits = hnb; &#125; // 如果q->exec_cksum不为0，说明不是第一次执行 // 后面运行的时候如果，和前面第一次trace_bits结果不同，则需要多运行几次 if (q->exec_cksum) &#123; u32 i; for (i = 0; i &lt; afl->fsrv.map_size; ++i) &#123; if (unlikely(!afl->var_bytes[i]) &amp;&amp; unlikely(afl->first_trace[i] != afl->fsrv.trace_bits[i])) &#123; afl->var_bytes[i] = 1; // ignore the variable edge by setting it to fully discovered afl->virgin_bits[i] = 0; &#125; &#125; // ...... &#125; var_detected = 1; afl->stage_max = afl->afl_env.afl_cal_fast ? CAL_CYCLES : CAL_CYCLES_LONG; &#125; else &#123; // 更新cksum和trace q->exec_cksum = cksum; memcpy(afl->first_trace, afl->fsrv.trace_bits, afl->fsrv.map_size); &#125; &#125; &#125;// end for for-loop ​ 在每个循环中，调用write_to_testcase()函数将修改后的数据写入文件进行测试。然后通过hash64()函数校验此次运行的trace_bits，检查是否出现新的情况。 ​ 最后，调用update_bitmap_score() 对这个测试用例的每一个byte进行排序，用一个top_rate[]来维护它的最佳入口。然后进行一些后续处理。 3.write_to_testcase() 函数原型：u32 __ attribute __((hot)) write_to_testcase(afl_state_t *afl , void **mem, u32 len, u32 fix) 来源：afl-fuzz-run.c 被引用：afl-fuzz-run.c 功能简介：将testcase写入到文件中去 ​ write_to_testcase()在检查相关参数合理性后，调用 afl_fsrv_write_to_testcase()函数，要么将mem的内容写入fsrv-&gt;shmem_fuzz中，要么写入fsrv-&gt;out_fd中。 4. :star:fuzz_run_target() 函数原型：fsrv_run_result_t __ attribute __((hot)) fuzz_run_target(afl_state_t afl, afl_forkserver_t fsrv, u32 timeout) 来源：afl-fuzz-run.c 被引用：afl-fuzz-run.c 功能简介： 运行目标待测试程序 ​ fuzz_run_target()函数用于执行目标应用程序、监控超时、返回状态信息，被调用的程序将更新trace_bits[]。其直接调用afl_fsrv_run_target(fsrv, timeout, &amp;afl-&gt;stop_soon)函数。 ​ 在afl_fsrv_run_target()中，运行程序的主要思路是通过管道向子进程写入控制信息，通知子进程开始fuzzing: // 将fsrv->last_run_timed_out通过控制管道写入 if ((res = write(fsrv->fsrv_ctl_fd, &amp;write_value, 4)) != 4) &#123; if (*stop_soon_p) &#123; return 0; &#125; RPFATAL(res, \"Unable to request new process from fork server (OOM?)\"); &#125; // 重新清空fsrv->last_run_timed_out fsrv->last_run_timed_out = 0; // 从forkserver读取子进程的pid if ((res = read(fsrv->fsrv_st_fd, &amp;fsrv->child_pid, 4)) != 4) &#123; if (*stop_soon_p) &#123; return 0; &#125; RPFATAL(res, \"Unable to request new process from fork server (OOM?)\"); &#125; ​ 然后，其会调用read_s32_timed()函数阻塞进程，等待子进程返回信息： // 阻塞父进程，从forkserver中读取信息 exec_ms = read_s32_timed(fsrv->fsrv_st_fd, &amp;fsrv->child_status, timeout, stop_soon_p); // 超时 &amp; 错误 &amp; crash处理 // ...... Main loop ​ 主循环是AFL++的核心流程，其行使了完整的fuzzing流程。 ​ Reference Forkserver of AFL: More about AFL — AFL 2.53b documentation (afl-1.readthedocs.io) lcamtuf's old blog: Fuzzing random programs without execve() AFL-Unicorn中的fork server机制详解 CSDN博客 AFLplusplus/docs/env_variables.md at 7f17a94349830a54d2c899f56b149c0d7f9ffb9c · AFLplusplus/AFLplusplus (github.com) :star:[原创]AFL afl_fuzz.c 详细分析-二进制漏洞-看雪-安全社区|安全招聘|kanxue.com :star:AFL内部实现细节小记 - 记事本 (rk700.github.io) System process： wait 和 waitpid 详解及代码示例_-CSDN博客 fork（函数）_百度百科 (baidu.com) fork和execve和Linux内核的一般执行过程 - 知乎 (zhihu.com) LINUX信号处理（sigaction信号捕获函数：struct sigaction）CSDN博客 select函数及fd_set介绍 - 博客园 Linux signal()和kill()_CSDN博客 C/C++: C/C++ 命令解析：getopt 方法详解和使用示例_CSDN博客 linux c解析命令行选项getopt、optarg、optind、opterr、optopt - 戴磊笔记 (daileinote.com) Linux access函数讲解_CSDN博客 linux系统调用函数 lstat--获取文件属性 CSDN博客 明晰argc -= optind, argv += optind为什么是跳过已读取的参数_CSDN博客 getcwd()函数的用法_CSDN博客","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Fuzzing","slug":"Fuzzing","permalink":"http://example.com/tags/Fuzzing/"}],"author":"Shaw"},{"title":"(论文阅读)FuzzBuilder- Automated building greybox fuzzing environment for C/C++ library","slug":"【论文阅读】FuzzBuilder--Automated-building-greybox-fuzzing-environment-for-CC++-library","date":"2023-07-23T06:07:38.504Z","updated":"2023-08-18T09:21:13.837Z","comments":true,"path":"2023/07/23/【论文阅读】FuzzBuilder--Automated-building-greybox-fuzzing-environment-for-CC++-library/","link":"","permalink":"http://example.com/2023/07/23/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91FuzzBuilder--Automated-building-greybox-fuzzing-environment-for-CC++-library/","excerpt":"FuzzBuilder: Automated building greybox fuzzing environment for C/C++ library 时间：2019 作者：Joonun Jang、Huy Kang Kim（三星研究院、首尔大学） 会议：ACSAC 开源：https://github.com/hksecurity/FuzzBuilder Abstract ​ Fuzzing是发现软件漏洞的一种有效方法，由于fuzzing发现的大多数错误都与安全漏洞有关，因此许多安全社区都对模糊测试这种验证软件安全性的自动化方法很感兴趣。然而，并非所有软件都能通过模糊测试进行测试，因为模糊测试需要运行环境，特别是可执行文件，值得注意的是，就库而言，大多数库实际上都没有相关的可执行文件。 ​ 因此，最先进的fuzzer在测试任意库方面存在局限性，为了克服这个问题，我们提出了 FuzzBuilder，为库提供自动fuzzing environment。FuzzBuilder生成的可执行文件会调用库的 API 函数，从而实现库模糊测试，此外，FuzzBuilder 生成的任何可执行文件都与 AFL 等现有模糊器兼容。 ​ 我们通过测试开源库来评估 FuzzBuilder 的整体性能。因此，我们在实现高代码覆盖率的同时发现了库中的未知错误。我们相信，FuzzBuilder 可以帮助安全研究人员节省库模糊测试的设置成本和学习成本。","text":"FuzzBuilder: Automated building greybox fuzzing environment for C/C++ library 时间：2019 作者：Joonun Jang、Huy Kang Kim（三星研究院、首尔大学） 会议：ACSAC 开源：https://github.com/hksecurity/FuzzBuilder Abstract ​ Fuzzing是发现软件漏洞的一种有效方法，由于fuzzing发现的大多数错误都与安全漏洞有关，因此许多安全社区都对模糊测试这种验证软件安全性的自动化方法很感兴趣。然而，并非所有软件都能通过模糊测试进行测试，因为模糊测试需要运行环境，特别是可执行文件，值得注意的是，就库而言，大多数库实际上都没有相关的可执行文件。 ​ 因此，最先进的fuzzer在测试任意库方面存在局限性，为了克服这个问题，我们提出了 FuzzBuilder，为库提供自动fuzzing environment。FuzzBuilder生成的可执行文件会调用库的 API 函数，从而实现库模糊测试，此外，FuzzBuilder 生成的任何可执行文件都与 AFL 等现有模糊器兼容。 ​ 我们通过测试开源库来评估 FuzzBuilder 的整体性能。因此，我们在实现高代码覆盖率的同时发现了库中的未知错误。我们相信，FuzzBuilder 可以帮助安全研究人员节省库模糊测试的设置成本和学习成本。 Background ​ 编写库fuzzing代码时，首先要选择一个基本函数。此外，还需要调用与基础函数相关的其他函数，以实现足够的代码覆盖率。例如，库中特定功能的实现可分为一个或多个函数。此外，如果函数需要其他函数的返回值，则不能单独测试库中的特定函数，在这种情况下，应联合测试所有相关函数。因此，在编写库fuzzing代码时，应考虑调用函数序列而不是单个函数。Han 等人[18]在他们的内核模糊器中引入了类似的 API 模型概念，其中包括两类依赖关系：排序依赖关系和值依赖关系。 ​ 本文将函数序列定义为一组需要联合测试的函数。图 2 显示了编写库模糊测试代码需要函数序列的原因: ​ 依次调用init - insert - parse_A, and init - insert - parse_B可以获得最高的覆盖率。、 ​ 因此，我们提出了一种通过使用单元测试中准备好的函数序列和测试输入来生成可执行文件和种子的方法。虽然这种方法要求项目必须有单元测试，但如表 2 所示，这种方法非常实用，因为大多数项目已经有了单元测试。 Contribution 我们提出了一种自动生成可执行文件以对library做fuzzing的新方法； 为实用起见，生成的可执行文件与 AFL 等各种灰盒fuzzer兼容； 我们将这种方法作为基于 LLVM 框架的工具 FuzzBuilder 来实现。 Model 1. User Configuration ​ 要使用FuzzBuilder，用户首先需要提供一个LLVM IR形式的unit test文件和FA（Fuzzable API，用于向目标库传递Input和分析API序列）。 1.1 FA ​ 用户需要提供关于FA的信息，包括用于input的参数信息，例如： ​ 其中，（1）指明了FA是CBS_init，其第2和第3个参数用于指定输入的值和大小；（2）指明了FA是yr_compiler_add_string，第2个参数用于指定输入的值，不需要额外的参数来指定大小。 1.2 Test functions ​ Test function进行单元测试的函数，在源代码提供的unit test中有许多函数，但只有部分是test function，故FuzzBuilder需要识别其中哪些是test function。如果单元测试是基于流行的单元测试框架（如 google test [3]），test function名称就会有特定的模式。因此，识别它们并不难。但是，如果单元测试是在没有任何约定的情况下编写的，那么就需要手动指定它们的名称，因为没有明确的方法来识别test function。 ​ 因此，FuzzBuilder支持可配置选项，通过逐一指定test function的名称来识别这些函数。然而，由于单元测试中有大量测试函数，这种配置非常耗时。幸运的是，大多数项目都使用带有特定前缀或后缀的测试函数名称，如 test_A、test_B、A_test 和 B_test。因此，为了缓解这一问题，FuzzBuilder 支持星号 (*)。 1.3 Functions to be skipped ​ 用户可以选择需要跳过的功能。遗憾的是，某些测试函数的执行可能会耗费大量时间。例如，test function中过多的循环就会导致这一问题。如果执行速度慢，灰盒模糊测试的效率就会降低。这是因为灰盒模糊测试需要执行大量程序，用程序生成的各种输入值进行测试。因此，这种配置有助于跳过此类函数，从而提高模糊测试的效率。 2. Automated generation of an executable ​ 为了生成可执行文件，假设unit test中的以下两个条件都已经被满足： 每个test都以函数的形式存在； 每个test互相独立。 ​ JUnit [6]是一种流行的 Java 单元测试框架，其最佳实践指南中提到了这些条件。此外，大多数基于 google test的单元测试都满足这些条件。因此，这些条件不会对拟议方法的实用性产生不利影响。 ​ 生成可执行文件的算法如下： preprocess ​ 该过程从 LLVM bitcode 文件中的每个函数中提取入口函数和test function。如果单元测试基于流行的测试框架，则会使用特定模式提取test function，否则，它们将根据用户配置提取。入口函数即main函数。 insert_interface ​ 这个过程插入了一个接口，用于将fuzzer生成的输入值加载到内存中。首先，添加两个新的全局变量，用于存储输入值及其大小。然后，在提取的入口函数中插入一组指令，以实现以下目标: 从fuzzer中获取输入值； 分配足够的空间以加入一个全局变量； 将输入值复制到全局变量中； 将变量大小存储到另外一个全局变量中。 is_necessary ​ 该过程可识别包含调用特定FA的指令的test function，这可以通过遍历测试函数中的指令来实现。然后，如果test function调用了特定的FA，则执行insert_operands，否则执行 remove_test。如果test function是用户配置中跳过的函数，则始终执行 remove_test。 insert_operands ​ 该过程将test function中的FA的参数更改为insert_interface过程中添加的全局变量，User Configuration用于确定哪些参数需要更改。通过这一过程，可以使用fuzzer生成的输入值执行库中的指令。 remove_test ​ 此过程会删除不必要的test functions，删除这些函数很有必要，因为它们会降低生成的可执行文件的执行速度。执行速度对fuzzing的性能有重大影响，因为fuzzing需要尽可能多的输入值。删除test function是安全的，因为我们假设了单元测试之间相互独立。 modify ​ 这个过程将插桩过的函数存储在bitcode文件中。根据项目的构建流程，这些插桩文件将被构建为可执行文件。因此，生成的可执行文件带有从fuzzer获取输入值的接口，这些输入值被用作 FA 的参数。最后，fuzzer的输入值可用于探索库代码以发现漏洞。 ​ 请注意，上述过程是在单元测试可执行文件的编译过程中进行的。因此，如果一个项目有多个单元测试可执行文件，则可生成多个可执行文件。 ​ 3. Automated generation of seed files ​ 大多数项目用以下的方式存储unit test的输入：源码、执行单元测试的脚本文件、额外的文件。 ​ 要从单元测试中静态提取测试输入，需要使用各种分析工具。例如，如果测试输入是C源代码，那么就需要 C 源代码静态分析器，然而，准备所有类型的静态分析器并不现实。因此，我们采用动态方法，在单元测试工作期间收集测试输入。 ​ 为此，FuzzBuilder对FA插桩，将其参数值存储到特定文件中。如下图所示，在这段代码中，输入参数表示特定的缓冲区地址，大小参数表示缓冲区的大小，插桩指令用于将输入缓冲区中的值存储到 \"file.txt \"中。通过这种插桩，在单元测试工作时，每个测试输入都会被收集到一个特定的文件中。最后，将每个种子文件分割成不同的文件，生成种子文件。 ​ 生成种子的整体工作流程如图所示： EVALUATION ​ 在实验中，我们从OSS-Fuzz中选择了几个库项目，每个项目都有用于fuzzing的可执行文件和种子。大多数可执行文件和种子都是由对库有深入了解的开发人员准备的，通过与这些可执行文件和种子文件进行比较，可以对 FuzzBuilder进行评估。 被选择的待测试项目满足以下条件： ​ (1) 32位； ​ (2) 至少支持一个包含FA的单元测试； ​ (3) 其单元测试满足上述假设条件。 AFL版本：AFL 2.5.b 选择的项目：c-ares、expat、boringssl、yara 实验配置： ​实验结果： [后续……]","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Fuzzing","slug":"Fuzzing","permalink":"http://example.com/tags/Fuzzing/"}],"author":"Shaw"},{"title":"(论文阅读)RULF-Rust Library Fuzzing via API Dependency Graph Traversal","slug":"【论文阅读】RULF-Rust-Library-Fuzzing-via-API-Dependency-Graph-Traversal","date":"2023-07-22T13:47:37.043Z","updated":"2023-07-23T05:48:23.018Z","comments":true,"path":"2023/07/22/【论文阅读】RULF-Rust-Library-Fuzzing-via-API-Dependency-Graph-Traversal/","link":"","permalink":"http://example.com/2023/07/22/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91RULF-Rust-Library-Fuzzing-via-API-Dependency-Graph-Traversal/","excerpt":"RULF: Rust Library Fuzzing via API Dependency Graph Traversal 时间：2021 作者：Jianfeng Jiang、Hui Xu、Yangfan Zhou（复旦大学） 会议：ASE 开源：https://github.com/Artisan-Lab/RULF Abstract ​ 鲁棒性是 Rust 库开发的一个关键问题，因为 Rust 承诺，如果开发人员只使用安全的 API，就不会出现未定义行为的风险。Fuzzing是检查程序鲁棒性的一种实用方法，然而，由于缺乏目标，现有的fuzzing工具并不能直接适用于library API。故这项工作主要依靠人工逐个设计fuzzing target，耗费大量人力物力。 ​ 为了解决这个问题，本文提出了一种新颖的自动fuzzing目标生成方法，通过遍历 API 依赖图来fuzzing Rust 库。我们确定了library fuzzing的几个基本要求，包括target的有效性、高 API 覆盖率和fuzzing的效率。为了满足这些要求，我们首先采用了带有剪枝功能的广度优先搜索，以找到长度低于阈值的 API 序列，然后反向搜索更长的序列以查找未覆盖的 API，最后将序列集作为集合覆盖问题进行优化。 ​ 我们实现了fuzz target生成器，并使用 AFL++ 在多个现实世界中流行的 Rust 项目上进行了fuzzing实验。我们的工具最终为每个库生成了 7 到 118 个fuzzing target，API 覆盖率高达 0.92。我们以 24 小时为阈值对每个目标进行测试，并从七个库中发现了 30 个以前未知的错误。","text":"RULF: Rust Library Fuzzing via API Dependency Graph Traversal 时间：2021 作者：Jianfeng Jiang、Hui Xu、Yangfan Zhou（复旦大学） 会议：ASE 开源：https://github.com/Artisan-Lab/RULF Abstract ​ 鲁棒性是 Rust 库开发的一个关键问题，因为 Rust 承诺，如果开发人员只使用安全的 API，就不会出现未定义行为的风险。Fuzzing是检查程序鲁棒性的一种实用方法，然而，由于缺乏目标，现有的fuzzing工具并不能直接适用于library API。故这项工作主要依靠人工逐个设计fuzzing target，耗费大量人力物力。 ​ 为了解决这个问题，本文提出了一种新颖的自动fuzzing目标生成方法，通过遍历 API 依赖图来fuzzing Rust 库。我们确定了library fuzzing的几个基本要求，包括target的有效性、高 API 覆盖率和fuzzing的效率。为了满足这些要求，我们首先采用了带有剪枝功能的广度优先搜索，以找到长度低于阈值的 API 序列，然后反向搜索更长的序列以查找未覆盖的 API，最后将序列集作为集合覆盖问题进行优化。 ​ 我们实现了fuzz target生成器，并使用 AFL++ 在多个现实世界中流行的 Rust 项目上进行了fuzzing实验。我们的工具最终为每个库生成了 7 到 118 个fuzzing target，API 覆盖率高达 0.92。我们以 24 小时为阈值对每个目标进行测试，并从七个库中发现了 30 个以前未知的错误。 Background ​ 本文旨在弥补 Rust 库fuzzing与现有fuzzing工具之间的差距，Rust 库fuzzing面临的一个主要问题是缺乏模糊目标。 ​ Fuzz target代表着一个字节数组，作为执行由某些库 API 组成的程序的输入[14]，fuzzer可以更改fuzz target的输入，以探索不同的路径。现有的fuzzing工具，如 AFL [15]、honggfuzz [16] 和 libFuzzer [17]，都需要fuzz target来对目标库进行fuzzing测试，而编写fuzz target主要依靠人力。 Fudge [18] （FSE/ESEC'2019）是最近提出的一种用于 C/C++ 程序的fuzz target生成器，它从谷歌代码库中提取代码片段，然而，它的有效性在很大程度上取决于库的使用情况，并且存在很大的局限性。例如，它不适用于新发布的库或 API；或者它无法为未使用的 API 生成模糊目标，但错误可能与很少使用的功能有关； FuzzGen [31]（USENIX Security'2020）从系统中已有使用库的代码出发，通过对整个系统进行分析，整理出抽象API依赖图(A2DG)，并基于依赖图生成libFuzzer的桩代码，从而进行不需人工干预、能较好地平衡宽度和深度的fuzz; Contirbution ​ 本文研究了一种自动fuzzing target生成方法，我们的方法追求四个目标：Validity，即程序应能成功编译；effectiveness，即模糊目标应便于模糊工具实现高代码覆盖率或错误查找；覆盖率和效率，即模糊目标应覆盖尽可能多的应用程序接口，其集合应尽可能小。 ​ 为确保validity，我们根据给定库的 API 依赖关系图来组成fuzzing target。由于每个fuzzing target都可以看作是 API 调用的一个序列，因此我们会在API依赖图的长度阈值下对 API 序列进行广度优先搜索（BFS）。对于由于长度限制而未被发现的 API（深层 API），我们会反向搜索其依赖的 API 序列。最后，我们对序列集进行细化，以获得涵盖相同 API 集的最小子集。 ​ 我们实现了一个fuzzing target生成器RULF。根据 Rust 库的 API 规范，它可以生成一组fuzzing target，并与 AFL++ [19] 无缝集成，用于模糊测试。我们对 14 个流行的 Rust 库进行了实验，其中包括三个来自 GitHub 的库和 11 个来自 crates 的库。由于 BFS 的深度约束为 3，我们为每个库生成了 7-118 个模糊目标，此外，我们以 24 小时的预算对每个目标进行模糊测试，在七个库中发现了 30 个以前未知的错误。 为 Rust 库自动生成fuzzing target的试点研究。它扩展了现有fuzzing技术的适用性，而考虑到 Rust 对未定义行为的不容忍，这种扩展正是 Rust 所迫切需要的; 我们提出的方法利用了一种复杂的遍历算法，只需少量浅层fuzzing target即可实现较高的 API 覆盖率。这种方法被证明是有效和高效的。它可以为进一步研究代码遍历提供启示； 我们为 Rust 库实现了一个开源的fuzzing target生成器RULF，利用该工具，我们成功地在 7 个流行的 Rust 库中发现了 30 个以前未知的漏洞。 Reference 【论文总结】Fuzz Driver Generation - 知乎 (zhihu.com)","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Fuzzing","slug":"Fuzzing","permalink":"http://example.com/tags/Fuzzing/"}],"author":"Shaw"},{"title":"(论文阅读)GraphFuzz-Library API Fuzzing with Lifetime-aware Dataflow Graphs","slug":"【论文阅读】GraphFuzz-Library-API-Fuzzing-with-Lifetime-aware-Dataflow-Graphs","date":"2023-07-22T06:23:23.676Z","updated":"2023-07-22T13:14:35.154Z","comments":true,"path":"2023/07/22/【论文阅读】GraphFuzz-Library-API-Fuzzing-with-Lifetime-aware-Dataflow-Graphs/","link":"","permalink":"http://example.com/2023/07/22/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91GraphFuzz-Library-API-Fuzzing-with-Lifetime-aware-Dataflow-Graphs/","excerpt":"GraphFuzz: Library API Fuzzing with Lifetime-aware Dataflow Graphs 时间：2022 作者：Harrison Green、Thanassis Avgerinos 会议：ICSE 开源：https://github.com/ForAllSecure/GraphFuzz Abstract ​ 提出了一种新fuzzer：GraphFuzz，能够自动测试low-level Library APIs。与其他fuzzer不同的是，GraphFuzz 将已执行函数的序列建模为数据流图，因此能够在data和execution跟踪级别执行graph-based mutations。GraphFuzz 自带自动规范生成器，可最大限度地减少开发人员的集成工作。 ​ 我们使用 GraphFuzz 对 Skia（经过严格测试的 Google Chrome 浏览器图形库）进行分析，并将 GraphFuzz 生成的fuzzing harnesses与手工优化、精心编写的 libFuzzer harnesses进行比较。我们发现，GraphFuzz生成的测试用例平均代码覆盖率提高了2-3倍，而开发工作量却很小，而且在此过程中还发现了以前未知的缺陷。我们通过分析另外四个开源库，发现了数十个以前未知的缺陷，从而证明了 GraphFuzz 在low-level Library APIs上的适用性。开发人员已经报告并修复了所有与安全相关的发现。","text":"GraphFuzz: Library API Fuzzing with Lifetime-aware Dataflow Graphs 时间：2022 作者：Harrison Green、Thanassis Avgerinos 会议：ICSE 开源：https://github.com/ForAllSecure/GraphFuzz Abstract ​ 提出了一种新fuzzer：GraphFuzz，能够自动测试low-level Library APIs。与其他fuzzer不同的是，GraphFuzz 将已执行函数的序列建模为数据流图，因此能够在data和execution跟踪级别执行graph-based mutations。GraphFuzz 自带自动规范生成器，可最大限度地减少开发人员的集成工作。 ​ 我们使用 GraphFuzz 对 Skia（经过严格测试的 Google Chrome 浏览器图形库）进行分析，并将 GraphFuzz 生成的fuzzing harnesses与手工优化、精心编写的 libFuzzer harnesses进行比较。我们发现，GraphFuzz生成的测试用例平均代码覆盖率提高了2-3倍，而开发工作量却很小，而且在此过程中还发现了以前未知的缺陷。我们通过分析另外四个开源库，发现了数十个以前未知的缺陷，从而证明了 GraphFuzz 在low-level Library APIs上的适用性。开发人员已经报告并修复了所有与安全相关的发现。 A fuzzing harness is a test case or a particular test target. Background ​ 尽管近来fuzzing研究方兴未艾，但能够对 C/C++ 库进行模糊测试的系统却明显不足。 现有的greybox-fuzzing（如 libFuzzer [3]）特别适合一次fuzz一个或两个端点，但要同时fuzz多个端点，则需要人工操作（如使用 FDP）； CSmith [6] 可以合成逼真的 C 代码，但当目标是 C 库而不是 C 编译器时，每次迭代时重新编译的代价都很高； FUDGE [7] 是一种很有前途的meta-fuzzing技术，它通过分析和切分客户端代码的种子语料库来自动生成harnesses，但是，它依赖于谷歌的内部基础设施，并不是开源的。 API Fuzzing Methods Method 1:Harness ​ Standard grey-box harness可通过手动配置充当 API fuzzer，例如，开发人员可以通过在for-loop和/或switch语句中程序化地调用函数，对C++库进行fuzzing。通常情况下，来自非结构化模糊器的原始字节序列被用来初始化这些伪随机值。 ​ 同样，可以将 libProtobuf-mutator (LPM) [5] 与 libFuzzer [3] 等coveraged-based fuzzer结合使用，构建tree-based API fuzzer。例如，在 Chromium 的 AppCache fuzzer[12]中，Protocol Buffer实例代表了 IPC 的调用序列。 Method 2:Code-gen ​ 一些API fuzzer合成并运行程序源代码来测试API，这种方法最适用于 JavaScript 和 Ruby 等基于脚本的语言，因为它们在执行前不需要昂贵的编译步骤[6]。 ​ 虽然这些fuzzer可以通过使用context-free grammars或类似模型生成逼真的语法模式，但它们往往无法生成高级的、语义上有意义的代码。例如，Han 等人[13]指出，jsfunfuzz [9]（一种流行的 JavaScript fuzzer）99% 的测试用例仅在 3 条语句后就会引发运行时错误。 Method 3:Harness-gen ​ 相较于手工生成测试用例，也可以自动生成测试用例。 IMF[14]跟踪系统调用日志以识别依赖关系，并合成可对这些系统调用进行fuzzing的 C语言测试用例； FUDGE[7]和FuzzGen[15]分析了大量客户端C/C++代码库，并提取代码片段来创建测试用例； ​ 虽然上述这些系统可以生成不同的harnesses，但单个测试用例中的应用程序API调用结构在fuzzing时是静态的，只有值会发生变化。 Method 3:Dynamic ​ 在 API fuzzing的动态方法中，每个测试用例代表一个完整的 API 交互序列。Fuzzer动态处理每个测试用例，逐个调用端点。 ​ 动态fuzzer与code-gen的主要区别在于，在动态fuzzer中，API交互的结构是在fuzzing时指定的（作为测试用例的一部分），这使得fuzzer可以控制API调用的值和结构。Code-gen fuzzer也可以在fuzzing时通过重新编译（如 CSmith [6]）改变 API 调用的结构，而 Syzkaller [16] 和 GraphFuzz（本作品）等动态fuzzer则绕过了这一高成本的重新编译步骤。 Contribution ​ 为了弥补这一不足，我们引入了dataflow graphbased fuzzing，即用数据流图来表示库应用程序API的交互。我们介绍了 C/C++ 库中数据流图突变、生成和执行的算法，在许可协议下开源了基于数据流图的模糊测试实现（名为 GraphFuzz），并通过查找真实世界目标中的错误来证明其有效性，同时将其性能与 Skia 图形库中最先进的工具进行量化比较。 Model-based API Fuzzer Survey: 对迄今为的model-based fuzzers进行了分类，并展示了 GraphFuzz 在设计领域的优势； Dataflow graph-based fuzzing: 我们正式定义了dataflow graphbased fuzzing，并介绍了在基于coverage的fuzzing中执行图突变和生成的算法； GraphFuzz for C/C++: 介绍了名为 GraphFuzz 的dataflow graphbased fuzzing开源实现，它能够对 C 和 C++ 库进行半自动模糊测试。我们通过发现现实世界中的错误来验证这项技术，并将其性能与当前最先进的harnesses进行量化比较。 Model 1. 一些问题： low-level library APIs 中的“low-level”代表什么？ “A low-level API, also known as a system-level or hardware-level API, refers to an interface provided by an operating system or software library that allows direct interaction with the underlying system or hardware components. It provides a way for developers to access and control the lower-level functionalities of a system, such as hardware devices, system calls, and system resources.” dataflow graphbased fuzzing中的“graphbaesd”代表什么？ 一个test case中有多个个API调用，这些调用组成一个API序列，以数据流图的方式表示。 2. Dataflow graph ​ 下图是一个触发UAF漏洞的C++代码片段： ​ 下图将这个Bug表示为了dataflow graph，数据流图，函数是顶点，对象是边： ​ GraphFuzz 的关键是这两种表示法是等价的，我们可以通过编译和运行图 1 中的 C++ 代码或动态执行图 2 中的数据流图来调用此测试用例。 2.1 Graph Mutations ​ 如何对数据流图做mutate； 2.2 Graph Completion ​ 如何补全图，以防止因为生成图本身的问题而在fuzzing中导致的假阳性。 2.3 Graph Minimization ​ 只保留那些表现出相同崩溃且较小的graph，我们就能获得接近手工最小化示例大小的数据流图。 3. Graphfuzz for C/C++ ​ GraphFuzz分为两个部分：libgraphfuzz（一个用C++写的对数据流图做突变的工具）和gfuzz（Python 命令行工具，用于生成harness文件并执行图最小化和自动模式提取等其他任务。） ​ Graphfuzz harness的核心是schema，schema是一个用YAML写的可读文件，其中包含了API endpoints，object types等信息，GraphFuzz通过使用schema来自动生成exec和write fuzzer harnesses。 ​ schema样例： ​ 生成harness的过程： Instrumentation：使用现有的fuzzer coverage sanitizer对目标library做插桩，例如在使用Clang是使用-fsanitize=fuzzer； Schema Inference(可选)：可以使用使用 gfuzz 运行shcema提取工具，从library源代码中自动提取类、结构体、枚举、类型定义和方法到shcema中，生成的schema可以作为人工修改的基础； Manual Revision：根据对API的理解，通过添加/删除类、添加函数或重新定义函数的输入和输出类型，手动修复schema； Harness Generation：运行gfuzz工具来自动化生成两种harness：fuzzExec（运行数据流图）和fuzzWrite（将数据流图转换为普通C/C++代码，使测试样例可以被外部继续编译）； Compilation/Linking： 将生成的两种hanesses link到目标库中来生成libFuzzer可执行文件。 ​ GraphFuzz 是在 libFuzzer 基础上作为自定义突变引擎实现的（好巧妙的写法hhh），fuzzing的过程就如普通fuzzer一样，只是Mutation的过程变成了作者自定义的graph-level mutaitons。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Fuzzing","slug":"Fuzzing","permalink":"http://example.com/tags/Fuzzing/"}],"author":"Shaw"},{"title":"(论文阅读)Everything Old is New Again- Binary Security of WebAssembly","slug":"【论文阅读】Everything-Old-is-New-Again--Binary-Security-of-WebAssembly","date":"2023-07-04T03:35:50.683Z","updated":"2023-07-08T07:53:04.210Z","comments":true,"path":"2023/07/04/【论文阅读】Everything-Old-is-New-Again--Binary-Security-of-WebAssembly/","link":"","permalink":"http://example.com/2023/07/04/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Everything-Old-is-New-Again--Binary-Security-of-WebAssembly/","excerpt":"Everything Old is New Again: Binary Security of WebAssembly 时间：2020 作者：Daniel Lehmann（德国斯图加特大学），Johannes Kinder（慕尼黑联邦国防大学） 会议：USENIX'2020 Abstract ​ WebAssembly是一种越来越流行的编译目标，其旨在通过严格分离代码和数据、强制执行类型和限制间接控制流，在浏览器和其他平台上安全可靠地运行代码。不过，内存不安全的源语言的漏洞仍然可以转化为WebAssembly二进制文件的漏洞。 ​ 在文本中，我们分析了什么样的漏洞在WASM二进制文件中是可利用的，以及其与本地代码的比较。我们发现，许多经典的漏洞，由于常见的缓解措施，在本地二进制文件中不再可利用，但在WebAssembly中却完全暴露。另外，WebAssembly能够实现一些独特的攻击，例如覆盖所谓的常量数据或使用堆栈溢出操纵堆。 ​ 我们提出了一套攻击原语，使攻击者(i)能够写入任意内存，(ii)能够覆盖敏感数据，以及(iii)能够通过转移控制流或操纵主机环境来触发意外行为。我们提供了一套易受攻击的POC应用程序，以及完整的端到端漏洞，其中涵盖了三个WebAssembly平台。对真实世界的二进制文件和SPEC CPU程序编译成WebAssembly的经验性风险评估表明，我们的攻击原语在实践中可能是可行的。总的来说，我们的发现表明，WebAssembly缺乏二进制的安全性，这也许是令人惊讶的，我们讨论了潜在的保护机制，以减轻由此产生的风险。","text":"Everything Old is New Again: Binary Security of WebAssembly 时间：2020 作者：Daniel Lehmann（德国斯图加特大学），Johannes Kinder（慕尼黑联邦国防大学） 会议：USENIX'2020 Abstract ​ WebAssembly是一种越来越流行的编译目标，其旨在通过严格分离代码和数据、强制执行类型和限制间接控制流，在浏览器和其他平台上安全可靠地运行代码。不过，内存不安全的源语言的漏洞仍然可以转化为WebAssembly二进制文件的漏洞。 ​ 在文本中，我们分析了什么样的漏洞在WASM二进制文件中是可利用的，以及其与本地代码的比较。我们发现，许多经典的漏洞，由于常见的缓解措施，在本地二进制文件中不再可利用，但在WebAssembly中却完全暴露。另外，WebAssembly能够实现一些独特的攻击，例如覆盖所谓的常量数据或使用堆栈溢出操纵堆。 ​ 我们提出了一套攻击原语，使攻击者(i)能够写入任意内存，(ii)能够覆盖敏感数据，以及(iii)能够通过转移控制流或操纵主机环境来触发意外行为。我们提供了一套易受攻击的POC应用程序，以及完整的端到端漏洞，其中涵盖了三个WebAssembly平台。对真实世界的二进制文件和SPEC CPU程序编译成WebAssembly的经验性风险评估表明，我们的攻击原语在实践中可能是可行的。总的来说，我们的发现表明，WebAssembly缺乏二进制的安全性，这也许是令人惊讶的，我们讨论了潜在的保护机制，以减轻由此产生的风险。 问题背景 1. WebAssembly的安全分为两个方面： Host security：runtime环境在保护主机系统免受恶意WebAssembly代码侵害方面的有效性； 对host security的攻击依赖于执行错误[16, 59]，因此通常是聚焦于一个特定的虚拟机（VM）。 Binary security：内置故障隔离机制在防止其他良性的WebAssembly代码被利用方面的有效性。 针对binary security的攻击--本文的重点--是针对每个WebAssembly程序及其编译器工具链的攻击，WebAssembly的设计包括各种功能，以确保二进制安全。例如，由WebAssembly程序维护的内存与它的代码、执行堆栈和底层虚拟机的数据结构是分开的；为了防止与type有关的崩溃和攻击，二进制文件被设计成容易进行类型检查的方式，并且在执行前静态检查类型；此外，WebAssembly程序只能跳转到指定的代码位置，这种故障隔离的形式可以防止许多经典的控制流攻击。 ​ 综合Wasm的安全机制，以及Wasm的源语言（C/C++/Rust）一般都是会对内存进行操作的，引出了如下问题：内存漏洞对Wasm二进制安全性有何影响？ ​ Wasm的原始论文说：“在最坏的情况下，一个有错误的或被利用的WebAssembly程序会把它自己内存中的数据弄得一团糟”；Wasm的官方文档说：“常见的缓解措施，如数据执行预防（DEP）和堆栈粉碎保护（SSP），在WebAssembly程序中并不需要”。 2. Wasm的控制流： ​ 与本地代码或Java字节码不同，WebAssembly只有结构化的控制流。一个函数中的指令被组织成良好的嵌套块，分支只能跳到周围块的末尾，而且只能在当前函数内，并且多分支只能指向在分支表中静态指定的块，不受限制的goto或跳转到任意地址是不可能的。特别是，人们不能把内存中的数据作为字节码指令来执行。因此，许多经典的攻击在WebAssembly中被排除了，例如，注入shellcode或滥用无限制的间接跳转，如x86中的jmp *%reg。 3. Wasm的间接跳转： ​ 如上图所示，间接调用（目标函数的地址不确定，存储在变量或者寄存器中）需要通过table sectio来完成，左边的call_indirect指令从堆栈中弹出一个值，用来索引table section，table section将这个索引映射到一个函数，随后被调用。因此，只有当一个函数出现在table中时才能被间接调用。为了确保类型的正确性，虚拟机在执行调用前会检查目标函数是否与间接调用指令中静态声明的类型兼容，否则就会终止执行。 ​ 贡献 对WebAssembly的线性内存和从C、C++和Rust等语言编译的程序的使用进行了深入的安全分析，WebAssembly缺少哪些常见的内存保护，以及这如何使一些代码比编译成本地二进制时更不安全（第三节）； 一组从我们的分析中得到的攻击原语，以及对WebAssembly生态系统所提供或不提供的缓解措施的讨论； 一组易受攻击的应用程序和端到端的exploit实例，显示了我们在三个不同的WebAssembly平台上的攻击结果； 经验证明，数据流和控制流攻击都可能是可行的，对来自真实世界网络应用的WebAssembly二进制文件以及从大型C和C++程序中编译出来的文件进行了测试； 讨论可能的缓解措施，以加固WebAssembly二进制文件对所述的攻击的防御（第7节）。我们公开了我们的攻击原语、端到端漏洞和分析工具，以帮助这个过程。 ​ 对Wasm线性内存的安全分析 3.1 Managed vs. Unmanaged Data Managed Data：即局部变量、全局变量、评估堆栈上的值和返回地址，位于由虚拟机直接处理。 WebAssembly代码只能通过指令与managed data进行隐式交互，但不能直接修改其底层存储。例如，可以使用local.get 0读取local 0，但在任何时候，程序都无法看到local的实际底层地址。 Unmanaged Data：所有驻留在线性内存中的数据，它们完全在程序的控制之下，通常由编译器生成的代码组织。 将unmanaged data放在线性内存中有几个原因，因为WebAssembly只有四种数据类型，而且managed data只能容纳这些原始类型的实例，所有非标量数据，如字符串、数组或列表，都必须存储在线性内存中; 因为managed data没有地址，所以任何在源程序中曾经被使用地址的变量，例如，out parameters（使用参数指针而不是返回值来返回结果），也必须存储在线性存储器中。 由于许多非标量类型在源程序中作为函数范围的数据，具有动态寿命，编译器在线性内存中为call stack、heap和static data创建了一块区域。我们将把编译器在线性内存中创建的call stack称为unmanaged stack，以区别于managed evaluation stack（存放指令的中间值）和managed call stack（存放locals和返回地址）。重要的是，这意味着大量的数据位于unmanagedd的线性内存中，不在虚拟机的保护之下，而是在程序中内存写入指令的完全控制之下。 3.2 Memory layout ​ Memory layout指的是stack、heap和data在linear memory中的顺序。在linear memory中，为了保证heap可以动态生长，heap必须是放在最后的。Heap下面是stack和静态数据，由于在WebAssembly中没有只读内存（在下一节会有更多的介绍），所以在.data和.rodata之间没有区别，而且由于内存总是零初始化的，所以不需要专门的.bss部分。换句话说，.data、.rodata和.bss在WebAssembly中没有明确的区分。 ​ 在下文中，当我们提到linear memory中的data section时，我们指的是所有这些在程序的整个生命周期内有效的数据，例如，静态初始化的字符串常量、全局数组或零字节范围。 ​ 不同编译器生成的WASM内存布局如下： ​ 如图所示，注意到Heap的生长方向都是向上的，但Stack不一定，其根据不同布局生长方向不同。在Emscripten和Clang中，static data默认是第一位的，但使用Rust和Clang的链接器选项-stack-first，就可以使stack位于第一，data位于stack和heap之间。 3.3 Memory Protections WebAssembly的线性内存是一个单一的、连续的内存空间，没有任何空隙，所以每个指针∈[0, max_mem]都是有效的，只要攻击者保持在这个范围内，任何读写操作都会成功。因为不能在static data、unmanaged stack和heap上安装guard pages，一个section的溢出会无声地破坏相邻section的数据（第4节显示，缓冲区和堆栈溢出因此是WebAssembly中非常强大的攻击原语）； 在WebAssembly中，线性内存在设计上是不可执行的，故直接jump到线性内存中没用。然而，WebAssembly不允许将内存标记为只读，相反，线性内存中的所有数据都是可写的。这是线性内存的另一个相当令人惊讶的限制，并使我们在第4节中的一个攻击原语成为可能； 在WebAssembly中，没有ASLR。WebAssembly线性内存的排列是确定的，也就是说，stack和heap的位置是可以从编译器和程序中预测的。即使在WebAssembly中加入某种形式的ASLR，线性内存也是由32位指针来寻址的，这很可能没有提供足够的熵来进行强有力的保护。 Attack Primitives，攻击原语 ​ 本节介绍了可用于利用编译为WebAssembly的代码中的漏洞的攻击原语，原语横跨三个方面： 获取写操作原语，即攻击者利用一个漏洞来实现对内存的意外写入的能力； 能够覆盖敏感数据； 覆盖数据来触发破坏安全的行为。 ​ 原则上，这三个维度的原语可以自由组合。例如，第一个维度的写原语可以覆盖第二个维度的任何数据，以触发第三个维度的任何类型的错误行为。 ​ 如上图所示，打叉的防御措施表明其在原生平台下一般都会使用但在WASM平台用不了。这里的一些攻击在原生平台下存在，这里关注的重点是是否可以迁移到WASM平台上；另外一些攻击原语在原生平台下是不可能实现的，但在WASM下成为了可能。 4.1 Obtaining a Write Primitive ​ 这里，我们讨论了那些在原生平台上有有效缓解措施，但在WebAssembly中没有的攻击类型。（我们不讨论那些在WebAssembly中可能存在的、但既不新颖也不专门针对该平台的攻击原语。例如，整数溢出存在于WebAssembly，就像它们存在于x86或ARM中那样。） 4.1.1 Stack-based Buffer Overflow ​ 与目前的看法相反，基于堆栈的缓冲区溢出在WebAssembly中是可以利用的。 ​ 如上图所示，由于line 9没做边界检查导致buffer可以被溢出写入。 ​ 因为WebAssembly虚拟机隔离了managed data，特别是程序的返回地址，所以很容易让人产生强烈的（和错误的）安全感，正如第1节中引用的WebAssembly官方设计文档所说明的那样。然而，缓冲区溢出会损害WebAssembly中的数据，因为C语言中的部分funcion-scope的数据是存储在线性内存的unmanaged stack中的(如这里的frame数组)。 ​ 如图c所示，顶部是线性内存中的unmanaged stack，底部是VM内部存储managed data的区域。虽然底部的managed data受到了VM的保护，但unmanaged stack并没有受到保护。 事实上，在写进unmanaged stack的局部变量（如buffer）时的溢出，可能会覆盖同一堆栈中的其他局部变量，甚至是向上的其他堆栈帧中的局部变量，如parent_frame。因为溢出也可以写到父函数中的数据（如我们上面所示），甚至写到其他内存部分（如我们后面所示），所以这个原语比以前意识到的更强大，stack canary的使用会更重要。 4.1.2 Stack Overflow ​ 另一种写原语是stack overflows，其由于过分或无限制的递归操作，或在stack上分配可变大小的本地buffer时，例如使用alloca，就会发生这种情况。如果攻击者控制了stack分配的大小，或者提供了违反递归函数内部假设的坏数据，就可能触发堆栈溢出。 在原生平台，stack overflows会导致栈生长触碰特殊的guard page保护页，接着导致程序crash；但在WebAssembly中，这种保护措施不存在于unmanaged stack中，所以攻击者控制的stack overflow可以用来覆盖stack中的潜在敏感数据。 4.1.3 Heap Metadata Corruption ​ Heap Metadata Corruption指的是对堆块中特殊数据的破坏（如prev和next指针）。 ​ 因为在WebAssembly中，host环境没有提供默认的分配器，编译器会包含一个内存分配器作为编译好的程序的一部分。由于WebAssembly module通常要在执行前从网上下载，分配器的代码量大小是一个重要的考虑因素，Emscripten会让开发者自己在默认的分配器（基于dlmalloc）和特定的分配器（emmalloc，其可以减少最终的代码大小）中间选择。类似地，Rust程序也可以在编译为Wasm时选择一个轻量级的分配器（wee_alloc）。 ​ 虽然标准的分配器，如dlmalloc，已经针对各种元数据破坏攻击进行了加固，但简化和轻量级的分配器往往容易受到传统攻击的影响。我们发现emmalloc和wee_alloc都容易受到元数据破坏的攻击，下面对emmalloc的一个版本进行说明。 ​ 当通过调用free来释放一个内存块时，分配器会试图将尽可能多的相邻free块合并到一个更大的内存块中，以避免碎片化内存。这就导致了经典的堆溢出unlink漏洞，如上图所示，通过将相邻堆块溢出，覆盖其metadata指针。 ​ 由于emmalloc是一个first-fit分配器，它将返回空闲列表中第一个足以满足分配请求的大块，因此，两个直接跟随的分配请求在内存中就会产生两个相邻的块，如图6a中的alloc1和alloc2。图6c中emmalloc源代码的第1到9行显示，每个块的metadata开始于一个表示当前块是否空闲的位（used），该块的大小（size），一个指向前一个块的指针（*prev），最后是payload或一个FreeInfo结构。在一个正常的分配操作中，该块是空闲块的双链列表的一部分。 ​ 将alloc1中的数据溢出（例如，由于长度错误的memcpy），攻击者可以写到直接相邻的alloc2，以清除used位并建立一个 \"假的 \"FreeInfo结构（图6b）。最后，当alloc1被释放时，分配器检查是否有机会将新释放的块与相邻的自由块合并，alloc2会被识别为已经free了，分配器调用removeFromFreeList来解除它的链接，以准备合并这两个块。 ​ 在图6c的第13行，emmalloc在alloc2上执行unlink代码，然后将攻击者控制的下一个字段的值写入另一个FreeInfo结构的下一个字段（即，偏移量为4字节），在攻击者控制的prev中的地址。在第14行，另外还有一个镜像写到Next所指向的位置。因此，为了避免运行时错误终止执行，prev和next都必须是有效的指针。 由于Emscripten分配的默认堆栈大小为5MB，低于5×220的值很可能可以安全写入。这对于覆盖函数表索引（见第4.3.1节）来说是绰绰有余的，这些索引最多只有几千的范围。 ​ 其他可能的攻击可能利用格式字符串漏洞、UAF和双重释放漏洞、单字节缓冲区溢出，或对内存管理进行更复杂的攻击。 4.2 Overwriting Data ​ 当给出一个写操作原语，这里讨论了什么样的数据可以被覆盖。 4.2.1 Overwriting Stack Data ​ 线性内存中的unmanaged stack中的function-scoped数据包含：如数组、结构体或者使用地址的变量。通过一个给定的完全灵活的写操作原语，攻击者可以覆盖任何潜在的关键本地数据，包括作为函数表索引的函数指针或安全关键函数的参数。 ​ 与原生平台不同的是，unmanaged stack上没有返回地址，故简单的buffer overflow并不好直接影响控制流。然而，如果堆栈向下增长，溢出操作可以达到所有当前活动的调用帧。因为没有返回地址或堆栈canary，溢出可以覆盖所有调用函数的本地数据，反倒没有因为返回地址异常提前终止的风险。 4.2.2 Overwriting Heap Data ​ Heap通常包含有较长寿命的数据，并会在不同的函数中存储复杂的数据结构。在WebAssembly中，由于完全确定的内存分配，对heap数据的定向写入是很简单的。更糟糕的是，即使是足够长的基于stack的线性缓冲区溢出也会破坏堆数据（因为heap位于最上方），而且没有任何机制，如保护页，可以阻止这种方法。 ​ 对于单一的线性内存，没有办法避免stack溢出或基于stack的缓冲区溢出。如果stack本身向上增长，stack溢会无声地破坏heap的数据。即使是stack向下增长（远离heap方向），但由于缓冲区溢出的方向是向上的，Stack-based Buffer Overflow就是罪魁祸首。 4.2.3 Overwriting “Constant” Data ​ 在原生平台下，覆盖常数基本是不可能的。将数据声明为“constant”本身就是许多平台保护数据不被覆盖的一种方式，在执行过程中常数会被放在只读的内存中。 ​ 由于WebAssembly没有办法使数据在线性内存中保持不变，一个任意的写原语就可以改变程序中任何非标量常数的值，例如所有的字符串。甚至更多的受限制的写原语允许修改常量：图4b的内存布局的堆栈溢出可以写入恒定数据；同样，Stack-based Buffer Overflow可以达到图4c的内存布局中的恒定数据，因此，具有这两种能力的攻击者可以覆盖任何所谓的常量数据。 4.3 Triggering Unexpected Behavior ​ 给出写原语、需要覆盖的数据，有许多方法可以让攻击者触发程序的异常行为。 4.3.1 Redirecting Indirect Calls ​ 在WebAssembly中，与本地控制流攻击最接近的攻击方法是间接函数调用的重定向，这种类型的攻击允许执行通常不会在特定环境下执行的代码。 ​ 在第2节，我们已经说明了WebAssembly中的间接函数调用，攻击者可以通过覆盖间接调用指令使用的一个整数，这个整数用作table section中的一个索引，来重定向一个间接调用。正如第4.2节所述，这个整数值可能是unmanaged stack的局部变量，heap对象的一部分，在vtable中，甚至是一个所谓的常量值。 ​ WebAssembly有两种机制限制攻击者重定向间接调用： 首先，并不是所有定义在WebAssembly二进制文件中或导出到二进制文件中的函数都出现在间接调用表中，而只是那些可能被间接调用的函数在table中； 其次，所有的调用，包括直接和间接调用，都要进行类型检查。因此，攻击者只能在相同类型的函数的等价类中重定向调用，类似于基于类型的CFI[15]。在第6节中，我们衡量这些机制在多大程度上减少了攻击者可以选择的可用调用目标。 4.3.2 Code Injection into Host Environment ​ WebAssembly模块可以通过各种方式与他们的host环境互动，以引起外部可见的效果。其中一种方式是调用JavaScript主机环境中臭名昭著的eval函数，它将给定的字符串解释为代码，为了访问eval，通过Emscripten编译的WebAssembly模块可以使用，例如，emscripten_run_script（它在host环境中执行JavaScript代码，无论是在浏览器中还是在基于Node.js的服务器端代码中）。在浏览器中，任何允许向文档添加代码的函数（例如，document.write）都可以作为eval函数的等价物；在Node.js中，API的低级特性为代码注入提供了更多的选择，例如，child_process模块的exec函数。 ​ 使用第4.1节和第4.2节中描述的原语，攻击者可以通过重写传递给类似eval的函数的参数来注入恶意代码。例如，假设WebAssembly通常用一个存储在线性内存中的 \"常量 \"代码串来调用eval，那么攻击者可以用恶意代码覆盖该常量。 4.3.3 Application-specific Data Overwrite ​ 根据不同的应用程序，还可以有其他敏感的数据覆盖目标。例如，一个通过导入的函数发出网络请求的WebAssembly模块，可以通过覆盖目标字符串使其与不同的主机联系，以启动cookie窃取。作为进一步的例子，一些解释器和runtime已经被编译成WebAssembly，例如，直接在浏览器中执行CIL/.NET代码[5]。这类环境包含了许多显著改变程序行为的机会，例如，通过覆盖然后由运行时解释的字节码。 5. 端到端攻击方法 5.1 End-to-End Attacks ​ 这一攻击表明，将编译为WebAssembly的易受攻击的代码纳入客户端Web应用程序，可以实现基于JavaScript的应用程序的已知攻击，如跨站脚本（XSS）。 ​ 假设我们有一个图片服务网站，该服务提供了一个网络应用，其在客户端转换不同格式的图像，使用编译为WebAssembly的libpng图像编解码库。如上图所示，其可以将一个用户上传的PNM格式图像在本地转换为一个PNG格式图像，在转换完成后，通过DOM 操作函数（如document.write）展示该图片。 ​ 然而，1.6.35版本的libpng库有一个著名的buffer overflow漏洞（CVE-2018-14550），当进行图片格式PNM-&gt;PNG转换时可以被触发。在原生平台下，这个漏洞可以被stack canaries禁止，但在WASM平台下，这个漏洞可以不被限制的被利用。 ​ 具体利用方法如下： 攻击者提供给其他用户一个恶意图片，其被使用一个web应用输入并展示（如上图d）： 在上图Line 3，其使用pnm2png函数转换格式； 在上图Line 4，将png文件编码为base64格式，并添加到img_tag中； 在上图Line 5，将img_tag加入document； 在Wasm中，字符串img_tag存储在heap中，通过stack-baesd buffer overflow可以修改它： 攻击者可以利用溢出将img_tag修改为一个script脚本； 恶意脚本会在Line 5被写入document； 取决于数据如何被上传，上述攻击可能导致反射型（非持久）XSS和持久型XSS，攻击者可以选择自己上传恶意脚本或者让用户上传，已达到不同的目的。 5.2 Remote Code Execution in Node.js ​ 我们证明了在基于Node.js的应用程序中包含有漏洞的WebAssembly可以实现远程代码执行。 ​ 假设有一个记录对某些产品满意或不满意的客户的ID的服务器程序（如a），handle_request()函数接受三个input，其都可以被攻击者控制： input1表明顾客是否happy； input2表明表明input1的长度； input3表明顾客的id。 ​ 根据顾客的快乐程度，代码调用log_happy或log_unhappy，其通过将各自的函数分配给函数指针func来选择。如上图所示（Line 9），其通过memcpy函数来将input1的值复制进happiness数组中，但由于input2长度攻击者可控，就可以配合Line 12的free函数实现unlink exploit。通过这么操作，攻击者获得了一次写原语。 ​ 由于其通过函数指针来决定运行哪个函数，故函数指针func是存储在unmanaged stack中的，攻击者可以利用这个写原语来修改func的间接跳转目标。因为Wasm没有ASLR，故所有函数的地址都是确定的，这样的攻击非常容易实现，如图b所示，因为type类型相同，攻击者完全可以将控制流导向exec函数，并在覆盖func地址时向堆中注入一个合适的命令，然后将该命令的地址以input3传入，即可运行该命令。 5.3 Arbitrary File Write in Stand-alone VM ​ 尽管独立的WebAssembly VM被宣传为执行C/C++代码的安全平台，但WebAssembly目前可以实现现代本地执行平台中不可能实现的攻击。 ​ 上图展示了一个将常量字符串加入一个静态已知文件的程序，只看Line 1-4，该功能明显是无害的。即使程序中有其他buffer overflow漏洞（Line 6-8），在原生平台中，其也是无害的，因为像“file.txt”这种字符串常量在x86中是存储在只读内存部分的，不可能被更改。 ​ 当运行一个WASM VM时： “file.txt”，“Append constant text.”等字符串都是存储在unmanaged线性内存中的data section（图b）； 其可以被buffer overflow修改，故fopen函数就可以打开任意文件，并以任意模式写入任意内容。 6. 量化评估 ​ 为了更好地了解到目前为止所描述的攻击在实践中的真实性，我们现在对真实世界的WebAssembly二进制文件进行了定量评估。我们解决了以下研究问题： RQ1：有多少数据是存储在unmanaged stack上的？ Unmanaged stack既可作为获得写原语的入口点，例如通过stack-based buffer overflow，也可作为覆写的目标，例如操纵敏感数据。 RQ2：间接调用有多常见？有多少函数可以被间接调用涉及？ 这个问题表明了通过重定向间接调用导致控制流被修改的风险有多大。 RQ3：与目前的CFI相比，WebAssembly的type检查CFI防御效果如何？ 由于WebAssembly VM对间接调用目标进行的运行时验证与CFI防御相似，我们在CFI等价类和类大小方面对两者进行了比较。 6.1 Experimental Setup and Analysis Process Program Corpus 测试使用的二进制程序分为两部分： 真实世界的9个已部署的程序： 名称 描述 Adobe’s Document Cloud View SDK7 renders 可以在浏览器中渲染和注释PDF Figma8 一个合作的用户界面设计网络应用 1Password X 1.17 浏览器扩展插件，包含一个用于生成密码的WebAssembly组件。 Doom 3（《毁灭战士》系列） 一个大型游戏引擎移植到WebAssembly上 一组编解码器（webp, mozjpeg, optipng, hqx） 用于浏览器内的图像转换 这些二进制程序被应用在不同的领域（文档编辑、游戏、编码解码等），以及不同的语言（C、C++、Rust），所以我们相信这些样本是对真实Wasm样本分布的一个很好的初步近似。 SPEC CPU 2017基准套件中的17个C和C++程序，其被编译为WebAssembly： SPEC CPU以前曾被用来研究WebAssembly的性能[37]，它也被用来评估原生代码的CFI技术的安全性[21, 69]，使我们能够解决RQ3。这些程序来自于计算量大的领域（编程语言的实现、模拟、视频编解码器、压缩），与WebAssembly的原始用例相匹配。 Static Analysis 为了解决我们的研究问题，我们开发了一个轻量静态分析工具。据我们所知，它是第一个用于WebAssembly二进制文件的安全分析工具，其是用Rust语言编写的，并且可以做到： 提取程序的一般信息，如指令数、函数数和它们的类型等； 通过推断哪个global是stack指针，哪个函数可以访问它，以及stack指针如何增减来分析unmanaged stack； 分析table section和其静态初始化，来查找哪些函数在其中表示，以及每个初始化table索引的函数类型； 分析间接调用edges，以提取允许call_indirect目标的静态编码类型，有多少函数符合该类型，对调用目标的额外限制，以及CFI等价类及其大小。 6.2 Measuring Unmanaged Stack Usage ​ 这一节回答问题RQ1，有多少程序数据存储在unmanaged stack中。 6.2.1 Stack Analysis ​ 我们的静态分析测量每个非import函数在unmanaged stack上的栈帧的大小，该分析在没有调试信息的优化、剥离的二进制文件上运行，就像现实中的攻击者一样，因此必须直接从字节码中推断出unmanaged stack的使用。 ​ 首先，分析需要确定stack指针。与本地二进制文件不同，这里不能使用固定寄存器（如x86上的rsp，在WebAssembly中不存在）或全局变量作为stack指针。相反，分析会提取所有修改globals的指令，并选择最经常被读写的指令。人工分析证实，这种启发式方法可靠地找到了stack指针。从确定的全局的静态初始化中，我们也知道了线性内存中unmanaged stack的基址。 其次，对于每个函数，分析推断出unmanaged stack上的栈帧的大小。在所有被分析的二进制文件中，先前确定的stack指针被修改，其协议类似于本地二进制文件中的**function prologue**和**function epilogue**。具体来说，我们的分析会匹配与下面的指令序列，并提取`delta`值，然后得出栈帧大小： ​ 上图首先从全局变量$i读取当前的栈指针，然后增加或减少它（取决于堆栈是向上还是向下增长，见第3.2节），可以选择将它保存到一个局部变量（类似于一个基本指针），最后将修改后的值写回去。 function prologue：函数开头的几行汇编代码，它为堆栈和寄存器做准备，以便在函数中使用。 function epilogue：出现在函数的末尾的汇编代码，将堆栈和寄存器恢复到函数被调用前的状态。 6.2.2 Results ​ 下图显示了所有被分析的二进制文件中栈帧大小的分布，包括直方图（图10a）和累积分布（图10b）： 1/3（32,651）的函数在unmanaged stack中存储数据，最小的栈帧为16字节，由13620个函数（占所有函数的14%）分配； 栈帧的大小跨越从16字节到1MB的整个范围，1MB是最大的静态stack分配。从图10b的累积分布中，我们看到6%（6127）的函数在unmanaged stack上分配了128字节或更多，1.3%（1232）的函数分配了至少1KiB； 总的来说，许多函数使用了unmanaged stack，这不仅容易受到任意内存写入的影响，也容易受到缓冲区溢出的影响。这意味着，随着调用深度的增加，攻击者至少找到一些数据进行覆盖的机会也会迅速增加，例如，如果有10个嵌套调用（假设函数分布均匀），在unmanaged stack上会有一些数据的概率为\\(1-((1-0.33)^{10}) ≈ 98.2\\%\\)。 ​ 我们的结论是： ​ （1）Wasm 中存在大量的stack数据容易被缓冲区溢出和任意写原语覆盖； ​ （2）在unmanaged stack上隔离堆栈帧是很重要的，例如，使用canaries。 6.3 Measuring Indirect Calls and Targets ​ 这一节回答问题RQ2，分析了间接调用。 6.3.1 Indirect Calls ​ 我们对表2中的所有二进制文件进行了反汇编，并对call_indirect 指令的数量进行了统计。间接调用在所有调用中占的百分比在不同的程序中差异很大，其分布从0.6%到31.3%都有。 ​ 我们还发现，间接调用的比例与源语言是C还是C++无关，从所有26个程序的平均值来看，9.8%的调用指令是间接调用，也就是说，几乎每十个调用都有可能被转移到其他函数上。 6.3.2 Indirectly Callable Functions ​ 想要成功地通过间接调用改变控制流，不仅需要间接调用指令，还需要找到合适的target函数（type相同，其该函数必须位于table中）。 ​ 我们的静态分析工具在程序启动时发现哪些函数在table中被初始化。Table中的条目不能被WebAssembly程序本身所操纵，原则上，host环境，如浏览器中的JavaScript，可以在运行时添加或删除条目。我们手动验证了由Emscripten生成的JavaScript代码不会修改该表，因此假设我们的分析精确地测量了间接调用的潜在目标。 ​ 表2中的“Indirectly Callable”表明了有多少函数在table中的同时至少跟一个call_indirect指令的type相吻合。可间接调用的函数的百分比从5%到77.3%不等，平均占程序corpus中所有函数的49.2%。 6.2.4 Function Pointers in Memory ​ 上述分析给出了通过间接调用来劫持控制流的“上限”，但在实践中，如果传递给call_indirect的table索引来自一个局部变量、全局变量、或者是一连串指令运行的结果，那么攻击者可以选择的索引可能会更受限制。 ​ 为了找出这种攻击方式的“下限”，我们还测量了有多少table index是直接从内存中读取的，我们通过对间接调用之前的指令进行静态分析来获得这个数字。表2中的\"Idx.from mem. \"列显示了类型兼容和表内函数的数量，其中至少有一个间接调用直接从线性内存中获取其table index。 ​ 对于每个这样的函数，给定一个任意的写入线性内存的原语，一个间接调用就可以被转移以到该函数。也许令人惊讶的是，这个可达函数的“下限”与“上限”非常接近： 平均来说，48.1%的函数可以通过从线性内存中获取参数的间接调用来达到。 ​ 总的来说，我们对间接调用目标的分析显示了控制流劫持攻击的巨大潜力。许多函数是可以间接调用的（平均49.2%），而且大多数函数可以通过简单地覆盖存储在线性内存中的索引来达到（48.1%）。我们得出结论，间接函数调用对WebAssembly中控制流的完整性构成严重威胁。 ​ 6.4 Comparing with Existing CFI Policies ​ Wasm对于间接调用的type检查可以看做一种CFI，这里将WebAssembly的类型检查与最先进的本地二进制文件的CFI防御进行比较（RQ3）。 6.4.1 Equivalence Classes ​ 按照先前关于CFI的工作[21]，我们通过分析一个间接转移可能（根据CFI机制）被转移到的目标集合来衡量其有效性，这个集合就是CFI equivalence class。为了评估CFI防御的有效性，我们使用两个衡量标准： 类的数量，即存在多少个不同的类； 类的数量如果很小意味着CFI对目标的区分很小，给了攻击者更多控制流转移的选择。 类的大小，即每个类中有多少个目标； 类的大小如果很大意味着大量的target都可以由一个间接调用指令到达，也是不安全的。 ​ 对于WebAssembly，我们通过分析可间接调用的函数的类型签名来衡量CFI的等价类，将所有具有相同类型签名的函数分配到一个等价类。此外，我们还分析了间接调用之前的指令，以确定它们是否将表的索引限制在较小的范围内，例如，通过比特掩码。 ​ 表2的最后一列显示了分析结果，平均来说，每个程序有62个等价类，每个类包含33.2个函数。最大的等价类，在Blender程序中，包含超过5300个函数。总的来说，这表明攻击者有大量的调用目标可以选择。 6.4.2 Comparing with Native CFI Defenses ​ 为了正确看待关于等价类的结果，我们将其与本地CFI的结果进行比较[21]。 ​ 如下图11a和图11b中的表格分别比较了等价类的数量和大小。例如，MCFI[48]和πCFI[49]将xalancbmk的控制流目标分别划分为1534和1200个类，而WebAssembly的间接调用目标限制只产生77个这样的类。关于等价类的大小，WebAssembly对omnetpp和xalancbmk的等价类特别大，而对其他程序的等价类大小与本地防御相似。 ​ 有趣的是，omnetpp和xalancbmk是大量使用虚拟函数的面向对象编程的C++程序。源码级的类型信息，例如关于类的层次结构，可以帮助基于编译器的CFI方法识别更精确的，从而限制的等价类。相比之下，WebAssembly的类型检查只有四种低级原始类型（组合）来处理，这可能解释了与本地方案的明显区别。 ​ 总的来说，WebAssembly的类型检查往往不如本地二进制文件的现代CFI防御措施有效。尽管与没有任何CFI防御措施相比，类型检查的间接调用当然是一个进步，但适应更复杂的CFI防御措施可以大大加强目前生产的二进制文件。例如，Clang的CFI方案使用源码级信息，在编译成WebAssembly时，也可以通过传递-fsanitize=cfi来使用。 7. 关于缓解措施的讨论 ​ 下面讨论了几种可以击败本文提出的攻击的缓解措施，例如，通过修改语言规范、更新编译器，或者由应用程序和库的开发者来实现。 7.1 WebAssembly Language ​ 一些关于扩展核心WebAssembly语言的建议可以解决我们的一些攻击原语。 多存储器方案[54]给了一个模块拥有多个线性内存的选择。在该提议下，内存操作静态地编码它们操作的内存，例如，i32.load $mem2指令只能从内存2加载数据。多个内存将使堆栈、堆和常量数据分离。因此，一个内存部分的溢出将不再影响另一个内存的数据。 另外，指向heap的指针不能再被伪造成指向stack，反之亦然。最后，如果编译器只对一个特定的内存区发出加载指令，它就会变成有效的只读区域，因为对其他内存的存储不能修改它，这将防止对常量的修改。这个建议的一个挑战是，对多个内存进行编译并不简单。由于内存访问被静态地限制在某个内存中，必须处理不同区域指针的代码必须在内存之间重复或明确地复制对象。 参考类型方案[55]允许模块有多个表用于间接调用。我们的调用重定向攻击之所以强大，只是因为目前所有可间接调用的函数都在同一个表中。多个table可以实现更细化的防御，一种选择是定义不同的保护域，例如，每个静态链接库一个，并为每个保护域保留一个单独的表；另一个选择是将调用目标分成等价类，类似于现有的本地二进制文件的CFI技术，并为每个等价类保留一个单独的表。 MS-Wasm方案[26]明确地针对内存安全，它建议在WebAssembly中增加所谓的段（segment），即具有定义的大小和寿命的内存区域。进入这些段的处理程序被提升为第一类类型，有自己的分配和分片操作，这需要主机的一些实现工作，除非提供内存安全的硬件支持，否则可能会产生性能开销。 7.2 Compilers and Tooling ​ 防止我们许多攻击原语的最简单方法是对编译器插桩，使编译器、链接器和分配器支持已经为本地编译目标提供的安全功能。几十年来对二进制安全的研究[61]已经产生了一些可以应用于WebAssembly的缓解措施。有利于 WebAssembly 编译器的例子是类似 FORTIFY_SOURCE 的代码重写、堆栈canaries、CFI 防御和内存分配器中的安全unlink。特别是对于堆栈canaries和overwirte通常被利用的C语言字符串函数，我们认为在部署上没有原则性的障碍。我们希望它们能在未来被编译器实现，因为它们能以相对较少的变化给生态系统带来良好的安全效益，而不像语言变化那样。 ​ 编译器中的一个较长期的缓解措施是使用上面讨论的WebAssembly语言扩展，一旦它们可用。例如，当把C/C++编译成WebAssembly时，多个内存可以模仿本地代码中页面保护所提供的一些安全功能。 7.3 Application and Library Developers ​ WebAssembly应用程序的开发者可以通过尽可能少地使用 \"不安全 \"语言（如C）的代码来降低风险。为了减少攻击面，开发者还应该确保只从主机环境中导入那些绝对必要的API。例如，调用关键的主机函数，如eval或exec是不可能的，除非这些函数在WebAssembly模块中被导入。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"WASM","slug":"WASM","permalink":"http://example.com/tags/WASM/"}],"author":"Shaw"},{"title":"(论文阅读)Fuzzm-Finding Memory Bugs through Binary-Only Instrumentation and Fuzzing of WebAssembly","slug":"【论文阅读】Fuzzm-Finding-Memory-Bugs-through-Binary-Only-Instrumentation-and-Fuzzing-of-WebAssembly","date":"2023-07-04T03:06:36.336Z","updated":"2023-07-04T03:35:30.593Z","comments":true,"path":"2023/07/04/【论文阅读】Fuzzm-Finding-Memory-Bugs-through-Binary-Only-Instrumentation-and-Fuzzing-of-WebAssembly/","link":"","permalink":"http://example.com/2023/07/04/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Fuzzm-Finding-Memory-Bugs-through-Binary-Only-Instrumentation-and-Fuzzing-of-WebAssembly/","excerpt":"Fuzzm: Finding Memory Bugs through Binary-Only Instrumentation and Fuzzing of WebAssembly 时间：2021 作者：Daniel Lehmann（德国斯图加特大学），Martin Toldam Torp（丹麦奥胡斯大学） Abstract ​ WebAssembly二进制文件通常是由内存不安全的语言，如C和C++编译而成。由于WebAssembly的线性内存和缺失的保护功能，例如堆栈canaries，源码级的内存漏洞在编译的WebAssembly二进制文件中是可以利用的，有时甚至比本地代码更容易。 ​ 本文通过第一个只针对WebAssembly的二进制fuzzer来解决检测此类漏洞的问题。我们的方法被称为Fuzzm，它结合了检测堆栈和堆的溢出的canaries插桩、有效的代码覆盖率插桩、WebAssembly虚拟机和一个流行的AFL fuzzer的输入生成算法。除了作为fuzzer的oracle，我们的canary还可以作为独立的二进制加固技术，以防止生产中的脆弱二进制文件被利用。 ​ 我们用28个真实世界的WebAssembly二进制文件来评估Fuzzm，其中一些是从源代码编译的，还有一些是在野外发现的，没有源代码。该fuzzer探索了数以千计的执行路径，触发了几十次崩溃，每秒执行数百次程序执行。当用于二进制加固时，该方法可以防止先前公布的针对脆弱的WebAssembly二进制文件的漏洞，同时施加较低的运行时间开销。","text":"Fuzzm: Finding Memory Bugs through Binary-Only Instrumentation and Fuzzing of WebAssembly 时间：2021 作者：Daniel Lehmann（德国斯图加特大学），Martin Toldam Torp（丹麦奥胡斯大学） Abstract ​ WebAssembly二进制文件通常是由内存不安全的语言，如C和C++编译而成。由于WebAssembly的线性内存和缺失的保护功能，例如堆栈canaries，源码级的内存漏洞在编译的WebAssembly二进制文件中是可以利用的，有时甚至比本地代码更容易。 ​ 本文通过第一个只针对WebAssembly的二进制fuzzer来解决检测此类漏洞的问题。我们的方法被称为Fuzzm，它结合了检测堆栈和堆的溢出的canaries插桩、有效的代码覆盖率插桩、WebAssembly虚拟机和一个流行的AFL fuzzer的输入生成算法。除了作为fuzzer的oracle，我们的canary还可以作为独立的二进制加固技术，以防止生产中的脆弱二进制文件被利用。 ​ 我们用28个真实世界的WebAssembly二进制文件来评估Fuzzm，其中一些是从源代码编译的，还有一些是在野外发现的，没有源代码。该fuzzer探索了数以千计的执行路径，触发了几十次崩溃，每秒执行数百次程序执行。当用于二进制加固时，该方法可以防止先前公布的针对脆弱的WebAssembly二进制文件的漏洞，同时施加较低的运行时间开销。 问题背景 ​ 贡献 ​ 模型","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Fuzzing","slug":"Fuzzing","permalink":"http://example.com/tags/Fuzzing/"},{"name":"WASM","slug":"WASM","permalink":"http://example.com/tags/WASM/"}],"author":"Shaw"},{"title":"(论文阅读)WAFL- Binary-Only WebAssembly Fuzzing with Fast Snapshots Oracle for WebAssembly","slug":"【论文阅读】WAFL--Binary-Only-WebAssembly-Fuzzing-with-Fast-Snapshots-Oracle-for-WebAssembly","date":"2023-07-03T13:29:58.410Z","updated":"2023-07-28T07:24:13.044Z","comments":true,"path":"2023/07/03/【论文阅读】WAFL--Binary-Only-WebAssembly-Fuzzing-with-Fast-Snapshots-Oracle-for-WebAssembly/","link":"","permalink":"http://example.com/2023/07/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91WAFL--Binary-Only-WebAssembly-Fuzzing-with-Fast-Snapshots-Oracle-for-WebAssembly/","excerpt":"WAFL: Binary-Only WebAssembly Fuzzing with Fast Snapshots 时间：2021 作者：Keno Haßler，Dominik Maier（柏林工业大学） 期刊：ROOTS’21 Abstract ​ WebAssembly 是一种用于二进制代码的开放标准，正在迅速在网络和其他领域得到应用。由于这些二进制文件通常是用低级语言（如C和C++）编写的，它们可能存在与传统对应物相同的错误。目前存在着很少的工具可以用于发现这些 WebAssembly 二进制文件中的错误。 ​ WAFL 在 WAVM（WebAssembly 虚拟机）中添加了一组补丁，以生成用于流行的 AFL++ 模糊测试工具的覆盖率数据。借助于提前编译（AOT）的 WAVM，WAFL 的性能已经非常高效。WAFL 还添加了轻量级的虚拟机快照，通过用 WAFL 的快照替换传统上在 AFL++ 测试中使用的fork函数，WAFL 的测试可以在原始模糊测试性能方面甚至超过具有编译时插桩的本机测试。据我们所知，WAFL 是首个用于仅限二进制 WebAssembly 的覆盖率引导模糊测试工具，而无需源代码。 ​ 总结来说，WAFL 是一种用于对 WebAssembly 二进制文件进行模糊测试的工具，通过在 WAVM 中添加补丁和轻量级虚拟机快照，提供了高效的覆盖率引导模糊测试能力。","text":"WAFL: Binary-Only WebAssembly Fuzzing with Fast Snapshots 时间：2021 作者：Keno Haßler，Dominik Maier（柏林工业大学） 期刊：ROOTS’21 Abstract ​ WebAssembly 是一种用于二进制代码的开放标准，正在迅速在网络和其他领域得到应用。由于这些二进制文件通常是用低级语言（如C和C++）编写的，它们可能存在与传统对应物相同的错误。目前存在着很少的工具可以用于发现这些 WebAssembly 二进制文件中的错误。 ​ WAFL 在 WAVM（WebAssembly 虚拟机）中添加了一组补丁，以生成用于流行的 AFL++ 模糊测试工具的覆盖率数据。借助于提前编译（AOT）的 WAVM，WAFL 的性能已经非常高效。WAFL 还添加了轻量级的虚拟机快照，通过用 WAFL 的快照替换传统上在 AFL++ 测试中使用的fork函数，WAFL 的测试可以在原始模糊测试性能方面甚至超过具有编译时插桩的本机测试。据我们所知，WAFL 是首个用于仅限二进制 WebAssembly 的覆盖率引导模糊测试工具，而无需源代码。 ​ 总结来说，WAFL 是一种用于对 WebAssembly 二进制文件进行模糊测试的工具，通过在 WAVM 中添加补丁和轻量级虚拟机快照，提供了高效的覆盖率引导模糊测试能力。 问题背景 ​ 随着Web的发展，进一步推进可移植性的想法，开放的WASI标准 [4] 允许独立的WebAssembly程序甚至在浏览器之外运行。其目标是创建一个真正通用的二进制平台，虽然围绕WASI的基础设施还很稚嫩，但已经开始逐渐增长。例如WebAssembly软件包管理器（wapm） [23]，使用wapm，用户可以下载在WebAssembly系统接口（WASI）启用的虚拟机上运行的WebAssembly二进制文件。以WebAssembly二进制文件形式分发的程序可以在每个可用运行时的平台上运行。 ​ 由于WebAssembly是像其他编译目标一样的编译目标，因此不安全源语言（如C）中的内存漏洞会被转化为WebAssembly，并且仍然存在潜在的漏洞。虽然该平台在开发时考虑了安全性并支持了一些现代的缓解措施，其仍可能存在可利用的bug，并导致恶意代码执行[9]。到目前为止，用于发现WebAssembly二进制文件中的内存破坏的工具还很有限。 ​ AFL在对有可用源代码的程序使用现有编译器的包装器 afl-cc 进行插桩，该工具向gcc或clang注入所需的pass。AFL++中包含的InsTrim pass[6]通过分析cfg来提高插桩速度，它只标记了区分路径所需的一个块的子集（根据作者的说法，大约20%）。作为InsTrim中使用的块ID散列技术和传统的afl-clang通道的一个缺点，当需要插桩的基本块的数量增加时，这些算法很可能产生哈希碰撞。 ​ LLVM的SanitizerCoverage[21] pass采取了一种更复杂的方法。它为每个边分配了一个防护变量（guard variable），并插入了一个使用该变量作为参数的回调函数。guard的初始化是在第二个回调函数中进行的，因此每个guard都可以被设置为一个唯一的数字，从而使其哈希值变得过时。AFL++使用这个pass作为默认pass。 ​ 本工作针对两个fully-featured wasm runtime：WAVM 和 wasm3。 贡献 ​ 在这篇论文中，我们介绍了WAFL，一种用于 WebAssembly 二进制文件的高吞吐量fuzzing工具。WAFL 使用了著名的 AFL++ 模糊测试工具进行输入生成，并利用轻量级虚拟机快照来提高性能。基于 WebAssembly 虚拟机（WAVM）的基础上，我们可以在没有源代码的情况下对 WebAssembly 二进制文件进行fuzzing。我们评估了其fuzzing速度，并展示了由于其快照机制，WAFL 甚至在 x86-64 平台上的性能超过了从源代码编译的简单测试用例。 我们开发了WAFL，这是一个开源的、针对纯二进制文件的WebAssembly fuzzer； 我们在基于wasm3的初始实现的基础上实现了多种改进，并进行了基准（benchmark）测试； 在其最终形式中，AOT编译、基于WAVM的快照fuzzer甚至超过了传统的编译、使用慢速fork系统调用的本地代码AFL。 模型 1. 执行 ​ 在AFL++术语中，persistent mode[2]意味着在多次迭代中重复使用一个子进程。它允许通过在子进程中的相关代码区域进行循环来取代时间密集的fork()系统调用。Persistent mode很适合我们的应用，其中有趣的代码是预编译的目标。然而，如果一直不fork，目标在执行过程中可能会积累状态，甚至泄露内存，从而使持久性的fuzzing变得不稳定。因此，如果我们想在没有fork()的情况下进行fuzzing，我们必须在每次执行后重置目标状态。理想情况下，我们希望在不对WebAssembly二进制文件打补丁的情况下完成这一工作，或者进一步对其进行检测，特别是在仅有二进制文件的情况下。 ​ WebAssembly定义了三种可能被目标程序改变的状态对象：globals、tables和memories[3]。目前，编译器只使用一种内存，即字节数组，在其中，他们创建了一个熟悉的布局，由Stack、Heap和Data部分组成[9]。基于这一观察，我们可以实现虚拟机快照和恢复：我们在第一次调用目标代码前不久拦截runtime，这时，线性内存已经被运行时初始化了。我们对其内容和大小创建一个快照，当控制流在每个循环迭代后返回到运行时，我们将内存缩小到其初始大小并写回快照。 2. 覆盖率 ​ WAVM使用LLVM-JIT来将Wasm二进制文件翻译到平台原生代码，并在其上面执行一些优化pass。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Fuzzing","slug":"Fuzzing","permalink":"http://example.com/tags/Fuzzing/"},{"name":"WASM","slug":"WASM","permalink":"http://example.com/tags/WASM/"}],"author":"Shaw"},{"title":"(论文阅读)WasmFuzzer- A Fuzzer for WebAssembly Virtual Machines","slug":"【论文阅读】WasmFuzzer--A-Fuzzer-for-WebAssembly-Virtual-Machines","date":"2023-07-03T12:35:37.206Z","updated":"2023-07-03T13:26:59.842Z","comments":true,"path":"2023/07/03/【论文阅读】WasmFuzzer--A-Fuzzer-for-WebAssembly-Virtual-Machines/","link":"","permalink":"http://example.com/2023/07/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91WasmFuzzer--A-Fuzzer-for-WebAssembly-Virtual-Machines/","excerpt":"WasmFuzzer: A Fuzzer for WebAssembly Virtual Machines 时间：2022 作者：Bo Jiang, Zichao Li（北航） 期刊：SEKE（CCF-C） Abstract ​ WebAssembly是一种快速、安全、可移植的低级语言，适用于各种应用场景，Web浏览器或区块链平台广泛使用WebAssembly虚拟机作为执行引擎。当Wasm虚拟机的实现存在bug时，WebAssembly的执行可能导致应用程序中的错误或漏洞。由于WASM虚拟机的语法检查机制，二进制级别的fuzzing无法暴露bug，因为大多数输入无法到达WASM虚拟机的深层逻辑。 ​ 在这项工作中，我们提出了WasmFuzzer，一个用于WASM虚拟机的bytecode级fuzzing工具。WasmFuzzer提出在Wasm字节码级别上生成初始种子进行fuzzing，并设计了一套系统的Wasm字节码突变mutation operators。此外，WasmFuzzer还提出了一种自适应的突变策略，以寻找适用于不同fuzzing目标的最佳mutator。 ​ 我们对三个真实的Wasm虚拟机进行评估，结果显示WasmFuzzer在代码覆盖率和唯一崩溃(unique crash)方面明显优于AFL。","text":"WasmFuzzer: A Fuzzer for WebAssembly Virtual Machines 时间：2022 作者：Bo Jiang, Zichao Li（北航） 期刊：SEKE（CCF-C） Abstract ​ WebAssembly是一种快速、安全、可移植的低级语言，适用于各种应用场景，Web浏览器或区块链平台广泛使用WebAssembly虚拟机作为执行引擎。当Wasm虚拟机的实现存在bug时，WebAssembly的执行可能导致应用程序中的错误或漏洞。由于WASM虚拟机的语法检查机制，二进制级别的fuzzing无法暴露bug，因为大多数输入无法到达WASM虚拟机的深层逻辑。 ​ 在这项工作中，我们提出了WasmFuzzer，一个用于WASM虚拟机的bytecode级fuzzing工具。WasmFuzzer提出在Wasm字节码级别上生成初始种子进行fuzzing，并设计了一套系统的Wasm字节码突变mutation operators。此外，WasmFuzzer还提出了一种自适应的突变策略，以寻找适用于不同fuzzing目标的最佳mutator。 ​ 我们对三个真实的Wasm虚拟机进行评估，结果显示WasmFuzzer在代码覆盖率和唯一崩溃(unique crash)方面明显优于AFL。 \"Unique crash\"（唯一崩溃）指的是在软件或系统中发生的独特的错误或异常情况，导致程序的崩溃或异常终止。这种崩溃是指与其他崩溃不同的、独特的错误情况，可能由于特定的输入或特定的执行路径引起。在上述文本中，作者提到WasmFuzzer在唯一崩溃方面的表现优于AFL，意味着WasmFuzzer能够发现更多不同于其他测试工具的独特错误情况。 问题背景 ​ WebAssembly是在WebAssembly虚拟机[7]中执行的，现有的Wasm虚拟机实现包括WAVM[8]、Wasmtime[9]、Wasmer[10]等。虚拟机是执行WebAssembly的基础设施，其应该正确、高效、鲁棒地实现。然而，如果虚拟机的实现有错误，WebAssembly的执行可能会导致错误的结果，或者程序会异常退出，其中一些错误甚至会导致安全漏洞。例如，在2018年，有7个CVE报告给名为WAVM的Wasm虚拟机[8]，为了避免这些情况，我们可以采用模糊技术[11]来识别虚拟机实现中的错误。 ​ 针对Wasm VM的fuzzing需要面对两大挑战： 首先，Wasm VM经常在执行前进行Wasm代码验证（validation），这使得它很难产生有效的输入以达到虚拟机内的深层逻辑。虽然主流的fuzzing软件AFL可以用来测试用C/C++编写的WebAssembly虚拟机，但它们生成的测试用例都是二进制数据，没有考虑Wasm字节码语法，很难通过Wasm虚拟机通常进行的代码验证； 其次，WASM VM有许多不同的实现，它们有不同的代码结构和bug模式，使用固定的突变策略很难适应这些Wasm VM之间的差异，从而达到最佳的fuzzing效果。 贡献 提出了一个名为WasmFuzzer的Wasm字节码级fuzzing框架，用于Wasm虚拟机，该工具可以生成和变异Wasm字节码模块，以达到Wasm虚拟机的深层逻辑; 提出了一种自适应突变策略，可以动态地更新不同mutation operator的概率，通过这种方式，我们可以为测试目标优化mutation operator的配置； 用WasmFuzzer对3个现实生活中的Wasm虚拟机进行了系统的fuzzing测试。我们的评估结果显示，WasmFuzzer在代码覆盖率和错误检测方面都比AFL更有效，而且WasmFuzzer在WAVM、WAMR和EOS-VM中检测到235个独特的崩溃。 模型 1. The Generation of Wasm Bytecode ​ 为WASM指令生成对应的参数分为两种情况： 从module中选择参数：如global.set id指令，其作用是将编号为id的全局变量置于栈顶，故其参数范围只能是module中global array中的参数（否则就会非法），故对于这种指令仅仅从module中选择对应的参数； 从对应数据域内选择参数：对于确定参数type的指令，从对应的数据域随机选择一个数即可。 ​ WasmFuzzer扩展了WebAssembly Binary Toolkit（WABT）以帮助生成不同种类的指令。具体来说，它使用WABT的内部功能来生成不同种类的操作码，这些操作码与相应的参数相结合，以建立不同的指令。最后，这些指令被进一步组装成函数和模块，作为种子输入。 2. Mutation Operator for Wasm Bytecode 2.1 Mutation operations ​ Mutation operations被分为两类，对指令的变异和对其它的变异: ​ 为了确保变异的WebAssembly代码能够通过Wasm VM的验证[12]过程，我们控制不同的mutator的概率，使新生成的Wasm模块有更大的机会成为有效的输入。 2.2 Adaptive Random Mutation Strategy ​ 在变异步骤中，每个mutator都有被选中的概率。一般来说，我们的突变策略将通过动态增加mutator的概率来奖励导致新的代码覆盖率或崩溃的mutator，这样一来，那些更有 \"前途 \"的mutator就有更大的机会被选中。 2.3 Test Oracle and Bug Report Generation ​ 当被测试的软件在fuzzing过程中崩溃或中止时，系统将发出信号，如SIGSEGV或SIGABT，WasmFuzer将捕获这些信号来报告错误。此外，WasmFuzzer还利用AddressSanitizer[13]来检测与内存有关的软件错误，如UAF、缓冲区溢出、堆栈溢出、内存泄漏等。 ​ 当WasmFuzzer检测到一个错误，它将生成错误报告，以方便进一步调试。错误报告包括两个部分：引发独特崩溃的Wasm字节码，以及引发独特挂起的Wasm字节码。通过 \"独特\"，它意味着这些Wasm字节码的执行导致了独特的代码路径。此外，我们还测量了在fuzzing过程中实现的代码覆盖率，作为另一个指标。 ​ 3. EVALUATION ​ 测试了三个WASM VM：WAVM, WAMR, EOS VM，都是使用C/C++编写。 WebAssembly virtual machine（github 2.5k starred），WAVM，是一个为非浏览器WASM应用设计的应用； WebAssembly Micro Runtime（github 3.9k starred），WAMR，是一个小型WASM虚拟机，经常用在嵌入式系统中； EOS-VM，是一个为区块链应用设计的WASM虚拟机。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Fuzzing","slug":"Fuzzing","permalink":"http://example.com/tags/Fuzzing/"},{"name":"WASM","slug":"WASM","permalink":"http://example.com/tags/WASM/"}],"author":"Shaw"},{"title":"(论文阅读)Fuzzing-A Survey for Roadmap","slug":"【论文阅读】Fuzzing-A-Survey-for-Roadmap","date":"2023-06-30T04:50:57.795Z","updated":"2023-07-02T12:46:47.758Z","comments":true,"path":"2023/06/30/【论文阅读】Fuzzing-A-Survey-for-Roadmap/","link":"","permalink":"http://example.com/2023/06/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Fuzzing-A-Survey-for-Roadmap/","excerpt":"Fuzzing: A Survey for Roadmap 时间：2022 作者：Xiaogang Zhu、Sheng Wen（澳洲斯威本科技大学） 期刊：ACM Computing Surveys（中科院一区） Abstract ​ 最近，模糊测试（fuzzing）在检测安全缺陷方面有着大量使用，它产生了大量的测试案例，并监控缺陷的执行情况，fuzzing已经在各种应用程序中发现了成千上万的错误和漏洞。 ​ Fuzzing虽然有效，但对其所面临的问题缺乏系统的分析。作为一种缺陷检测技术，fuzzing需要缩小整个输入空间（input space）和缺陷空间（defect space）之间的差距。如果对生成的输入没有限制，输入空间是无限的，然而，应用中的缺陷是稀疏的，这表明缺陷空间要比整个输入空间小得多。此外，由于fuzzing会产生大量的测试用例来反复检查目标，这就要求fuzzing以自动的方式进行，由于应用程序和漏洞的复杂性，对不同的应用程序进行自动化执行具有挑战性 ​ 在这篇文章中，我们系统地回顾和分析了这些gap以及它们的解决方案，同时考虑了广度和深度。这项调查可以作为初学者和高级开发人员更好地了解fuzzing的路线图。","text":"Fuzzing: A Survey for Roadmap 时间：2022 作者：Xiaogang Zhu、Sheng Wen（澳洲斯威本科技大学） 期刊：ACM Computing Surveys（中科院一区） Abstract ​ 最近，模糊测试（fuzzing）在检测安全缺陷方面有着大量使用，它产生了大量的测试案例，并监控缺陷的执行情况，fuzzing已经在各种应用程序中发现了成千上万的错误和漏洞。 ​ Fuzzing虽然有效，但对其所面临的问题缺乏系统的分析。作为一种缺陷检测技术，fuzzing需要缩小整个输入空间（input space）和缺陷空间（defect space）之间的差距。如果对生成的输入没有限制，输入空间是无限的，然而，应用中的缺陷是稀疏的，这表明缺陷空间要比整个输入空间小得多。此外，由于fuzzing会产生大量的测试用例来反复检查目标，这就要求fuzzing以自动的方式进行，由于应用程序和漏洞的复杂性，对不同的应用程序进行自动化执行具有挑战性 ​ 在这篇文章中，我们系统地回顾和分析了这些gap以及它们的解决方案，同时考虑了广度和深度。这项调查可以作为初学者和高级开发人员更好地了解fuzzing的路线图。 Generating input optimization ​ 如上图所示为fuzzing的基本流程，在生成输入时，其可以对seed set,seed schedule,byte schedule和mutation schedule做优化。 1. Seed Set Selection ​ 在保障代码覆盖率的前提下，seed set越小越好。这是因为多余的种子会浪费算力，重复检测已经检测过的代码块。COVERSET[158]将最小化种子集的问题表述为最小集合覆盖问题（MSCP），它最小化包含所有元素的子集。由于MSCP是一个NP-hard问题，COVERSET使用贪心多项式近似算法来获得最小集。 2. Seed Schedule ​ 在选择了Seed set之后，Seed Schedule的任务是从其中选择对应的种子用于后续操作，并为所选种子分配其可运行的最大时间。 ​ 由于 PUTs 与defects的复杂性，未发现代码覆盖率与未发现漏洞是不可知的，我们无法知道一个输入是否能触发漏洞，类似地在检索代码之前我们也不能获得程序行为的概率分布，数学上几乎不可能找到一个全局最优解法，因此研究人员基于多种优化方法来近似地解决这个问题。 2.1 Fitness by #Bugs ​ Fitness == 衡量seed/input指标。Fitness by Bugs意味着以发现bug的多少作为种子的评价标准。 为了使bug最多，一种方法是在随机或按顺序选择种子的同时，分配每个种子的时间预算。如果不考虑执行状态，最大化问题可以简化为整数线性规划（ILP）问题。也就是说，ILP打算在线性约束条件（例如每个种子的时间预算的上限值）下最大化bug的数量。通过解决ILP问题，可以自动计算每个种子的时间预算。 另一种见解是将发现bug的过程视为WCCP问题。经典概率问题：优惠券收集问题 - cnblogs.com ILP和WCCP都会给更可能发现bug的种子分配更多可用时间。 ILP和WCCP这两种理论上可以计算出全局最优解的算法需要知道环境的全部信息，由于这并不可能，所以基本效果都不好（例如强化学习中动态规划算法虽然可以直接求得全局最优策略，但由于环境信息不可知或算力限制，基本没有实际应用场景），只在早期使用。 2.2 Fitness by State Transition (Markov Chain) ​ 因为在PUT中，bug是稀疏的，当使用bug的数量作为fitness时，优化过程将迅速收敛到局部优化。因此，它可能会错过探索更多代码覆盖的机会，由复杂条件包裹的深层bug就会避开fuzzing。 ​ 为了缓解这个问题，fuzzer基于执行状态（如代码覆盖率）作为fitness，因为执行状态可以为fuzzing提供更多的信息。目前大多数现有的fuzzer都是基于代码覆盖率计算fitness。使用代码覆盖率的另一个原因是，更大的代码覆盖率表明发现错误的可能性更高[130]。 ​ 两种建模方法： Block transition Fuzzing之前通过蒙特卡洛采样（Monte Carlo method），计算出程序CFG中每个基本块跳转的概率Pij，进而计算出某个种子在执行过程中执行路径的概率（经过的基本块概率相乘）。种子对应的概率越低则fitness越高。 Path transition Pij这里代表从Seedi变异到Seedj的概率，每个P通过之前执行fuzzing结果计算，同样是概率越小fitness越高，更倾向于生成稀有的path。这里AFLFast[23]使用1/pij为每个种子分配能量，其还有变式：directed greybox fuzzing (DGF) [22, 217]和regression greybox fuzzing (RGF) [214]。 使用马尔科夫理论对state transition建模，以此优化seed schedule有一定效果，但其缺点是MC需要计算所有状态的概率。实际使用中，很多状态并没有被检测，故MC方法也容易陷入局部最优解（还是环境信息获取不全面的问题）。 2.3 Fitness by State Transition (Multi-armed Bandit) ​ 前置知识： rule of three(statistics)：如果前n次采样事件a都没有发生，则有95%的置信度表明至多3/n的概率事件a会发生。Rule of three (statistics) - HandWiki； Round-Robin Scheduling：轮询调度算法； ​ 对于MC建模方法导致的问题： 对于使用MC的Block transition：可以使用统计学中的rule of three规则来为未出现的state赋概率值； 对于使用MC的Path transition：使用Round-Robin Scheduling先为每个seed赋相同的time budget，后续经过不断采样再使用计算的概率值。但这么做的问题就是不好平衡Round-Robin和Markov，搜索有所seed和聚焦于某个seed是一个“exploration and exploitation”问题（又是经典的e and e问题）。 ​ 综上，为了解决这个问题引入了Multi-armed Bandit模型。 多摇臂老虎机，Multi-armed Bandit是强化学习中的经典模型，老虎机有n个摇杆，每个摇杆i有P~i~的概率中奖，每次可以选择一个摇杆拉下。&lt;u&gt;玩家的目的是通过有策略的尝试，找到中奖率最高的摇杆（因为这么做就可以reward期望最大化）。&lt;/u&gt;在MAB游戏中，其exploration代表不断尝试不同的摇杆，获取其对应reward的期望，也就是对环境采样；其exploitation代表找到最好的策略使reward最大化，这里最好的策略就是只拉下中奖概率最高的摇杆。 ​ 在fuzzing中，一个seed就是一个摇杆（arm），对应的reward就是该seed运行时的一系列发现。 ​ EcoFuzz[203]将其建模为一个MAB问题，并使用\\(E(t_i)=1-\\frac{P_{ii}}{\\sqrt{i}}\\)来表示每个seed ti的期望（而不是最开始的新路径数/变异次数，因为这样会导致期望越来越小，梯度过小，比较结果不明显），这里Pii表示一个种子变异后仍走原来路径的概率，故EcoFuzz更偏向可以生成新路径的种子； ​ AFL-HIER[88]也将其建模为一个MAB问题，不同于EcoFuzz只使用了单一的edge coverage来retain新的种子，AFL-HIER利用了更多评价标准（函数，edge，基本块等），其使用一个MAB算法UCB1来解决多等级评价标准MAB问题。 2.4 Fitness by State Discovery ​ 物种发现问题：生态学家从野外收集大量样本，样本中的物种可能是丰富的或罕见的。生态学家根据这些样本推断出一个完整组合的属性，包括未发现的物种。 ​ 同样地，fuzzer产生的输入是收集的样本，而程序的输入空间是整个集合体。fuzzing算法根据特定的指标将输入归类为不同的种类。例如，一个执行路径可以是一个物种，所有行使该路径的输入都属于这个物种。在这种情况下，一个罕见的物种是一个只有少数输入行使的执行路径。物种发现中的一个重要假设是，未发现的物种的属性几乎只能由已发现的稀有物种来解释[31]。这个假说意味着fuzzing可以给稀有物种（稀有路径）分配更多的能量来发现新的状态。 ​ 基于物种发现的问题，Entropic[21]将fuzzing理解为一个学习过程；即fuzzer逐渐学习更多关于程序行为的信息（物种）。Entropic建议使用Shannon’s entropy（香农熵）[170]来衡量物种发现的效率，原始的香农熵H衡量物种的平均信息，计算公式为\\(H = -\\sum_i{p_ilog(p_i)}\\)，其中pi是选择物种Si的概率。如果收集的样本包含许多物种，熵H就大（信息量大）；否则，如果收集的样本包含少数物种，熵H就小（信息量小）。 ​ 同时，Entropic认为，物种的发现率可以量化fuzzer的效率。根据香农理论推导，Entropic衡量种子的物种发现效率。具体来说，\\(p_i^t\\)是变异种子t并产生属于物种Si的输入的概率。种子t的学习率是根据概率\\(p_i^t\\)和改进的熵估计器计算的。通过熵得出的结论是，更多的能量被分配给学习率较大的种子；也就是说，发现新物种更有效的种子被分配更多的能量。 3. Byte Schedule ​ Byte Schedule的作用是决定在种子中选择一个字节来进行变异的频率。大多数fuzzer通过运行信息来启发式或随机地选择字节。相较于Seed Schedule，Byte Schedule需要对程序有着跟深入的理解，例如对路径条件和数据流的分析。 ​ 定义The importance of bytes：bytes如何影响fuzzing。 影响branch behavior：NEUZZ [172]和MTFuzz [171]将输入bytes和branch behaviors之间的关系通过深度学习模型建模，DL模型的梯度量化了bytes的重要性，因为一个bytes的梯度越大，该bytes的很小的扰动就会导致branch behaviors的重大差异。故对于接下来的种子变异，fuzzing将优先考虑具有较高重要性的bytes进行突变。 影响fitness：AFLChurn [214]利用了Ant Colony Optimization (ACO)，蚁群优化算法来学习bytes如何影响种子的fitness。 4. Mutation Operator Schedule ​ Mutation Operator Schedule的作用是选择一个变异操作来对所选bytes进行变异，Mutation Schedule决定了下一次变异bytes时使用那种变异方法，即变异器（mutator）。 ​ Classfuzz [42]认为探索了更多新状态的mutator被选中的概率应该更高，因此，Classfuzz假设Markov Chain Monte Carlo (MCMC)可以对Mutation Schedule的过程进行建模，其采用了H-M(Metropolis-Hastings)算法。具体来说，每个突变器都有一个成功率，它可以量化突变器所探索的新状态。Classfuzz首先随机选择下一个变体，然后根据当前变体和所选变体的成功率来接受或拒绝选择。 ​ MOPT[116]采用了Particle Swarm Optimization (PSO)，粒子群优化算法来对mutator选择过程建模，构建mutator选择的概率分布。 5. Diverse Information for Fitness ​ Fitness除了应用于schedule of seeds, bytes, 和mutators，也可以被应用于seed retention。Fuzzers通常利用遗传算法（GA）来制定种子保留的过程。具体来说，fuzzer通过变异种子生成输入，如果输入探索到新的执行状态（即更好的fitness），则该输入会被保留为新的种子。当为下一轮测试选择种子时（基于seed schedule），fuzzing可能会选择这个新的种子。 ​ 为了提高对defect发现的能力，需要更敏感的代码覆盖率来揭示更多的执行状态信息。另一方面，针对一些特定的场景，如深度学习模型[148]或机器人车辆[82]，设计了新的fitness类型。请注意，fitness信息的多样性在前面提到的seed retention和schedule问题上都得到了利用。 5.1 Sensitive Code Coverage ​ Fitness的敏感性表明其区别不同程序运行状态的能力。 ​ 许多coverage-guided fuzzers会实现一个bitmap用于向fuzzing提供edge-coverage的信息，bitmap本质上是一个紧凑的vector，其索引代表了对应edge的标识符，标识符是\\(hash(b_i,b_j)\\)，bi和bj是随机分配的块标识符。 ​ 如上图所示，如果存在哈希碰撞，导致\\(id_{AB}=id_{AC} , id_{BD}=id_{CD}\\)，则路径ABD和ACD就会被认为是一条路径。如果存在Bug路径ACDEG，则其会被fuzzer忽略。虽然这种实现在执行过程中速度很快，但它牺牲了edge-coverage的精度。 ​ 有了bitmap，fuzzing可以确定一个输入是否行覆盖了新的edge，如果有的话，就保留这个输入作为新的种子。具体来说，fuzzing维护一个总体bitmap，它是单个执行的bitmap的联合。当确定新边时，fuzzing将单个bitmap与整体bitmap进行比较，以检查单个bitmap中是否存在新边。 ​ 然而，位图的联合会失去执行的信息[118]。例如，如果图3(a)中的路径ABDEG和ACDFG已经被执行，那么执行新路径ACDEG的输入将不会被保留为种子，因为所有的边已经存在于整体bitmap中。因此，一个解决方案是将所有单个的bitmap组合起来[118]。因为bitmap的组合会引入太多的种子，一个关键的挑战是如何平衡fuzzing的效率和保持覆盖率的敏感性。一个潜在的解决方案是使用动态主成分分析[191]来降低数据集的维度[118]。 ​ 其他提高edge-coverage灵敏度的解决方案包括路径哈希[198]、调用上下文[37, 87, 171]、多级覆盖[88]和代码复杂性[105]，这些都为边缘覆盖增加了额外的信息。 ​ 专注于代码覆盖率的fuzzing也不一定适合探索复杂的执行状态。上图是一个迷宫程序，每次走一步，只有当走到出口时才会出发Bug。然而，由于switch语句只有四条edge，很快就会探索完，在这之后fuzzing就很难继续根据代码覆盖率来指导测试。 5.2 Diverse Fitness ​ Fitness并不一定非得用code coverage，实际上，code coverage不是一直是最好的适合fuzzing反馈信息。如果没有code coverage，一个直觉上的做法是根据执行结果保留种子，如执行结果的合法性[141]或协议实现的状态机[154]。不同的fitness如下： Legality of execution result：一个面向对象的程序（如Java）由一连串的方法调用组成，执行结果要么合法，要么抛出异常。Fuzzing生成并获得可以可以探索更多新的、合法的对象状态新的方法调用序列[141] ； State machine of protocol implementations：一个状态机由状态集合和转变其状态的输入组成。由于协议的复杂性，fuzzer通常通过逐渐向状态机添加新的状态来推断状态机[55, 61, 64, 69, 154]。状态机从一个种子（即初始状态机）开始，fuzzer对状态机的当前状态进行突变以探索新的状态。漏洞的分析是基于状态机的，其目的是为了搜索导致漏洞的转换[55]； Safety policy of robotic vehicles：安全策略是对机器人车辆的物理或功能安全的要求，例如车辆发动机的最高温度[82]。当一个输入更接近于违反政策时，该输入就会被保留下来，供以后突变使用； Fitness for deep learning systems：The fuzzing of deep learning systems (DLSs) 旨在提高它们的鲁棒性和可靠性[68, 115, 148]。为了实现这一目标，fuzzer设计了不同类型的fitness，例如用于发现角落状态的神经元覆盖率[148]，用于增强训练数据的损失函数[68]，或者用于探索深度学习推理引擎（即框架和库）的操作者级覆盖率[115]。 Validation log of Android SmartTVs：验证日志是正在执行的Android智能电视的信息[1]。验证日志被用来推断有效输入和提取输入边界。有效输入为fuzzing提供了有效的种子，而输入边界则减少了输入的搜索空间。 Behavioral asymmetry of differential testing：对于差分测试(differential testing)，错误是通过观察不同实现的行为差异发现的，这些实现具有相同的功能，在相同的输入上。行为的不对称性表明各种实现的差异程度。模糊测试的目的是生成能够发现更多差异的测试案例； Alias coverage for data race：别名覆盖是为了检测内核文件系统中的数据竞争[194]。数据竞争是一个并发的错误，其中两个线程访问一个共享的内存位置而没有适当的同步。因此，别名覆盖跟踪可能相互交错的内存访问对； Dangerous locations for bugs：危险的位置（Dangerous locations）是那些有更高概率触发错误的代码区域。因此，fuzzer可以将资源引向这些位置，以提高fuzzing的效果和效率。对于并发性错误，危险位置通常是指导致违反原子性的代码区域[97]、数据竞赛[84, 167]或可疑的交织[35]。对于非并发性错误，危险位置可以通过补丁测试[122]、崩溃再现[155]、静态分析报告[48]或信息流检测[123]获得。此外，危险位置可能是内存访问[84，182，188]，sanitizer检查[40，140]，或提交历史[214]。 ​ 6. Evaluation Theory ​ Fuzzing的评测通常与检测阶段分开进行，然而，我们认为评估是fuzzing过程的一部分，因为适当的评估可以帮助提高fuzzing的性能[215]。适当的评价包括有效的实验corpus[215]、公平的评价环境/平台[30, 104, 126]、合理的fuzzing时间[17, 20]和全面的比较指标[96, 104]。尽管这些研究工作在适当的评价方面做出了努力，但关于如何评价技术（即fuzzing algorithms）而不是实现（即实现算法的代码），仍然是一个开放的问题[18]。一个广泛使用的解决方案是基于统计测试来评估fuzzer，它提供了一个反映模糊技术之间差异的可能性[96]。 7. Summary ​ 下表表明了不同fuzzing processes使用的不同优化方法来优化input generation： Solution: MC:Markov Chain MSCP:Minimal Set Cover Problem，最小集合覆盖问题； Tutorial-覆盖问题 ILP:Integer Linear Programming Problem，整数规划问题； WCCP:Weighted Coupon Collector’s Problem，彩票收集问题； VAMAB:Variant of Adversarial Multi-Armed Bandit，对抗性多臂老虎机的变种； UCB1:Upper Confidence Bound算法，解决MAB问题的一种算法； MH:Metropolis-Hastings采样； PSO:Particle Swarm Optimization，粒子群优化； Shannon:香农理论； **Species*:**Models of Species Discovery，物种发现模型； ACO:Ant Colony Optimization，蚁群优化； SA:Simulated Annealing，模拟退火算法； NN: 神经网络； MTNN:Multi-task Neural Networks，多任务NN； GA:Genetic Algorithm，遗传算法； GD:Gradient Descent，梯度下降； MOO:Multi-objective Optimization，多目标优化； R:Random，随机。 set:Seed Set Selection seed:Seed Schedule byte:Byte Schedule mutation:Mutation Schedule rete:Seed Retention-&gt;将测试过程中生成的有价值的input加入population Input space optimization ​ 上一节描述了fuzzer可以通过优化输入的生成来提高效率，这一节讲解其如何通过减少输入空间来优化。 ​ Fuzzer可以将输入中的相关bytes分组，并对每组应用特定的mutator。假设一个输入包括a×b个字节，并被平均分成a个部分；那么在解决一个特定的路径约束时，fuzzing的搜索空间是\\(a\\times256^b\\)，而不是\\(256^{a\\times b}\\)。 ​ 相关联的字节可以是构建相同数据结构的字节[16, 201]，影响相同路径约束的字节[37, 38, 65, 67, 157, 160, 187]，或者符合语法的相同部分[78, 115, 120, 136, 181, 197, 212]。Mutator包括字节突变（例如，比特翻转、字节删除和字节插入）[23, 206]和块突变（例如，块替换、块删除和块插入）。 ​ 如上图所示，输入被分为了变量i、k和数组a，如果前面的条件满足（line13），则当判断到14行时，整个搜索空间就只剩1bytes了。例如，如果在全局输入空间对上图（a）中的line14的条件进行检验，fuzzing需要生成\\(256^{11}\\)个输入来遍历所有可能的情况（输入有11个字节）。但如果根据源码分析，只有第11个字节才影响a[2]的值，那么只需要变异这一个字节即可，故只需要生成256个输入就可以遍历所有可能情况。 ​ 一种特殊的输入是高度结构化的输入，它被用于协议实现、文档对象模型（DOM）引擎和编译器等应用。如图上图所示，cJSON解析器要求一个输入的片段以某些特定的字符开始，如果一个输入违反了这个要求，那么这个输入就不允许检查解析器所保护的功能。 1. Byte-constraint Relation ​ 对于大多数路径约束，它们只受输入的一小部分影响。如果fuzzer只对相关的字节进行变异，那么通过减少输入的搜索空间，fuzzing的性能可以得到明显的改善（如上图a)，这就是byte-constraint relation。 ​ 在获得Byte-constraint relation后，一个简单的变异方案是随机地变异相关的字节[67, 157, 187]。一个更统一的方法是将一个字节的值分别从0到255设置[172]。然而，这两种方案是无效的，因为它们并不了解其生成的输入的质量。如果byte-constraint relation的推断过程可以获得程序中比较指令的值，fuzzing就可以突变相关的字节，并选择在通过路径约束方面取得进展的输入。此外，fuzzer可以利用梯度下降算法来突变相关字节并逐渐解决路径约束[37, 38]。 1.1 Dynamic Taint Analysis ​ 动态污点分析，Dynamic taint analysis (DTA)，是一种常见的技术，用于建立输入字节和路径约束之间的关系。DTA在输入中标记某些数据，并在执行过程中传播这些标签，如果程序中的一个变量获得了一个标签，该变量就会被连接到具有该标签的数据上。Fuzzer[37, 38, 67, 157, 160, 187]一般利用DTA在输入字节和安全敏感节点（系统/库调用，条件跳转）之间建立关系。 DTA需要大量的手工工作，并且由于隐含的数据流，也可能导致不准确的关系。 1.2 Relation Inference ​ 由于fuzzing用许多测试用例测试目标程序，一个轻量级的解决方案是在运行时推断bytes relation。一种方法是观察一个字节的突变是否改变了一个变量的值[65]、一个比较指令的结果[7, 103, 200]或一个分支的命中率[101]，如果改变了，该字节就会分别与该变量、比较指令或分支相联系；另一种推理方法是基于深度学习[172]在输入字节和分支行为之间建立近似的联系。 2. Concolic Execution ​ Concolic Execution也被成为动态符号执行，同时利用符号执行和fuzzing的技术被称为hybrid fuzzing或whitebox fuzzing。 ​ Hybrid fuzzing一个改进是优先选择最难最复杂的路径让Concolic Execution解决[210]。除了路径选择，Hybrid fuzzing的性能还可以通过开发近似的SMT约束条件求解器来提高；约束解算器也可以根据目标的特点进行改进。在嵌套条件方面（如图4（a）中的第13-15行），Pangolin[81]提出了多面体路径抽象来解决嵌套路径约束。多面体路径抽象保留了历史约束的解空间，并重用该解空间来满足当前路径约束的可达性。例如，为了解决图4(a)第14行的约束，输入必须首先满足第13行的条件。为了在需要高度结构化输入的程序中利用混合模糊法，Godefroid等人[71]首先将语法中的token符号化为符号变量。然后，他们使用上下文自由约束解算器来生成新的输入。 3. Program Transformation ​ 对于fuzzing来说，程序转换的目的是去除阻碍fuzzing发现更多执行状态的合理性检查。通过移除这些检查，fuzzing可以探索目标程序中的深层代码并暴露出潜在的bug[150]。去除后会引入许多错误位置的假阳性，这可以通过符号执行来进一步验证。因此，程序转换通过专注于可能潜在触发bug的输入来减少搜索空间。 4. Input Model ​ 例如像协议处理、DOM引擎、JS引擎、PDF阅读器、系统调用或编译器等程序都需要高度结构化的输入，input model代表着构建高度结构化输入的一系列规则，包括结构、格式、数据限制等。为了生成满足规范的输入，生成过程限制只能做特定的操作，如果一个输入违反了目标程序的语法或语义，该输入将在早期阶段被程序拒绝，换句话说，input space要受制于input model。 4.1 Accessible Models or Tools ​ 许多fuzzer通过Accessible Models或者现有的工具来生成有效输入，由于规范的解析很复杂，所以容易出错。图4(b)中的cJSON解析器是对JSON规范的实现，由于对不同数据类型的复杂解析，它虽然简单，但却容易出错。因此，研究界已经开源了一些用于高度结构化输入的工具，例如QuickCheck[50]和ANTLR[146]。例如，NAUTILUS[5]和Superion[186]基于ANTLR生成新的输入。然后，NAUTILUS和Superion都使用代码覆盖率来优化变异过程。在某些情况下，input model可以只是生成的数据符合的类型（例如，API参数或物理信号的类型）[1, 41, 70, 179]。例如，网络物理系统（CPSs）的执行器的数据可以是二进制的开或关[41]。 4.2 Integration of Implementations ​ 另一种有效方法是将fuzzing与目标应用程序的实现相结合[64, 89, 173]。这种整合允许fuzzing通过定制输入生成过程来检查目标应用程序的预期属性。例如，TLS-Attacker[173]创建了一个框架，可以根据每个片段的类型突变输入，并操纵协议信息的顺序。这个框架包括一个完整的传输层安全（TLS）协议实现。 4.3 Intermediate Representation ​ 一个更复杂的方法是将input model转换为中间表示法（IR）。对于高度结构化的输入，对原始输入文件的突变过于复杂，无法保持语法和语义，因此，研究人员将原始文件翻译成IR，使其更简单和统一。Fuzzer对IR进行突变，然后将突变后的IR再翻译成原始输入格式，这种变异策略可以保持句法或语义的正确性，并产生更多不同的输入。例如，IR被用来测试数据库管理系统（DBMS）[212]，检查DOM引擎[197]，或模糊不同的语言处理器（例如，编译器或解释器）[43]。 5. Fragment Recombination ​ 片段重组的基本思想是将输入文件分成许多小块（即片段），然后通过合并不同输入文件的小块来生成一个新的输入文件。每个片段都符合输入的规格，因此重新组合的输入文件在语法上是正确的。理想情况下，重新组合的输入文件将行使一个新的执行路径或暴露出一个新的错误。 ​ 如图5所示，fuzzer首先将输入文件解析成一棵树（如抽象语法树（AST）），它保持了句法的正确性。为了正确解析输入，输入语料库必须是valid的[78, 180, 185, 199] ，其可以从网络上下载。 ​ 除了有效的输入，fuzzer也会收集有问题的输入，这些输入之前已经引起了无效的行为[80，99，145] 。基本假设是，在输入已经发现错误的位置或附近，可能仍然存在新的错误[80]。有问题的输入已经行使了复杂的执行路径，导致无效的行为。因此，片段的重新组合可能会行使相同或相邻的复杂路径，这有助于fuzzer探索深层代码行。在第二阶段，输入文件被分离成许多片段，这些片段被储存在片段池中。因为模糊分析器将输入解析成AST，所以片段可以是包含非终端的子树。当重组片段时，要求新生成的输入文件在语法上是正确的。因此，模糊器基于随机选择[80, 120, 199]、遗传算法[180]或机器学习[185]来重组句法兼容的片段。除了句法上的正确性，语义上的正确性对fuzzing的有效性也有很大影响。例如，为了生成句法和语义正确的JavaScript输入，CodeAlchemist[78]用汇编约束来标记片段。也就是说，只有当约束条件得到满足时，不同的片段才会被合并。 6. Format Inference ​ 如果input model无法访问，推断输入的格式是产生有效输入的一个有效方法。此外，一个input model只能生成具有特定格式的输入，为了支持更多格式的输入，开发者必须利用新的input model，并在生成输入时选择相应的input model。因此，格式推理比基于模型的方法更具可扩展性。 6.1 Corpus-based ​ 为了推断格式，一个直接的方法是向有效的输入语料库学习。由于缺乏input model，研究人员建立端到端的深度学习模型来替代input model。RNN是fuzzer生成结构化输入的一个较好的深度学习模型[74, 79, 111, 112]。然而，通过使用深度学习来代替input model的方案可能会受到生成无效输入的影响。例如，DeepFuzz[112]生成有效语法输入的最高比率仅为82.63%。 ​ 为了提高有效输入的生成率，需要对训练数据进行相应的改进。例如，在生成PDF文件时，训练数据是由PDF对象的序列组成的，而不是文本数据。对于智能合约，训练数据是关于交易的序列[79]，类似地，LipFuzzer[208]训练对抗性语言学模型以生成语音命令，其中训练数据是通过语言结构呈现的。此外，fuzzing可以根据有效的输入语料库合成一个context-free grammar（例如，重复和交替等规则属性）[12]，然后利用合成的语法来生成高度结构化的输入。 基于语料库的解决方案要求训练数据全面覆盖输入规范，这可能并不实际。此外，它不使用来自内部执行状态的知识（例如，代码覆盖率），这可能导致低代码覆盖率。 6.2 Coverage-based ​ 从本质上讲，输入的格式表明输入中不同字节之间的关系。因此，在代码覆盖率的基础上，fuzzer推断字节与字节之间的关系，以促进fuzzing过程。 GRIMOIRE [16]使用代码覆盖率来推断目标程序所需的格式，它的目的是识别输入的格式边界。具体来说，它改变了输入中的一些字节，并检查这些改变是否会导致不同的代码覆盖率。如果代码覆盖率保持不变，则可以随机地改变该字节。否则，这些位置就需要仔细地进行变异； ProFuzzer[201]首先定义了六种数据类型，涵盖了大多数输入内容。然后，根据边缘覆盖率的分布，它推断出每个字节的类型，并将属于同一类型的连续字节合并。 6.3 Encoding Function ​ 与上述所有专注于输入的方法不同，一些fuzzer聚焦于搜索编码输入格式的代码区域。因为这样的代码区通常负责生成结构化的输入，所以fuzzer在编码输入的格式之前进行变异操作。尽管PUT的源代码可能无法访问，但其生成结构化的输入的相应实现通常可以访问。 ​ 举例来说，物联网设备中的大多数是通过配套的应用程序控制的，这些应用程序生成与目标设备通信的消息[36]。通过定位与编码格式相关的代码区域，可以对函数的参数[36, 159]或计算格式的指令[92]进行变异操作。例如，IoTFuzzer[36]钩住此类函数，并对这些函数的参数数据进行突变。 Format inference主要用于满足程序所需的句法格式，但其仍可能生成错误的数据。 如上图js代码所示，虽然snippet 2满足程序所需的数据格式，但line2-5有一个语义错误，原因是errf()函数未定义。 7. Dependency Inference ​ 许多应用程序要求输入中的数据依赖性正确，而这些数据通常是由语句序列组成的。这些序列包括内核代码的系统调用[77, 95, 142]，面向对象程序的处理器的对象[59, 117]，服务/库的应用编程接口（API）[8, 83, 110]，或智能合约的应用二进制接口（ABIs）[86]。一方面，这些应用大多需要在使用输入的数据之前进行定义/声明，如图6所述。另一方面，执行一些语句的输出是其他一些语句的参数数据。 7.1 Documents or Source Code ​ 序列的数据依赖性通常是通过静态分析推断出来的。因为许多应用程序都有描述其界面的文件或源代码，研究人员根据这些资源推断出数据依赖性[8, 53, 59, 86, 110, 117]。这些资源包含了如何使用一个接口的信息和接口的预先需求。当fuzzing生成包括接口的输入时，fuzzing也需要生成接口的先决条件，否则，生成的输入将在早期阶段被拒绝。 ​ 然而，静态分析会带来很高的误报率，并且会遗漏接口的依赖关系。因此，当有机会接触到PUT的源代码时，更好的解决方案是结合静态分析和动态分析[95]。 7.2 Real-world Programs ​ 许多现实世界的程序实现了调用接口的代码行，这些代码行已经考虑了接口的数据依赖性。因此，fuzzing可以根据对现实世界程序进行的程序切片，合成调用接口的新程序[10]。 ​ 此外，通过分析那些真实世界程序的执行日志，可以推断出数据的依赖性[77, 83, 142]。执行日志明确地包含了接口的排序信息，也就是哪个接口先被执行的信息。此外，执行日志还隐含了接口之间的参数依赖性信息。为了获得显性和隐性信息，在执行真实世界的程序时，fuzzing会钩住每个接口并记录所需的信息。 8. Summary ​ 下表描述了减少搜索空间的方法和用于分组输入字节的关系，其方法都减少了输入空间： Automation ​ 自动化分为三个部分：自动化运行PUT；自动化检测是否发生了bug；更快的运行速度。针对这三个部分： 大多数fuzzer已经成功地自动化运行命令行软件，但它们不能直接用于其他目标，如硬件或多语言软件； 目前fuzzing一般使用crash作为是否发生Bug的检测指标，但类似data race等bug可能并不会发生crash。 1. Automatic Execution of PUTs ​ 这一段介绍了fuzzing针对不同应用场景下自动化执行程序的方法。 1.1 Command-line Programs ​ Fuzzing在命令行程序的测试上取得了巨大的成功。 ​ Fuzzing在一个子进程中运行PUTs，然后将程序需要的参数和输入传递给它。为了提高执行速度，fuzzing不会重复执行测试一个PUT的所有步骤。相反，它克隆了一个子进程，以便跳过预处理步骤，如将程序文件加载到内存中等。 ​ 通常，fuzzing对所有测试只采取同一个命令行选项，也就是说，所有生成的输入都使用同一个命令行参数。因为不同的选项表示不同的代码覆盖率，所以一个彻底的测试需要在fuzzing期间列举所有的命令选项。一个有效的方案是，如果一个输入对一个选项无效，fuzzing会跳过对所有其余选项的测试[176]。这个方案的一个重要观察点是，如果一个输入对一个选项无效，那么这个输入将使所有其他的选项失效。 1.2 Deep Learning Systems ​ 对于深度学习系统，输入就是training data、test data甚至是深度学习模型。输入的fitness可以是neuron coverage（神经元覆盖率）、loss function或者operator-level coverage。 ​ 对于深度学习系统，fuzzing不仅检测其可能出现的错误，还可以检测其鲁棒性。 1.3 Operating System Kernels ​ 对于操作系统，其更为复杂，内核包括许多中断和内核线程，导致非确定性的执行状态。Fuzzing一般选择用hypervisor虚拟机（QEMU、KVM等）来运行目标内核，同时通过Intel的Processor Trace (PT)技术来获取代码覆盖率。 ​ 操作系统的输入通常是文件系统镜像（file system image）或系统调用序列，fuzzer可以通过对内核进行数据独立性分析后生成对应的系统调用序列来测试内核，然后检测该序列的运行情况来判断结果。另一种fuzzing操作系统内核的方法是模拟外部设备，由于内核与仿真设备进行通信，fuzzer可以产生输入来测试内核中的驱动程序。 1.4 Cyber-Physical Systems Cyber-Physical Systems（CPS），信息物理系统，物理和软件组件在不同的空间和时间尺度上运行。其应用包括自动汽车系统、医疗监控、过程控制系统、机器人系统、自动飞行员电子设备、智能电网、交通物流系统等。 ​ CPS包括两个主要部件，计算单元和物理进程。一个广泛使用的计算单元是可编程逻辑控制器（PLC），它控制执行器来管理物理过程并接收来自传感器的输入。因此，在对CPS进行fuzzing时，fuzzer可以取代PLC，直接通过网络向执行器发送大量指令[41]。另一种fuzzing测试CPS的方法是检查PLC的控制应用程序和运行时间[179]。然而，PLC的二进制文件不能像摸索命令行程序那样被摸索。因为PLC应用程序有各种二进制格式，并与物理组件进行复杂的通信，这些应用程序的自动化程度各不相同。基于对PLC二进制文件及其开发平台（如Codesys）的分析，在PLC设备上运行PLC二进制文件时，有可能自动进行fuzzing[179]。 1.5 Internet of Things ​ 对物联网的fuzzing包括了模拟（emulation）和网络层级测试（network-level test）。仿真器（emulator）[34, 205]可以模拟执行原本在物联网固件上运行的程序，在仿真器的帮助下，fuzzer以灰盒方式运行目标程序[211]。 ​ 另一方面，网络层面的fuzzing以黑箱方式检查物联网设备，由于物联网设备可以通过网络与外界进行通信，fuzzer自动向物联网设备发送消息（请求），并等待物联网设备的执行结果（响应）[36, 63, 159]。通过对响应进行分类，fitness是类别的数量，也就是说，目的是为了探索更多的类别[63]。 1.6 Applications with Graphical User Interface ​ GUI程序的执行速度比命令行程序慢很多，而在fuzzing中执行速度又很重要，故一般对GUI程序的测试都将其替换为一个更快的命令行执行方法。举例来说，fuzzer可以对用户界面的互动进行建模，从而为Android应用程序生成事件序列。此外，fuzzer还可以利用准备好执行环境的约束条件，直接调用图形用户界面中的目标函数。 1.7 Applications with Network ​ 一些例如智能合约、协议处理、云服务、安卓原生服务、智能驾驶等应用程序通过网络接受输入，因此，输入可以在本地生成，而目标应用程序的执行可以在远程进行。自动测试的效率依赖于生成的输入的质量，以及反映执行状态的fitness。例如，智能合约的输入是合约交易的序列，即不同账户之间的信息。当收到交易时，智能合约中的功能在其区块链的基础设施上执行。 2. Automatic Detection of Bugs ​ 这一段介绍了如何自动的检测是否发生了bug，介绍了6中成功被fuzzing检测的bug： 2.1 Memory-violation Bugs ​ Memory-violation，内存损坏，是一种最古老又最严重的安全bug，其可以分为两类（如下图）： spatial safety violations：out-of-bounds，内存越界访问，如（a）； Buffer overflow是Out-of-bounds的一种经典样例，Dowser [76]认为其主要由于在循环中访问数组引起。为了检测循环中的缓冲区溢出，Dowser对循环中访问缓冲区的指令进行排序，并对行使较高等级访问的输入进行优先排序。然后，它使用污点分析和concolic execution来解决所选输入的路径约束。由于Dowser专注于循环中的数组，因此只需要对少量指令进行检测。这种关注提高了污点分析和concolic execution的执行速度。 temporal safety violations：UAF，如图（b）; UAF是temporal safety violation的经典样例，其包含了分配、释放和再次使用三个步骤，这种错误模式促使UAFL[184]（ICSE‘2020）生成能够逐渐覆盖潜在UaF的整个序列的输入，潜在的UaF序列是通过基于错误模式的静态类型状态分析得到的。 ​ 尽管有很多方法被发明出来用于减轻这两种漏洞的影响，但由于成本以及低兼容性问题，几乎没有在实际上使用。 2.2 Concurrency Bugs ​ 并发错误被分为以下几类： deadlock bugs 发现死锁的一个解决方案是检测锁序图，其中每个节点代表一个锁[4]，如果图中存在一个闭环，就会检测到一个潜在的死锁[90]。为了提高循环检测的效率和可扩展性，MagicFuzzer[27]迭代地删除图中的锁，如果这些锁不包括在任何循环中。然后，MagicFuzzer根据一个随机调度器检查剩余的周期。 non-deadlock bugs atomicity-violation bugs： 违反原子性原则bug，如下图（a）所示，line3需要在line1之后运行，但由于Thread 2在中间改变了p-&gt;info的值，导致产生错误。 ATOMFUZZER[144]观察到一个典型的错误模式，即一个原子块内的锁被两个线程反复获取和释放。具体来说，如果一个原子块内的线程t要获取一个之前已经被t获取和释放的锁L，ATOMFUZZER会延迟线程t的执行，并等待另一个线程t ′获取该锁L，当另一个线程t ′在线程t的延迟期间获取该锁L时，就是一种原子性违反。 order-violation bugs： 内存被以错误的顺序访问，如下图（b）所示，Thread2中的mThd-&gt;State在线程1中的mThd初始化之前被执行，这就产生了一个错误，使用未初始化的变量。 ​ 更为普遍的说 ，并发错误的发生是由于线程的不正确交织。挑战在于，并发程序可能有太多的交错状态，无法逐一检查（即状态爆炸问题）。CalFuzzer[166]基于以下事实缓解了状态爆炸问题：一些交织是等价的，因为它们来自非交互指令的不同执行顺序。这种等价性表明，对它们的执行将导致相同的状态。CalFuzzer随机选择一组线程，这些线程的后续指令互不交互，并同时执行这些指令。因此，CalFuzzer[166]可以更有效地检查不同的交织。 2.3 Algorithmic Complexity ​ Algorithm complexity (AC)漏洞指的是当一个算法的最坏情况下的复杂性导致大大降低性能，这可能导致拒绝服务（DoS）攻击。 ​ 如上图所示的代码，array = [8,5,3,7,9]和[1,5,6,7,9]两种输入导致quicksort的算法复杂度是完全不同的。 SlowFuzz[152]通过引导fuzzing向增加执行指令数量的方向发展，来检测AC错误； HotFuzz[15]通过最大化单个method的资源消耗来检测Java method中的AC错误； MemLock[44]根据边缘覆盖率和内存消耗这两个指标来检测AC错误，它将fuzzing引向那些能够发现更多边缘或消耗更多内存的输入; 前面提到的fuzzer直接生成最差性能的输入（WPI）来发现AC错误。相反，Singularity[190]根据对这些WPI总是遵循一个特定模式的观察，合成了用于生成输入的程序。 2.4 Spectre-type Bugs ​ 有零漏洞是一种微架构攻击，利用错误预测的分支推测来控制内存访问[139]。例如，在图10中，攻击者可以为变量input发送几个in-bound值，这将训练分支预测器来推测第2行的检查是否总是真的。当攻击者为输入发送一个超限值时，预测器将错误地预测分支行为，第3-4行被投机性地执行（即在没有第2行检查的情况下被执行）。由于输入实际上并不满足第2行的检查，第3-4行的执行会导致缓冲区超读。 ​ 因此，SpecFuzz[139]对目标程序进行分析，以模拟投机执行，它可以强制执行错误预测的代码路径。然后，错误预测的路径中的任何无效内存访问都会被触发。 2.5 Side Channels ​ 侧信道漏洞通过观察系统的非功能行为（如执行时间）泄露秘密信息。例如，如果一个秘密是语句 \"if (a &gt; 0){...}else{...}\"中的变量a，人们可以观察then-branch和else-branch的执行时间来判断a的值是否大于0。一种特殊的边信道被称为JIT诱导的边信道，它是由及时优化（JIT）引起的[25]。与前面提到的Spectre型bug类似，人们可以反复运行程序来训练JIT编译器，使其优化the then-branch或else-branch的执行时间。然后，训练过的分支（如the then-branch）和未训练过的分支（如else-branch）的执行时间将有足够的偏差，可以被观察到。因此，变量a的秘密值被泄露了。 2.6 Integer Bugs ​ 当一个算术表达式的值超出机器类型所决定的范围时，就会发生整数溢出/下溢漏洞。另一方面，整数转换错误发生在将一种整数类型错误地转换为另一种整数类型时。 ​ 为了检测整数bug，SmartFuzz[132]根据不同的整数bug在符号仿真中加入了特定的约束。然后，符号解算器打算生成可能触发整数错误的具体输入。 3. Improvement of Execution Speed ​ 提升运行的速度对fuzzing非常重要，因为fuzzing会在time budget上会运行多个测试样例。 3.1 Binary Analysis ​ 作为一个预处理过程，fuzzing主要利用静态工具来获取执行状态，因为静态工具为fuzzing提供了高执行速度[58, 134]。一个广泛使用的静态分析工具是LLVM[113]，它在编译过程中对程序进行分析。 ​ 当面对不开源应用时，传统的额二进制插桩工具（如Dyninst）应用到fuzzing上时时间开销过大，为了解决这个问题： RetroWrite[58]提出使用基于可重构汇编的静态二进制重写技术。它的重点是通过利用PIC的重定位信息对汇编文件进行仪器化的64位独立代码（PIC）的二进制文件。由于RetroWrite可以对内联的代码片段进行检测，因此性能开销有所降低。尽管很快，RetroWrite只支持64位PIC二进制； 为了维护低运行时开销和可扩展性，FIBRE[134]通过四个IR修改阶段简化了代码插桩过程。这四个阶段通过静态重写、内联、跟踪寄存器的有效性和考虑各种二进制格式来检测程序。上述重写技术只重写一次二进制文件，这可能导致不健全的二进制重写，特别是对于剥离的二进制文件[189]； 为了解决这个问题，STOCHFUZZ[209]基于模糊处理重复执行目标程序的事实，提出了增量和随机重写技术。具体来说，STOCHFUZZ对目标二进制文件进行多次改写，并逐步修复之前改写结果所带来的问题。 3.2 Execution Process ​ 程序执行速度也可以提高。 UnTracer[133]观察到，在模糊处理过程中产生的大多数测试用例并没有发现新的覆盖范围。这表明，追踪所有的测试用例（AFL使用）会产生大量的运行时间开销。因此，UnTracer只跟踪覆盖率增加的测试案例，以提高执行速度。这是通过在基本块的开头插入中断来完成的。当一个块被检查时，UnTracer会删除该块的插桩代码，这样将来执行时就不会在该块被中断； 由于block coverage失去了执行状态的信息，CSI-Fuzz[216]利用边缘覆盖来改进UnTracer； Zeror[213]通过在Untracer-instrumented二进制和AFL-instrumented二进制之间自适应切换来改进UnTracer。对于hybrid-fuzzing，concolic execution被用来解决路径约束。然而，concolic execution中的符号模拟在制定路径约束时很慢，这是混合模糊法在扩展到现实世界应用时受到影响的主要因素; QSYM[204]通过删除一些耗时的组件，如IR翻译和快照，缓解了性能瓶颈。此外，它只收集和解决了一部分路径约束。尽管由QSYM生成的具体输入可能不是路径约束的精确解，但QSYM使用fuzzing通过改变这些具体输入来搜索有效输入； Intriguer[46]观察到，由于QSYM解决了许多不必要的约束，所以QSYM仍然存在性能瓶颈。然后，Intriguer对更多的相关指令进行了符号仿真，这是由动态污点分析决定的。除了插桩和hybrid-fuzzing，另一个优化是提高并行模式下的执行速度。Xu等人[195]观察到，AFL[206]在120个内核上并行运行时，速度明显减慢。这促使他们设计新的操作原语来提高执行速度。 3.3 Various Applications ​ 除了一般的应用，fuzzing也被用来检测不同领域目标的缺陷，如物联网、操作系统内核和虚拟机监视器（VMM）。由于这些目标通常有特殊的功能，所以模糊测试是为目标定制的，以便以有效的方式进行测试。 ​ 虽然仿真是一种很有前途的模糊物联网固件的方法，但全虚拟化的吞吐量很低。全虚拟化的运行时间开销主要来自于翻译内存访问的虚拟地址和仿真系统调用。 FIRM-AFL[211]通过结合用户模式虚拟化和全系统虚拟化来减轻开销，它主要在用户模式仿真中运行程序； 为了对VMM进行模糊处理，Schumilo等人[162, 163]设计了一个定制的操作系统和一个快速的快照恢复机制，以便有效地进行模糊处理。 至于文件系统，由于image太大，突变整个磁盘image会大大降低模糊处理的吞吐量。JANUS[196]只对种子image的元数据进行了修改；也就是说，它利用了结构化数据的特性。这个解决方案减少了输入的搜索空间，从而提高了吞吐量; 操作系统内核也可以通过外部设备被破坏，也就是说，漏洞是沿着硬件-操作系统边界发生的。为了检测设备-驱动通信中的缺陷，PeriScope[174]提出了基于内核的页面故障处理机制的Fuzz； Windows的应用程序与Linux的不同，因为它们大量使用图形界面，而且Windows缺乏快速克隆进程的方法。WINNIE[91]合成了一个运行没有图形界面的应用程序的约束。此外，它还为Windows实现了fork()来有效地克隆进程； BigFuzz[207]将数据密集型可扩展计算（DISC）应用程序转换为语义等价的程序，该程序独立于DISC框架。由于DISC框架引入了较长的延迟，独立于框架的执行方式显著提高了执行速度。 Gap ​ 综上所述，目前fuzzing解决的三个gap： Gap 1: Sparse defect space of inputs ​ 在应用程序中的漏洞分布是分散的，而仅有部分特定的输入能够触发漏洞；浅显的漏洞可以在短时间内被 fuzz 到，但许多安全漏洞需要测试复杂的执行路径并解决严格的路径约束，因此一个高效的 fuzzing 算法需要同时对 待测试程序（program under test， PUTs）与 安全缺陷（security flaws）足够精通，以在一个更有可能存在漏洞的代码区域分配计算资源。 Gap 2: Strict valid input space ​ 每种应用程序都有着自己的特定输入格式，现代程序越来越大，导致了越来越复杂的输入，因此，生成有效输入是有挑战性的。 ​ 此外，为了提高fuzzing的效率，生成的输入最好能执行不同的执行状态（例如，代码覆盖率）。这就要求fuzzing为有效输入的生成开发更先进的方案。如果没有对PUT的系统性分析，几乎不可能精确限制输入空间。例如，PDF文件的随机突变可能违反PDF的规范。模糊法需要仔细地突变PDF文件，使生成的输入属于有效输入空间。 Gap 3: Various targets ​ 由于 fuzzing 大量重复地测试 PUTs，这需要高效的自动化方法。PUTs 与漏洞都是多种多样的，有的程序可以简单直接地被自动化地测试（命令行），但许多程序在自动化测试前都需要做大量的工作（例如硬件）；此外，安全缺陷同样需要自动化的 indicator 以记录潜在的真正漏洞，程序崩溃是一个常用的 indicator 因为其可以被 OS 自动捕获，但有的安全缺陷并不会表现出崩溃（例如data race），这需要精心设计的 indicator。 PS: data race(数据争用) &amp; race condition(竞态条件) 竞态条件（Race condition）与数据竞争（Data Race）的区别 Direction of future research ​ 未来可能的几个方向： 1. More sensitive fitness ​ 提高代码覆盖率的效率和效果，尤其是其敏感性（Fitness的敏感性表明其区别不同程序运行状态的能力）。最近，研究人员意识到，代码覆盖率在发现复杂的bug方面有其局限性。因此，他们通过引入通过分析bug获得的信息（如危险代码区域）来扩展代码覆盖率。未来的工作可以分析bug，并根据bug的特征进行检测，特别是分析那些逃避当前fuzzing的bug。 2. More sophisticated fuzzing theories ​ 目前的fuzzing理论研究都是部分地定制了fuzzing的某个过程（第3节）。大多数现有的工作旨在制定seed schedule，而关注其他fuzzing过程的工作则少得多。由于fuzzing的复杂性，现有的工作中很少有制定整个fuzzing过程的。 ​ 从数学理论上制定整个fuzzing过程是non-trivial的。然而，制定一个以上的fuzzing过程是可能的，如博弈论，其同时考虑seed schedule和bytes schedule。 ​ 更长远来看，关于fuzzing的理论限制也可以是研究方向（例如，灰盒fuzzing的限制）。另一方面，用多种类型的fitness来制定fuzzing过程是建立更复杂的fuzzing理论的另一种方式。例如，未来的工作可以同时考虑错误的到来和状态的转换来制定fuzzing过程。 3. Sound evaluation ​ 少部分研究工作关注评价的合理性，但没有得出确切的结论（3.6节）。这些工作只为合理的评价提供了建议，如时间预算或评价指标，更多的问题仍然有待回答。 我们应该使用合成的bug还是真实世界的bug作为评价体例？ 统计测试是区分两种fuzzing技术的最终答案吗？ 终止fuzzing的合理时间预算是什么？ 当不存在用于比较fuzzer时，我们如何评估特殊的目标应用，如硬件？ 4. Scalable input inference ​ 如果在fuzzing过程中使用特定格式或数据依赖性，其效率可以得到显著提高。静态分析被广泛用于格式推断和数据依赖性推断。然而，静态分析是特定于应用程序的；也就是说，推理方法的实现需要考虑不同应用程序的特点。目前，动态分析侧重于格式推断，很少有作品在数据依赖性推断方面做出努力。具有动态分析的推理方法有可能被用于多种应用；也就是说，动态分析比静态分析更具可扩展性。更多的研究可以集中在基于动态分析的数据依赖性推断上。 5. Efficient mutation operators ​ 几乎所有的fuzzer在fuzzing过程中都使用了固定的mutator。也就是说，fuzzer根据目标应用程序的特点提前设计了一些mutator，并且在摸索过程中并不改变mutator。有几项工作打算优化mutator，但没有人关注可改变的mutator，是否有可能设计出在fuzzing过程中可以改变的mutator来提高性能？因为mutator schedule与bytes schedule密切相关，所以在设计mutator时考虑到bytes schedule可能是有希望的。此外，高度结构化输入的mutator可能对一般应用有不同的属性，因此，高度结构化输入的mutator schedule可能也值得研究。 6. More types of applications ​ Fuzzing在检测命令行程序的错误方面取得了巨大成功。研究人员也在对更多类型的应用程序进行fuzzing方面做出了许多努力（第5.1节）。由于不同应用程序的复杂性，fuzzing在实际检测更多类型的应用程序时有其局限性。例如，一些工作探索了对网络物理系统进行fuzzing的可能性，但fuzzing的能力是有限的[41, 179]。由于执行速度对fuzzing至关重要，因此hard-fuzzing应用的一个潜在方向是提高其执行速度。 7. More types of bugs ​ Fuzzing已经成功地检测到了诸如memory-violation bugs, concurrency bugs, 或者algorithmic complexity bugs。然而，它很难检测到许多其他类型的错误，如特权升级或逻辑错误。 ​ 目前的挑战是为这些错误设计适当的指标，以便在fuzzing过程中自动记录它们。因为这种指标反映了相应的bug的特征，所以指标的设计需要研究人员对fuzzing和目标bug都有很好的理解。例如，即使触发了逻辑错误，程序也会在没有异常的情况下运行。为了设计逻辑错误的自动指标，需要对开发代码的功能需求有深刻的理解。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Fuzzing","slug":"Fuzzing","permalink":"http://example.com/tags/Fuzzing/"}],"author":"Shaw"},{"title":"(论文阅读) Concolic Execution for WebAssembly","slug":"【论文阅读】Concolic-Execution-for-WebAssembly","date":"2023-06-20T11:16:32.576Z","updated":"2023-06-20T13:15:31.319Z","comments":true,"path":"2023/06/20/【论文阅读】Concolic-Execution-for-WebAssembly/","link":"","permalink":"http://example.com/2023/06/20/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Concolic-Execution-for-WebAssembly/","excerpt":"Concolic Execution for WebAssembly 时间：2022 作者：Filipe Marques、José Fragoso Santos、Nuno Santos（里斯本大学） 会议：ECOOP’2022（软工CCF-B） Abstract ​ WebAssembly（Wasm）是一种新的二进制指令格式，允许用高级语言编写的目标编译代码以接近原生的速度被浏览器的JavaScript引擎执行。尽管Wasm有明显的性能优势，但它为网络程序引入错误或安全漏洞提供了机会，因为用不安全语言编写的程序中已有的问题可以转移到交叉编译的二进制文件中。这种二进制文件的源代码经常无法用于静态分析，这就需要有能够直接处理Wasm代码的工具。尽管这种潜在的安全关键情况，仍然明显缺乏分析Wasm二进制文件的工具支持。 ​ 我们提出了WASP，一个用于测试Wasm模块的符号执行引擎，它直接在Wasm代码上工作，并建立在一个符合标准的Wasm参考实现之上。我们对WASP进行了全面的评估：它被用来符号执行测试C语言的通用数据结构库和C语言的亚马逊加密SDK，证明它可以为真实世界的C语言应用找到错误并产生高覆盖率的测试输入；并进一步针对Test-Comp基准进行测试，获得了与成熟的C语言符号执行和测试工具相当的结果。","text":"Concolic Execution for WebAssembly 时间：2022 作者：Filipe Marques、José Fragoso Santos、Nuno Santos（里斯本大学） 会议：ECOOP’2022（软工CCF-B） Abstract ​ WebAssembly（Wasm）是一种新的二进制指令格式，允许用高级语言编写的目标编译代码以接近原生的速度被浏览器的JavaScript引擎执行。尽管Wasm有明显的性能优势，但它为网络程序引入错误或安全漏洞提供了机会，因为用不安全语言编写的程序中已有的问题可以转移到交叉编译的二进制文件中。这种二进制文件的源代码经常无法用于静态分析，这就需要有能够直接处理Wasm代码的工具。尽管这种潜在的安全关键情况，仍然明显缺乏分析Wasm二进制文件的工具支持。 ​ 我们提出了WASP，一个用于测试Wasm模块的符号执行引擎，它直接在Wasm代码上工作，并建立在一个符合标准的Wasm参考实现之上。我们对WASP进行了全面的评估：它被用来符号执行测试C语言的通用数据结构库和C语言的亚马逊加密SDK，证明它可以为真实世界的C语言应用找到错误并产生高覆盖率的测试输入；并进一步针对Test-Comp基准进行测试，获得了与成熟的C语言符号执行和测试工具相当的结果。 问题背景 1. Concolic execution ​ Concolic execution是符号执行的一种特殊变体，在这种情况下，人们将具体的执行与纯粹的符号执行配对，通过一次探索一个执行路径来避免与底层SMT求解器的交互。Concolic执行引擎为符号输入分配具体数值，并同时以具体和符号方式执行给定的程序，只遵循具体路径，但像纯符号执行那样构建与该路径对应的路径条件。 ​ 更具体地说，它可以用来为符号变量生成新的具体输入，从而强制探索不同的路径。为此，人们需要否定上一次执行获得的路径条件，并查询底层求解器，以获得公式的模型。通过跟踪所有通过Concolic执行产生的路径条件，引擎可以列举出所有的程序执行路径，直到一个边界，其优点是每个探索的路径只需要与底层求解器交互一次。请注意，在纯粹的符号执行中，引擎必须在每次遇到分支点时查询求解器，以确定其then-和else-分支是否可行。 ​ 以如下代码为例(参考《Robust Symbolic Execution for WebAssembly》)： ​ 目标：测试assert语句成立的条件。 ​ 如上图所示，程序有三条可能的执行路径，对于每一个执行路径（execution path），我们称其为一个concolic iteration。 ​ 在Concolic execution中： 第一个concolic iteration开始前，变量x与y被赋予具值0与2，这些输入导致Concolic execution引擎探索上图最右边的路径，产生最后的路径条件：X≤0； 第二个concolic iteration开始前，Concolic execution引擎查询底层SMT求解器，为符号输入寻找一个满足公式x&gt;0的输入值，即对应于第一个路径条件的否定。让我们假设求解器返回x=1和y=0。这些输入导致引擎探索中间的执行路径，产生路径条件：（x&gt;0）∧（x≥y）； 第三个concolic iteration开始前，同2，引擎继续利用SMT求解器查找对2生成条件的否定，得到：(x &gt; 0) ∧ ((x ≤ 0) ∨ (x &lt; y))，也就是等价于：(x &gt; 0) ∧ (x &lt; y)。假设这里得到了具体输入x=1和y=2，程序探索了最左边的执行路径，但此时这个输入并没有触发断言，其导致a=4，b=6。当这条路径执行到断言语句时，条件为： 符号执行引擎会继续对这个条件做分析，即在满足PC条件（x&gt;0 and x&lt;y）下，是否可以推出： 即是否存在反例： SMT求解这个式子很容易得出，x=1,y=4，故这条路径上存在导致断言失败的输入。 2. 现有WASM符号执行工具 ​ 据我们所知，目前只有两个工具用于象征性地执行Wasm代码： WANA[73]和Manticore[51]。然而，这两个工具主要是针对智能合约的分析，并有重要的限制，限制了它们对独立的Wasm模块的应用。WANA[73]处于初步开发阶段，只能应用于EOSIO和Ethereum智能合约，因为它不包括可以独立运行的Wasm的符号执行引擎。Manticore[51]最近获得了对Wasm[33]的支持，但尚未对Wasm代码进行系统的评估。此外，它对Wasm模块的应用需要为每个可能的输入内存手动设置一个复杂的Python脚本，这使得它很麻烦，难以实现自动化。 ​ 贡献 ​ 我们提出了WebAssembly符号处理器，WASP，一个用于测试Wasm（1.0版）模块的新型Concolic execution引擎。WASP遵循所谓的Concolic discipline[28, 64]，将具体执行与符号执行相结合，一次探索一条执行路径。然而，与大多数通过对程序插桩的Concolic execution引擎[65, 79, 64, 63]不同，我们通过对Haas等人[30]开发的Wasm解释器的插桩实现WASP。为此，我们将作者的参考解释器从具体数值提升到具体数值和符号数值对。通过将插桩转移到解释器层面，我们为Concolic execution中的一系列优化提供了可能性。 1. WASP能够分析独立的Wasm模块（不同于WANA），它能够被用作一个通用的平台，为编译成Wasm的高级编程语言建立符号分析； 2. WASP能够分析大多数C语言库； 模型","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Symbolic Execution","slug":"Symbolic-Execution","permalink":"http://example.com/tags/Symbolic-Execution/"},{"name":"WASM","slug":"WASM","permalink":"http://example.com/tags/WASM/"}],"author":"Shaw"},{"title":"(论文阅读) WANA-Symbolic Execution of Wasm Bytecode for Extensible Smart Contract Vulnerability Detection","slug":"【论文阅读】WANA-Symbolic-Execution-of-Wasm-Bytecode-for-Extensible-Smart-Contract-Vulnerability-Detection","date":"2023-06-19T10:17:02.922Z","updated":"2023-06-19T12:10:27.965Z","comments":true,"path":"2023/06/19/【论文阅读】WANA-Symbolic-Execution-of-Wasm-Bytecode-for-Extensible-Smart-Contract-Vulnerability-Detection/","link":"","permalink":"http://example.com/2023/06/19/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91WANA-Symbolic-Execution-of-Wasm-Bytecode-for-Extensible-Smart-Contract-Vulnerability-Detection/","excerpt":"(论文阅读)WANA: Symbolic Execution of Wasm Bytecode for Extensible Smart Contract Vulnerability Detection 时间： 2021 作者： B Jiang, Y Chen, D Wang（北航） 会议： QRS‘2021 （软工CCF-C） 开源： https://github.com/gongbell/WANA Abstract ​ 许多流行的区块链平台支持智能合约，以建立去中心化的应用程序。然而，智能合约内的漏洞已经证明导致其终端用户的严重经济损失。特别是EOSIO智能合约平台上的智能合约导致了大约38万个EOS代币的损失，在攻击发生时，价值约为190万美元。EOSIO智能合约平台是基于Wasm虚拟机的，它也是支持其他智能合约平台以及网络应用的底层系统。在这项工作中，我们提出了WANA，一个基于Wasm字节码符号执行的可扩展智能合约漏洞检测工具。WANA提出了一套基于Wasm字节码分析的算法来检测EOSIO智能合约的漏洞。我们的实验分析表明，WANA可以有效地、高效地检测EOSIO智能合约中的漏洞。此外，我们的案例研究还表明，WANA可以扩展到有效检测Ethereum智能合约的漏洞。","text":"(论文阅读)WANA: Symbolic Execution of Wasm Bytecode for Extensible Smart Contract Vulnerability Detection 时间： 2021 作者： B Jiang, Y Chen, D Wang（北航） 会议： QRS‘2021 （软工CCF-C） 开源： https://github.com/gongbell/WANA Abstract ​ 许多流行的区块链平台支持智能合约，以建立去中心化的应用程序。然而，智能合约内的漏洞已经证明导致其终端用户的严重经济损失。特别是EOSIO智能合约平台上的智能合约导致了大约38万个EOS代币的损失，在攻击发生时，价值约为190万美元。EOSIO智能合约平台是基于Wasm虚拟机的，它也是支持其他智能合约平台以及网络应用的底层系统。在这项工作中，我们提出了WANA，一个基于Wasm字节码符号执行的可扩展智能合约漏洞检测工具。WANA提出了一套基于Wasm字节码分析的算法来检测EOSIO智能合约的漏洞。我们的实验分析表明，WANA可以有效地、高效地检测EOSIO智能合约中的漏洞。此外，我们的案例研究还表明，WANA可以扩展到有效检测Ethereum智能合约的漏洞。 问题背景 ​ EOSIO是一个流行的公共区块链平台，支持智能合约技术。然而，EOSIO智能合约中的漏洞导致了其终端用户的经济损失。对于EOSIO智能合约来说，区块信息依赖漏洞、假的EOS转移漏洞和伪造的转移通知漏洞总共导致了大约38万个EOS代币的损失 。在攻击发生时，这些漏洞的累计损失金额约为价值190万美元。因此，需要有效的漏洞检测工具来保护EOSIO区块链平台的生态系统。 ​ Wasm不仅被EOSIO公共区块链平台采用作为智能合约执行引擎[35]，也被其他区块链平台的议程项目采用。例如，以太坊区块链平台已经计划为以太坊2.0采用Ethereum Wasm（EWasm）虚拟机。Polkadot平台[40]进一步采用Wasm作为其parachain运行时和智能合约执行的编译目标。Wasm在构建Web应用程序中也很受欢迎，因为Wasm模块可以调用到JavaScript上下文，并通过从JavaScript访问的相同Web API访问浏览器的功能。Wasm的综合符号执行引擎有希望为任何以Wasm为目标的应用程序提供一个可扩展的安全分析框架。 贡献 它为Wasm提出了一个通用的符号执行框架WANA； 它提出了一个基于符号执行引擎的智能合约漏洞检测工具的新的可扩展架构； 它提出了一个全面的实验研究，以评估WANA对EOSIO智能合约的漏洞检测效果； 它提出了一个案例研究，以评估WANA在Ethereum平台上漏洞检测方面的可扩展性。 模型 ​ 如上图所示，Wasm字节码被解析、加载，并在Wasm符号执行引擎中被初始化。WANA的符号执行引擎是作为一个新的虚拟机实现的，它可以根据WASM规范评估具体和符号输入。它已经实现了Wasm规范1.0版中的所有指令。当一个模块被加载到WANA Wasm虚拟机中时（在加载和初始化阶段），WANA的符号执行引擎会准备一个执行环境，其中包括存储器、各种表（包括函数表和符号表）、全局变量和一个执行堆栈，以保持模块的执行上下文。 1. 符号执行引擎 ​ WANA会在所有exported函数上进行符号执行，对于每个导出的函数正文中的指令所调用的每个Wasm函数，WANA首先准备一个框架作为其执行环境，其中包括参数、局部变量、返回值和对其模块的引用。然后，它开始依次符号执行被调用函数的code section的指令。 ​ 在所有的Wasm指令中，主要有四种指令，包括数字、内存、控制和函数调用指令,下面介绍WANA如何处理: Numeric instructions: WANA实现了基于堆栈的执行逻辑。WANA的符号执行引擎首先弹出操作数，进行符号计算，并将结果推回堆栈。所有关于整数和浮点值类型的数字指令都支持。 Control instructions: 有两种分支指令：无条件分支（如br）和条件分支（如br_if）。 非条件性分支： 在Wasm中，执行无条件分支将直接跳到指令参数指定的标签上继续执行，这对实现循环很有用。然而，当循环的深度增加时，符号执行引擎将变得缓慢或由于状态爆炸而被困住。因此，WANA在路径探索过程中对每个标签的最大嵌套循环深度设置了一个上限。 条件性分支： 对于指令br_if，其执行将取决于该指令表达式的评估结果。WANA将记录每个分支的执行环境，并遍历各个分支以实现路径覆盖。对于每个分支，在遍历之前，相应的路径约束将被输入到z3[15]进行约束解算，这可以通过修剪那些不可行的路径来提高执行效率。和上面一样，WANA在路径探索过程中也对每个标签的最大嵌套循环深度设置了一个上限。 Memory and Memory instructions: 在Wasm中，有三种类型的内存操作指令：load、store和增加内存的大小。一个Wasm模块可以在任何字节地址上从/向线性存储器加载和存储值。由于Wasm中对整数和浮点数据类型有许多位操作指令，WANA被设计为用z3中的位向量数据类型来表示整数和浮点数据类型。WANA使用32位（64位）位向量数据类型来表示32位（64位）整数和浮点符号数据类型。由于字节数组不能存储位向量或其表达式，WANA使用线性列表来存储位向量的具体值和符号值的引用，以模拟模块的内存。 在符号执行过程中，WANA在执行存储操作时，将把键值对（address, value）插入字典中。在load操作中，如果符号内存地址存在于字典中，WANA将直接从字典中获取相应的值。否则，WANA将从线性列表中随机选择一个内存地址并返回其值。此后，符号内存地址将被绑定到一个随机选择的内存地址。 Function call: 在Wasm中，有两种类型的函数调用：直接和间接。 对于间接函数调用，WANA的符号执行引擎首先从执行堆栈的顶部框架获得一个索引。然后，符号执行引擎使用该索引从函数表中获得具体的函数地址。对于当前Wasm模块中的函数，WANA直接进入函数，继续进行符号执行。 2. 对库函数建模 ​ 一个智能合约可能会调用底层区块链平台提供的各种库函数。WANA根据这些库函数的效果来处理这些库函数的调用，并相应地模拟其行为。由于库函数与平台有关，WANA为不同的平台模拟了不同的库函数行为。当把WANA扩展到一个新的平台时，其相应的库函数也应被模拟。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Symbolic Execution","slug":"Symbolic-Execution","permalink":"http://example.com/tags/Symbolic-Execution/"},{"name":"WASM","slug":"WASM","permalink":"http://example.com/tags/WASM/"}],"author":"Shaw"},{"title":"(论文阅读) Eunomia-enabling User-specified Fine-Grained Search in Symbolically Executing WebAssembly Binaries","slug":"【论文阅读】Eunomia-Enabling-User-specified-Fine-Grained-Search-in-Symbolically-Executing-WebAssembly-Binaries","date":"2023-06-18T05:28:45.246Z","updated":"2023-06-19T11:08:32.149Z","comments":true,"path":"2023/06/18/【论文阅读】Eunomia-Enabling-User-specified-Fine-Grained-Search-in-Symbolically-Executing-WebAssembly-Binaries/","link":"","permalink":"http://example.com/2023/06/18/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Eunomia-Enabling-User-specified-Fine-Grained-Search-in-Symbolically-Executing-WebAssembly-Binaries/","excerpt":"Eunomia: Enabling User-specified Fine-Grained Search in Symbolically Executing WebAssembly Binaries 时间：2023.4 作者：Ningyu He、Zhehao Zhao（北大）/Haoyu Wang（华科） 会议：ISSTA‘2023 开源： https://github.com/HNYuuu/Eunomia-ISSTA23 Abstract ​ 尽管现有的技术已经提出了自动化的方法来缓解符号执行的路径爆炸问题，但用户仍然需要通过仔细应用各种搜索策略来优化符号执行。由于现有的方法主要只支持粗粒度的全局搜索策略，它们不能有效地遍历复杂的代码结构。在本文中，我们提出了Eunomia，一种符号执行技术，允许用户指定局部领域知识，以实现细粒度搜索。 ​ 在Eunomia中，我们设计了一个富有表现力的领域特定语言(DSL)，即AES，让用户可以精确地将本地搜索策略定位到目标程序的不同部分。为了进一步优化局部搜索策略，我们设计了一种基于区间的算法，该算法可以自动隔离不同局部搜索策略的变量背景，避免同一变量的局部搜索策略之间的冲突。 ​ 我们将Eunomia作为一个针对WebAssembly的符号执行平台来实现，这使我们能够分析用各种语言（如C和Go）编写但可以编译成WebAssembly的应用程序。据我们所知，Eunomia是第一个支持WebAssembly运行时全部功能的符号执行引擎。 ​ 我们用一个专门的符号执行微基准套件和六个真实世界的应用来评估Eunomia。我们的评估显示，Eunomia在现实世界的应用中加速了错误检测，最多可达到三个数量级。根据一项全面的用户研究结果，用户可以通过编写一个简单直观的AES脚本来显著提高符号执行的效率和效果。除了验证六个已知的真实世界的bug，Eunomia还在一个流行的开源项目Collections-C中检测到两个新的0-day bug。","text":"Eunomia: Enabling User-specified Fine-Grained Search in Symbolically Executing WebAssembly Binaries 时间：2023.4 作者：Ningyu He、Zhehao Zhao（北大）/Haoyu Wang（华科） 会议：ISSTA‘2023 开源： https://github.com/HNYuuu/Eunomia-ISSTA23 Abstract ​ 尽管现有的技术已经提出了自动化的方法来缓解符号执行的路径爆炸问题，但用户仍然需要通过仔细应用各种搜索策略来优化符号执行。由于现有的方法主要只支持粗粒度的全局搜索策略，它们不能有效地遍历复杂的代码结构。在本文中，我们提出了Eunomia，一种符号执行技术，允许用户指定局部领域知识，以实现细粒度搜索。 ​ 在Eunomia中，我们设计了一个富有表现力的领域特定语言(DSL)，即AES，让用户可以精确地将本地搜索策略定位到目标程序的不同部分。为了进一步优化局部搜索策略，我们设计了一种基于区间的算法，该算法可以自动隔离不同局部搜索策略的变量背景，避免同一变量的局部搜索策略之间的冲突。 ​ 我们将Eunomia作为一个针对WebAssembly的符号执行平台来实现，这使我们能够分析用各种语言（如C和Go）编写但可以编译成WebAssembly的应用程序。据我们所知，Eunomia是第一个支持WebAssembly运行时全部功能的符号执行引擎。 ​ 我们用一个专门的符号执行微基准套件和六个真实世界的应用来评估Eunomia。我们的评估显示，Eunomia在现实世界的应用中加速了错误检测，最多可达到三个数量级。根据一项全面的用户研究结果，用户可以通过编写一个简单直观的AES脚本来显著提高符号执行的效率和效果。除了验证六个已知的真实世界的bug，Eunomia还在一个流行的开源项目Collections-C中检测到两个新的0-day bug。 Background 1. 样例 1.1 代码功能 ​ 以上图代码为例，其为一个工业网络协议处理函数check_sections。函数的输入是一个section 向量sec_vec和每个section所含的fields数sec_field_cnt。每个section最多有5个fields（L4）。具体来说，前三个section：token、index和checksum，呈现了每个部分的元数据，它们分别指的是发送方的token、收到的相应部分的索引，以及数据的校验和。len表示数据的长度，其正确性由上述的校验和验证。 ​ 综上，函数check_sections检验sec_field_cnt限制下的所有字段，以两层嵌套循环的方式实现，外层循环遍历所有收到的部分，而内部循环遍历所有字段并进行相应的验证。 1.2 现有工具问题 1.2.1 Klee ​ 由于路径爆炸问题，直接在上述代码上使用符号执行无法在合理的时间内完成验证。在实践中，开发者可以提供两块领域知识来加速分析，如下所示： ​ DK1. 优先考虑成本较低的else分支，推迟分析昂贵的函数foo，同时验证用户令牌（L23 - L29）； ​ DK2. 为了避免在分析复杂的数据（L41）时陷入困境，符号执行可以首先完成对简单场的分析，即tokn、index，以及checksum。 ​ Klee不能有效地应用DK1和DK2，因为它没有确定优先级的原语。通常，我们使用KLEE原语，如klee_assume(cond)和klee_prefer_cex(obj, cond)来指定符号执行中的额外约束。不幸的是，这些原语只能修剪不需要的状态，而不能优先考虑有趣的路径。具体来说，klee_assume(cond)可以用来插入额外的约束，不符合cond的路径将被剪除。至于klee_prefer_cex(obj, cond)，它为待测函数的符号参数增加了一个优先值。它只能在测试驱动中使用，而不是在代码中的任何地方（只能在产生输入时使用，故其不能直接引导符号执行去偏好某一部分代码）。 ​ 对于DK1，KLEE能做的最接近的做法是添加klee_assume(isValid(token)==0)，这样就可以删去包含foo()的分支。然而，在DK1中，我们只想优先处理通向bar()的分支，直接修剪掉的路径可能会破坏分析的合理性。同样地，KLEE也不能利用DK2，其最接近的做法是在L22后面加上klee_assume(j&lt;3)。然而，这种方法也影响了分析的合理性，因为KLEE直接放弃了对LEN和DATA字段的分析。 综上，利用Klee只能做到舍弃某部分的控制流分支而做不到“偏好”，但舍弃部分控制流并不符合分析工作的初衷。 1.2.2 其他方法 ​ 虽然有其他工作对执行路径进行优先排序[33, 34, 46, 53, 68]，但它们也不能正确利用用户定义的领域知识。现有的路径优先化方法要么依赖于预先定义的启发式方法、黑盒策略，甚至是机器学习算法。他们的目标是加速一般的符号执行，而不是采用用户定义的领域知识。因此，它们与我们的工作大多是正交的。 1.3 解决方法 ​ 上图是为样例代码生成的AES自定义脚本，其可以实现DK1与DK2。每个语句由两部分组成，即定位部分和知识部分。我们可以看到，这两个语句被包裹在一个checker中，该checker为一个函数check_sections()（L1）工作。上图脚本的语义为： ​ （1）验证前三个元数据section； ​ （2）跳到内循环条件检查，不验证长度和数据； ​ （3）移动到下一个部分，重复（1）和（2）； ​ （4）一旦所有前三个步骤完成，处理剩余的长度和数据字段。 2. 问题背景 ​ 目前已知的符号执行技术的问题是往往过于粗·略，无法满足某些分析目的。现有的方法大多支持应用于整个程序的全局搜索策略。然而，全局策略并不是最优的，因为一个程序的不同代码块具有明显的特征，可能适合不同的局部搜索策略。 ​ 假设代码的一个嵌套循环部分负责解析收到的网络数据包，开发者想检查嵌套循环中是否存在缓冲区溢出。然而，内层循环有一个复杂的函数，需要大量的时间来验证。因此，开发者可能想优先考虑内层循环中的其他轻量级部分，以最大化符号执行的覆盖率。不幸的是，现有的方法不能优先考虑内循环的一个子集。这导致了要么在处理复杂函数时被卡住，要么产生不健全的分析结果。因此，有必要让用户为不同程序代码块的局部搜索策略提供提示。 ​ 要实现为不同程序代码块提供不同局部搜索策略，需要面对的问题有： 如何为目标程序的不同部分有效地指定本地搜索策略； 实现本地搜索策略，同时避免潜在的冲突： 同一个变量可能同属于不同的代码结构，例如，一个变量可能同时被多层循环结构共享。因此，多个本地搜索策略可能因为相同的变量产生冲突。 ​ 已知的对Wasm做符号执行的方法缺少对WASI的支持，因此限制了应用的范围。 Contributions 提出并实现了一个新的符号执行框架Eunomia，它的路径搜索过程可以通过用户指定的领域知识进行细化调整，而无需对目标程序进行任何修改； 提出一个原创的领域特定语言(DSL)，即AES，其可以可以绑定一组局部适配函数来加速分析过程。此外，用户还可以为语句或函数引入前置和后置条件，甚至可以在任意位置上引入to-checked谓词； 提出一个新的路径搜索策略，interval-based path searching，它可以将符号状态隔离到不同的语境中。为此，状态可以被任意修剪和重新排序而不影响最终结果的一致性； Eunomia在GitHub的一个2.5千星的项目（Collections-C）中发现了两个新的漏洞，开发人员已经承认并修补了这些漏洞； Eunomia是第一个支持Wasm全符号特性的符号执行引擎，并且比其他state-of-the-art表现更好。 Model ​ 如上图所示，Eunomia将待分析程序的源代码和一个Aes脚本作为输入。给定程序的CFG将被划分为不同区间（详见第3.2.1节），其中每个区间都可以被视为一个独立的上下文。基于分割出的区间，我们提出一种基于区间的路径搜索算法。该算法为状态维持一个优先级队列，这些状态的优先级分数由Aes脚本中提供的局部适配函数来评估。为此，该算法从队列中弹出分数最高的状态和它接下来的一个基本块作为指令模拟器的输入。模拟器根据基本块中的指令对状态进行符号执行，如果有必要进行路径分叉，则返回一个或多个状态。注意，状态将在其相应的上下文下被评估。这样的迭代一直持续到队列中没有候选状态或分析终止。Eunomia最后会输出所有可满足的路径。 WebAssembly ​ 目前最先进的符号执行引擎是一个商业的开源工具，Manticore [48]，它需要大量的手工工作来对Wasm运行时的API进行建模，以分析Wasm应用程序。为了减轻安全研究人员分析Wasm二进制文件的负担，我们实现了Eunomia作为第一个支持具有约8K Python3代码的商用现成Wasm应用程序符号执行引擎。 1. Memory Modeling ​ WebAssembly采用线性内存作为内存模型。其内存中的数据是原始的比特串，可以被索引和解释。为了模拟通过具体指针的load和store指令，我们采用了[35]提出的映射结构，其中值是由BitVector建模的原始位串，而键是其对应的地址范围。然而，这个模型并不能正确地处理符号指针。 ​ 为了解决符号指针问题[40]，我们采用完全符号化的内存模型[4]。具体来说，如果加载的地址是一个符号，Eunomia会考虑其所有可能的位置。我们没有像KLEE[7]那样对多个状态进行分叉，这引入了巨大的开销，而是将负担转移给SMT求解器，因为它在解决这种约束时不断地更新[7, 8, 19, 55]。换句话说，我们利用if-then-else（ite）语句来列举所有可能的位置，如下图所示，v代表load操作，内存的范围是（0-5），指针可能指向任意位置，store指令类似。 2. External Functions Emulating ​ 在Runomia引擎中，我们应用基于摘要的技术来处理这个问题。具体来说，有一个WebAssembly接口（WASI）[66]，它定义了一个Wasm二进制文件与外部环境互动的标准接口。WASI主要包括IO相关的函数，如fd_write和fd_open。为此，我们参考了文档，对所有这些与IO相关的函数进行建模，以模拟来自外部环境的响应。此外，我们还总结了C和Go中常见的标准库函数的行为，包括算术运算，以及字符串和内存操作函数。因此，所有对外部的调用都将被拦截。每个状态中的相应字段将根据函数总结进行更新。 3. SMT-Query Cache ​ 我们设计了一个用于查询的缓存池来缓解这个问题。从形式上看，我们将SMTquery缓存定义为一个包含所有已解决约束条件的集合𝐶=[𝑐1, 𝑐2, ..., 𝑐𝑛]。对于每个𝑐𝑖∈ 𝐶，我们的缓存池都会缓存其结果和所有从中推断出的公理。然后，对于一个给定的约束𝑐𝑠𝑜𝑙𝑣𝑒需要解决，在要求SMT求解器进行求解之前，Eunomia首先按照三个规则查询缓存 𝐶： ​ 如果𝑐𝑠𝑜𝑙𝑣𝑒 不符合所有三个规则，Eunomia将𝑐𝑠𝑜𝑙𝑣𝑒 发送给SMT解算器并缓存结果。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Symbolic Execution","slug":"Symbolic-Execution","permalink":"http://example.com/tags/Symbolic-Execution/"},{"name":"WASM","slug":"WASM","permalink":"http://example.com/tags/WASM/"}],"author":"Shaw"},{"title":"(论文复现)GREBE-Unveiling Exploitation Potential for Linux Kernel Bugs","slug":"【论文复现】GREBE-Unveiling-Exploitation-Potential-for-Linux-Kernel-Bugs","date":"2023-06-11T07:19:53.408Z","updated":"2023-07-13T07:19:24.144Z","comments":true,"path":"2023/06/11/【论文复现】GREBE-Unveiling-Exploitation-Potential-for-Linux-Kernel-Bugs/","link":"","permalink":"http://example.com/2023/06/11/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91GREBE-Unveiling-Exploitation-Potential-for-Linux-Kernel-Bugs/","excerpt":"(论文复现)GREBE: Unveiling Exploitation Potential for Linux Kernel Bugs 源码：Markakd/GREBE (github.com)","text":"(论文复现)GREBE: Unveiling Exploitation Potential for Linux Kernel Bugs 源码：Markakd/GREBE (github.com) 1. Analysis 1.1 关键内核结构确定 1.1.1 report来源： ​ syzbot是一个基于syzkaller的自动化fuzzing系统。它能持续不停的运行syzkaller，对linux内核各个分支进行模糊测试，自动报告crash，监控bug的当前状态（是否已被修复等），监测对于bug的patch是否有效，完成发现-报告-复现-修复的整个流程。 ​ 对每个错误，syzbot会发布其对应的报告以及可能存在的POC程序： 某个错误报告 ​ 如上图所示，syzbot发布了某个错误发生时其对应的寄存器内容，call trace以及3次crashes（底部）的对应信息，可以看到，该错误提供了一个syz脚本编写的reproducer，也就是Poc程序。 ​ syzkaller repro是用特殊的syzkaller符号编写的程序，它们可以在目标系统上执行。并且，syzkaller repro可以转化为对应的C语言poc，如果syzbot没有提供C语言的repro，它就无法使用C语言程序来触发该错误（这可能只是因为该错误是由一个竞态条件触发的）。 ​ GREBE就是从这些报告中提取call trace进行后续分析。 1.1.2 编译Analyzer ​ 安装llvm–10（LLVM Debian/Ubuntu packages）： #To install a specific version of LLVM: wget https://apt.llvm.org/llvm.sh chmod +x llvm.sh sudo ./llvm.sh &lt;version number> ​ clang-10被安装在/usr中，故将analyer的make文件修改来指定clang，如下（这里直接指定C与C++编译器）： CUR_DIR = $(shell pwd) SRC_DIR := $&#123;CURDIR&#125;/src BUILD_DIR := $&#123;CURDIR&#125;/build include Makefile.inc NPROC := $&#123;shell nproc&#125; build_ka_func = \\ (mkdir -p $&#123;2&#125; \\ &amp;&amp; cd $&#123;2&#125; \\ &amp;&amp; cmake $&#123;1&#125; \\ -DCMAKE_CXX_COMPILER=/home/wx/Shaw/llvm/patched_llvm/bin/clang++\\ -DCMAKE_C_COMPILER=/home/wx/Shaw/llvm/patched_llvm/bin/clang\\ -DCMAKE_BUILD_TYPE=Release \\ -DCMAKE_CXX_FLAGS_RELEASE=\"-std=c++14 -fno-rtti -fpic -g\" \\ &amp;&amp; make -j$&#123;NPROC&#125;) all: analyzer analyzer: $(call build_ka_func, $&#123;SRC_DIR&#125;, $&#123;BUILD_DIR&#125;) ​ 接着修改analyzer/src中的CMakeLists.txt文件来指定LLVM： cmake_minimum_required(VERSION 2.8.8) project(KANALYZER) #指定LLVM版本 set(LLVM_DIR \"/home/wx/Shaw/llvm/patched_llvm/lib/cmake/llvm\") find_package(LLVM REQUIRED CONFIG) message(STATUS \"Found LLVM $&#123;LLVM_PACKAGE_VERSION&#125;\") message(STATUS \"Using LLVMConfig.cmake in: $&#123;LLVM_DIR&#125;\") # Set your project compile flags. # E.g. if using the C++ header files # you will need to enable C++14 support # for your compiler. # Check for C++14 support and set the compilation flag include(CheckCXXCompilerFlag) #CHECK_CXX_COMPILER_FLAG(\"-std=c++14\" COMPILER_SUPPORTS_CXX14) # if(COMPILER_SUPPORTS_CXX14) # set(CMAKE_CXX_FLAGS \"$&#123;CMAKE_CXX_FLAGS&#125; -std=c++14 -fno-rtti -fPIC -Wall\") # else() # message(STATUS \"The compiler $&#123;CMAKE_CXX_COMPILER&#125; has no C++14 support. Please use a different C++ compiler.\") # endif() include_directories($&#123;LLVM_INCLUDE_DIRS&#125;) add_definitions($&#123;LLVM_DEFINITIONS&#125;) add_subdirectory (lib) ​ 编译好的analyer位于GREBE/analyzer/build/lib中。 1.1.3 编译内核bitcode文件 1.1.3.1 安装带补丁的LLVM ​ 内核bitcode文件指的是待测试的Linux内核，需要将其编译为bc文件后进行分析。 ​ 这里需要使用llvm-10并且给LLVM编译器打上补丁，以便在调用任何编译器优化通道之前转储比特码。通过这种方式，可以防止编译器优化影响分析的准确性。故这里单独准备一个llvm并安装到特定文件夹中，以避免对全局llvm的影响： git clone https://github.com/llvm/llvm-project cd llvm-project git checkout 5521236a18074584542b81fd680158d89a845fca ​ 打补丁： patch -p0 &lt; WriteBitcode.patch ​ build clang: mkdir build &amp;&amp; cd build cmake -DCMAKE_INSTALL_PREFIX=/home/wx/Shaw/llvm/patched_llvm -DLLVM_ENABLE_PROJECTS=clang -DCMAKE_BUILD_TYPE=Release -G \"Unix Makefiles\" ../llvm sudo make -j$(nproc) &amp;&amp; make install ​ 这里通过指定DCMAKE_INSTALL_PREFIX的方式指定其安装位置。注意，LLVM编译后体积非常大，如果在虚拟机中编译需要给足够内存和硬盘空间（80G+）。 1.1.3.2 编译内核 ​ 编译安装完带有特定补丁的LLVM，接下来就需要使用其来编译Linux内核源码。 ​ 以KASAN: slab-use-after-free Read in hfsplus_read_wrapper为例，其附带的.config文件中详细的说明了漏洞的内核版本、config编译选项等信息。 ​ 在kernel/git/torvalds/linux.git - Linux kernel source tree处下载对应版本的内核源码，解压后先安装编译所需的包： sudo apt-get install git fakeroot build-essential ncurses-dev xz-utils libssl-dev bc flex libelf-dev bison ​ 使用如下命令编译,CC和CXX指定为带补丁的clang，由于LLVM-10存在一定bug，这里令LLVM_IAS为0关闭integrated assembler： make CC=/home/wx/Shaw/llvm/patched_llvm/bin/clang CXX=/home/wx/Shaw/llvm/patched_llvm/bin/clang++ LLVM_IAS=0 all -j$(nproc) ​ analyzer编译完成后，使用如下命令运行： python run_analyze.py ./case ​ 可以在对应case目录下看到对应的解析结果sys.txt： ​ 注意： 编译analyzer与源码的LLVM一定要相同版本； 作者给出的LLVM-10是可以成功运行的，但是存在的问题如下： 目前使用LLVM编译新版本的内核最低要求其版本为11，其无法编译内核； 如果使用LLVM-11，其编译analyzer存在错误（见文末错误日志）； 故目前作者仓库中给出的代码仅适合版本不高的内核。 部分工作已通过脚本自动化，整个内核的下载+解压+编译已自动化为/analyzer/scripts/get_kernel.py，复现analyzer需要： 在/analyzer/Testcase/下创建对应case文件夹，命名格式为case+数字； 将对应report中的.config文件与report文件以名称.config和report复制到case文件夹中； 修改/analyzer/scripts/下的三个py文件中的CASE_DIR，PATCHED_LLVM和AnalyzerPath变量，使其分别对应Testcase，打过补丁的LLVM和编译好的analyzer； 按次序运行get_cg.py、get_kernel.py和run_analyze.py，其参数为case序号，例如： #分析/analyzer/Testcases/case7 python get_cg.py 7 python get_kernel.py 7 python run_analyze.py 7 1.1.3 静态分析代码解析 ​ 见(代码分析)GREBE-Analyzer污点分析代码解析 | Shaw (shawdox.github.io) 2. Fuzzing 2.1 编译GCC ​ 使用作者提供的gcc-9.3.0来编译内核，首先进入其文件夹中编译GCC： ./contrib/download_prerequisites mkdir gcc-bin export INSTALLDIR=`pwd`/gcc-bin mkdir gcc-build cd gcc-build ../configure --prefix=$INSTALLDIR --enable-languages=c,c++ make -j`nproc` &amp;&amp; make install ​ 2.2 使用GCC编译内核 ​ 在内核代码中运行： export OBJ_FILE=\"/home/wx/Shaw/GREBE/analyzer/TestCases/case7/sts.txt\" make CC=\"/home/wx/Shaw/GREBE/gcc-9.3.0/gcc-bin/bin/gcc\" -j`nproc` ​ 注意，内核的.config文件标志了其编译所需的最低版本，故不论是用clang编译还是gcc都需要符合对应版本。 2.3 编译Fuzzer ​ GREBE的Fuzzer是syzkaller的改版，其使用方法与syzkaller基本相同。根据syzkaller官方给出的方法编译，这里集成为/fuzzer/compile_fuzzer.py： #Author: xiao wu #Time: 2023.6.16 #Functionality: # Complie the modified syzkaller import sys import os assert ('linux' in sys.platform) GO_DIR = \"/home/wx/Shaw/go\" FUZZ_DIR = \"/home/wx/Shaw/GREBE/fuzzer\" os.environ[\"PATH\"] += GO_DIR+\"/bin\" os.chdir(FUZZ_DIR) os.system(\"make\") ​ 这里需要在脚本中指定Go语言环境以及fuzzer的位置，Go的版本需要大于等于1.11。编译好的fuzzer位于/fuzzer/bin中。 2.4 测试QEMU ​ syz-manager需要通过ssh来与ssh-fuzzer通信，后者运行在QEMU中，故在运行syzkaller之前，需要手动测试QEMU连通性： qemu-system-x86_64 \\ -m 2G \\ -smp 2 \\ -kernel $KERNEL/arch/x86/boot/bzImage \\ -append \"console=ttyS0 root=/dev/sda earlyprintk=serial net.ifnames=0\" \\ -drive file=$IMAGE/bullseye.img,format=raw \\ -net user,host=10.0.2.10,hostfwd=tcp:127.0.0.1:10021-:22 \\ -net nic,model=e1000 \\ -enable-kvm \\ -nographic \\ -pidfile vm.pid \\ 2>&amp;1 | tee vm.log ​ 注意，QEMU需要当前系统支持KVM虚拟化，如果是虚拟机可以直接查找对应处理器设置，如果是物理机需要在BIOS中开启。 ​ 成功开启QEMU后另开一个bash，用ssh测试其连通性： ssh -i $IMAGE/bullseye.id_rsa -p 10021 -o \"StrictHostKeyChecking no\" root@localhost ​ 如果成果连通则说明QEMU通信部分没有问题，具体配置过程以及相关可能的问题可见：(技术积累)Syzkaller环境配置 | Shaw (shawdox.github.io) ​ 2.5 运行fuzzer ​ 直接使用/fuzzer/scripts/run_fuzzer.py脚本即可运行fuzzer，其会自动定位case文件夹并创建对应的config文件，运行syz-manager: python run_fuzzer.py [case_number] #python run_fuzzer.py 8 ​ 下面是run_fuzzer.py的运行逻辑： 首先在对应的case文件夹下创建其config文件： 然后将config文件复制到workdir（如上图）中： ​ 如上图fuzzer源码所示，注意到poc是默认位于workdir中的，故在使用命令时仅传入poc文件名称即可（此次复现中，poc.txt默认位于对应的case文件夹中，这里run_fuzzer.py脚本会在运行syz-manager前将对应的poc.txt复制过来）。 3. 运行syz-manager: syz-manager -config /home/wx/Shaw/GREBE/analyzer/TestCases/case8/syzconfig.cfg --auxiliary poc.txt ​ 再次注意，由于fuzzer源码限制，使用--auxiliary标志传入poc.txt只能传入该名称，并且poc.txt文件应该位于workdir文件夹下。 ​ 运行即可得到对应结果： 2.6 原理解析 ​ 对gcc和kernel都做了修改，使其在编译内核时可以将特定的basic block的16bit地址替换为一个magic_number，这样在代码覆盖率反馈中就可以识别哪些basic block属于关键内核对象。 2.6.1 Syzkaller原理 ​ 如上图所示，具体描述见：syzkaller/docs/internals.md at master · google/syzkaller · GitHub 2.6.2 Syscall descriptions ​ Syzkaller使用声明性的系统调用描述来控制程序（系统调用的序列），举例： open(file filename, flags flags[open_flags], mode flags[open_mode]) fd read(fd fd, buf buffer[out], count len[buf]) close(fd fd) open_mode &#x3D; S_IRUSR, S_IWUSR, S_IXUSR, S_IRGRP, S_IWGRP, S_IXGRP, S_IROTH, S_IWOTH, S_IXOTH ​ 翻译后的系统调用描述被用来生成、变异、执行、最小化、序列化和反序列化程序，程序指的是有着一系列具体参数的系统调用，例如： r0 = open(&amp;(0x7f0000000000)=\"./file0\", 0x3, 0x9) read(r0, &amp;(0x7f0000000000), 42) close(r0) ​ 在实际操作中，syzkaller使用类似AST的内存表示法，由prog/prog.go中定义的Call和Arg值组成。这种表示法被用来分析、生成、变异、最小化、验证等程序。内存中的表示法可以转换为文本形式，以存储在磁盘语料库中，并展示给人类，等等。还有另一种程序的二进制表示法（称为exec），它更简单，不包含丰富的类型信息（不可逆），用于实际执行（解释）程序。 2.6.3 Coverage 2.6.3.1 Syzkaller Coverage ​ 覆盖率通过追踪coverage points的方式获取，coverage points一般通过编译器插入对象代码中。coverage points一般指一个基本块或者CFG边（取决于编译器，例如clang默认是cfg边而gcc是基本块），编译器在翻译转换和优化代码的过程中插入coverage points。 ​ 因此，覆盖率与源代码的关系可能很差。例如，你可能会在一个非覆盖行之后看到一个覆盖行，或者你可能在你期望看到的地方没有看到覆盖点，反之亦然（如果编译器拆分基本块，或将控制流结构变成没有控制流的条件动作，就可能发生这种情况。）。 https://github.com/google/syzkaller/blob/master/docs/coverage.md#syz-cover这里可以参照官网的syz-cover来从原始覆盖数据中生成报告。 ​ Syzkaller使用kcov来从Linux内核中获取代码覆盖率，kcov会输出每个被运行的基本块的地址，然后syzkaller会用objdump、nm、addr2line、readelf等binutils工具来将该地址映射到源码对应的行数。 2.6.3.2 GREBE Coverage GREBE-GCC ​ add grebe code changes · whoismissing/grebe-gcc@172f8e6 (github.com)这里可以看到GREBE对GCC9.3.0版本做了怎样的修改，其修改了两个文件：sancov.c和sanitizer.def。 ​ 首先，GREBE在sancov.c中定义了存储关键对象的结构struct_maps: ​ 定义了init_structs()函数，用于将从analyzer生成的内核关键对象读取到st_map-&gt;st数组中： ​ 定义了process_tree()函数，用于匹配关键内核对象： ​ 定义了find_st()函数，用于从tree中找出符合关键内核对象的子树： ​ 然后在sancov_pass()函数中插入以下代码： ​ 这段代码的大致作用是选择对basic block做插桩的函数，BUILT_IN_SANITIZER_COV_TRACE_PC是kcov原本的插桩函数，BUILT_IN_SANITIZER_OBJ_COV_TRACE_PC是GREBE实现的插桩函数，二者都在对应内核的kernel/kcov.c文件中实现，二者的区别如下： ​ 其中，_RET_IP_代表当前函数的返回地址，可以发现，GREBE实现的BUILT_IN_SANITIZER_OBJ_COV_TRACE_PC相较于BUILT_IN_SANITIZER_COV_TRACE_PC就是将返回地址截取了前32位。 ​ 回到sancov_pass()，其遍历每个基本块，对于非空基本块判断其是否是关键内核对象，如果是则将fndecl设置为BUILT_IN_SANITIZER_OBJ_COV_TRACE_PC，否则设置为BUILT_IN_SANITIZER_COV_TRACE_PC。然后代码根据fndecl设置一个gcall，将其插入到代码块之前。 ​ 最后，在sanitizer.def文件中，将自己实现的__sanitizer_obj_cov_trace_pc()定义为sanitizer函数: GREBE-Syzkaller 3. 错误日志 问题1：编译llvm时报错： Killed (program cc1plus) Please submit a full bug report, with preprocessed source if appropriate. See file:///usr/share/doc/gcc-5/README.Bugs for instructions. lib/DebugInfo/CodeView/CMakeFiles/LLVMDebugInfoCodeView.dir/build.make:494: recipe for target 'lib/DebugInfo/CodeView/CMakeFiles/LLVMDebugInfoCodeView.dir/EnumTables.cpp.o' failed make[2]: *** [lib/DebugInfo/CodeView/CMakeFiles/LLVMDebugInfoCodeView.dir/EnumTables.cpp.o] Error 4 CMakeFiles/Makefile2:6769: recipe for target 'lib/DebugInfo/CodeView/CMakeFiles/LLVMDebugInfoCodeView.dir/all' failed make[1]: *** [lib/DebugInfo/CodeView/CMakeFiles/LLVMDebugInfoCodeView.dir/all] Error 2 解决方法： 编译时虚拟机的内存与硬盘空间太小，在服务器上跑即可成功编译。 问题2：在编译analyzer时报错： error: no member named 'hasNPredecessorsOrMore' in 'llvm::BasicBlock' 解决方法： 查看错误报告发现是LLVM的BasicBlock没找到对应的子数据结构hasNPredecessorsOrMore，首先在LLVM官网查找对应数据结构定义： ​ 可以看到在BasicBlock.cpp的319行有该数据结构的定义，查找本机上下载的llvm源码： ​ 查找对应源码是可以发现对应数据结构定义的： ​ 阅读报错信息，发现编译时自动搜索到了以前安装的llvm-6.0旧版本，手动更改路径，上述问题解决，但是发现仍旧报错。 ​ 在llvm的github项目中找到了一样错误：Build failure when targeting LLVM 11.0 · Issue #87 · google/autofdo (github.com)。可以基本确定这是LLVM-11的问题，换回LLVM-10版本即可解决。 问题3：在编译analyzer时报错： ld: cannot find -lz 解决方法： sudo apt-get install zlib1g zlib1g-dev 问题4：在使用analyer时报错： /home/wx/Shaw/GREBE/analyzer/build/lib/analyzer: error loading file './case/linux-bitcode/lib/dump_stack.c.bc' 解决方法： 问题定位到KAMain.cc文件使用ParseIR()函数解析bc文件： std::unique_ptr&lt;Module> M = parseIRFile(InputFilenames[i], Err, *LLVMCtx); if (M == NULL) &#123; errs() &lt;&lt; argv[0] &lt;&lt; \": error loading file '\" &lt;&lt; InputFilenames[i] &lt;&lt; \"'\\n\"; continue; &#125; 问题5：编译内核（部分版本）时报错： error New address family defined, please update secclass_map. 解决方法： 编译错误 error New address family defined, please update secclass_map.解决-CSDN博客 问题6：编译内核（部分版本）时报错： passing argument 1 to restrict-qualified parameter aliases with argument 5 [-Werror=restrict] cc1: all warnings being treated as errors 解决方法： 对tools/lib/str_error_r.c打如下补丁： Re: New -Werror=restrict error with incremental gcc - Laura Abbott (kernel.org) 问题7：无法使用py脚本（在其中使用export）改变环境变量 解决方法： How to use export with Python on Linux - Stack Overflow Reference GREBE: GREBE/analyzer at master · Markakd/GREBE (github.com) Markakd/LLVM-O0-BitcodeWriter: patch for LLVM to generate O0 bitcode (github.com) LLVM: LLVM Debian/Ubuntu packages Kernel: How To Build Linux Kernel {Step-By-Step} | phoenixNAP KB Setup: Ubuntu host, QEMU vm, x86-64 kernel (googlesource.com) KCOV: code coverage for fuzzing — The Linux Kernel documentation 内核测试指南 — The Linux Kernel documentation Syzkaller： syzkaller/docs/internals.md at master · google/syzkaller · GitHub syzkaller/docs/linux/setup_ubuntu-host_qemu-vm_x86-64-kernel.md at master · google/syzkaller · GitHub (技术积累)Syzkaller环境配置 | Shaw (shawdox.github.io) Understanding kcov – play with -fsanitize-coverage=trace-pc from the user space | davejingtian.org kcov-用于内核模糊测试的代码覆盖-CSDN博客","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Vulnerability","slug":"Vulnerability","permalink":"http://example.com/tags/Vulnerability/"},{"name":"AEG","slug":"AEG","permalink":"http://example.com/tags/AEG/"}],"author":"Shaw"},{"title":"(技术积累)Syzkaller环境配置","slug":"【技术积累】Syzkaller环境配置","date":"2023-06-11T07:19:53.173Z","updated":"2023-06-16T04:19:22.900Z","comments":true,"path":"2023/06/11/【技术积累】Syzkaller环境配置/","link":"","permalink":"http://example.com/2023/06/11/%E3%80%90%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF%E3%80%91Syzkaller%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","excerpt":"Syzkaller环境配置 Syzkaller内核模糊测试工具环境搭建，简单测试 项目地址：google/syzkaller: syzkaller is an unsupervised coverage-guided kernel fuzzer (github.com)","text":"Syzkaller环境配置 Syzkaller内核模糊测试工具环境搭建，简单测试 项目地址：google/syzkaller: syzkaller is an unsupervised coverage-guided kernel fuzzer (github.com) Install gcc 6.10 or later; go 1.20 or later; C compiler with coverage support Linux kernel with coverage additions Virtual machine or a physical device syzkaller itself 更新apt并安装相关编译器： sudo apt update sudo apt install make gcc flex bison libncurses-dev libelf-dev libssl-dev ​ 下载内核源码： git clone --branch v6.2 git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git $KERNEL ​ 内核编译常用的配置参数： #文本对话式，基于命令行的一种配置,其会在命令行一个个询问具体配置选择 make config #基于图形界面配置 make menuconfig ##将当前系统存在的.config 文件拷贝至源码目录，并询问新符号如何设置 make oldconfig #将当前系统存在的.config 文件拷贝至源码目录，新符号设为默认值，不提示 make olddefconfig #基于当前config和加载的模块创建一个配置 make localmodconfig #基于QT的配置工具 make xconfig #使用系统中的默认符号值创建一个config make defconfig #基于GTK+的配置工具 make gconfig #为kvm客户内核支持启用其他选项 make kvm_guest.config ​ 进入源码目录： make olddefconfig ​ 手动在.config文件中添加编译选项（一定去掉原来的注释）： # Coverage collection. CONFIG_KCOV=y # Debug info for symbolization. CONFIG_DEBUG_INFO_DWARF4=y # Memory bug detector CONFIG_KASAN=y CONFIG_KASAN_INLINE=y # Required for Debian Stretch and later CONFIG_CONFIGFS_FS=y CONFIG_SECURITYFS=y #这个一定要加上 CONFIG_CMDLINE_BOOL=y CONFIG_CMDLINE=\"net.ifnames=0\" ​ 再次make： make olddefconfig ​ 编译： make -j`nproc` ​ 编译好的内核文件夹内应出现： ​ debootstrap是debian/ubuntu下的一个工具，用来构建一套基本的系统(根文件系统)。生成的目录符合Linux文件系统标准(FHS)，即包含了/boot、/etc、/bin、/usr等等目录，但它比发行版本的Linux体积小很多，当然功能也没那么强大，因此，只能说是“基本的系统”。 ​ 这里以创建一个Debian Bullseye版本的Linux镜像为例： sudo apt install debootstrap mkdir $IMAGE cd $IMAGE/ wget https://raw.githubusercontent.com/google/syzkaller/master/tools/create-image.sh -O create-image.sh chmod +x create-image.sh ./create-image.sh ​ 创建好后对应文件夹下应该有一个bullseye.img文件。 ​ 如果Host使用的是虚拟机，需要在设置处开启虚拟化引擎（若是物理机则需要在BIOS上开启）： ​ 测试qemu： qemu-system-x86_64 \\ -m 2G \\ -smp 2 \\ -kernel /home/wx/SyzKaller/linux/arch/x86/boot/bzImage \\ -append \"console=ttyS0 root=/dev/sda earlyprintk=serial net.ifnames=0\" \\ -drive file=/home/wx/SyzKaller/image/bullseye.img,format=raw \\ -net user,host=10.0.2.10,hostfwd=tcp:127.0.0.1:10021-:22 \\ -net nic,model=e1000 \\ -enable-kvm \\ -nographic \\ -pidfile vm.pid \\ 2>&amp;1 | tee vm.log ​ 另开一个终端，测试ssh连接： ssh -i $IMAGE/bullseye.id_rsa -p 10021 -o \"StrictHostKeyChecking no\" root@localhost ​ 测试完成后就可以关闭qemu（直接poweroff），下面进行syzkaller安装： ​ 安装go： #如果显示地址不可达 #在站长工具处查询dl.google.com #找到可以Ping的IP #修改本机hosts文件即可 wget https://go.dev/dl/go1.20.3.linux-amd64.tar.gz #如果之前安装过go，一定要先删除原来的 tar -C /usr/local -xzf go1.20.3.linux-amd64.tar.gz #添加环境变量 export GOROOT=`pwd`/go export PATH=$GOROOT/bin:$PATH #测试 go version #-> go version go1.20.3 linux/amd64 ​ 安装syzkaller: git clone https://github.com/google/syzkaller cd syzkaller #安装之前一定要保证gcc和go的版本正确 make Crash Test ​ 在$linux/fs/open.c文件中的chmod_common（）添加一段代码，使得当连续两次chmod调用的mode参数值为0时会产生空指针解引用异常： static umode_t old_mode = 0xffff; if (old_mode == 0 &amp;&amp; mode == 0) &#123; path = NULL; &#125; old_mode = mode; ​ 重新编译Linux内核，设置Syzkaller配置文件如下： &#123; \"target\": \"linux/amd64\", \"http\": \"127.0.0.1:56741\", \"workdir\": \"/home/wx/SyzKaller/syzkaller/workdir\", \"kernel_obj\": \"/home/wx/SyzKaller/linux/\", \"image\": \"/home/wx/SyzKaller/image/bullseye.img\", \"sshkey\": \"/home/wx/SyzKaller/image/bullseye.id_rsa\", \"syzkaller\": \"/home/wx/SyzKaller/syzkaller\", \"enable_syscalls\": [\"chmod\"], \"procs\": 8, \"type\": \"qemu\", \"vm\": &#123; \"count\": 4, \"kernel\": \"/home/wx/SyzKaller/linux/arch/x86/boot/bzImage\", \"cpu\": 2, \"mem\": 2048 &#125; &#125; enable_syscalls选项表明了仅对其中的系统调用做fuzzing，如果其中的某个系统调用依赖其他调用，syzkaller会提醒你。 同理，disable_syscalls选项表明了不对哪些系统调用fuzzing。 ​ 执行： syz-manager --config config.json ​ 在对应的web127.0.0.1:56741上就可以看到当前fuzzing的情况： ​ 可以看到已经抓到了一个内核Crash： ​ Using syzkaller, part 2: Detecting programming bugs in the Linux kernel (collabora.com)这个Blog详细说明了网站里各个模块的作用。 ​ 查看报告： ​ 打开目录workdir/carsh/···/log0： Problem Summary 问题1：在使用ssh连接qemu时无法连接，报错： “ssh_exchange_identification: Connection closed by remote host” ​ 解决方法： ​ 查看QEMU虚拟机内sshd服务状态，发现其服务没有开启： ​ 尝试使用命令service sshd start，无效。 ​ 尝试google，发现如下帖子：ssh : Why sshd does not start on qemu booting (google.com) 这也能遇到自己老师hh ​ 故重新检查linux源码的config后发现，由于手动修改后没有删除原来对应的“xxx not set”注释，导致当时的修改在后续make olddefconfig时又被改回去了。 ​ 重新修改.config文件，重新编译，创建qemu虚拟机，再次尝试登陆： ​ 这里的问题其实就出现在没有去掉注释，在.config文件中注释也会被扫描分析。 问题二：sshd服务错误定位 解决方法： /usr/bin/sshd -T命令可以显示出sshd配置文件的错误之处； 在ssh连接时使用命令-v/-vv可以查看调试信息 问题三：开启syzkaller后一直没有虚拟机连接 解决方法：在使用命令./bin/syz-manager -config=my.cfg后面加上-debug，查看调试信息后发现qemu虚拟机显示”Failed to start Raise network interfaces“，查找官方文档后发现需要在内核config上加上： CONFIG_CMDLINE_BOOL=y CONFIG_CMDLINE=\"net.ifnames=0\" Reference google/syzkaller: syzkaller is an unsupervised coverage-guided kernel fuzzer (github.com) syzkaller/setup.md at master · google/syzkaller (github.com) How to set up syzkaller (googlesource.com) ssh : Why sshd does not start on qemu booting (google.com) Debian-GNU-Linux-Profiles/test.c at master · hardenedlinux/Debian-GNU-Linux-Profiles (github.com) Syzkaller Fuzz Android Kernel | BruceFan's Blog (pwn4.fun)","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Vulnerability","slug":"Vulnerability","permalink":"http://example.com/tags/Vulnerability/"},{"name":"AEG","slug":"AEG","permalink":"http://example.com/tags/AEG/"}],"author":"Shaw"},{"title":"(技术积累)Klee安装使用","slug":"【技术积累】Klee安装使用","date":"2023-05-30T09:09:53.697Z","updated":"2023-06-05T05:07:29.038Z","comments":true,"path":"2023/05/30/【技术积累】Klee安装使用/","link":"","permalink":"http://example.com/2023/05/30/%E3%80%90%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF%E3%80%91Klee%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/","excerpt":"Klee安装使用 Linux系统下著名符号执行工具Klee的安装使用","text":"Klee安装使用 Linux系统下著名符号执行工具Klee的安装使用 Prerequisites 删除旧版本（非官方发行版的Docker） for pkg in docker.io docker-doc docker-compose podman-docker containerd runc; do sudo apt-get remove $pkg; done 设置GPG key和仓库，确保下载源 #Update the apt package index and install packages to allow apt to use a repository over HTTPS: sudo apt-get update sudo apt-get install ca-certificates curl gnupg #Add Docker’s official GPG key: sudo install -m 0755 -d /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg sudo chmod a+r /etc/apt/keyrings/docker.gpg #Set up the repository: echo \\ \"deb [arch=\"$(dpkg --print-architecture)\" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\ \"$(. /etc/os-release &amp;&amp; echo \"$VERSION_CODENAME\")\" stable\" | \\ sudo tee /etc/apt/sources.list.d/docker.list > /dev/null 安装Docker： #install sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin #test sudo docker run hello-world Install ​ 这里使用现成的Docker环境，直接pull即可： sudo docker pull klee/klee ​ 运行： docker run --rm -ti --ulimit='stack=-1:-1' klee/klee ​ 其中，--rm表明容器停止，即使用命令docker stop后直接删除容器；-ti表明为容器重新分配一个伪输入终端（-t）并且以交互模式运行容器(-i)；--ulimit表明将栈设置为无限大。 ​ 进入容器后检查Klee： Klee 1. Small Function 测试一个简单函数get_sign() ​ 以get_sign函数为例： //First KLEE tutorial: testing a small function #include \"klee/klee.h\" int get_sign(int x) &#123; if (x == 0) return 0; if (x &lt; 0) return -1; else return 1; &#125; int main() &#123; int a; klee_make_symbolic(&amp;a, sizeof(a), \"a\"); return get_sign(a); &#125; ​ 首先将其编译为bc文件： clang -I ../../include -emit-llvm -c -g -O0 -Xclang -disable-O0-optnone get_sign.c ​ 其中，-I+&lt;dir&gt;表明添加搜索路径，用于引入头文件klee/klee.h；-c表明只进行预处理、编译和汇编；-Xclang+&lt;arg&gt;用于给clang编译器传递参数，这里禁止了优化。 ​ 运行klee： klee get_sign.bc ​ 由上图可见klee探索了程序中的3条路径并生成了3个测试样例，并生成了两个目录： ​ 其中klee-out-0是输出结果目录，klee-last是其符号链接，每次都链接到最新的测试输出中，其包含： ​ klee生成的测试样例都以.ktest结尾，借助ktest-tool工具来查看： ​ 使用libkleeRuntest工具手动复现测试样例： export LD_LIBRARY_PATH=path-to-klee-build-dir/lib/:$LD_LIBRARY_PATH gcc -I ../../include -L path-to-klee-build-dir/lib/ get_sign.c -lkleeRuntest KTEST_FILE=klee-last/test000001.ktest ./a.out echo $? ​ 如图所示，最后一个测试样例返回255（-1）的原因是-1转换为0-255范围内的有效退出代码值。 ​ 可见，klee通过对C代码插装，并接受bc输入的方式进行符号执行测试。 2. Test GNU coreutils 2.1 安装coreutils &amp; WLLVM ​ 下载GNU coreutils源码，这里选用6.11版本（可以用其他版本）： #下载 wget https://ftp.gnu.org/gnu/coreutils/coreutils-6.11.tar.gz #解压 tar -zxvf coreutils-6.11.tar.gz ​ 配置并编译coreutils： #如果该版本的coreutils有Bug,就使用如下补丁 wget http://web.cs.ucla.edu/classes/winter16/cs35L/assign/coreutils.diff patch -p0 &lt; coreutils.diff #编译 mkdir obj-gcov cd obj-gcov ../configure --disable-nls CFLAGS=\"-g -fprofile-arcs -ftest-coverage\" make ​ 编译好的文件位于coreutils/src目录下。通过编译加上CFLAGS=\"-g -fprofile-arcs -ftest-coverage\"配置选项，使其支持gcov，每次你运行它时其就会生成一个.gcda文件表明其运行覆盖率如何，例如： rm -f *.gcda # Get rid of any stale gcov files ./echo** ls -l echo.gcda :' -rw-rw-r-- 1 klee klee 896 Nov 21 22:00 echo.gcda ' gcov echo :' File '../../src/echo.c' Lines executed:24.27% of 103 Creating 'echo.c.gcov' File '../../src/system.h' Lines executed:0.00% of 3 Creating 'system.h.gcov' ' ​ 安装WLLVM： pip3 install --upgrade wllvm export LLVM_COMPILER=clang ​ 使用WLLVM编译coreutils： mkdir obj-llvm cd obj-llvm CC=wllvm ../configure --disable-nls CFLAGS=\"-g -O1 -Xclang -disable-llvm-passes -D__NO_STRING_INLINES -D_FORTIFY_SOURCE=0 -U__OPTIMIZE__\" make ​ 这里： -fprofile-arcs -ftest-coverage表明使用gcov对即将用klee测试的文件插桩，这里舍弃了这个flag； -O1 -Xclang -disable-llvm-passes表明不使用优化，由于LLVM5.0以上版本的O0优化会影响Klee本身的优化措施，故这里使用O1优化并禁止所有LLVM Pass运行； D__NO_STRING_INLINES表明不使用内联字符串；-D_FORTIFY_SOURCE=0表明不使用fortify安全技术，因为其可能会替换现有的函数（fprintf -&gt; __fprintf_chk）导致Klee无法对其建模而将其视为外部函数；-U__OPTIMIZE__取消 __OPTIMIZE__ 的宏定义，禁用编译器所有优化。 ​ 可以通过extract-bc命令从生成的可执行文件中提取bitcode： find . -executable -type f | xargs -I '&#123;&#125;' extract-bc '&#123;&#125;' 2.2 使用Klee测试文件 ​ 接下来就可以使用klee运行bc文件： klee --libc=uclibc --posix-runtime ./cat.bc --version --libc=uclibc指定了Klee外部函数库，其中定义了程序可能调用的外部函数； --posix-runtime指定 KLEE 使用 POSIX 标准库作为程序的运行时环境； --version是传递给cat命令的参数。 ​ 当Klee指定了uclibc和POSIX，它就会替换程序的main()函数为库中的klee_init_env()函数，这个函数用于支持符号参数的构建。 运行结果 ​ 分析以上WARNING： *undefined reference to function: ___ctype_b_loc*表明__ctype_b_loc函数未定义； *executable has module level assembly (ignoring)*表明一些被编译进应用程序的文件有内嵌汇编语句，Klee无法分析，故跳过（来自uClibc，这里安全）； *calling external: getpagesize()*表明调用的函数未定义。在这种情况下，Klee尝试调用该函数的本地版本，如果它存在的话。这有时是安全的，只要该函数不写入任何程序内存或试图处理符号值。例如，getpagesize()只是返回一个常数。 ​ 下面尝试用符号化输入测试echo： klee --optimize --libc=uclibc --posix-runtime ./echo.bc --sym-arg 3 ​ 使用如下命令查看统计结果： klee-stats klee-last ------------------------------------------------------------------------ | Path | Instrs| Time(s)| ICov(%)| BCov(%)| ICount| TSolver(%)| ------------------------------------------------------------------------ |klee-last| 64546| 0.15| 22.07| 14.14| 19943| 62.97| ------------------------------------------------------------------------ ​ 其中： ICov为LLVM指令覆盖率； BCov为分支覆盖率； ​ 可以看到覆盖率并不高，其中一个原因是由于这些数字是用比特码文件中的所有指令或分支来计算的，包括很多可能是不可执行的库代码。故对于这种情况使用–optimize优化去除死代码会更好： klee --optimize --libc=uclibc --posix-runtime ./echo.bc --sym-arg 3 klee-stats klee-last ------------------------------------------------------------------------ | Path | Instrs| Time(s)| ICov(%)| BCov(%)| ICount| TSolver(%)| ------------------------------------------------------------------------ |klee-last| 33991| 0.13| 30.16| 21.91| 8339| 80.66| ------------------------------------------------------------------------ ​ 可以看到各项覆盖率都高了一些，klee执行的更快，执行的代码指令更少。 2.3 可视化klee进程 ​ KCachegrind是一个优秀的可视化工具，可以直接用apt安装。 ​ PS: ​ Kcachegrind是一个图形化工具，如果是通过windows使用ssh服务连接Linux系统，则需要在windows端安装X11服务并在Linux端修改ssh配置使其可以允许X11服务。 相关参考：X11 forwarding，Windows与Linux结合的最佳开发环境【编程环境优化篇】 - 知乎 (zhihu.com) 2.4 结果分析 ​ 可以通过ktest-tool工具查看每个单独的测试样例： $ ktest-tool klee-last/test000001.ktest ktest file : 'klee-last/test000001.ktest' args : ['./echo.bc', '--sym-arg', '3'] num objects: 2 object 0: name: 'arg0' object 0: size: 4 object 0: data: '\\x00\\x00\\x00\\x00' object 1: name: 'model_version' object 1: size: 4 object 1: data: '\\x01\\x00\\x00\\x00' ​ 可以使用ktest-reply工具来复现： klee-replay ./echo ../../obj-llvm/src/klee-last/*.ktest 3. Binary ​ Reference Install: Prerequisites | Docker Documentation Install Docker Engine on Ubuntu | Docker Documentation Docker · KLEE docker run 参数详解_-CSDN博客 travitch/whole-program-llvm: A wrapper script to build whole-program LLVM bitcode files (github.com) Tutorial: Files · KLEE Tutorials · KLEE Testing Coreutils · KLEE","categories":[{"name":"Project","slug":"Project","permalink":"http://example.com/categories/Project/"}],"tags":[{"name":"Klee","slug":"Klee","permalink":"http://example.com/tags/Klee/"},{"name":"Symbolic Execution","slug":"Symbolic-Execution","permalink":"http://example.com/tags/Symbolic-Execution/"}],"author":"Shaw"},{"title":"(论文阅读)Automated WebAssembly Function Purpose Identification With Semantics-Aware Analysis","slug":"【论文阅读】Automated-WebAssembly-Function-Purpose-Identification-With-Semantics-Aware-Analysis","date":"2023-05-29T04:03:21.126Z","updated":"2023-05-29T04:02:47.343Z","comments":true,"path":"2023/05/29/【论文阅读】Automated-WebAssembly-Function-Purpose-Identification-With-Semantics-Aware-Analysis/","link":"","permalink":"http://example.com/2023/05/29/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Automated-WebAssembly-Function-Purpose-Identification-With-Semantics-Aware-Analysis/","excerpt":"Automated WebAssembly Function Purpose Identification With Semantics-Aware Analysis 会议：WWW'23（International World Wide Web Conference，CCF-A） 作者：Alan Romano、Weihang Wang（USC） 时间：2023.4 ABSTRACT ​ WebAssembly是最近建立的一个网络标准，用于提高网络应用的性能。该标准定义了一种二进制代码格式，作为各种语言的编译目标，如C、C++和Rust。该标准还定义了一种可读性的文本表示法，不过，WebAssembly模块很难被人类读者解释，无论他们的经验水平如何。这使得理解和维护任何现有的WebAssembly代码变得困难。因此，第三方WebAssembly模块需要被开发者隐含地信任，因为验证功能本身可能是不可行的。 ​ 为此，我们构建了WASPur，一个自动识别WebAssembly函数功能的工具。为了构建这个工具，我们首先构建了一个广泛的WebAssembly样本集，代表了WebAssembly的状态。其次，我们分析数据集，并确定所收集的WebAssembly模块的不同使用情况。我们利用WebAssembly模块的数据集来构建模块中功能的语义感知的中间表示（IR）。我们对函数IR进行编码，用于机器学习分类器，我们发现这个分类器可以预测一个给定函数与已知命名函数的相似性，其准确率为88.07%。我们希望我们的工具能够检查优化和减化的WebAssembly模块，这些模块去除了函数名称和大多数其他语义标识符。","text":"Automated WebAssembly Function Purpose Identification With Semantics-Aware Analysis 会议：WWW'23（International World Wide Web Conference，CCF-A） 作者：Alan Romano、Weihang Wang（USC） 时间：2023.4 ABSTRACT ​ WebAssembly是最近建立的一个网络标准，用于提高网络应用的性能。该标准定义了一种二进制代码格式，作为各种语言的编译目标，如C、C++和Rust。该标准还定义了一种可读性的文本表示法，不过，WebAssembly模块很难被人类读者解释，无论他们的经验水平如何。这使得理解和维护任何现有的WebAssembly代码变得困难。因此，第三方WebAssembly模块需要被开发者隐含地信任，因为验证功能本身可能是不可行的。 ​ 为此，我们构建了WASPur，一个自动识别WebAssembly函数功能的工具。为了构建这个工具，我们首先构建了一个广泛的WebAssembly样本集，代表了WebAssembly的状态。其次，我们分析数据集，并确定所收集的WebAssembly模块的不同使用情况。我们利用WebAssembly模块的数据集来构建模块中功能的语义感知的中间表示（IR）。我们对函数IR进行编码，用于机器学习分类器，我们发现这个分类器可以预测一个给定函数与已知命名函数的相似性，其准确率为88.07%。我们希望我们的工具能够检查优化和减化的WebAssembly模块，这些模块去除了函数名称和大多数其他语义标识符。 知识背景 ​ WebAssembly阅读困难的原因： WebAssembly只有四种数字数据类型，i32、i64、f32和f64，这使得例如字符串操作和加密散列等操作的指令序列变得十分相似，难以阅读; 其次，它的堆栈机设计使得在某个位置推导出一个变量的值很困难。必须从一个给定的位置追踪堆栈，以确定特定代码位置的计算值。 ​ 由于许多第三方模块交付时并没有源码，故确定该WASM模块的功能就需要手工验证。有以前的工作研究了WASM样本本身的目的，但是没有工作帮助开发者理解WASM模块的函数功能。 ​ WebAssembly模块有一个明确的结构定义。每个模块由10个部分组成，分别描述模块的不同组成部分： Name Description Types 所有函数参数和返回值类型 Functions 所有WASM函数的类型、使用的局部变量和WASM指令组成的函数体 Tables 间接调用目标函数表 Memory 本模块线性内存部分属性 Globals 该模块使用的全局变量 Elements 用于初始化指定函数表的函数索引 Data 用于初始化指定的线性内存部分的字节序列 Start 模块初始化函数 Import 从JS导入，并在WASM调用的函数 Exports 导出到JS中被调用的函数 ​ 本工作的分类方法聚焦于Functions节。 贡献 我们提出了一个中间表示法（IR）来抽象WebAssembly应用程序的底层语义，以实现语法弹性分析； 构建了从真实网站、火狐插件、Chrome拓展和Github仓库中爬取的WASM样本数据集； 对WASM样本综合分析，将行为目的分为12类； 开发自动分类工具WASPur，以实现WASM函数的自动打标签，准确率达到88.07%。 模型方法 1. 生成中间表示IR ​ 对虚拟栈操作的抽象： 2. 抽象处理 ​ 首先构建每个函数的内部cfg（iCFG）,再通过call调用连接各个iCFG构建程序间ICFG。为每个函数建立一个单独的ICFG，所需的函数被用作图形遍历的起始点。call的深度被限制为2，其防止了递归函数无限调用。 3. 分类器 模型：全连接层神经网络； 输入：抽象序列（每个函数的）； 输出：189个unit（对应人工分析的189个不同function类） 4. 数据集 来源：Alexa、Chrome extensions、Firefox add-ons、GitHub repositories。 构建的数据集： Dataset for WebAssembly Binaries 上表显示了从四个source爬取的：样本总数、使用WASM的样本数、WASM程序数。故这里共有6769个WASM样本，由于一个程序可能有多个WASM模块，这里共有1829个独立模块。 Dataset for WebAssembly GitHub Repositories 从112M的Github仓库中定位了435个与WASM有关的仓库，上表表明了这些仓库的功能目的。 Module-level 分类： 首先将样本分为12类： 对于每一类，下表给出其位置、文件大小信息： 下表给出了每个类的特征数和特征例子： Function-level 分类： 由于WASM在编译时会采用最小化函数名称的机制，会损失很多函数名称信息。这里从至少两个独立模块中出现的函数中创建标签，将类似malloc, _malloc, 和memory.allocate的函数名称压缩为一个单独的标签组malloc。这里得到了189个不同功能的函数类别。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"WASM","slug":"WASM","permalink":"http://example.com/tags/WASM/"}],"author":"Shaw"},{"title":"(论文阅读)Binary-level Directed Fuzzing for Use-After-Free Vulnerabilities","slug":"【论文阅读】Binary-level Directed Fuzzing for Use-After-Free Vulnerabilities","date":"2023-05-25T07:01:42.340Z","updated":"2023-05-25T07:01:02.170Z","comments":true,"path":"2023/05/25/【论文阅读】Binary-level Directed Fuzzing for Use-After-Free Vulnerabilities/","link":"","permalink":"http://example.com/2023/05/25/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Binary-level%20Directed%20Fuzzing%20for%20Use-After-Free%20Vulnerabilities/","excerpt":"(论文阅读)Binary-level Directed Fuzzing for Use-After-Free Vulnerabilities 时间：2020 作者：Manh-Dung Nguyen（巴黎萨克雷大学CEA）、Sébastien Bardin、Richard Bonichon 会议：RAID 开源：[1]https://github.com/strongcourage/uafuzz ;[2]https://github.com/strongcourage/uafbench ABSTRACT ​ Directed fuzzing聚焦于通过利用额外信息（bug stack trace、补丁或者有风险的操作）来测试代码的特定部分，其重要的应用场景包括漏洞复现、补丁测试以及对静态分析报告的验证。尽管Directed fuzzing最近受到了很多关注，但诸如UAF等难以检测的漏洞仍然没有得到很好的解决，特别是在二进制层面。 ​ 我们提出了UAFUZZ，第一个针对UAF漏洞的二进制级别directed greybox fuzzer。该技术包括了一个针对UAF特性设计的Fuzzer，一个轻量级的代码插装（code instrumentation）工具和一个高效的bug处理步骤。 ​ 对真实案例中的bug复现进行的实验评估表明，UAFUZZ在故障检测率、暴露时间和bug处理方面明显优于最先进的Directed fuzzer。UAFUZZ在补丁测试中也被证明是有效的，在Perl、GPAC和GNU Patch等程序中发现了30个新的错误（7个CVEs）。最后，我们为社区提供了一个专门用于UAF的大型模糊测试基准，该基准建立在真实代码和真实bug之上。","text":"(论文阅读)Binary-level Directed Fuzzing for Use-After-Free Vulnerabilities 时间：2020 作者：Manh-Dung Nguyen（巴黎萨克雷大学CEA）、Sébastien Bardin、Richard Bonichon 会议：RAID 开源：[1]https://github.com/strongcourage/uafuzz ;[2]https://github.com/strongcourage/uafbench ABSTRACT ​ Directed fuzzing聚焦于通过利用额外信息（bug stack trace、补丁或者有风险的操作）来测试代码的特定部分，其重要的应用场景包括漏洞复现、补丁测试以及对静态分析报告的验证。尽管Directed fuzzing最近受到了很多关注，但诸如UAF等难以检测的漏洞仍然没有得到很好的解决，特别是在二进制层面。 ​ 我们提出了UAFUZZ，第一个针对UAF漏洞的二进制级别directed greybox fuzzer。该技术包括了一个针对UAF特性设计的Fuzzer，一个轻量级的代码插装（code instrumentation）工具和一个高效的bug处理步骤。 ​ 对真实案例中的bug复现进行的实验评估表明，UAFUZZ在故障检测率、暴露时间和bug处理方面明显优于最先进的Directed fuzzer。UAFUZZ在补丁测试中也被证明是有效的，在Perl、GPAC和GNU Patch等程序中发现了30个新的错误（7个CVEs）。最后，我们为社区提供了一个专门用于UAF的大型模糊测试基准，该基准建立在真实代码和真实bug之上。 问题背景 CGF： Coverage-based Greybox Fuzzing DGF： Directed Greybox Fuzzing PUT： program under test Regression Bug： When some bugs are found to be occurring as a result of the bug fix, those are known as regression bugs. Bug stack traces： sequences of function calls at the time a bug is triggered（KASAN、ASan、VALGRIND） Noninterference Bug： 原本应该隔离的部分发生了影响，例如多线程的静态条件漏洞 Flaky bug： 不可靠的bug，其结果难以可靠的复现，其根本原因难以分析 ​ Directed fuzzing的应用场景： bug reproduction，漏洞复现[25, 28, 42, 61] patch testing，补丁测试[25, 51, 59] static analysis report verification，静态分析报告验证[31, 49] 1. 触发特定漏洞的必要性 ​ 基于应用场景的不同，在Directed fuzzing中目标位置会被bug stack traces、补丁文件或者静态分析报告所引导。本文聚焦于漏洞复现，由于信息缺失和用户隐私问题，通常只有54.9%的错误报告可以被重现，所以特别需要这种方法。即使错误报告中提供了PoC，开发人员在修复的过程中可能仍然需要考虑错误的所有情况，以避免regression bug或不完整的修复。在这种情况下，提供更多的触发错误的输入，对促进和加快bug的修复过程非常重要。 2. 目前fuzzer的局限 ​ 目前的grey box fuzzer（无论是否directed）仍然很难找到复杂的漏洞，例如UAF、Noninterference或flaky漏洞，这些漏洞需要满足非常具体的属性的漏洞触发路径。例如，OSSFUZZ 或最近的grey box fuzzer 只发现了少量的UAF。 3. UAF ​ UAF漏洞相比其他类型的漏洞缺乏解决的技术，并且危害十分严重，如数据损坏、信息泄露和Dos攻击。并且要检测UAF还需要面对两个问题： 状态空间的复杂性：一个UAF的产生需要经过分配(alloc)-释放(free)然后利用(use)三个顺序过程，在时间和空间上都有限制； 隐性性状：UAF漏洞经常没有例如segmentation fault的显性表现，单纯观察崩溃行为的fuzzer就无法发现这种错误。如今流行的内存检测工具：ASan、VALGRIND由于其开销过大不能在fuzzing中使用。 （ps：如果是仅仅漏洞复现，可以利用其产生的报告信息，参考[GREBE| shawdox.github.io]） ​ 目前的state-of-the-art：AFLGO和HAWKEYE没法处理UAF并且成本过高。 创新点&amp;贡献 ​ 下表是UAFUZZ与state-of-the-art的比较： ​ 创新点与贡献：针对UAF的Directed Fuzzing，比state-of-the-art的方法准确率更高，速度更快；开源发布了针对UAF漏洞的测试benchmark，包括了从公开软件中提取的30个真实的Bug。 方法 Overview of UAFUZZ 1. Bug Trace Flattening ​ Bug Trace Flattening指重构从report中提取的bug trace，以下图的report为例: ​ 将上述report生成的3个call trace合并为一个call tree，并将其按照UAF漏洞的执行顺序（i.e alloc-&gt;free-&gt;use）的顺序生成分支： ​ 如上图所示，该树状图共有三个分支，分别对应了stack trace for the Alloc、stack trace for the free和stack trace for the bad USE的调用路径。按照0到6的顺序遍历该树，就是UAF漏洞的执行过程，漏洞在6处触发。 ​ 0 → 1 → 2 → 3(nalloc) → 4(nfree) → 5 → 6(nuse) 2. Seed Selection 2.1 Similarity Metrics ​ s代表某个input，T代表report中的目标UAF bug trace，t(s, T )代表s与T的相似度。这里定义了4个测试标准： Target prefix tP(s, T )：s与T的轨迹覆盖前缀（遇到第一个不同就停止）； UAF prefix t3TP(s, T )：s与T的UAF轨迹覆盖前缀（只关注trace中的UAF事件）； Target bag tB(s, T )：s与T的轨迹覆盖数； UAF bag t3TB(s, T )：s与T的UAF轨迹覆盖数。 ​ 以下图为例，其需要在buf数组的前三个字节填充“AFU”来触发UAF漏洞，当s='ABUA'时，上述的四个标准值分别为：tP(s, T ) = 2，t3TP(s, T ) = 1，tB(s, T ) = 3，t3TB(s, T ) = 2。 ​ 将四个metrics结合，得到P-3TP-B： \\[ t_{P-3TP-B} = &lt;t_{P}(s,T),t_{3TP}(s,T),t_{B}(s,T)&gt; \\] ​ 上述式子代表，衡量Similarity的标准首先是轨迹前缀覆盖，若其相同则次要考虑UAF轨迹的前缀，最后考虑轨迹的整体覆盖率。这样做兼顾了精度与广度，UAFUZZ的默认种子衡量算法使用P-3TP-B。 2.2 Seed Selection Algorithm ​ 如上图所示，种子的选择策略是：要么其与report中的目标bug trace T有着更高的重合度，要么其可以提升代码覆盖率。 2.3 UAF-based Seed Distance ​ AFL使用原始CFG图，图中边的权重都是1；HAWKEYE通过修改边的权重来引导fuzzer。 ​ 如何引导Fuzzer按某种顺序依次运行？这里定义了三个集合：Ralloc, Rfree, 和Ruse，分别表示可以执行alloc、free、use操作的函数集合。根据函数调用关系图来判断，例如，如果fa ∈ Ralloc并且fb ∈ R free ∩ Ruse，则从a到b的调用则可能触发UAF漏洞。如下图红色的边。 ​ 确定了fa-&gt;fb的调用边，通过减少其边的权重来让fuzzer更容易执行它，在本工作的实验中，使用如下权重（β=0.25）： 2.4 Cut-edge Coverage Metric ​ 由于对基本块插装的成本过高，HAWKEYE使用对函数插装的方式来跟踪某个种子的运行轨迹（function level）。 ​ 本工作提出cut-edge coverage metric，在edge level上衡量关键节点的程序运行轨迹，该方法是basic block level和function level的平衡。 ps： cut-edge：两个basic block（source和sink）之间的cut edge就是存在一条通过这条edge的路径，可以从source到达sink； algorithm：算法3、4说明了如何在函数间/函数内部计算识别cut edge； 想法：遍历更多cut-edge，更少non-cut edge更容易达到目标轨迹。 2.5 Power Schedule ​ Power Schedule结合了上述三种方法（target similarity metric tP(s, T )、UAF-based seed distance d(s, T )和cut-edge coverage metric es(s, T )）。 ​ 2.6 Postprocess and Bug Triage ​ UAF漏洞发生时一般并不会伴随显式的崩溃，故要检测某个种子是否触发了UAF，需要将其送入bug triager中（例如VALGRIND）检测。因此，当fuzzer生成了大量的种子时，这么做成本很高。 ​ 但由于本工作的target similarity metric可以检测种子的指令路径是否包含了三个UAF关键事件，故bug triager只需要检测包含这些事件的种子即可。 ​ 代码实现基于AFL和QEMU。 测试结果 baseline：AFL-QEMU compare：AFLGO、HAWKEYE benchmark：自行构建 REFERENCE","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Fuzzing","slug":"Fuzzing","permalink":"http://example.com/tags/Fuzzing/"},{"name":"UAF","slug":"UAF","permalink":"http://example.com/tags/UAF/"}],"author":"Shaw"},{"title":"(代码分析)GREBE-Analyzer污点分析代码解析","slug":"【代码分析】GREBE-Analyzer污点分析代码解析","date":"2023-05-09T07:06:56.538Z","updated":"2023-05-14T14:07:05.083Z","comments":true,"path":"2023/05/09/【代码分析】GREBE-Analyzer污点分析代码解析/","link":"","permalink":"http://example.com/2023/05/09/%E3%80%90%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90%E3%80%91GREBE-Analyzer%E6%B1%A1%E7%82%B9%E5%88%86%E6%9E%90%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/","excerpt":"(代码分析)GREBE-Analyzer污点分析代码解析 Code：Markakd/GREBE (github.com) Target：GREBE/analyzer","text":"(代码分析)GREBE-Analyzer污点分析代码解析 Code：Markakd/GREBE (github.com) Target：GREBE/analyzer ## 一、get_cg.py &amp; run_analyze.py 二、analyzer/src/lib 前置知识： GREBE LLVM IR LLVM Pass(legacy manager &amp; new manager) C++面向对象 taint analysis 2.1 代码来源 ​ analyzer的主要作用是用于污点分析，其基于的代码是ucr副教授Chengyu Song 基于kint（2013年的分析工具）的工作《Enforcing-Kernel-Security-Invariants-with-Data-Flow-Integrity》，其在kint的基础上实现了自己的call graph和taint analysis。过去几年有多篇安全A类会议都使用了这份分析代码。 ​ 针对最新的LLVM(14)版本，目前也有开源的kint：ganler/mini-kint: Enhanced implementation of Kint in LLVM-14, in C++17. (github.com) 2.2 总体结构 ​ analyzer的源码分为几个模块：KAMain、Annotation、CallGraph、CrashAnalyzer、PointerAnalysis。KAMain.cc是程序的主模块，其引用模块： ​ analyzer在GlobalCtx模块中定义了自己的Pass父类IterativeModulePass： class IterativeModulePass &#123; protected: GlobalContext *Ctx; const char *ID; public: &#x2F;&#x2F;构造者函数 IterativeModulePass(GlobalContext *Ctx_, const char *ID_) : Ctx(Ctx_), ID(ID_) &#123; &#125; &#x2F;&#x2F; run on each module before iterative pass virtual bool doInitialization(llvm::Module *M) &#123; return true; &#125; &#x2F;&#x2F; run on each module after iterative pass virtual bool doFinalization(llvm::Module *M) &#123; return true; &#125; &#x2F;&#x2F; iterative pass virtual bool doModulePass(llvm::Module *M) &#123; return false; &#125; virtual void run(ModuleList &amp;modules); &#125;; ​ 可以看到IterativeModulePass实现了四个虚函数doInitialization、doFinalization、doModulePass和run分别用于Pass的运行前后处理以及在多个modules上运行Pass。从虚函数的定义就可以看出该项目使用的是旧版的Pass Manager。 ​ 项目中实现了四个子类，其继承关系如图所示： 2.3 KAMain.cc 2.3.1 IterativeModulePass::run ​ IterativeModulePass::run的完整实现在KAMain.cc中，run函数的参数是一个module列表(ModuleList &amp;modules)，其数据结构是： typedef std::vector&lt; std::pair&lt;llvm::Module*, llvm::StringRef&gt; &gt; ModuleList; ​ llvm:StringRef类型表示一个固定不变的字符串的引用（包括一个字符数组的指针和长度），它支持可用在std::string类上的各种通用字符串操作。 ​ ①在run函数中，首先对传入的module列表进行遍历，并依次进行初始化操作： &#x2F;&#x2F;KAMain.cc bool again &#x3D; true; while (again) &#123; again &#x3D; false; &#x2F;&#x2F;遍历所有modules初始化，这里没有做任何操作 for (i &#x3D; modules.begin(), e &#x3D; modules.end(); i !&#x3D; e; ++i) &#123; KA_LOGS(3, &quot;[&quot; &lt;&lt; i-&gt;second &lt;&lt; &quot;]&quot;); &#x2F;&#x2F; doInitialization只返回false，循环结束后again为0 again |&#x3D; doInitialization(i-&gt;first); &#125; &#125; ​ 这里的doInitialization和后续的doModulePass函数都是各个子类中定义的函数，其在父类的函数定义中出现是C++多态的体现，doInitialization函数并不通过IterativeModulePass类运行，而是通过其对应子类ChildName::doInitialization来运行子类特定的对应函数。由于所有子类中的doInitialization都只返回false，故这段初始化操作实际什么也没做。 ​ ②接着，对module列表中的每个module依次调用doModulePass函数，其调用各个子类中实现的Pass操作，并对结果进行统计。 &#x2F;&#x2F;KAMain.cc unsigned iter &#x3D; 0, changed &#x3D; 1; while (changed) &#123; ++iter; changed &#x3D; 0; for (i &#x3D; modules.begin(), e &#x3D; modules.end(); i !&#x3D; e; ++i) &#123; KA_LOGS(3, &quot;[&quot; &lt;&lt; ID &lt;&lt; &quot; &#x2F; &quot; &lt;&lt; iter &lt;&lt; &quot;] &quot;); &#x2F;&#x2F; FIXME: Seems the module name is incorrect, and perhaps it&#39;s a bug. KA_LOGS(3, &quot;[&quot; &lt;&lt; i-&gt;second &lt;&lt; &quot;]&quot;); &#x2F;&#x2F;运行Pass bool ret &#x3D; doModulePass(i-&gt;first); if (ret) &#123; ++changed; KA_LOGS(3, &quot;\\t [CHANGED]&quot;); &#125; else &#123; KA_LOGS(3, &quot; &quot;); &#125; &#125; KA_LOGS(3, &quot;[&quot; &lt;&lt; ID &lt;&lt; &quot;] Updated in &quot; &lt;&lt; changed &lt;&lt; &quot; modules.&quot;); &#125; ​ 由于所有子类的doModulePass函数返回值都是false，故这里的change应该不会被触发。 ​ ③最后，与doInitialization相似，调用doFinalization函数对modules做后处理，这里实际上除了CallGraphPass类对module更新了相关caller和callee映射，其它类的doFinalization什么都没做。所有子类的doFinalization都返回了false，故这里也只遍历了一轮。 &#x2F;&#x2F;KAMain.cc again &#x3D; true; while (again) &#123; again &#x3D; false; for (i &#x3D; modules.begin(), e &#x3D; modules.end(); i !&#x3D; e; ++i) &#123; again |&#x3D; doFinalization(i-&gt;first); &#125; &#125; ​ 综上，子类的run函数的作用就是接受一个module列表，对其中的每个module运行其对应的Pass。 2.3.2 doBasicInitialization ​ KAMain.cc中实现了一个独立函数doBasicInitialization： &#x2F;&#x2F;KAMain.cc void doBasicInitialization(Module *M) &#123; &#x2F;&#x2F; collect global object definitions &#x2F;&#x2F;llvm::GlobalVariable for (GlobalVariable &amp;G : M-&gt;globals()) &#123; &#x2F;&#x2F; bool llvm::GlobalValue::hasExternalLinkage() 查找全局变量是否外部可见 if (G.hasExternalLinkage()) GlobalCtx.Gobjs[G.getName().str()] &#x3D; &amp;G; &#125; &#x2F;&#x2F; collect global function definitions for (Function &amp;F : *M) &#123; if (F.hasExternalLinkage() &amp;&amp; !F.empty()) &#123; &#x2F;&#x2F; external linkage always ends up with the function name StringRef FNameRef &#x3D; F.getName(); std::string FName &#x3D; &quot;&quot;; if (FNameRef.startswith(&quot;__sys_&quot;)) FName &#x3D; &quot;sys_&quot; + FNameRef.str().substr(6); else FName &#x3D; FNameRef.str(); GlobalCtx.Funcs[FName] &#x3D; &amp;F; &#125; &#125; return; &#125; ​ 其功能分为两个部分，将输入的module中的全局对象存储到GlobalCtx.Gobjs中，将输入modules中的全局函数存储到GlobalCtx.Funcs中。 2.3.3 main() ​ main函数的工作流程可以分为以下几部分： 2.3.3.1 准备工作： 分配堆栈资源： &#x2F;&#x2F;KAMain.cc -&gt; main() #ifdef SET_STACK_SIZE &#x2F;&#x2F;struct rlimit&#123; &#x2F;&#x2F; rlim_t rlim_cur; &#x2F;&#x2F;软限制 &#x2F;&#x2F; rlim_t rlim_max; &#x2F;&#x2F;应限制 &#x2F;&#x2F;&#125; struct rlimit rl; &#x2F;&#x2F;getrlimit函数获取RLIMIT_STACK的当前资源限制 &#x2F;&#x2F;RLIMIT_STACK表示最大的进程堆栈，以字节为单位 if (getrlimit(RLIMIT_STACK, &amp;rl) &#x3D;&#x3D; 0) &#123; rl.rlim_cur &#x3D; SET_STACK_SIZE; setrlimit(RLIMIT_STACK, &amp;rl); &#125; #endif ​ 上述代码将进程的栈长度设置为预定义的SET_STACK_SIZE，以字节为单位。 打印stack trace： &#x2F;&#x2F;KAMain.cc -&gt; main() &#x2F;&#x2F; Print a stack trace if we signal out. #if LLVM_VERSION_MAJOR &#x3D;&#x3D; 3 &amp;&amp; LLVM_VERSION_MINOR &lt; 9 sys::PrintStackTraceOnErrorSignal(); #else sys::PrintStackTraceOnErrorSignal(StringRef()); #endif PrettyStackTraceProgram X(argc, argv); &#x2F;&#x2F; Call llvm_shutdown() on exit. llvm_shutdown_obj Y; ​ 如果程序发生错误，上述代码将打印Stack Trace。 命令行选项： KAMain.cc定义了如下命令行全局变量: &#x2F;&#x2F;KAMain.cc cl::list&lt;std::string&gt; InputFilenames( cl::Positional, cl::OneOrMore, cl::desc(&quot;&lt;input bitcode files&gt;&quot;)); cl::opt&lt;unsigned&gt; VerboseLevel( &quot;debug-verbose&quot;, cl::desc(&quot;Print information about actions taken&quot;), cl::init(0)); cl::opt&lt;std::string&gt; DumpLocation( &quot;dump-location&quot;, cl::desc(&quot;dump found structures&quot;), cl::NotHidden, cl::init(&quot;&quot;)); cl::opt&lt;std::string&gt; CrashReport( &quot;crash-report&quot;, cl::desc(&quot;crash report&quot;), cl::Required, cl::init(&quot;&quot;)); cl::opt&lt;std::string&gt; CallGraph(&quot;call-graph&quot;, cl::desc(&quot;call graph from the report&quot;), cl::Required, cl::init(&quot;&quot;)); ​ 其中，InputFilenames是一个list，包含输入的文件名称；VerboseLevel代表输出等级（具体见Common.h）；DumpLocation代表dump文件存储的位置；CrashReport代表syzbot报告的位置；CallGraph代表从报告中提取的call trace文件的位置。 2.3.3.2 读取文件信息 ​ 对InputFilenames列表中的每个LLVM IR文件，需要依次对其做以下处理： IR File -&gt; llvm::Module &#x2F;&#x2F; KAMain.cc -&gt; main() &#x2F;&#x2F; Use separate LLVMContext to avoid type renaming LLVMContext *LLVMCtx &#x3D; new LLVMContext(); &#x2F;&#x2F;来自#include &lt;llvm&#x2F;IRReader&#x2F;IRReader.h&gt; &#x2F;&#x2F;parseIRFile()函数接收一个bitcode文件，返回一个module std::unique_ptr&lt;Module&gt; M &#x3D; parseIRFile(InputFilenames[i], Err, *LLVMCtx); if (M &#x3D;&#x3D; NULL) &#123; errs() &lt;&lt; argv[0] &lt;&lt; &quot;: error loading file &#39;&quot; &lt;&lt; InputFilenames[i] &lt;&lt; &quot;&#39;\\n&quot;; continue; &#125; &#x2F;&#x2F;std::unique_ptr智能指针相关 &#x2F;&#x2F;release()将指针的控制权转移给外部代码 Module *Module &#x3D; M.release(); ​ std::unique_ptr是c++智能指针类型，用于对象对指针的使用权限管理，不必过于深究；这里LLVM::LLVMContext类用于多线程共享/线程独享，不必过于深究。 ​ parseIRFile()来自llvm/IRReader/IRReader.h，其接收一个文件，判断其是否是bitcode文件，如果是则将其转化为Module。若分析失败则打印对应日志信息。 std::string -&gt; llvm::StringRef &#x2F;&#x2F; KAMain.cc -&gt; main() &#x2F;&#x2F;将string复制到一个StringRef上 &#x2F;&#x2F;string.data()返回string字符串的首地址 &#x2F;&#x2F;strdup()用于字符串复制 StringRef MName &#x3D; StringRef(strdup(InputFilenames[i].data())); ​ 将函数名从std::string转化为llvm::StringRef，用于后续记录。 全局信息记录 &#x2F;&#x2F;GlobalCtx.Modules是ModuleList类型 &#x2F;&#x2F;ModuleList &#x3D; std::vector&lt; std::pair&lt;llvm::Module*, llvm::StringRef&gt;&gt; &#x2F;&#x2F;lobalCtx.Modules存储[&amp;Module,ModuleName]键值对 GlobalCtx.Modules.push_back(std::make_pair(Module, MName)); GlobalCtx.ModuleMaps[Module] &#x3D; InputFilenames[i]; doBasicInitialization(Module); ​ 将读取的Module和其名称存到GlobalCtx.Modules和GlobalCtx.ModuleMaps中，并调用doBasicInitialization函数，将Module中的全局对象存储到GlobalCtx.Gobjs中，全局函数存储到GlobalCtx.Funcs中。 ​ 完整代码如下： &#x2F;&#x2F; Load modules KA_LOGS(0, &quot;Total &quot; &lt;&lt; InputFilenames.size() &lt;&lt; &quot; file(s)&quot;); &#x2F;&#x2F; 遍历每个文件 for (unsigned i &#x3D; 0; i &lt; InputFilenames.size(); ++i) &#123; &#x2F;&#x2F; Use separate LLVMContext to avoid type renaming KA_LOGS(1, &quot;[&quot; &lt;&lt; i &lt;&lt; &quot;] &quot; &lt;&lt; InputFilenames[i] &lt;&lt; &quot;&quot;); LLVMContext *LLVMCtx &#x3D; new LLVMContext(); &#x2F;&#x2F;来自#include &lt;llvm&#x2F;IRReader&#x2F;IRReader.h&gt; &#x2F;&#x2F;parseIRFile()函数接收一个bitcode文件，返回一个module std::unique_ptr&lt;Module&gt; M &#x3D; parseIRFile(InputFilenames[i], Err, *LLVMCtx); if (M &#x3D;&#x3D; NULL) &#123; errs() &lt;&lt; argv[0] &lt;&lt; &quot;: error loading file &#39;&quot; &lt;&lt; InputFilenames[i] &lt;&lt; &quot;&#39;\\n&quot;; continue; &#125; &#x2F;&#x2F;std::unique_ptr智能指针相关 &#x2F;&#x2F;release()将指针的控制权转移给外部代码 Module *Module &#x3D; M.release(); &#x2F;&#x2F;将string复制到一个StringRef上 &#x2F;&#x2F;string.data()返回string字符串的首地址 &#x2F;&#x2F;strdup()用于字符串复制 StringRef MName &#x3D; StringRef(strdup(InputFilenames[i].data())); &#x2F;&#x2F;GlobalCtx.Modules是ModuleList类型 &#x2F;&#x2F;ModuleList &#x3D; std::vector&lt; std::pair&lt;llvm::Module*, llvm::StringRef&gt;&gt; &#x2F;&#x2F;lobalCtx.Modules存储[&amp;Module,ModuleName]键值对 GlobalCtx.Modules.push_back(std::make_pair(Module, MName)); GlobalCtx.ModuleMaps[Module] &#x3D; InputFilenames[i]; doBasicInitialization(Module); &#125; 2.3.3.3 分析CrashReport ​ 该部分的功能是分析从syzbot爬取的报告，其目的是分析报告中是否存在可check的点： std::ifstream report(CrashReport); &#x2F;&#x2F; do we find explicit check expression bool explicity &#x3D; false; if (report.is_open()) &#123; &#x2F;&#x2F;std::istreambuf_iterator 输入流缓冲区迭代器 &#x2F;&#x2F;从指定的流缓冲区中读取字符元素 &#x2F;&#x2F;这句代码将report从文件流转化为了一个string std::string reportContent((std::istreambuf_iterator&lt;char&gt;(report)), std::istreambuf_iterator&lt;char&gt;()); &#x2F;&#x2F;如果report中有&quot;WARNNING&quot; 和 &quot;invalid_op&quot; &#x2F;&#x2F;代表存在可check点 if (reportContent.find(&quot;WARNING&quot;) !&#x3D; string::npos &amp;&amp; reportContent.find(&quot;invalid_op&quot;) !&#x3D; string::npos) &#123; explicity &#x3D; true; &#125; &#x2F;&#x2F;如果report中有&quot;kernel BUG at&quot; &#x2F;&#x2F;代表存在可check点 if (reportContent.find(&quot;kernel BUG at&quot;) !&#x3D; string::npos) &#123; explicity &#x3D; true; &#125; report.close(); &#125; 2.3.3.4 分析CallGraph ​ CallGraph就是使用get_cg.py脚本从syzbot报告中提取的call tarce，其以文本文件存储，CallGraph的每一行的组成是[函数名]+[空格]+[调用位置]，例如： ​ 使用std::ifstream类打开文件： std::ifstream file(CallGraph); &#x2F;&#x2F;用于定位Call Trace中的Crash点 std::string CrashLoc; &#x2F;&#x2F;用于检查是否存在KASAN报错 bool kasan_check &#x3D; false; if (file.is_open()) &#123; &#x2F;&#x2F;······ file.close(); &#125; ​ 打开CallGraph后，逐行分析其中的每个函数是否在GlobalCtx.h中预定义的skipFunc函数集中，如果在call trace中前一个函数在skipFunc中而当前函数不在，则认为当前的函数是crash location。 if (file.is_open()) &#123; std::string line, curFunc; std::string lastFunc &#x3D; &quot;&quot;; bool skipped &#x3D; true; &#x2F;&#x2F;读取每一行call trace while (std::getline(file, line)) &#123; StringRef readin &#x3D; StringRef(line); &#x2F;&#x2F;函数名就是CallGraph每行的第一个单词 curFunc &#x3D; readin.split(&quot; &quot;).first.str(); &#x2F;* if previous function is in the skipped function list while current function is not, we set current function as the crash location *&#x2F; &#x2F;&#x2F;skipFunc有哪些是GlobalCtx.h中预定义的 if (skipFunc.find(curFunc) !&#x3D; skipFunc.end()) &#123; skipped &#x3D; true; &#125; else &#123; if (skipped) &#x2F;&#x2F;上个函数在skipFunc中，而这个不在 CrashLoc &#x3D; line; skipped &#x3D; false; &#125; &#x2F;&#x2F; 检查是否存在KASAN报错 if (curFunc.find(&quot;kasan_check_&quot;) !&#x3D; string::npos) &#123; kasan_check &#x3D; true; &#125; if (lastFunc !&#x3D; &quot;&quot;) &#123; KA_LOGS(0, &quot;inserting &quot; &lt;&lt; lastFunc &lt;&lt; &quot; &quot; &lt;&lt; curFunc); &#x2F;&#x2F;std::map&lt;string, string&gt; &#x2F;&#x2F;记录调用关系 GlobalCtx.CallGraph[lastFunc] &#x3D; curFunc; &#125; lastFunc &#x3D; curFunc; &#125; file.close(); &#125; ​ 在遍历CallGraph的过程中，会将函数的调用关系记录到 GlobalCtx.CallGraph中。 2.3.3.5 运行Pass &amp;&amp; Dump ​ 接下来对GlobalCtx.Modules中存储的所有Module调用CallGraphPass和PointerAnalysisPass： &#x2F;&#x2F;调用CallGraphPass CallGraphPass CGPass(&amp;GlobalCtx); CGPass.run(GlobalCtx.Modules); &#x2F;&#x2F;调用PointerAnalysisPass PointerAnalysisPass PAPass(&amp;GlobalCtx); PAPass.run(GlobalCtx.Modules); ​ 如果前文的分析过程中存在Crash check point，则调用CrashAnalyzer Pass： assert(CrashLoc !&#x3D; &quot;&quot;);&#123; &#x2F;&#x2F;调用CrashAnalyzePass CrashAnalyzer CA(&amp;GlobalCtx, explicity, CrashLoc); CA.run(GlobalCtx.Modules); &#x2F;&#x2F; test_bit include&#x2F;asm-generic&#x2F;bitops&#x2F;instrumented-non-atomic.h:110 if (DumpLocation !&#x3D; &quot;&quot;) CA.dump(DumpLocation); else CA.dump(); &#125; ​ 这是整个代码的核心部分，具体Pass的分析过程见后文。 2.4 CallGraphPass 2.4.1 C/C++特殊函数调用 ​ CallGraphPass的目的是构建文件的CallGraph，并将相关调用信息存储到Ctx全局变量中。在进行具体代码分析前，首先来关注一下C语言中函数的特殊调用问题。 2.4.1.1 间接调用(indirect call) ​ C中的间接调用一般是指通过函数指针调用函数： //directCall_test.c #include &lt;stdio.h> void foo() &#123; printf(\"function foo\\n\"); &#125; int main(int argc, char **argv)&#123; foo(); return 0; &#125; //IndirectCall_test.c #include &lt;stdio.h> void foo() &#123; printf(\"function foo\\n\"); &#125; int main(int argc, char **argv)&#123; void (*fp)() = foo; fp(); return 0; &#125; ​ 将其编译为ll文件如下： &#x2F;&#x2F;directCall_test.ll ; Function Attrs: noinline nounwind optnone uwtable define dso_local void @foo() #0 &#123; %1 &#x3D; call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str, i64 0, i64 0)) ret void &#125; declare dso_local i32 @printf(i8*, ...) #1 ; Function Attrs: noinline nounwind optnone uwtable define dso_local i32 @main() #0 &#123; %1 &#x3D; alloca i32, align 4 store i32 0, i32* %1, align 4 call void @foo() ret i32 0 &#125; &#x2F;&#x2F;IndirectCall_test.ll ; Function Attrs: noinline nounwind optnone uwtable define dso_local void @foo() #0 &#123; %1 &#x3D; call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str, i64 0, i64 0)) ret void &#125; declare dso_local i32 @printf(i8*, ...) #1 ; Function Attrs: noinline nounwind optnone uwtable define dso_local i32 @main() #0 &#123; %1 &#x3D; alloca i32, align 4 %2 &#x3D; alloca void (...)*, align 8 store i32 0, i32* %1, align 4 store void (...)* bitcast (void ()* @foo to void (...)*), void (...)** %2, align 8 %3 &#x3D; load void (...)*, void (...)** %2, align 8 call void (...) %3() ret i32 0 &#125; ​ 可以看到，直接调用指令的操作数就是确定Callee的地址（foo），但是间接调其操作数是一个虚拟寄存器%3（在汇编中就是一个确定的寄存器）。故当Pass分析到call语句时没有办法直接得出目标函数的地址，因为寄存器中的值可能是直接载入的确定的地址，也可能是其它地方载入的值。换句话说，直接调用语句可以确定call语句调用的foo函数，但是间接调用语句不能，因为调用什么函数取决于%3内加载了什么值。 ​ 在以上例子中，我们当然可以轻松看出间接调用的就是foo函数的地址，但是万一间接调用的地址取决于用户的输入/程序运行时的具体状态/读取的文件信息等，代码的分支情况就复杂了起来。在C++中的虚函数调用就是通过间接调用完成的，这也是其多态的基础。 2.4.1.2 内联汇编语句 ​ 内联汇编语言（或“inline asm”）是一些编程语言中的一项功能，允许在代码中直接包含汇编语言指令。在需要执行无法使用高级语言结构有效或清晰表达的特定操作时，使用内联汇编可能会很有用。例如，可以使用内联汇编访问硬件设备或优化性能关键的代码段。 ​ 内联汇编语句中可以包含调用指令，例如： #include &lt;stdio.h&gt; int main() &#123; int x &#x3D; 10; int y; &#x2F;&#x2F; 使用内联汇编语言调用一个汇编语言函数 __asm__(&quot;movl %1, %%eax; call assembly_function; movl %%eax, %0;&quot; : &quot;&#x3D;r&quot;(y) : &quot;r&quot;(x)); printf(&quot;The result is: %d\\n&quot;, y); return 0; &#125; &#x2F;&#x2F; 汇编函数用于将输入参数加5并返回结果 __asm__( &quot;assembly_function:\\n&quot; &quot;addl $5, %eax\\n&quot; &quot;ret\\n&quot; ); ​ 上述代码使用内联汇编语言调用一个在汇编语言中定义的函数assembly_function。该函数接受一个输入参数，将其加5，然后返回结果。将其转化为LLVM IR如下： define dso_local i32 @main() #0 &#123; %1 &#x3D; alloca i32, align 4 %2 &#x3D; alloca i32, align 4 %3 &#x3D; alloca i32, align 4 store i32 0, i32* %1, align 4 store i32 10, i32* %2, align 4 %4 &#x3D; load i32, i32* %2, align 4 %5 &#x3D; call i32 asm &quot;movl $1, %eax; call assembly_function; movl %eax, $0;&quot;, &quot;&#x3D;r,r,~&#123;dirflag&#125;,~&#123;fpsr&#125;,~&#123;flags&#125;&quot;(i32 %4) #2, !srcloc !2 store i32 %5, i32* %3, align 4 %6 &#x3D; load i32, i32* %3, align 4 %7 &#x3D; call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str, i64 0, i64 0), i32 %6) ret i32 0 &#125; ​ 可见其使用call i32 asm语句直接调用汇编，并不对其处理。CallGraphPass跳过了对内联汇编函数调用语句的分析。 2.4.1.3 Intrinsic函数 ​ Intrinsic函数是编译器内建的函数，由编译器提供，类似于内联函数。在LLVM中，Intrinsic函数一般是在IR级代码优化时引入的，也就是由前端产生。也可以在程序代码中写Intrinsic函数，并通过前端直接发射。这些函数名的前缀一般是保留字“llvm.”。LLVM后端选择用最高效的形式将Intrinsic函数转换给硬件执行，可以将Intrinsic函数拆分为一系列机器指令，也可以映射为单独一条机器指令，并直接调用相应的硬件功能。 ​ 这里CallGraphPass跳过了Intrinsic函数的调用分析，其与内核并无关系，是LLVM引入的。Intrinsic名必须全部以“ llvm”开头前缀。 2.4.2 代码分析 ​ CallGraph的Pass执行代码如下： &#x2F;&#x2F;CallGraph.cc bool CallGraphPass::doModulePass(Module *M) &#123; bool Changed &#x3D; true, ret &#x3D; false; while (Changed) &#123; Changed &#x3D; false; &#x2F;&#x2F;遍历Module中每个Function for (Function &amp;F : *M) &#x2F;&#x2F;对每个Function操作 Changed |&#x3D; runOnFunction(&amp;F); ret |&#x3D; Changed; &#125; return ret; &#125; ​ 进入函数CallGraph::runOnFunction: &#x2F;&#x2F;CallGraph.cc -&gt; runOnFunction() &#x2F;&#x2F;llvm::GlobalObject -&gt; hasSection(): Check if this global has a custom object file section. &#x2F;&#x2F;llvm::GlobalObject -&gt; getSection(): Get the custom section of this global if it has one. if(F-&gt;hasSection() &amp;&amp; F-&gt;getSection().str() &#x3D;&#x3D; &quot;.init.text&quot;) return false; ​ 首先排除了初始化函数。在C代码中，使用__init宏声明的函数会在编译时将函数放在\".init.text\"这个代码区中。标记为初始化的函数,表明该函数供在初始化期间使用。在模块装载之后，模块装载就会将初始化函数扔掉。这样可以将该函数占用的内存释放出来。 ​ 这里，程序通过使用inst_iterator直接遍历函数里的每条指令： &#x2F;&#x2F;CallGraph.cc -&gt; runOnFunction() bool Changed &#x3D; false; for (inst_iterator i &#x3D; inst_begin(F), e &#x3D; inst_end(F); i !&#x3D; e; ++i) &#123; &#x2F;&#x2F;...... &#125; ​ 对于每条指令，可能与inst_iterator的指针重载有关，需要重新取址获取指向每条指令的地址[LLVM开发者手册]。接着，排除了asm内联调用和intrinsic调用： &#x2F;&#x2F;&#x2F;&#x2F;CallGraph.cc -&gt; runOnFunction() &#x2F;&#x2F;获取指向指令引用的指针 Instruction *I &#x3D; &amp;*i; &#x2F;&#x2F; map callsite to possible callees &#x2F;&#x2F; dyn_cast检查指针I是否是CallInst类型 if (CallInst *CI &#x3D; dyn_cast&lt;CallInst&gt;(I)) &#123; &#x2F;&#x2F; ignore inline asm or intrinsic calls if (CI-&gt;isInlineAsm() || (CI-&gt;getCalledFunction() &amp;&amp; CI-&gt;getCalledFunction()-&gt;isIntrinsic())) continue; ​ 接下来需要获取该CallInst的Callee，即该指令调用的函数。对于直接调用，使用CI-&gt;getCalledFunction()即可；对于间接调用，由于其调用存在多种情况，需要具体分析： &#x2F;&#x2F; CallGraph.cc -&gt; runOnFunction() &#x2F;&#x2F; might be an indirect call, find all possible callees FuncSet &amp;FS &#x3D; Ctx-&gt;Callees[CI]; if (!findCallees(CI, FS)) continue; ​ findCallees()函数流程如下： &#x2F;&#x2F; CallGraph.cc -&gt; findCallees() &#x2F;&#x2F; typedef llvm::SmallPtrSet&lt;llvm::Function*, 32&gt; FuncSet; bool CallGraphPass::findCallees(CallInst *CI, FuncSet &amp;FS) &#123; Function *CF &#x3D; CI-&gt;getCalledFunction(); &#x2F;&#x2F; real function, S &#x3D; S + &#123;F&#125; if (CF) &#123; &#x2F;&#x2F; prefer the real definition to declarations &#x2F;&#x2F; 获取函数定义 CF &#x3D; getFuncDef(CF); return FS.insert(CF).second; &#125; &#x2F;&#x2F;...... &#125; ​ CI-&gt;getCalledFunction()函数用于获取直接调用call指令的callee地址，若其是一个间接调用/非调用指令则返回nullptr。如果返回不为nullptr，则进入以下调用过程： ​ getFuncDef()过程如下： &#x2F;&#x2F; CallGraph.cc -&gt; getFuncDef() Function* CallGraphPass::getFuncDef(Function *F) &#123; &#x2F;&#x2F; typedef std::unordered_map&lt;std::string, llvm::Function*&gt; FuncMap FuncMap::iterator it &#x3D; Ctx-&gt;Funcs.find(getScopeName(F)); if (it !&#x3D; Ctx-&gt;Funcs.end()) return it-&gt;second; else return F; &#125; ​ getScopeName()过程如下： &#x2F;&#x2F; Annotation.h -&gt; getScopeName() static inline std::string getScopeName(const llvm::GlobalValue *GV) &#123; if (llvm::GlobalValue::isExternalLinkage(GV-&gt;getLinkage())) return GV-&gt;getName().str(); else &#123; llvm::StringRef moduleName &#x3D; llvm::sys::path::stem( GV-&gt;getParent()-&gt;getModuleIdentifier()); return &quot;_&quot; + moduleName.str() + &quot;.&quot; + GV-&gt;getName().str(); &#125; &#125; ​ 其中，llvm::GlobalValue类是llvm::Function类的父类llvm::GlobalObject的父类： ​ getScopeName()的作用是检查一个函数是否为全局函数(extern)，如果是则直接返回其函数名，如果不是则查找该函数所属的Module，构建“_{ModuleName}.{FuncName}”字符串并返回。 ​ 回到getFuncDef()函数，其功能是在Ctx-&gt;Funcs中查找函数的定义，如果其在Ctx-&gt;Funcs中存在则返回Ctx-&gt;Funcs中的函数指针，否则返回输入的函数指针F本身。 ​ 回到findCallees()函数，如果输入的指令CI是一个直接调用，则获取其Callee函数指针CF，并调用getFuncDef()在Ctx-&gt;Funcs中查找并返回函数的定义。然后将指针插入FuncSet FS中，如果第一次插入则返回true，否则返回false。因为CF这里传入的是Ctx-&gt;Callees[CI]，返回false就代表查找到的调用关系（CI-&gt;CF）已经存在。 ​ 如果findCallees()函数中CI指令并不是直接调用，则将其插入到Ctx-&gt;IndirectCallInst中： &#x2F;&#x2F; CallGraph.cc -&gt; findCallees() &#x2F;&#x2F; save called values for point-to analysis Ctx-&gt;IndirectCallInsts.push_back(CI); #ifdef TYPE_BASED &#x2F;&#x2F; use type matching to concervatively find &#x2F;&#x2F; possible targets of indirect call return findCalleesByType(CI, FS); #else &#x2F;&#x2F; use assignments based approach to find possible targets &#x2F;&#x2F; const Value* llvm::CallInst::getCalledValue() &#x2F;&#x2F; getCalledValue() - Get a pointer to the function that is invoked by this instruction. return findFunctions(CI-&gt;getCalledValue(), FS); #endif ​ 接下来，调用findFunctions查找其所有可能的Callee，并存储到Ctx-&gt;Callees[Ins]中，具体细节这里不再展开。 ​ 至此，已经找到了当前Call指令的所有Callee，接下来分析callInst指令的所有参数，找到其可能存在的函数指针参数并分析其所有函数指针的Callee，将其存储到Ctx-&gt;FuncPtrs[Id]中： &#x2F;&#x2F;CallGraph.cc -&gt; runOnFunction() #ifndef TYPE_BASED &#x2F;&#x2F; looking for function pointer arguments &#x2F;&#x2F; CI-&gt;getNumArgOperands(): &#x2F;&#x2F; Return the number of invoke arguments for (unsigned no &#x3D; 0, ne &#x3D; CI-&gt;getNumArgOperands(); no !&#x3D; ne; ++no) &#123; &#x2F;&#x2F; CI-&gt;getArgOperand(no) &#x2F;&#x2F; Return the i-th invoke argument. Value *V &#x3D; CI-&gt;getArgOperand(no); if (!isFunctionPointerOrVoid(V-&gt;getType())) continue; &#x2F;&#x2F; find all possible assignments to the argument FuncSet VS; if (!findFunctions(V, VS)) continue; &#x2F;&#x2F; update argument FP-set for possible callees for (Function *CF : FS) &#123; if (!CF) &#123; WARNING(&quot;NULL Function &quot; &lt;&lt; *CI &lt;&lt; &quot;\\n&quot;); assert(0); &#125; std::string Id &#x3D; getArgId(CF, no); Changed |&#x3D; mergeFuncSet(Ctx-&gt;FuncPtrs[Id], VS); &#125; &#125; #endif ​ 如果I不是CallInst指令，而是StoreInst类型指令，则： &#x2F;&#x2F;CallGraph.cc -&gt; runOnFunction() #ifndef TYPE_BASED if (StoreInst *SI &#x3D; dyn_cast&lt;StoreInst&gt;(I)) &#123; &#x2F;&#x2F; stores to function pointers Value *V &#x3D; SI-&gt;getValueOperand(); if (isFunctionPointerOrVoid(V-&gt;getType())) &#123; std::string Id &#x3D; getStoreId(SI); if (!Id.empty()) &#123; FuncSet FS; findFunctions(V, FS); Changed |&#x3D; mergeFuncSet(Id, FS, isFunctionPointer(V-&gt;getType())); &#125; else &#123; &#x2F;&#x2F; errs() &lt;&lt; &quot;Empty StoreID: &quot; &lt;&lt; F-&gt;getName() &lt;&lt; &quot;::&quot; &lt;&lt; *SI &lt;&lt; &quot;\\n&quot;; &#125; &#125; &#125; else if (ReturnInst *RI &#x3D; dyn_cast&lt;ReturnInst&gt;(I)) &#123; &#x2F;&#x2F; function returns if (isFunctionPointerOrVoid(F-&gt;getReturnType())) &#123; Value *V &#x3D; RI-&gt;getReturnValue(); std::string Id &#x3D; getRetId(F); FuncSet FS; findFunctions(V, FS); Changed |&#x3D; mergeFuncSet(Id, FS, isFunctionPointer(V-&gt;getType())); &#125; &#125; #endif ​ 如果一个StoreInst类型指令，并且其操作数是函数指针，则获取其函数指针所有可能的Callee并存储到Ctx-&gt;FuncPtrs[]中。 ​ 在runOnFunction函数执行完毕后，其run函数调用CallGraphPass::doFinalization对每个Module进行善后处理： &#x2F;&#x2F;CallGraph.cc -&gt; doFinalization() bool CallGraphPass::doFinalization(Module *M) &#123; &#x2F;&#x2F; update callee and caller mapping &#x2F;&#x2F; 遍历每个函数 for (Function &amp;F : *M) &#123; &#x2F;&#x2F;遍历每条指令 for (inst_iterator i &#x3D; inst_begin(F), e &#x3D; inst_end(F); i !&#x3D; e; ++i) &#123; &#x2F;&#x2F; map callsite to possible callees &#x2F;&#x2F; 如果该指令是CallInst类型 &#x2F;&#x2F; 根据之前存储的Callees，反向计算Callers if (CallInst *CI &#x3D; dyn_cast&lt;CallInst&gt;(&amp;*i)) &#123; FuncSet &amp;FS &#x3D; Ctx-&gt;Callees[CI]; &#x2F;&#x2F; calculate the caller info here for (Function *CF : FS) &#123; CallInstSet &amp;CIS &#x3D; Ctx-&gt;Callers[CF]; CIS.insert(CI); &#125; &#125; &#125; &#125; return false; &#125; ​ 至此，CallGraphPass分析完毕。 ​ 2.5 PointerAnalysisPass 2.5.1 Alias Analysis ​ Alias Analysis/Pointer Analysis是一类试图确定两个指针是否可以指向内存中同一个对象的技术[LLVM Alias Analysis Infrastructure — LLVM 17.0.0]。 ​ Alias Analysis（别名分析）是编译器理论中的一种技术，用于确定存储位置是否可以以多种方式访问。如果两个指针指向相同的位置，则称这两个指针为别名。 但是，它不能与Pointer Analysis（指针分析）混淆，指针分析解决的问题是一个指针可能指向哪些对象或者指向哪些地址，而别名分析解决的是两个指针指向的是否是同一个对象。指针分析和别名分析通常通过静态代码分析来实现。 ​ 别名分析在编译器理论中非常重要，在代码优化和安全方面有着非常广泛且重要的应用。编译器级优化需要指针别名信息来执行死代码消除（删除不影响程序结果的代码）、冗余加载/存储指令消除、指令调度（重排列指令）等。编译器级别的程序安全使用别名分析来检测内存泄漏和内存相关的安全漏洞。 2.5.2 代码分析 ​ 定义相关数据结构： &#x2F;&#x2F;GlobalCtx.h typedef DenseMap&lt;Value *, SmallPtrSet&lt;Value *, 16&gt;&gt; PointerAnalysisMap; typedef unordered_map&lt;Function *, PointerAnalysisMap&gt; FuncPointerAnalysisMap; typedef unordered_map&lt;Function *, AAResults *&gt; FuncAAResultsMap; ​ 分析代码： &#x2F;&#x2F;PointerAnalysis.cc bool PointerAnalysisPass::doModulePass(Module *M) &#123; &#x2F;&#x2F;llvm::legacy::FunctionPassManager是旧版的Pass Manager legacy::FunctionPassManager *FPasses &#x3D; new legacy::FunctionPassManager(M); AAResultsWrapperPass *AARPass &#x3D; new AAResultsWrapperPass(); FPasses-&gt;add(AARPass); &#x2F;&#x2F;return false FPasses-&gt;doInitialization(); for (Function &amp;F : *M) &#123; &#x2F;&#x2F;如果该函数的定义在Module之外 if (F.isDeclaration()) continue; FPasses-&gt;run(F); &#125; FPasses-&gt;doFinalization(); AAResults &amp;AAR &#x3D; AARPass-&gt;getAAResults(); for (Module::iterator f &#x3D; M-&gt;begin(), fe &#x3D; M-&gt;end(); f !&#x3D; fe; ++f) &#123; Function* F &#x3D; &amp;*f; PointerAnalysisMap aliasPtrs; if (F-&gt;empty()) continue; detectAliasPointers(F, AAR, aliasPtrs); Ctx-&gt;FuncPAResults[F] &#x3D; aliasPtrs; Ctx-&gt;FuncAAResults[F] &#x3D; &amp;AAR; &#125; return false; &#125; ​ 其使用legacy::FunctionPassManager创建了一个旧版的Function Pass Manager，并将Pointer Analysis分析Pass AAResultsWrapperPass添加进去。 ​ 接下来使用(Function &amp;F : *M）语句遍历Module中的每个函数，如果该函数F的定义不在Module之外，则运行AAResultsWrapperPass，并通过AAResult结构获取分析结果。 ​ 接下来再次遍历Module中的每个Function，对其调用函数detectAliasPointers： &#x2F;&#x2F;PointerAnalysis.cc void PointerAnalysisPass::detectAliasPointers(Function* F, AAResults &amp;AAR, PointerAnalysisMap &amp;aliasPtrs) &#123; std::set&lt;Value *&gt; addr1Set; std::set&lt;Value *&gt; addr2Set; Value *Addr1, *Addr2; &#x2F;&#x2F;获取所有指针类型 for (Argument &amp;A : F-&gt;args()) if (A.getType()-&gt;isPointerTy()) addr1Set.insert(&amp;A); for (Instruction &amp;I : instructions(*F)) if (I.getType()-&gt;isPointerTy()) addr1Set.insert(&amp;I); &#x2F;&#x2F;why?? if (addr1Set.size() &gt; 1000) &#123; return; &#125; for (auto Addr1 : addr1Set) &#123; for (auto Addr2 : addr1Set) &#123; &#x2F;&#x2F;只分析不同的指针对 if (Addr1 &#x3D;&#x3D; Addr2) continue; &#x2F;&#x2F;用于从总的分析结果里获取单对指针分析结果 AliasResult AResult &#x3D; AAR.alias(Addr1, Addr2); bool notAlias &#x3D; true; if (AResult &#x3D;&#x3D; MustAlias || AResult &#x3D;&#x3D; PartialAlias) &#123; notAlias &#x3D; false; &#x2F;&#x2F;只要确定的 &#125; else if (AResult &#x3D;&#x3D; MayAlias) &#123; &#125; if (notAlias) continue; &#x2F;&#x2F;如果存在alias auto as &#x3D; aliasPtrs.find(Addr1); if (as &#x3D;&#x3D; aliasPtrs.end()) &#123; SmallPtrSet&lt;Value *, 16&gt; sv; sv.insert(Addr2); aliasPtrs[Addr1] &#x3D; sv; &#125; else &#123; as-&gt;second.insert(Addr2); &#125; &#125; &#125; &#125; ​ detectAliasPointers()对每个输入的函数，首先用循环将其指针类参数和指针类指令都存储到集合addr1Set中，并且如果addr1Set存储的指针数量大于100则直接返回，不做分析（为什么？）。 ​ 接下来对addr1Set内的所有指针两两分析，使用AAResult.alias()函数获取两个指针的分析结果AResult，如果AResult为MustAlias/PartialAlias则将这个指针对存储到aliasPtrs中。 ​ 在detectAliasPointers()分析完后，将其Ailas分析结果存储到Ctx-&gt;FuncPAResults[F]中，将整个AAResultsWrapperPass的分析结果存储到Ctx-&gt;FuncAAResults[F]中，至此，PointerAnalysisPass分析完毕。 2.6 CrashAnalyzer ​ CrashAnalyzer用于确定反向污点分析的source。 ​ 在CrashAnalyzer.h中定义了CrashAnalyzer的构造函数： &#x2F;&#x2F;CrashAnalyzer.h public: &#x2F;&#x2F;构造函数 CrashAnalyzer(GlobalContext *Ctx_, bool cond_, &#x2F;*llvm::StringRef fn, llvm::StringRef Sourcef_, unsigned l*&#x2F; llvm::StringRef CrashLoc ) : IterativeModulePass(Ctx_, &quot;CrashAnalyzer&quot;) &#123; cond &#x3D; cond_; &#x2F;&#x2F; KA_LOGS(0, &quot;crash loc : &quot; &lt;&lt; CrashLoc &lt;&lt; &quot;\\n&quot;); funcName &#x3D; CrashLoc.split(&quot; &quot;).first; auto loc &#x3D; CrashLoc.split(&quot; &quot;).second; source &#x3D; loc.split(&quot;:&quot;).first; line &#x3D; stoi(loc.split(&quot;:&quot;).second.str()); &#x2F;&#x2F; KA_LOGS(0, &quot;parsed loc: &quot; &lt;&lt; funcName &lt;&lt; &quot;\\n&quot;); &#x2F;&#x2F; KA_LOGS(0, &quot;source : &quot; &lt;&lt; source &lt;&lt; &quot;\\n&quot;); &#x2F;&#x2F; KA_LOGS(0, &quot;Line: &quot; &lt;&lt; line &lt;&lt; &quot;\\n&quot;); analyzed &#x3D; false; Ctx-&gt;InstNum &#x3D; 0; &#125; ​ 其继承了父类IterativeModulePass的构造函数，将Ctx设置为Ctx_，ID设置为“CrashAnalyzer”。接下来，设置cond（就是KAMain.cc中的explicity，用于表明是否在report中找到了显式可check点），并将CrashLoc中的函数名称与位置信息提取出来，分别赋值给变量funcName、loc、 source、line。最后将Ctx-&gt;InstNum设置为0。 ​ CrashAnalyzer::doModulePass对每个函数运行CrashAnalyzer::runOnFunction ： &#x2F;&#x2F;CrashAnalyzer.cc bool CrashAnalyzer::doModulePass(Module* M) &#123; &#x2F;&#x2F; some functions are defined in headers &#x2F;&#x2F; if (moduleName.str() !&#x3D; M-&gt;getSourceFileName()) &#x2F;&#x2F; return false; for (Function &amp;F : *M) runOnFunction(&amp;F); return false; &#125; ​ CrashAnalyzer::runOnFunction()会定位之前在KAMain.cc中定位的CrashLoc中的函数以及crash位置，并遍历该函数的每条指令： &#x2F;&#x2F;确定source void CrashAnalyzer::runOnFunction(Function *F) &#123; &#x2F;&#x2F;只对carsh函数做分析 if (funcName !&#x3D; F-&gt;getName() || analyzed) return; &#x2F;&#x2F;遍历每条指令 for (inst_iterator i &#x3D; inst_begin(F), e &#x3D; inst_end(F); i !&#x3D; e; i++) &#123; Instruction* I &#x3D; &amp;*i; &#x2F;&#x2F;DILocation metadata node provides information &#x2F;&#x2F;such as the file name, line number, &#x2F;&#x2F;and column number of the source code location &#x2F;&#x2F;corresponding to a particular instruction or operation in the IR DILocation* Loc &#x3D; I-&gt;getDebugLoc(); if (Loc &#x3D;&#x3D; nullptr) &#123; continue; &#125; &#x2F;* remove &quot;.&#x2F;&quot; for header files *&#x2F; StringRef sourceF &#x3D; Loc-&gt;getScope()-&gt;getFilename(); if (sourceF.startswith(&quot;.&#x2F;&quot;)) &#123; sourceF &#x3D; sourceF.split(&quot;.&#x2F;&quot;).second; &#125; if (line &#x3D;&#x3D; Loc-&gt;getLine() &amp;&amp; sourceF &#x3D;&#x3D; source) &#123; &#x2F;&#x2F;显式&#x2F;隐式定位source &#x2F;&#x2F;...... &#125; &#125;&#x2F;&#x2F;end of for &#125;&#x2F;&#x2F;end of runOnFunction() ​ 由上述代码可知，定位到call trace中的crash函数后，代码根据LLVM IR的debug信息来定位LLVM指令对应源代码的行数，以此定位到report中的crash行，例如对如下call trace： ​ 根据函数名来定位Module内的Crash函数，根据对应文件标志的代码行数来定位相关crash指令（遍历每个指令，根据metaData提供的debug信息查看指令对应的源码行数）。 2.6.1 Implicit Checking ​ CrashAnalyzer::runOnFunction()根据cond参数决定以显式/隐式的方式定位反向污点分析的source(即导致程序crash的指令)。当cond为false时，执行隐式检查(Implicit Checking)： &#x2F;&#x2F;CrashAnalyzer.cc -&gt; runOnFunction() &#x2F;&#x2F;Implicit Checking &#x2F;&#x2F;如果没有可以明确check的点 &#x2F;&#x2F;则分析隐式Crash指令 if (!cond) &#123; &#x2F;&#x2F;isa&lt;&gt; 与 java中的instanceof用法一致 &#x2F;&#x2F;用于测试I是否是LoadInst&#x2F;StoreInst类型 &#x2F;&#x2F;是则返回true，否则返回false if (isa&lt;LoadInst&gt;(I) || isa&lt;StoreInst&gt;(I)) &#123; Ctx-&gt;TaintSrc.insert(I); Ctx-&gt;InstNum ++; &#125; &#x2F;&#x2F;如果是Call指令 else if (isa&lt;CallInst&gt;(I)) &#123; Function *F &#x3D; cast&lt;CallInst&gt;(I)-&gt;getCalledFunction(); &#x2F;&#x2F;如果不是直接调用指令则直接返回 if (F &#x3D;&#x3D; nullptr) &#123; KA_WARNS(0, &quot;Fail to find Function from the CallInst &quot;&lt;&lt;*I); continue; &#125; StringRef Fname &#x3D; F-&gt;getName(); &#x2F;* since we skip some debugging functions in the first step let&#39;s taint starting from these functions&#39; argument *&#x2F; &#x2F;&#x2F;若Callee是skipFunc，则该Call指令作为source if (skipFunc.find(Fname) !&#x3D; skipFunc.end()) &#123; Ctx-&gt;TaintSrc.insert(I); &#x2F;&#x2F;若Callee函数名包含&quot;__write_once_size&quot; &#x2F;&#x2F;获取Call指令的第一个参数作为source &#125; else if (Fname.find(&quot;__write_once_size&quot;) !&#x3D; string::npos) &#123; Ctx-&gt;TaintSrc.insert(cast&lt;CallInst&gt;(I)-&gt;getArgOperand(0)); &#125;else &#123; KA_WARNS(0, &quot;Unknown call here &quot;&lt;&lt;*I); &#125; &#125; &#x2F;&#x2F;既不是存储&#x2F;加载指令，也不是call指令，放弃 else &#123; KA_LOGS(1, &quot;Unknown Inst here &quot;&lt;&lt;*I); &#125; &#125;&#x2F;&#x2F;end of implicit checking &#x2F;&#x2F;explicit checking else&#123; &#x2F;&#x2F;... &#125; ​ 对于implicit checking： ​ 1） 若定位的指令是LoadInst/StoreInst类型： ​ 直接将此指令作为source。 ​ 2） 若定位的指令是CallInst类型： ​ 若该Call不是直接调用则直接丢弃；否则若其Callee是skipFunc，直接将该指令作为source；或者其Callee函数名包含“__write_once_size”，将该Call指令的第一个操作数作为source。 ​ 3） 若以上二者都不是： ​ 丢弃。 2.6.2 Explicit Checking ​ 当cond为ture时，执行显式检查(Explicit Checking)。对于显式检查，GREBE文章中的定义是有明确错误检查功能的预定义宏（如WARN_ON和BUG_ON）、辅助函数等，其共性是在代码中直接进行检查，故代码中只分析CallInst类型指令： &#x2F;&#x2F;CrashAnalyzer.cc -&gt; runOnFunction() &#x2F;&#x2F;explicit checking else&#123; if (isa&lt;CallInst&gt;(I)) &#123; CallInst *CI &#x3D; cast&lt;CallInst&gt;(I); &#x2F;&#x2F;获取直接调用子函数 Function *F &#x3D; CI-&gt;getCalledFunction(); StringRef Fname &#x3D; &quot;&quot;; &#x2F;&#x2F; if calling asm if (F !&#x3D; nullptr) &#123; Fname &#x3D; F-&gt;getName(); &#125; &#x2F;&#x2F;...... &#125; &#123; ​ 针对不同的调用情况，其具体处理如下： &#x2F;* handle ODEBUG and DEBUG_OBJECTS_FREE. * which generate warns using &quot;implicit&quot; * checkings *&#x2F; if (Fname.find(&quot;init_work&quot;) !&#x3D; string::npos || Fname.find(&quot;print_unlock_imbalance_bug&quot;) !&#x3D; string::npos || Fname.find(&quot;debug_print_object&quot;) !&#x3D; string::npos || Fname.find(&quot;debug_object_init&quot;) !&#x3D; string::npos || Fname.find(&quot;debug_assert_init&quot;) !&#x3D; string::npos || &#x2F;* DEBUG_OBJECTS_FREE *&#x2F; Fname.find(&quot;debug_check_no_obj_freed&quot;) !&#x3D; string::npos) &#123; Ctx-&gt;TaintSrc.insert(I); &#125; ​ 对于子函数名中存在“printk”/内联汇编调用的，进行如下处理： &#x2F;&#x2F;定位指令属于的BB BasicBlock *BB &#x3D; CI-&gt;getParent(); KA_LOGS(2, &quot;Found BB : &quot;&lt;&lt;*BB); KA_LOGS(2, &quot;terminator : &quot;&lt;&lt;*BB-&gt;getTerminator()); Value *condV; bool warnOnce &#x3D; false; ​ 接着进行如下处理： while (BB-&gt;getSinglePredecessor()) &#123; &#x2F;&#x2F;Predecessor，前身，指在控制流中一个基本块的上一个块 BasicBlock *newBB &#x3D; BB-&gt;getSinglePredecessor(); &#x2F;* heuristic: if sotring true to &#96;refcount_inc_checked.__warned&#96; * exists in the skipped BB, there should exist an redundant * checking for the &#96;refcount_inc_checked.__warned&#96; *&#x2F; &#x2F;&#x2F;遍历基本块中的每条指令 for (Instruction &amp;BBInst : *BB) &#123; &#x2F;&#x2F;如果是StoreInst类型 if (isa&lt;StoreInst&gt;(&amp;BBInst)) &#123; StoreInst *SI &#x3D; cast&lt;StoreInst&gt;(&amp;BBInst); &#x2F;&#x2F;如果StoreInst指令的第一个参数为常数 &#x2F;&#x2F;&amp;&amp; 第二个参数为全局变量 if (isa&lt;ConstantInt&gt;(SI-&gt;getOperand(0)) &amp;&amp; isa&lt;GlobalVariable&gt;(SI-&gt;getOperand(1))) &#123; &#x2F;&#x2F;获取第二个参数的名称 StringRef GVName &#x3D; cast&lt;GlobalVariable&gt;(SI-&gt;getOperand(1))-&gt;getName(); KA_LOGS(0, &quot;Found Global Value: &quot;&lt;&lt;GVName); &#x2F;&#x2F;如果全局变量名称包含“__warned” &#x2F;&#x2F;并且子函数F存在（直接调用） &#x2F;&#x2F;并且子函数名称包含“__warn_printk” if (GVName.find(&quot;__warned&quot;) !&#x3D; string::npos &amp;&amp; F &amp;&amp; F-&gt;getName().find(&quot;__warn_printk&quot;) !&#x3D; string::npos) &#123; KA_LOGS(0, &quot;Warn ONCE checking here....&quot;); warnOnce &#x3D; true; &#125; &#125; &#125; &#125; &#x2F;&#x2F;如果是BranchInst类型 if (isa&lt;BranchInst&gt;(newBB-&gt;getTerminator())) &#123; &#x2F;&#x2F;getTerminator()获取基本块的终止指令，例如分支指令br，ret等 &#x2F;&#x2F;如果Predecessor块中的终止指令是BranchInst类型 BranchInst *BI &#x3D; cast&lt;BranchInst&gt;(newBB-&gt;getTerminator()); &#x2F;&#x2F;检查该br指令是否是条件跳转，isConditional() &#x2F;&#x2F;isConditional()返回true&#x2F;false if (BI-&gt;isConditional()) &#123; KA_LOGS(0, &quot;Found first condition : &quot;&lt;&lt;*BI-&gt;getCondition()); condV &#x3D; BI-&gt;getCondition(); break; &#125; &#125; &#x2F;&#x2F;如果父块的终止指令不是conditional br，则继续向上寻找 BB &#x3D; newBB; KA_LOGS(1, &quot;Skipping BB: &quot;&lt;&lt;*BB); ​ 如果指令的父基本块的终止指令是一个contional br并且指令所在的基本块不存在上述的warn调用，则将condition指令设置为污点源source： &#x2F;* * if we find a condition value and the logging is not WARN_ONCE, * we mark the condition value as taint source and continue. * *&#x2F; if (condV &amp;&amp; !warnOnce ) &#123; Ctx-&gt;TaintSrc.insert(condV); continue; &#125; ​ 接下来进行广度优先搜索： &#x2F;&#x2F; null the condition Value *SecondCondV &#x3D; nullptr; &#x2F;&#x2F; breadth first search std::vector&lt;BasicBlock *&gt; BBVec; std::set&lt;BasicBlock *&gt; BBSet; BBVec.push_back(BB); &#x2F;&#x2F;...... while (!BBVec.empty() &amp;&amp; !SecondCondV) &#123; BB &#x3D; BBVec.back(); BBVec.pop_back(); &#x2F;&#x2F; cyclic basic block if (!BBSet.insert(BB).second) &#123; continue; &#125; if (!BB-&gt;hasNPredecessorsOrMore(1)) &#123; &#x2F;* no predecessor, let&#39;s find find its parents *&#x2F; &#x2F;&#x2F;getParent()用于获取当前基本块所在函数 auto fName &#x3D; BB-&gt;getParent()-&gt;getName(); &#x2F;&#x2F;如果该函数在report报告的Call trace中 if (Ctx-&gt;CallGraph.find(fName) !&#x3D; Ctx-&gt;CallGraph.end()) &#123; auto callerName &#x3D; Ctx-&gt;CallGraph[fName]; for (auto M : Ctx-&gt;Callers) &#123; if (M.first-&gt;getName().endswith(fName)) &#123; auto CISet &#x3D; M.second; for (CallInst *caller : CISet) &#123; &#x2F;&#x2F;根据调用图找到parent if (caller-&gt;getFunction()-&gt;getName() &#x3D;&#x3D; callerName) &#123; BB &#x3D; caller-&gt;getParent(); KA_LOGS(0, &quot;Backwarding to its parent &quot;&lt;&lt;callerName); break; &#125; &#125; &#125; &#125; &#125; &#125; &#x2F;&#x2F;遍历其predecessors for (BasicBlock *Pred : predecessors(BB)) &#123; KA_LOGS(1, &quot;Found pre : &quot;&lt;&lt;*Pred); BBVec.push_back(Pred); if (isa&lt;BranchInst&gt;(Pred-&gt;getTerminator())) &#123; BranchInst *BI &#x3D; cast&lt;BranchInst&gt;(Pred-&gt;getTerminator()); if (BI-&gt;isConditional() &amp;&amp; condV !&#x3D; BI-&gt;getCondition()) &#123; SecondCondV &#x3D; BI-&gt;getCondition(); assert(SecondCondV); KA_LOGS(0, &quot;Found 1st condition : &quot;&lt;&lt;*condV); KA_LOGS(0, &quot;Found 2nd condition : &quot;&lt;&lt;*SecondCondV); break; &#125; &#125; &#125; &#125; if (SecondCondV) &#123; Ctx-&gt;TaintSrc.insert(SecondCondV); continue; &#125; ​ 这里具体为什么要这么做还需深入探索。 2.7 Backward Taint Analysis ​ 污点分析过程存储在StructFinderPass::doAnalyze()中： &#x2F;&#x2F; StructFinder.cc -&gt; doAnalyze() &#x2F;&#x2F; v是污点源 void StructFinderPass::doAnalyze(Value *v) &#123; VSet vs; vs.clear(); &#x2F;&#x2F; 将污点分析的结果存储到全局变量Ctx-&gt;CriticalSt中 mergeSet(Ctx-&gt;CriticalSt, taintAnalysis(v, vs, false)); &#125; &#x2F;&#x2F; StructFinderPass -&gt; mergeSet() static void mergeSet(std::set&lt;llvm::StringRef&gt; &amp;a, std::set&lt;llvm::StringRef&gt; b) &#123; a.insert(b.begin(), b.end()); &#125; ​ 接下来进入正式的污点分析过程StructFinderPass::taintAnalysis，首先遍历污点源的用户指令，对其中的Cast指令进行处理： &#x2F;&#x2F;StructFinder.cc -&gt; taintAnalysis() std::set&lt;llvm::StringRef&gt; result; &#x2F;&#x2F;每个污点源单独一个result result.clear(); if (!vs.insert(V).second) &#123; return result; &#125; &#x2F;&#x2F; debuging!!! remove this when deploying blockset &#x2F;&#x2F; found &#x3D; false; KA_LOGV(0, V); &#x2F;&#x2F; find the casting... &#x2F;&#x2F; V-&gt;users()获取污点源的用户指令 for (auto *user : V-&gt;users()) &#123; &#x2F;&#x2F;BitCastInst类型是LLVM的数据类型转换指令 &#x2F;&#x2F;其转换数据格式但不改变其存储方式 &#x2F;&#x2F;例如： &#x2F;&#x2F;%ptr &#x3D; alloca i32* &#x2F;&#x2F;%casted_ptr &#x3D; bitcast i32** %ptr to i8** if (isa&lt;BitCastInst&gt;(user)) &#123; BitCastInst *BCI &#x3D; dyn_cast&lt;BitCastInst&gt;(user); &#x2F;&#x2F; getDestTy &#x3D; get distination type Type *dst &#x3D; BCI-&gt;getDestTy(); &#x2F;&#x2F; *Type -&gt; StringRef auto name &#x3D; handleType(dst); KA_LOGS(0, &quot;Found &quot;&lt;&lt;name&lt;&lt;&quot; in casting&quot;); addToSet(result, name); &#125; &#125; ​ 可见，只要污点源的用户指令是BitCastInst类型，就将该指令的DestType的名称加入result中。 ​ 接下来，对污点源本身分为三类：Instruction、Argument与GlobalVaribal，三类污点源分别进行不同的处理。无需赘述，Instruction类型就是指令类型；Argument类型用于描述函数声明，GlobalVaribal表示全局变量。 0. StructFinderPass::handleType ​ handleType()函数用于获取struct/int的名称，如果传入的type是指针或数组则递归查找其指向类型。 StringRef StructFinderPass::handleType(Type *ty) &#123; if (ty &#x3D;&#x3D; nullptr) return StringRef(&quot;&quot;); if (ty-&gt;isStructTy()) &#123; StructType *ST &#x3D; dyn_cast&lt;StructType&gt;(ty); StringRef stname &#x3D; ST-&gt;getName(); &#x2F;&#x2F;如果该结构以struct.为首， &#x2F;&#x2F;并且不是匿名结构 if (stname.startswith(&quot;struct.&quot;) &amp;&amp; !stname.startswith(&quot;struct.anon&quot;)) return stname; &#125; else if (ty-&gt;isPointerTy())&#123; ty &#x3D; cast&lt;PointerType&gt;(ty)-&gt;getElementType(); return handleType(ty); &#125; else if (ty-&gt;isArrayTy())&#123; ty &#x3D; cast&lt;ArrayType&gt;(ty)-&gt;getElementType(); return handleType(ty); &#125; else if (ty-&gt;isIntegerTy()) &#123; return StringRef(&quot;int&quot;); &#125; return StringRef(&quot;&quot;); &#125; 1. Instruction类型source： ​ 针对不同类型的Insturction再分别处理. 1.1 Instruction::Store: ​ 在LLVM IR中，store指令的格式如下： %value = ... %ptr = ... store &lt;type1> %value, &lt;type2>* %ptr ​ 其表明将type1格式的value存入type2格式的指针ptr所指向的内存中。type1与type2必须相同或者兼容。 ​ 在LLVM IR中，getelementptr指令的格式如下： %array = alloca [10 x i32] %element_ptr = getelementptr [10 x i32], [10 x i32]* %array, i32 0, i32 3 ​ 其用于计算结构中某个元素的指针，C语言中所有对数组/结构体的取值操作都会被翻译为getelementptr。 ​ 在LLVM IR中，load/store指令经常与getelementptr指令一起使用，用于表示对数组/结构体的赋值操作，例如： %arr = alloca [10 x i32] %x = load i32, i32* getelementptr inbounds ([10 x i32], [10 x i32]* %arr, i64 0, i64 3) %arr = alloca [10 x i32] %3 = getelementptr inbounds [10 x i32], [10 x i32]* %arr, i64 0, i64 3 store i32 7, i32* %3 ​ 上述两个代码块分别表示从数组中取值和为数组某个成员赋值。 ​ 针对store指令的分析过程如下： &#x2F;&#x2F; StructFinder.cc -&gt; taintAnalysis() &#x2F;&#x2F; if (auto *I &#x3D; dyn_cast&lt;Instruction&gt;(V)) &#x2F;&#x2F; I-&gt;getOpcode() &#x3D;&#x3D; Instruction::Store: case Instruction::Store:&#123; StoreInst *SI &#x3D; cast&lt;StoreInst&gt;(I); &#x2F;&#x2F;获取指针类型 Type *SType &#x3D; SI-&gt;getPointerOperandType(); &#x2F;&#x2F;*Type -&gt; StringRef StringRef stName &#x3D; handleType(SType); &#x2F;&#x2F;如果该指针类型已经在该source的result中了则跳过分析 if (!addToSet(result, stName)) &#123; break; &#125; &#x2F;&#x2F; would find a GetElementType if (!isa&lt;GetElementPtrInst&gt;(SI-&gt;getOperand(0))) &#123; &#x2F;&#x2F; assert(0 &amp;&amp; &quot;didn&#39;t find a GetElementPtrInst before StoreInst&quot;); &#125; Value *GetV &#x3D; SI-&gt;getOperand(1); &#x2F;&#x2F; we skip these getElement since they are nested while (isa&lt;GetElementPtrInst&gt;(GetV)) &#123; GetElementPtrInst *GEI &#x3D; cast&lt;GetElementPtrInst&gt;(GetV); &#x2F;&#x2F;getSourceElementType()获取取值操作的原地址 &#x2F;&#x2F;hanleType获取类型名称，例如结构的名称 StringRef name &#x3D; handleType(GEI-&gt;getSourceElementType()); &#x2F;&#x2F;如果该结构已经处理则跳过 if (!addToSet(result, name)) &#123; break; &#125; &#x2F;&#x2F;继续递归，向上寻找其操作指针 GetV &#x3D; GEI-&gt;getOperand(0); &#125; &#x2F;&#x2F; the outside GetElementPtrInst &#x2F;&#x2F; 处理最后的的GteV mergeSet(result, taintAnalysis(GetV, vs, found)); break; &#125; ​ 正常来说，对于一个store指令，如果其value （Operand(0)）为污点源，那污点就会通过该指令传播到对应的ptr中去（Operand(1)）。但由于C语言中存在对数组/结构体取值的操作，故store指令的Ptr也可能是GetElementPtrInst类型，所以代码中存在对store指令操作数的反复递归迭代，如下图所示： 1.2 Instruction::load ​ load指令的作用是从目标地址取操作数，其格式如下： ​ load指令将ptr所指向的数据以&lt; type &gt;的形式取出，并存入%1中。 ​ Load指令处理部分： case Instruction::Load:&#123; &#x2F;&#x2F; should pair with a GetElementPtr &#x2F;&#x2F; remember to check if it is nested LoadInst *LI &#x3D; cast&lt;LoadInst&gt;(I); Type *lType &#x3D; LI-&gt;getPointerOperandType(); &#x2F;&#x2F;获取ptr指向的结构名称 StringRef stName &#x3D; handleType(lType); if (!addToSet(result, stName)) &#123; break; &#125; &#x2F;&#x2F;如果Load指令的ptr指向的结构以&quot;struct.list_head&quot;开头 &#x2F;&#x2F;并且Load指令的第一个参数为ConstantExpr(算术式)类型 if (stName &#x3D;&#x3D; &quot;struct.list_head&quot; &amp;&amp; isa&lt;ConstantExpr&gt;(LI-&gt;getOperand(0))) &#123; &#x2F;&#x2F; looking type info in list_head Value *bitcastV &#x3D; nullptr; &#x2F;&#x2F;分析污点源的所有用户指令 for (auto *user : V-&gt;users()) &#123; &#x2F;&#x2F;如果用户指令是phi指令 if (isa&lt;PHINode&gt;(user)) &#123; &#x2F;&#x2F;继续获取其父指令 for (auto *uuser : user-&gt;users()) &#123; &#x2F;&#x2F;如果其是一个类型转换指令 if (isa&lt;BitCastInst&gt;(uuser)) &#123; bitcastV &#x3D; uuser; &#125; &#125; &#125; &#125; &#x2F;&#x2F;如果找不到类型转换指令则跳过 if (bitcastV &#x3D;&#x3D; nullptr) &#123; break; &#125; &#x2F;&#x2F;遍历bitcast指令的父指令 for (auto *user : bitcastV-&gt;users()) &#123; &#x2F;&#x2F;如果其父指令也是bitcast if (isa&lt;BitCastInst&gt;(user)) &#123; BitCastInst *BCI &#x3D; dyn_cast&lt;BitCastInst&gt;(user); Type *src &#x3D; BCI-&gt;getDestTy(); &#x2F;&#x2F;将转换后的类型名称加入result if (!addToSet(result, handleType(src))) &#123; &#125; &#125; &#125; break; &#125; &#x2F;&#x2F; would find a GetElementType if (!isa&lt;GetElementPtrInst&gt;(LI-&gt;getOperand(0))) &#123; &#x2F;&#x2F; it may not in some cases &#x2F;&#x2F; outs() &lt;&lt; &quot;in &quot; &lt;&lt; LI-&gt;getFunction()-&gt;getName() &lt;&lt; &quot;\\n&quot;; &#x2F;&#x2F; assert(0 &amp;&amp; &quot;didn&#39;t find a GetElementPtrInst before LoadInst&quot;); &#125; &#x2F;&#x2F;同store指令，继续递归分析 Value *GetV &#x3D; LI-&gt;getOperand(0); &#x2F;&#x2F; we skip these getElement since they are nested while (isa&lt;GetElementPtrInst&gt;(GetV)) &#123; GetElementPtrInst *GEI &#x3D; cast&lt;GetElementPtrInst&gt;(GetV); StringRef name &#x3D; handleType(GEI-&gt;getSourceElementType()); if (!addToSet(result, name)) &#123; break; &#125; GetV &#x3D; GEI-&gt;getOperand(0); &#125; &#x2F;&#x2F; the outside GetElementPtrInst mergeSet(result, taintAnalysis(GetV, vs, found)); break; &#125; ​ 如上述代码所示，load指令与store指令相比增加了struct.list_head的分析部分，list_head是Linux内核中的经典双向链表，其定义如下： struct list_head &#123; struct list_head *next, *prev; &#125;; ​ 针对struct.list_head，若其满足stName == \"struct.list_head\" &amp;&amp; isa&lt; ConstantExpr &gt;(LI&gt;getOperand(0))： ​ 则代表其Load指令的type为struct.list_head类型且对应的指针ptr是ConstantExpr算术式类型，则分析该Load指令的所有父指令，其具体分析流程如下： ​ 对于某个Load指令污点源，分析其父指令里的phi指令，再分析phi指令的父指令，找到其中的bitcast指令，后续再次分析这个bitcast指令的父指令： ​ 如果bitcastV的父指令也为bitcast指令，则将其目标type（即上图最后一行的type2）所指向的结构名称加入result集中。接下来针对GetElementPtrInst的分析同store指令，具体过程见上述代码。 1.3 Instruction::Call ​ 遍历Call指令的所有参数，如果如果该参数不是某个结构体中的引用则将其指向的结构名加入result，然后递归深入分析arg参数： case Instruction::Call:&#123; CallInst *CI = cast&lt;CallInst>(I); //遍历其参数列表 for (auto AI = CI->arg_begin(), E = CI->arg_end(); AI != E; AI++) &#123; //获取单个参数 Value* arg = dyn_cast&lt;Value>(&amp;*AI); //跳过常数 if (dyn_cast&lt;Constant>(arg)) &#123; continue; &#125; // if not &amp;a->b // 如果该参数不是某个结构体中的引用（后续会分析） if (!isa&lt;GetElementPtrInst>(arg)) &#123; auto name = handleType(arg->getType()); addToSet(result, name); &#125; // taint argument // 继续递归分析 mergeSet(result, taintAnalysis(arg, vs, found)); &#125; break; &#125; 1.4 Instruction::GetElementPtr ​ GetElementPtr指令的分析大体同上，也是递归分析，详见如下代码： case Instruction::GetElementPtr:&#123; &#x2F;&#x2F; this is nested GetElementPtrInst *GEI &#x3D; cast&lt;GetElementPtrInst&gt;(I); &#x2F;&#x2F; while (isa&lt;GetElementPtrInst&gt;(GEI-&gt;getOperand(0))) &#123; &#x2F;&#x2F; &#x2F;&#x2F; nest struct &#x2F;&#x2F; Type *src &#x3D; GEI-&gt;getSourceElementType(); &#x2F;&#x2F; GEI &#x3D; cast&lt;GetElementPtrInst&gt;(I); &#x2F;&#x2F; &#125; Type *src &#x3D; GEI-&gt;getSourceElementType(); &#x2F;&#x2F; handle type auto name &#x3D; handleType(src); if (!addToSet(result, name)) &#123; break; &#125; &#x2F;&#x2F; addToSet(result, name); mergeSet(result, taintAnalysis(GEI-&gt;getOperand(0), vs, found)); &#x2F;&#x2F; handle GetElementPtr other operands for (unsigned i &#x3D; 1, e &#x3D; I-&gt;getNumOperands(); i !&#x3D; e; i++) &#123; V &#x3D; I-&gt;getOperand(i); if (dyn_cast&lt;Constant&gt;(V)) &#123; continue; &#125; &#x2F;&#x2F; taint value mergeSet(result, taintAnalysis(V, vs, found)); &#125; break; &#125; 1.5 Instruction::PHI ​ LLVM IR中PHI指令的格式如下所示: ​ phi指令用于不同代码块的分支判断，其根据不同代码块转移来的label选择value，对phi指令的相关函数操作如下所示： PHINode::getNumIncomingValues()：返回PHI节点的入边数量，即上图方括号的数量； PHINode::getIncomingValues(i)：返回第i个节点的value； ​ 具体代码如下所示： case Instruction::PHI:&#123; &#x2F;&#x2F; check code coverage here to find the node PHINode *PN &#x3D; cast&lt;PHINode&gt;(I); &#x2F;&#x2F;遍历每个入边节点 for (unsigned i &#x3D; 0, e &#x3D; PN-&gt;getNumIncomingValues(); i !&#x3D; e; i++) &#123; &#x2F;&#x2F;获取该节点的value Value* IV &#x3D; PN-&gt;getIncomingValue(i); &#x2F;&#x2F;这里什么都没做 if (Instruction *II &#x3D; dyn_cast&lt;Instruction&gt;(IV)) &#123; &#x2F;&#x2F; if II not get covered &#x2F;&#x2F; continue &#125; &#x2F;&#x2F;递归分析每个节点的value mergeSet(result, taintAnalysis(IV, vs, found)); &#125; break; &#125; 1.6 Instruction::Alloca ​ Alloca指令用于分配内存，这里遍历其所有父指令： case Instruction::Alloca: &#x2F;&#x2F; return &#x2F;&#x2F; solve alias &#x2F;&#x2F;遍历其所有父指令 for (auto *user : V-&gt;users()) &#123; &#x2F;&#x2F;若是store指令 if (isa&lt;StoreInst&gt;(user)) &#123; StoreInst *SI &#x3D; cast&lt;StoreInst&gt;(user); &#x2F;&#x2F;获取store的参数 Value *next &#x3D; SI-&gt;getOperand(0); &#x2F;&#x2F;递归分析 mergeSet(result, taintAnalysis(next, vs, found)); &#125; &#125; break; ​ 1.7 Instruction::BitCast ​ BitCast同理，具体见代码： case Instruction::BitCast:&#123; &#x2F;&#x2F; handle type info BitCastInst *BCI &#x3D; dyn_cast&lt;BitCastInst&gt;(V); Type *src &#x3D; BCI-&gt;getSrcTy(); auto name &#x3D; handleType(src); if (!addToSet(result, name)) &#123; break; &#125; mergeSet(result, taintAnalysis(BCI-&gt;getOperand(0), vs, found)); break; &#125; 1.8 case Instruction::Select ​ Select指令类似于C语言中的x?:a:b语法，其格式如下： ​ 其分析逻辑跟上述代码类似，详细见下： case Instruction::Select: for (unsigned i &#x3D; 0, e &#x3D; I-&gt;getNumOperands(); i !&#x3D; e; i++) &#123; V &#x3D; I-&gt;getOperand(i); &#x2F;&#x2F;排除常数 if (dyn_cast&lt;Constant&gt;(V)) &#123; continue; &#125; &#x2F;&#x2F; taint value mergeSet(result, taintAnalysis(V, vs, found)); &#125; break; 2. Argument类型Source else if (auto *Arg &#x3D; dyn_cast&lt;Argument&gt;(V)) &#123; &#x2F;&#x2F; argument unsigned argNo &#x3D; Arg-&gt;getArgNo(); StringRef name &#x3D; handleType(Arg-&gt;getType()); if (!addToSet(result, name)) &#123; return result; &#125; &#x2F;&#x2F;获取参数属于的function Function* callee &#x3D; Arg-&gt;getParent(); &#x2F;&#x2F;从Ctx-&gt;CallGraph中查找其父函数 auto parentName &#x3D; findParents(callee-&gt;getName()); bool matched &#x3D; false; CallInstSet CISet; &#x2F;&#x2F;遍历call graph &#x2F;&#x2F;typedef llvm::DenseMap&lt;llvm::CallInst*, FuncSet&gt; CalleeMap; for (auto M : Ctx-&gt;Callers) &#123; &#x2F;* use endswith here because functions in the Callers * are like &#96;filename&#96;.functionName *&#x2F; if (M.first-&gt;getName().endswith(callee-&gt;getName())) CISet &#x3D; M.second; &#x2F;&#x2F;查找callee的所有caller for (CallInst *caller : CISet) &#123; &#x2F;&#x2F; TODO need pricise location check if (parentName.find(caller-&gt;getFunction()-&gt;getName()) !&#x3D; parentName.end()) &#123; matched &#x3D; true; auto parentFname &#x3D; caller-&gt;getFunction()-&gt;getName(); if (parentFname.find(&quot;_sys_&quot;) !&#x3D; string::npos) continue; if (BlockFunc.find(parentFname) !&#x3D; BlockFunc.end()) continue; KA_LOGS(2, &quot;Taint to it&#39;s parent &quot;&lt;&lt;caller-&gt;getFunction()-&gt;getName()&lt;&lt;&quot; from &quot;&lt;&lt;callee-&gt;getName()); &#x2F;&#x2F;递归分析 mergeSet(result, taintAnalysis(caller-&gt;getArgOperand(argNo), vs, found)); &#125; &#125; &#125; return result; &#x2F;* global variable *&#x2F; &#125; 3. GlobalVariable类型Source ​ 全局变量单纯的添加即可： else if (isa&lt;GlobalVariable&gt;(V)) &#123; GlobalVariable *GV &#x3D; cast&lt;GlobalVariable&gt;(V); StringRef name &#x3D; handleType(GV-&gt;getType()); if (!addToSet(result, name)) &#123; return result; &#125; &#125; ​ ​ 综上所述，将污点分为instruction、argument和globalvariable三种类型，并分别分析，最终得到了一个结果集合result，这就是污点分析得到的关键结构对象。 ​ Reference Markakd/GREBE (github.com) LLVM Pass: LLVM Pass入门导引 llvm-project/llvm at main · llvm/llvm-project (github.com) About — LLVM 17.0.0git documentation PowerPoint Presentation (llvm.org) LLVM IR SSA 介绍 · GitBook (buaa-se-compiling.github.io) Writing an LLVM Pass — LLVM 17.0.0git documentation LLVM每日谈之八 PASS例子分析- (aliyun.com) LLVM开发者手册_llvm_shutdown_-CSDN CommandLine 2.0 Library Manual — LLVM 17.0.0git documentation LLVM: llvm::CallInst Class Reference LLVMdev] indirect calls tracking and control flow graph (google.com) LLVM: declaring an indirect function call in C that becomes a storedinst? - Stack Overflow LLVM Alias Analysis Infrastructure — LLVM 17.0.0git documentation 编译器优化：何为别名分析 - 知乎 (zhihu.com) Source Level Debugging with LLVM — LLVM 17.0.0git documentation I.users()_-CSDN博客 kint： KINT (mit.edu) Kint-learn/KINT学习记录.md at master · zhukailongaa/Kint-learn · GitHub CRYPTOlab/kint: git://g.csail.mit.edu/kint (github.com) ganler/mini-kint: Enhanced implementation of Kint in LLVM-14, in C++17. (github.com) Paper: Wang X, Chen H, Jia Z, et al. Improving integer security for systems with KINT[C]//Presented as part of the 10th {USENIX} Symposium on Opera。ting Systems Design and Implementation ({OSDI} 12). 2012: 163-177. Song C, Lee B, Lu K, et al. Enforcing kernel security invariants with data flow integrity[C]//NDSS. 2016. Lin Z, Chen Y, Wu Y, et al. **GREBE: Unveiling exploitation potential for Linux kernel bugs[**C]//2022 IEEE Symposium on Security and Privacy (SP). IEEE, 2022. C/C++ &amp;&amp; Kernel: 被知乎大佬嘲讽后的一个月，我重新研究了一下内联函数 - 知乎 (zhihu.com) c++ - How can I get Function Name of indirect call from CallInst in LLVM - Stack Overflow 函数指针及其定义和用法，C语言函数指针详解 (biancheng.net) 内部链接(internal linkage)和外部链接(external linkage)_CSDN博客 compiler - Difference between direct and indirect function() calls - Software Engineering Stack Exchange Linux内核中经典链表 list_head 常见使用方法解析_内核链表 CSDN博客 PS 在人工分析前，先问问Cursor： 提问：这段代码的功能是什么？ AI：根据提供的代码，这是一个C++程序，用于对LLVM模块进行全局分析。它从输入文件中加载模块，执行基本初始化，并运行两个Pass：CallGraphPass和PointerAnalysisPass。 程序还从两个文件CrashReport和CallGraph中读取数据，以确定是否存在显式检查表达式并找到崩溃位置。如果在CrashReport文件中找到显式检查表达式，则程序将将“explicitly”标志设置为true。如果在CrashReport文件中找到“kernel BUG at”字符串，则程序还将将“explicitly”标志设置为true。然后，程序使用GlobalCtx和“explicitly”标志运行CrashAnalyzer来分析崩溃位置。 如果DumpLocation不为空，则程序将将分析结果转储到指定位置。否则，它将将结果转储到标准输出。最后，程序返回0。 因此，该程序的主要功能是对LLVM模块进行全局分析，并分析崩溃位置。 提问：请介绍这段代码使用的LLVM API。 AI：根据提供的代码，该程序使用了LLVM的以下API： - llvm::IRReader：用于从文件中读取LLVM IR。 - llvm::LLVMContext：用于管理LLVM IR的上下文。 - llvm::Module：表示LLVM IR模块。 - llvm::PassManager：用于管理LLVM Pass。 - llvm::Verifier：用于验证LLVM IR的正确性。 - llvm::ManagedStatic：用于管理静态对象的生命周期。 - llvm::PrettyStackTrace：用于在程序崩溃时打印调用堆栈。 - llvm::ToolOutputFile：用于将输出写入文件。 - llvm::SystemUtils：提供了一些系统相关的实用函数。 - llvm::FileSystem：提供了一些文件系统相关的实用函数。 - llvm::SourceMgr：用于管理源文件和缓冲区。 - llvm::Signals：用于处理信号。 - llvm::Path：提供了一些路径相关的实用函数。 此外，该程序还使用了一些自定义的类和函数，如GlobalCtx、CallGraph、StructFinder、CrashAnalyzer和PointerAnalysis。 提问：请问你能画出代码的结构图吗？ AI： main function ├── cl::list &lt; std::string&gt; InputFilenames ├── cl::opt &lt; unsigned&gt; VerboseLevel ├── cl::opt &lt; std::string&gt; DumpLocation ├── cl::opt &lt; std::string&gt; CrashReport ├── CallGraphPass ├── PointerAnalysisPass ├── CrashAnalyzer └── return 0 其中，InputFilenames、VerboseLevel、DumpLocation和CrashReport是程序的命令行参数。CallGraphPass和PointerAnalysisPass是两个LLVM Pass，用于分析LLVM模块的调用图和指针分析。CrashAnalyzer是一个自定义的类，用于分析崩溃位置。程序最后返回0。","categories":[{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"}],"tags":[{"name":"Vulnerability","slug":"Vulnerability","permalink":"http://example.com/tags/Vulnerability/"},{"name":"AEG","slug":"AEG","permalink":"http://example.com/tags/AEG/"}],"author":"Shaw"},{"title":"(论文阅读)The Use of Likely Invariants as Feedback for FuzzersVulnerabilities","slug":"【论文阅读】The-Use-of-Likely-Invariants-as-Feedback-for-FuzzersVulnerabilities","date":"2023-05-08T13:21:58.186Z","updated":"2023-05-08T13:23:18.820Z","comments":true,"path":"2023/05/08/【论文阅读】The-Use-of-Likely-Invariants-as-Feedback-for-FuzzersVulnerabilities/","link":"","permalink":"http://example.com/2023/05/08/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91The-Use-of-Likely-Invariants-as-Feedback-for-FuzzersVulnerabilities/","excerpt":"(论文阅读)The Use of Likely Invariants as Feedback for Fuzzers 时间：2021.8 作者：Andrea Fioraldi、Daniele Cono D’Elia、Davide Balzarotti 会议：USENIX 开源：eurecom-s3/invscov: The Use of Likely Invariants as Feedback for Fuzzers (github.com) 截止2023.5.6被引23次 ABSTRACT ​ 如今Fuzzing的主要限制是以coverage-guided为基准设计的fuzzing方法是为了尽可能达到程序的不同部分而逐渐被优化，但若仅仅可达性不足以触发一个漏洞时，这种方法就会陷入困境。实际上，许多bug的触发不仅依赖于特定的控制流，还依赖一些程序的变量的值（数据流）。不幸的是，过去提出的捕捉程序状态的替代探索策略在实践中帮助不大，因为它们会立即导致状态爆炸问题。 ​ 在本文，我们提出了一个新型反馈机制，通过考虑到程序变量的”不变值“和其之间的关系来增强代码覆盖率。为此，我们在基本块层面上学习可能的变量“不变值”，并相应地划分程序状态空间。我们的反馈可以区分输入是否违反了一个或多个不变量，并对其进行奖励，从而完善代码覆盖通常提供的程序状态近似值。 ​ 基于LLVM和AFPL++，我们在一个名为INVSCOV的原型中实现了上述的技术。实验表明，与使用纯代码覆盖反馈的fuzzer相比，我们的方法可以发现更多、更不同的bug。此外，还发现了一个在OSS-Fuzz上每天测试的库中的两个漏洞，而且当时在其最新版本中仍然存在。","text":"(论文阅读)The Use of Likely Invariants as Feedback for Fuzzers 时间：2021.8 作者：Andrea Fioraldi、Daniele Cono D’Elia、Davide Balzarotti 会议：USENIX 开源：eurecom-s3/invscov: The Use of Likely Invariants as Feedback for Fuzzers (github.com) 截止2023.5.6被引23次 ABSTRACT ​ 如今Fuzzing的主要限制是以coverage-guided为基准设计的fuzzing方法是为了尽可能达到程序的不同部分而逐渐被优化，但若仅仅可达性不足以触发一个漏洞时，这种方法就会陷入困境。实际上，许多bug的触发不仅依赖于特定的控制流，还依赖一些程序的变量的值（数据流）。不幸的是，过去提出的捕捉程序状态的替代探索策略在实践中帮助不大，因为它们会立即导致状态爆炸问题。 ​ 在本文，我们提出了一个新型反馈机制，通过考虑到程序变量的”不变值“和其之间的关系来增强代码覆盖率。为此，我们在基本块层面上学习可能的变量“不变值”，并相应地划分程序状态空间。我们的反馈可以区分输入是否违反了一个或多个不变量，并对其进行奖励，从而完善代码覆盖通常提供的程序状态近似值。 ​ 基于LLVM和AFPL++，我们在一个名为INVSCOV的原型中实现了上述的技术。实验表明，与使用纯代码覆盖反馈的fuzzer相比，我们的方法可以发现更多、更不同的bug。此外，还发现了一个在OSS-Fuzz上每天测试的库中的两个漏洞，而且当时在其最新版本中仍然存在。 问题背景 “code coverage alone is a necessary but not sufficient condition to discover bugs” 代码覆盖率是发现bug的必要条件，不是充分条件。 1. bug被触发的条件 ​ 一个bug被触发应满足两个条件： 1. 程序运行到特定的指令； 2. 程序满足确定的条件。 ​ 少数情况下，程序不需要满足特定的条件也能触发bug，如LAVA-M数据集中的bug，其被人为的制造为只要运行到了特定的点就能触发。 2. coverage-based fuzzing的缺点 ​ 对于现有的coverage-based的fuzzing方法，fuzzer没有任何动力去探索更多的状态，因为其已经观察到了那里。因此，对于现有的工具来说，检测涉及到对程序状态的复杂约束的bug是相当困难的。如果简单对fuzzer探索更多的状态空间的行为作出奖励，其也会导致路径爆炸问题，因为对于非离散的应用，其状态空间基本是无限多的。 3. 例子 ​ 如图所示的漏洞是libsndfile的WAV文件格式解析中的堆溢出漏洞（Listing2第9行），libsndfile是一个用于操作音频文件的流行库。在Listing2第9行，代码引用了pms-&gt;samples所指向的C99变长数组（C99规定数组长度可以为变量）。当Listing1中的pmssize（Listing1第8行）较小，且pms-&gt;blocksize值（Listing1第13行）足够高时，写入操作会到达数组边界之外，造成堆溢出。 ​ Coverage-based fuzzer很容易到达该错误的问题点，但是很难触发。由于其并不会提供更多的代码覆盖率，fuzzer不会为这个点分配更多的energy。 创新点 ​ 在本文中，我们提出了一种新的模糊测试反馈，在考虑代码覆盖率的同时，也考虑到了程序状态中一些有趣的部分，以一种完全自动化的方式进行测试，并且不会引起状态爆炸。这项工作的创新点并不是“考虑代码覆盖率以外的东西”，这部分已经有人做过，但其问题是： 路径爆炸： 一些fuzzer通过使用更敏感的反馈来模拟程序状态，例如引入堆栈信息，甚至引用从内存加载和存储的值。《Be sensitive and collaborative: Analyzing impact of coverage metrics in greybox fuzzing》一文中就不仅考虑了控制流，还考虑了程序状态中的值。但其缺点就是会导致路径爆炸问题。 需要人工标注： 一些工作会使用人工辅助的方式进行，例如FUZZFACTORY让其开发者定义特定的目标，然后添加导航点，当生成的测试样例朝着这些目标前进（例如，当两个比较操作数中有更多位相同时），奖励Fuzzer。 ​ 故此项工作的创新点是：“考虑代码覆盖率以外的东西”，并将其过程自动化，且不会引入路径爆炸问题。 方法 1. Program State Partitions-程序状态分区 ​ 以上图Listing1与Listing2为例，用标准的CGF系统对libsndfile进行一定时间的fuzzing（如24h），然后调查fuzzer保存的所有种子，分析这些种子中所有变量，为Listing1中的初始函数确定两个不变量，为Listing2中的循环确定一个不变量（上图绿色注释）。根据这些注释，将程序的状态空间分为四部分，如下图所示： ​ 除了状态A，其余状态Fuzzer都没有访问过，通过如此抽象方法来向Fuzzer提供反馈，使其探索新的状态而又不会导致路径爆炸。 ​ 不变量能够在不引起状态爆炸的情况下划分程序状态空间，这也是方法的关键之一。在每个基本块中，N个不变量可以对状态进行局部划分，就像N条不平行的线可以将一个平面划分为N∗(N+1)/2+1个区域一样。在实践中，由于每个基本块通常只操纵几个变量，N通常是一个非常低的值（附录A中的统计数据）。 2. Using Invariants as Feedback-使用“不变量”反馈 ​ 动态“不变量”检测的常见限制是，所产生的“不变量”往往更多的是捕获测试套件的局部属性而不是程序的静态属性。然而这正是我们想要的，违反仅从Fuzzer语料库中学习到的可能的“不变量”可以提示Fuzzer哪些程序状态组合是不寻常的，进而定位错误的根源。 ​ 这里，使用“不变量”对Fuzzer进行反馈指的是edge-coverage与哪些“不变量”被违反的信息的组合。我们调整了大多数Coverage-based系统采用的新颖性算法，为每个被违反的“不变量”组合产生一个不同的搜索值，使其可以跟踪这些状态。 ​ 上述漏洞触发在B分区，当{blockalign = 1280, samplesperblock = 8}时会触发。我们的方法可以通过结合或突变以前的种子，生成违反多个\"不变量\"的输入，每个都违反一个或多个不同的\"不变量\"。 3. Pruning the Generated Checks-修剪生成的Check ​ 这里设计了三类修剪规则以排除不必要的/有害的“不变量”。 ​ 1）第一类需要丢掉的“不变量”是不可能被违反的： ​ 例如，unsigned integer &gt;= 0。其不可能被违反，对测试没有帮助。 ​ 为了识别类似的情况，我们对被测程序的每个函数进行了价值范围分析[36]。参数和全局存储最初是不受限制的，分析产生的函数变量界限在任何执行中都是成立的。利用这些分析出来的范围信息，指示分析器永远不要生成逻辑上比这些静态分析出的限制更弱的逻辑“不变式”。 ​ 2）第二类是包含无关变量： ​ 为被测程序的每个函数计算可比较性集：每个变量只属于一个这样的集，将不同集的变量结合在一起的“不变量”被丢弃。 ​ 最初为每个变量创建一个单独的集合，然后使用基于统一的策略，遍历函数指令，并在两个变量作为同一语句的操作数出现时合并这两个变量的集合。最终，一个可比性集合包含了参与相关计算的变量。这很少有例外：例如，在一个数组指针计算中，我们不合并基数和索引元素的集合，因为它们没有直接关系。 ​ 3） 第三类是与其他“不变量”的条件重叠： ​ 如果“不变量”逻辑重叠，就存在可以优化的空间。 4. Corpus Selection-语料库选择 ​ 仅使用有效文件是不够的。 ​ 只要该模糊器在达到新的覆盖点时有放缓的迹象，就可以作为语料库。（why？） REFERENCE 软件分析： 南京大学《软件分析》课程笔记01 Introduction_CSDN C/C++: Variable Length (Using the GNU Compiler Collection (GCC)) c99变长数组_C语言变长数组：使用变量指明数组的长度 CSDN博客","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Fuzzing","slug":"Fuzzing","permalink":"http://example.com/tags/Fuzzing/"}],"author":"Shaw"},{"title":"(技术总结)The Kernel Address Sanitizer(KASAN)","slug":"【技术总结】The Kernel Address Sanitizer(KASAN)","date":"2023-05-04T06:33:12.791Z","updated":"2023-05-10T03:43:10.042Z","comments":true,"path":"2023/05/04/【技术总结】The Kernel Address Sanitizer(KASAN)/","link":"","permalink":"http://example.com/2023/05/04/%E3%80%90%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BB%93%E3%80%91The%20Kernel%20Address%20Sanitizer(KASAN)/","excerpt":"The Kernel Address Sanitizer(KASAN) 1. 兼容性 ​ KASAN是一个动态内存安全错误检测器，旨在发现内核out-of-bounds和UAF错误。KASAN有三个模块：Generic KASAN、Software Tag-Based KASAN、Hardware Tag-Based KASAN。Generic KASAN兼容许多CPU架构，但性能开销很大；Software Tag-Based KASAN和Hardware Tag-Based KASAN都只兼容arm64架构的CPU，性能开销会更小。 ​ 一般的，称Generic KASAN和Software Tag-Based KASAN为software KASAN； ​ 称Software Tag-Based KASAN和Hardware Tag-Based KASAN为tag-based KASAN。 ​ Generic KASAN支持的指令集架构有：x86_64, arm, arm64, powerpc, riscv, s390, 和 xtensa；tag-based KASAN只支持arm64。","text":"The Kernel Address Sanitizer(KASAN) 1. 兼容性 ​ KASAN是一个动态内存安全错误检测器，旨在发现内核out-of-bounds和UAF错误。KASAN有三个模块：Generic KASAN、Software Tag-Based KASAN、Hardware Tag-Based KASAN。Generic KASAN兼容许多CPU架构，但性能开销很大；Software Tag-Based KASAN和Hardware Tag-Based KASAN都只兼容arm64架构的CPU，性能开销会更小。 ​ 一般的，称Generic KASAN和Software Tag-Based KASAN为software KASAN； ​ 称Software Tag-Based KASAN和Hardware Tag-Based KASAN为tag-based KASAN。 ​ Generic KASAN支持的指令集架构有：x86_64, arm, arm64, powerpc, riscv, s390, 和 xtensa；tag-based KASAN只支持arm64。 ### 2. 编译器要求 ​ KASAN对内存检查的逻辑是在编译的时候在内存访问操作之前插入相关检查指令，故需要相应的编译器支持该操作。 ​ Generic KASAN需要GCC 8.3.0+/任何版本的Clang(只要内核支持)； ​ Software Tag-Based KASAN需要GCC 11+/任何版本的Clang(只要内核支持)； ​ Hardware Tag-Based KASAN需要GCC10+/Clang12+。 3. 使用方法 ​ 开启KASAN需要在内核配置文件中开启对应配置： CONFIG_KASAN=y ​ 然后根据选择的KASAN类型选择标签：CONFIG_KASAN_GENERIC、CONFIG_KASAN_SW_TAGS、CONFIG_KASAN_HW_TAGS。 ​ 对于software KASAN，其需要指定其编译插装类型：CONFIG_KASAN_OUTLINE、CONFIG_KASAN_INLINE，outline类型生成体积更小的二进制代码，而inline类型速度比outline快两倍。 ​ 为了在报告中包括受影响的slab对象的stack traces，指定：CONFIG_STACKTRACE;包括受影响的物理页的stack traces，指定CONFIG_PAGE_OWNER并page_owner=on。 4. Report ​ 默认情况下，KASAN只对第一个无效的内存访问打印错误报告。使用 kasan_multi_shot，KASAN对每一个无效的访问都打印一份报告。这会禁用 了KASAN报告的 panic_on_warn。 ​ 典型的KASAN报告如下所示: ================================================================== BUG: KASAN: slab-out-of-bounds in kmalloc_oob_right+0xa8/0xbc [test_kasan] Write of size 1 at addr ffff8801f44ec37b by task insmod/2760 CPU: 1 PID: 2760 Comm: insmod Not tainted 4.19.0-rc3+ #698 Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.10.2-1 04/01/2014 Call Trace: dump_stack+0x94/0xd8 print_address_description+0x73/0x280 kasan_report+0x144/0x187 __asan_report_store1_noabort+0x17/0x20 kmalloc_oob_right+0xa8/0xbc [test_kasan] kmalloc_tests_init+0x16/0x700 [test_kasan] do_one_initcall+0xa5/0x3ae do_init_module+0x1b6/0x547 load_module+0x75df/0x8070 __do_sys_init_module+0x1c6/0x200 __x64_sys_init_module+0x6e/0xb0 do_syscall_64+0x9f/0x2c0 entry_SYSCALL_64_after_hwframe+0x44/0xa9 RIP: 0033:0x7f96443109da RSP: 002b:00007ffcf0b51b08 EFLAGS: 00000202 ORIG_RAX: 00000000000000af RAX: ffffffffffffffda RBX: 000055dc3ee521a0 RCX: 00007f96443109da RDX: 00007f96445cff88 RSI: 0000000000057a50 RDI: 00007f9644992000 RBP: 000055dc3ee510b0 R08: 0000000000000003 R09: 0000000000000000 R10: 00007f964430cd0a R11: 0000000000000202 R12: 00007f96445cff88 R13: 000055dc3ee51090 R14: 0000000000000000 R15: 0000000000000000 Allocated by task 2760: save_stack+0x43/0xd0 kasan_kmalloc+0xa7/0xd0 kmem_cache_alloc_trace+0xe1/0x1b0 kmalloc_oob_right+0x56/0xbc [test_kasan] kmalloc_tests_init+0x16/0x700 [test_kasan] do_one_initcall+0xa5/0x3ae do_init_module+0x1b6/0x547 load_module+0x75df/0x8070 __do_sys_init_module+0x1c6/0x200 __x64_sys_init_module+0x6e/0xb0 do_syscall_64+0x9f/0x2c0 entry_SYSCALL_64_after_hwframe+0x44/0xa9 Freed by task 815: save_stack+0x43/0xd0 __kasan_slab_free+0x135/0x190 kasan_slab_free+0xe/0x10 kfree+0x93/0x1a0 umh_complete+0x6a/0xa0 call_usermodehelper_exec_async+0x4c3/0x640 ret_from_fork+0x35/0x40 The buggy address belongs to the object at ffff8801f44ec300 which belongs to the cache kmalloc-128 of size 128 The buggy address is located 123 bytes inside of 128-byte region [ffff8801f44ec300, ffff8801f44ec380) The buggy address belongs to the page: page:ffffea0007d13b00 count:1 mapcount:0 mapping:ffff8801f7001640 index:0x0 flags: 0x200000000000100(slab) raw: 0200000000000100 ffffea0007d11dc0 0000001a0000001a ffff8801f7001640 raw: 0000000000000000 0000000080150015 00000001ffffffff 0000000000000000 page dumped because: kasan: bad access detected Memory state around the buggy address: ffff8801f44ec200: fc fc fc fc fc fc fc fc fb fb fb fb fb fb fb fb ffff8801f44ec280: fb fb fb fb fb fb fb fb fc fc fc fc fc fc fc fc >ffff8801f44ec300: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 03 ^ ffff8801f44ec380: fc fc fc fc fc fc fc fc fb fb fb fb fb fb fb fb ffff8801f44ec400: fb fb fb fb fb fb fb fb fc fc fc fc fc fc fc fc ================================================================== ​ BUG: KASAN: 第一行报告了错误类型，slab-out-of-bounds； ​ Call Trace:表明了当前error的堆栈跟踪； ​ Allocated by task 2760:表明了所访问内存分配位置的堆栈跟踪（“where the accessed memory was allocated ”）； ​ Freed by task 815:表明了对象被释放的位置的堆栈跟踪（“where the object was freed”）； ​ The buggy address belongs to ……:表明了访问的slab对象的相关描述； ​ Memory state around the buggy address:表明了访问slab对象周围的内存情况。 5. 影子内存 ​ KASAN的原理是利用“额外”的内存来标记那些可以被使用的内存的状态。这些做标记的区域被称为影子区域（shadow region）。了解 Linux 内存管理的读者知道，内存中的每个物理页在内存中都会有一个 struct page 这样的结构体来表示，即每 4KB 的页需要 40B 的结构体，大约 1% 的内存用来表示内存本身。Kasan 与其类似但“浪费”更为严重，影子区域的比例是 1:8，即总内存的九分之一会被“浪费”。用官方文档中的例子，如果有 128TB 的可用内存，需要有额外 16TB 的内存用来做标记。 Shadow Memory of KASAN ​ 做标记的方法比较简单，将可用内存按照 8 子节的大小分组，如果每组中所有 8 个字节都可以访问，则影子内存中相应的地方用全零（0x00）表示；如果可用内存的前 N（1 到 7 范围之间）个字节可用，则影子内存中响应的位置用 N 表示；其它情况影子内存用负数表示该内存不可用（KASAN使用不同的负值来区分不同类型的不可访问内存，如redzones 或已释放的内存，参见 mm/kasan/kasan.h）。 ​ 上述Report中，箭头指向的影子字节03，表示访问的地址是部分可访问的。报告中可访问的内存是“00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 03”，一共15个00和一个03，其表明了一共有15×8+3=123个字节可以访问，当试图访问这123个字节之外的内容时，就会报错out-of-bounds。 ​ KASAN错误标题（如 slab-out-of-bounds 或 use-after-free ） 是尽量接近的KASAN根据其拥有的有限信息打印出最可能的错误类型。错误的实际类型 可能会有所不同。 Reference 文档： The Kernel Address Sanitizer (KASAN) — The Linux Kernel documentation 内核地址消毒剂(KASAN) — The Linux Kernel documentation Kasan - Linux 内核的内存检测工具 - 腾讯云开发者社区-腾讯云 (tencent.com) 内存分配: Linux 内核 | 内存管理——slab 分配器 - 知乎 (zhihu.com) (60条消息) Linux内存子系统——分配物理页面（alloc_pages）_绍兴小贵宁的博客-CSDN博客","categories":[{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"}],"tags":[{"name":"Vulnerability","slug":"Vulnerability","permalink":"http://example.com/tags/Vulnerability/"},{"name":"AEG","slug":"AEG","permalink":"http://example.com/tags/AEG/"}],"author":"Shaw"},{"title":"(LLVM入门)编写LLVM PASS","slug":"【技术积累】(LLVM入门)编写LLVM PASS","date":"2023-05-01T06:40:01.508Z","updated":"2023-05-01T06:42:38.683Z","comments":true,"path":"2023/05/01/【技术积累】(LLVM入门)编写LLVM PASS/","link":"","permalink":"http://example.com/2023/05/01/%E3%80%90%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF%E3%80%91(LLVM%E5%85%A5%E9%97%A8)%E7%BC%96%E5%86%99LLVM%20PASS/","excerpt":"(LLVM入门)编写LLVM PASS ​ 前置知识： LLVM IR结构； C++ 面向对象； CMake；","text":"(LLVM入门)编写LLVM PASS ​ 前置知识： LLVM IR结构； C++ 面向对象； CMake； 一、理论 LLVM IR LLVM IR 文件的基本单位称为 module，LLVM中的Module，代表了一块代码。它是一个比较完整独立的代码块，是一个最小的编译单元。； 一个 module 中可以拥有多个顶层实体，比如 function 和 global variavle； 一个 function define 中至少有一个 basicblock； 每个 basicblock 中有若干 instruction，并且都以 terminator instruction 结尾。 (详见：PowerPoint Presentation (llvm.org)) What is a PASS? pass 对LLVM IR的一些单元进行操作，例如module或者function； pass有两类，Analysis pass和Transformation pass。Transformation pass会对单元进行修改操作，Analysis pass不修改，只观察并生成一些高层信息； ​ Pass Manager：调度Pass在各IR层级按顺序运行。 （什么是各IR层级？） opt ​ opt是LLVM的代码优化器，其输入ll源文件，其可以对源文件进行优化（输出优化后的ll源文件）或者分析（输出分析结果）。 ​ 在使用opt命令时，-{passname}提供了以任何顺序运行任何LLVM优化或分析Pass的能力。 二、代码实践 常见llvm编译命令： #.c -> .ll： clang -emit-llvm -S a.c -o a.ll #.c -> .bc: clang -emit-llvm -c a.c -o a.bc #.ll -> .bc: llvm-as a.ll -o a.bc #.bc -> .ll: llvm-dis a.bc -o a.ll #.bc -> .s: lc a.bc -o a.s 2. Hellow World PASS 目标：打印出编译程序中存在的非外部函数的名称，该 Pass 只是检查程序，不修改原程序。 ​ llvm安装编译过程略，详见github官方项目。 2.1 old manager ​ 旧版pass manager采用继承对应PASS类，覆写父类虚函数的方式定义用户自己的pass类，编写old_hello.cpp如下： //old_Hello.cpp #include \"llvm/Pass.h\" #include \"llvm/IR/Function.h\" #include \"llvm/Support/raw_ostream.h\" using namespace llvm; //使用匿名命名空间，使得其中定义的函数对其它文件不可见； //防止命名空间污染 namespace&#123; //FunctionPass每次操作一个函数,Hellp继承它 struct Hello:public FunctionPass&#123; static char ID; Hello() : FunctionPass(ID)&#123;&#125; //覆写父类的虚函数，override是覆写标志，使用它时当没有正确 //进行覆写操作时编译器会报error而不是warnning，且子类覆写 //的虚函数也不用再加virtual关键字； //如果要禁止子类覆写虚函数，可以使用final关键字。 bool runOnFunction(Function &amp;F) override &#123; //打印\"Hello: 函数名称\" errs() &lt;&lt; \"Hello: \"; errs().write_escaped(F.getName()) &lt;&lt; '\\n'; return false; &#125; &#125;; &#125; //初始化ID char Hello::ID = 0; //Register for opt static RegisterPass&lt;Hello> X(\"hello\",\"Hello World Pass\", false/* Only looks at CFG */, false/* Only looks at CFG */); ​ 编写一个待测试文件test.cpp： #include&lt;stdio.h> void fun1()&#123; printf(\"111\\n\"); &#125; void fun2()&#123; printf(\"222\\n\"); &#125; void fun3()&#123; printf(\"333\\n\"); &#125; int main(void)&#123; printf(\"%d\\n\",fun1()); printf(\"%d\\n\",fun2()); //printf(\"%d\\n\",fun3()); return 0; &#125; ​ 编译pass和test文件： #编译pass，也可以自行定义CMakeLists文件，手动编译; #llvm-config提供了CXXFLAGS与LDFLAGS参数方便查找LLVM的头文件与库文件; #如果链接有问题，还可以用llvm-config --libs提供动态链接的LLVM库; #具体llvm-config打印了什么，请自行尝试或查找官方文档; #-fPIC -shared 是编译动态库的必要参数。 #因为LLVM没用到RTTI，所以用-fno-rtti 来让我们的Pass与之一致; #-Wl,-znodelete是为了应对LLVM 5.0+中加载ModulePass引起segmentation fault的bug; #若Pass继承了ModulePass，务必加上。 clang `llvm-config --cxxflags` -Wl,-znodelete -fno-rtti -fPIC -shared old_hello.cpp -o LLVMHello.so `llvm-config --ldflags` #将待测试文件编译为bitcode clang -emit-llvm -c test.cpp -o test.bc ​ 使用opt命令加载运行，运行结果： #-loda 选项表明要加载进程序的pass #-hello 是注册时规定的参数 #由于此pass并不修改程序，故将opt的输出结果放入/dev/null(丢弃) sudo opt -load ./LLVMHello.so -hello &lt; test.bc > /dev/null Hello: _Z4fun1v Hello: _Z4fun2v Hello: _Z4fun3v Hello: main ​ 在命令中加入-time-passes参数，可以获得运行时间相关结果： $sudo opt -load ./LLVMHello.so -hello -time-passes &lt; test.bc > /dev/null Hello: _Z4fun1v Hello: _Z4fun2v Hello: _Z4fun3v Hello: main ==-------------------------------------------------------------------------== ... Pass execution timing report ... ==-------------------------------------------------------------------------== Total Execution Time: 0.0006 seconds (0.0006 wall clock) ---User Time--- --System Time-- --User+System-- ---Wall Time--- ---Name --- 0.0001 ( 61.1%) 0.0002 ( 62.0%) 0.0003 ( 61.7%) 0.0003 ( 62.0%) Bitcode Writer 0.0001 ( 33.7%) 0.0001 ( 33.2%) 0.0002 ( 33.3%) 0.0002 ( 33.0%) Hello World Pass 0.0000 ( 5.3%) 0.0000 ( 4.8%) 0.0000 ( 5.0%) 0.0000 ( 5.0%) Module Verifier 0.0002 (100.0%) 0.0004 (100.0%) 0.0006 (100.0%) 0.0006 (100.0%) Total ==-------------------------------------------------------------------------== LLVM IR Parsing ===-------------------------------------------------------------------------== Total Execution Time: 0.0005 seconds (0.0005 wall clock) ---User Time--- --System Time-- --User+System-- ---Wall Time--- --- Name --- 0.0002 (100.0%) 0.0003 (100.0%) 0.0005 (100.0%) 0.0005 (100.0%) Parse IR 0.0002 (100.0%) 0.0003 (100.0%) 0.0005 (100.0%) 0.0005 (100.0%) Total ​ 如果想直接使用clang集成这个过程，需要在pass注册时添加： #include \"llvm/IR/LegacyPassManager.h\" #include \"llvm/Transforms/IPO/PassManagerBuilder.h\" // Register for clang static RegisterStandardPasses Y(PassManagerBuilder::EP_EarlyAsPossible, [](const PassManagerBuilder &amp;Builder, legacy::PassManagerBase &amp;PM) &#123; PM.add(new Hello()); &#125;); ​ 接下来无需提前编译bc文件再调用opt，直接使用clang即可： clang -Xclang -load -Xclang ./LLVMHello.so test.cpp -o clang_test Hello: _Z4fun1v Hello: _Z4fun2v Hello: _Z4fun3v Hello: main 2.2 new manager ​ llvm新版本的pass manager定义依赖于多态，意味着并不存在显示的接口，所有的 Pass 是继承自 CRTP 模板PassInfoMixin&lt;PassT&gt;，其中需要有一个run()方法，接收一些 IR 单元和一个分析管理器，返回类型为 PreservedAnalyses。 &#x2F;&#x2F;new_hellp.cpp #include &quot;llvm&#x2F;IR&#x2F;LegacyPassManager.h&quot; #include &quot;llvm&#x2F;Passes&#x2F;PassBuilder.h&quot; #include &quot;llvm&#x2F;Passes&#x2F;PassPlugin.h&quot; #include &quot;llvm&#x2F;Support&#x2F;raw_ostream.h&quot; using namespace llvm; namespace&#123; void visitor(Function &amp;F)&#123; errs() &lt;&lt; &quot;(New Hello)FunctionName: &quot; &lt;&lt; F.getName() &lt;&lt; &quot;\\n&quot;; errs() &lt;&lt; &quot;(New Hello)ArgSize: &quot; &lt;&lt; F.arg_size() &lt;&lt; &quot;\\n&quot;; &#125; struct HelloWorld:PassInfoMixin&lt;HelloWorld&gt;&#123; PreservedAnalyses run(Function &amp;F,FunctionAnalysisManager &amp;)&#123; visitor(F); return PreservedAnalyses::all(); &#125; static bool isRequired()&#123;return true;&#125; &#125;; &#125;&#x2F;&#x2F;namespace llvm::PassPluginLibraryInfo getHelloWorldPluginInfo()&#123; return&#123; LLVM_PLUGIN_API_VERSION,&quot;HelloWorld&quot;,LLVM_VERSION_STRING, [](PassBuilder &amp;PB)&#123; PB.registerPipelineParsingCallback( [](StringRef Name, FunctionPassManager &amp;FPM, ArrayRef&lt;PassBuilder::PipelineElement&gt;)&#123; if(Name &#x3D;&#x3D; &quot;hello-world&quot;)&#123; FPM.addPass(HelloWorld()); return true; &#125; return true; &#125;); &#125; &#125;; &#125; extern &quot;C&quot; LLVM_ATTRIBUTE_WEAK ::llvm::PassPluginLibraryInfo llvmGetPassPluginInfo()&#123; return getHelloWorldPluginInfo(); &#125; ​ 以上代码分为两部分，Pass本体和Pass注册，具体含义和对应的CMakeLists.txt可参照llvm-tutor，这里不做赘述。尝试运行： #编译Pass export LLVM_DIR=/usr/local/include/llvm/ cmake -DLT_LLVM_INSTALL_DIR=$LLVM_DIR ../ make #编译输入文件 clang -O1 -S -emit-llvm ../../data/test.cpp -o ../../data/test.ll #使用new manager加载pass opt -load-pass-plugin ./libHelloWorld.so -passes=hello-world -disable-output ../../data/test.ll Reference LLVM IR 的第二个 Pass：上手官方文档 New Pass Manager HelloWorld Pass - 知乎 (zhihu.com) LLVM中的pass及其管理机制 - 知乎 (zhihu.com) Using the New Pass Manager — LLVM 17.0.0git documentation 2019 LLVM Developers’ Meeting: A. Warzynski “Writing an LLVM Pass: 101” - YouTube banach-space/llvm-tutor: A collection of out-of-tree LLVM passes for teaching and learning (github.com)","categories":[{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"}],"tags":[{"name":"LLVM","slug":"LLVM","permalink":"http://example.com/tags/LLVM/"}],"author":"Shaw"},{"title":"GREBE-Unveiling Exploitation Potential for Linux Kernel Bugs","slug":"【论文阅读】GREBE-Unveiling-Exploitation-Potential-for-Linux-Kernel-Bugs","date":"2023-04-10T07:24:25.618Z","updated":"2023-04-10T07:28:59.767Z","comments":true,"path":"2023/04/10/【论文阅读】GREBE-Unveiling-Exploitation-Potential-for-Linux-Kernel-Bugs/","link":"","permalink":"http://example.com/2023/04/10/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91GREBE-Unveiling-Exploitation-Potential-for-Linux-Kernel-Bugs/","excerpt":"GREBE: Unveiling Exploitation Potential for Linux Kernel Bugs 时间：2022 作者：Zhenpeng Lin,Yueqi Chen,Yuhang Wu 会议：SP ABSTRACT ​ 最近，动态测试工具显著提升了Linux内核漏洞的发掘速度，这些工具会在挖掘漏洞时自动地生成报告，具体说明Linux系统的error。报告中的error暗示了相应的内核错误的可能的exploitability，因此，许多安全分析员使用(报告中)表现出来的error来推断一个错误的可利用性，从而考虑其exploit开发的优先级。然而，使用报告中的error可能会低估一个错误的可利用性。报告中表现出的error可能取决于该error是如何被触发的。通过不同的路径或在不同的背景下，一个error可能表现出各种错误行为，意味着非常不同的利用潜力。 ​ 此文提出了一个新的内核fuzz技术来找到所有可能的内核漏洞的error的表现。与传统的专注于内核代码覆盖率的内核fuzzing技术不同，我们的fuzzing技术更多的是针对有漏洞的代码片段。为了探索不同触发同一个bug的上下文/路径，文章引入了object-driven内核fuzzing技术。通过新探索的error，安全研究人员可以更好地推断出一个error的可利用性。 ​ 为了评估我们提出的技术的有效性、效率和影响，我们将我们的fuzzing技术作为一个工具GREBE来实现，并将其应用于60个真实世界的Linux内核漏洞。平均来说，GREBE可以为每个内核漏洞表现出2个以上的额外错误行为。对于26个内核错误，GREBE发现了更高的开发潜力。我们向内核供应商报告了其中的一些错误--这些错误的可利用性被错误地评估了，相应的补丁还没有被仔细地应用--导致他们迅速地采用补丁。","text":"GREBE: Unveiling Exploitation Potential for Linux Kernel Bugs 时间：2022 作者：Zhenpeng Lin,Yueqi Chen,Yuhang Wu 会议：SP ABSTRACT ​ 最近，动态测试工具显著提升了Linux内核漏洞的发掘速度，这些工具会在挖掘漏洞时自动地生成报告，具体说明Linux系统的error。报告中的error暗示了相应的内核错误的可能的exploitability，因此，许多安全分析员使用(报告中)表现出来的error来推断一个错误的可利用性，从而考虑其exploit开发的优先级。然而，使用报告中的error可能会低估一个错误的可利用性。报告中表现出的error可能取决于该error是如何被触发的。通过不同的路径或在不同的背景下，一个error可能表现出各种错误行为，意味着非常不同的利用潜力。 ​ 此文提出了一个新的内核fuzz技术来找到所有可能的内核漏洞的error的表现。与传统的专注于内核代码覆盖率的内核fuzzing技术不同，我们的fuzzing技术更多的是针对有漏洞的代码片段。为了探索不同触发同一个bug的上下文/路径，文章引入了object-driven内核fuzzing技术。通过新探索的error，安全研究人员可以更好地推断出一个error的可利用性。 ​ 为了评估我们提出的技术的有效性、效率和影响，我们将我们的fuzzing技术作为一个工具GREBE来实现，并将其应用于60个真实世界的Linux内核漏洞。平均来说，GREBE可以为每个内核漏洞表现出2个以上的额外错误行为。对于26个内核错误，GREBE发现了更高的开发潜力。我们向内核供应商报告了其中的一些错误--这些错误的可利用性被错误地评估了，相应的补丁还没有被仔细地应用--导致他们迅速地采用补丁。 问题背景 1. 根据分析结果确定漏洞优先级 ​ 为了提高Linux其安全性，研究人员和分析人员引入了自动化的内核fuzzing技术和各种调试/sanitzation功能。在他们的推动下，安全研究人员和内核开发人员变得更容易确定Linux内核中的错误。然而，要确定触发bug的条件是否足以代表安全漏洞，仍然是一个挑战。例如，一个表现out-of-bound错误行为的bug通常意味着比那些表现出空指针解除引用错误行为的bug有更高的机会被利用。因此，我们的调查结果和以前的研究[1]、[2]、[3]都表明，在确定漏洞开发工作的优先次序时，漏洞的表现出的错误行为起着关键作用。 2. 自动化漏洞扫描工具提供的错误报告不完善 ​ 在实践中，当现有的fuzzing工具识别出一个内核错误时，该错误所表现出来的错误行为可能是其众多可能的错误行为之一。它的其他可能的错误行为可能与已经暴露的错误行为相去甚远。通过遵循不同的路径或执行环境来触发内核错误，我们可以使内核错误不仅表现出不太可能被利用的GPF错误，而且表现出极可能被利用的UAF错误。因此，如果只使用单一表现的错误行为来推断该错误可能的可利用性，这可能会产生一定误导。 3. 解决思路 ​ 为了解决上述问题，一种本能的反应是把一个内核错误报告作为输入，分析该内核错误的根本原因，并推断出该错误的根本原因可能带来的所有可能的后果（例如，内存越界、空指针解引用和内存泄漏等）。然而，根源诊断通常被认为是一项费时费力的工作。因此，我们认为，解决这个问题的一个更现实的策略是，在不进行根本原因分析的情况下，揭露出一个给定的内核错误的许多可能的后触发错误行为。然后，从公布的错误行为中，安全分析师可以更好地以更准确的方式推断其可能的可利用性。 4. 已有的方法 ​ 我们可以借用内核fuzzing的概念。然而，现有的内核fuzzing方法主要是为了最大化代码覆盖率而设计的（例如，Syzkaller[4]、KAFL[5]和Trinity[6]等）。在我们的任务中使用这些方法不可避免地存在效率低下和效果差的问题，这只是因为代码覆盖率驱动的内核fuzzing法没有被在该问题下定制，也没有为寻找与同一错误代码片段相关的各种路径或上下文进行优化。 ​ 为此，我们提出了一种定制的内核fuzzing处理机制，它将fuzzing处理的能量集中在有缺陷的代码区域，同时，将内核执行路径和上下文分散到目标有缺陷的代码片段。 问题引入 ​ 我们提出的内核fuzzing技术可以被看作是一种定向fuzzing技术。它首先将一个内核错误报告作为输入，并提取与报告的内核错误相关的内核结构/对象。然后，该方法进行fuzzing测试，并利用已识别的内核结构/对象的点击率作为对fuzzer的反馈。由于确定的内核结构/对象对成功触发错误至关重要，利用它们来指导fuzzing可以缩小内核fuzzer的范围，使fuzzer主要关注与报告错误有关的路径和背景。在这项工作中，我们将这种方法作为一个内核对象驱动的fuzzing工具来实现，并以GREBE命名，意味着 \"多行为探索fuzzing\"。 1. 例子 ​ 如上图所示，函数tun_attach是网络接口配置函数，它的参数tun是一个所有处于open状态的tun文件共享的全局变量。代码第3行表明，如果IFF_NAPI在tun-&gt;flags中被设定，内核将初始化一个定时器，并将相应的napi链接到网络设备napi_list的列表中。代码第12行表明，函数tun_detach负责清理tun_file中包含的数据以及关闭该文件。如果IFF_NAPI被设置，内核将取消定时器并从设备的napi_list中删除napi。在第24行，函数free_netdev将通过napi_list来删除列表中的napi。 ​ 这里的bug是由于tun_attach和tun_detach中的标志tun-&gt;flags的可能存在的不一致导致的。 ​ 以Syzkaller产生的内核错误报告为例： ​ 报告所附的PoC显示，一个系统调用在IFF_NAPI未设置的情况下调用了tun_attach。这样一来，内核既没有初始化定时器，也没有将相应的napi添加到列表中。在这个设置之后，PoC程序进一步调用系统调用ioctl函数，在调用tun_detach之前在tun-&gt;flags中设置IFF_NAPI，这导致tun_attach和tun_detach的标志不一致。然后，在第17行，内核试图停止定时器，它解除了对tun_detach中的定时器对象所包含的指针的引用。然而，如上所述，定时器在tun_attach中没有被初始化，这导致了一个一般保护故障。一般保护故障意味着访问未被指定使用的存储。因此，基于这个单一的观察，许多分析人员可能会推断出这个错误可能是不可利用的。 ​ 然而，通过改变PoC程序，修改共享变量的赋值方式，我们可以让内核表现出一个UAF错误。具体来说，我们可以在调用函数tun_attach之前用IFF_NAPI设置tun-&gt;flags。这样，在调用tun_attach后，它可以将相应的tun_file添加到设备列表napi_list。在这个设置之后，我们可以进一步调用ioctl来清除tun_flags，然后再调用tun_detach。如上图，函数tun_detach在第18∼19行没有从列表中删除相应的napi，而是在第21行free了它。因此，当遍历设备列表时，拥有KASAN功能的内核将抛出UAF的错误。与报中显示的错误相比，这种非允许的访问不是访问一个无效的内核内存地址而产生一般的保护故障，而是与一个有效的内核内存地址联系在一起，并最终可以破坏内核内存。因此，基于这个UAF错误，许多分析人员可能认为这个错误可能是可利用的。 ps: Kernel Address SANitizer(KASAN)是一种动态内存安全错误检测工具，主要功能是检查内存越界访问和使用已释放内存的问题； UAF，Use after free。 2. 设计原理 ​ 鉴于内核错误报告展示了一个特定的错误行为，探索该错误其他可能的错误行为的一个本能反应是利用directed fuzzing，即探索通往我们感兴趣的程序站点的路径。但这种方法有两个局限： 首先，为了使用directed fuzzing来暴露多种错误行为，我们需要确定有错误的代码片段（即错误的root），将其作为锚点，并将其提供给directed fuzzer。然而，要正确和自动地确定内核错误的root是很有挑战性的。如果不正确地将一个非根本原因的点视为fuzzer的锚点，甚至可能使fuzzer无法触发该错误，更不用说找到该错误的多种错误行为了; 其次，即使我们能够指出内核错误的根源，也不意味着内核可以表现出多种错误行为。除了遵循不同的路径到达有缺陷的代码外，错误行为的展示也依赖于错误触发后的环境。例如，除了遵循一个特定的路径到有缺陷的代码片段，我们还需要一个单独的内核线程来改变一个全局变量，使触发错误和展示不同错误所需的背景多样化。根据设计，定向fuzzing法在接触到其感兴趣的目标代码后不能改变上下文。 ​ 在本文，我们通过扩展现有的带有内核-对象指导的内核fuzzing方法来解决这个问题。根据我们对许多内核错误的观察，我们发现内核错误的根本原因通常来自两种： 对内核对象的不恰当使用。这进一步导致了内核错误（例如前面提到的为tun_struct类型的内核对象分配不一致的标志值的案例）； 在使用内核对象进行计算时涉及到一个不正确的值，它被进一步传播到一个关键的内核操作中，迫使内核表现出一个错误（例如，一个未消毒的整数被用作内核对象的偏移量，导致一个越界的内存访问）。 ​ 因此，在错误报告中指定的与错误相关的对象的指导下，我们可以让内核fuzzer远离那些与错误无关的路径和上下文，从而显著提高其效率。 模型方法 ​ 如上图所示，首先将一个内核错误报告作为输入，运行所附带的PoC，并追踪那些涉及内核错误的内核结构（例如，例子中的结构tun_file）。进一步检查内核源代码，找出操作这些类型的对象的代码语句。我们将这些语句视为对内核错误触发的成功至关重要的锚点。因此，我们对这些语句进行检测，以便在进行内核fuzzing时收集对象覆盖率作为反馈，然后利用覆盖率来调整相应的PoC程序。在这项工作中，我们的内核fuzzing机制将错误报告中附加的原始PoC程序作为输入。使用一种新的突变和种子生成方法，它逐步改变PoC，提高了已知错误的多种错误行为探索的效率和效果。 1. 确定关键结构 ​ 利用后向污点分析来识别基本的内核结构（即参与给定报告中错误的相关结构）。 1.1 报告分析 &amp; 确定污点源 1.1.1 Explicit Checking ​ 在上图中，函数vhost_dev_cleanup()的作用是：如果dev-&gt;work_list为空，清除连接到vhost_dev设备上的worker；否则通过WARN_ON内的宏报错。故在这里，污点分析的sources应该就是dev-&gt;work_list。在这个例子中，内核开发者明确地将预定义的条件制定为一个表达式，并将其传递给宏WARN_ON进行错误处理。然而，对于其他一些调试功能，检查是由编译器检测的，或者由硬件完成，而不是由内核开发者编写的一段源代码。对于这些功能，条件是隐含的，不能从内核的源代码中识别。 ​ Explicit Checking就是对这一类明确条件的检查。内核开发者明确地将检查制定为一个表达式，并将其传递给标准调试功能，如WARN_ON和BUG_ON。这些宏是模式化的代码块，包括条件语句和日志语句，如果条件得到满足就会执行。除了这种标准化的记录内核错误的方式外，开发者还可以建立自己的宏，将日志语句包裹在一个辅助函数中（如上图15,16行）。 ​ 为了找到触发bug日志记录语句的源头，确定污点分析的sources，需要沿着支配树（如上图右半部分）回溯，直到找到一个条件跳转基本块。然后，我们将其相应的比较语句作为触发error记录操作的条件，从其中提取相应的变量作为sources。 1.1.2 Implicit Checking ​ 对于由编译器检测或由硬件完成的相关条件检查，称之为隐式检查。 ​ 对于通过编译器工具完成的隐式检查，内核地址消毒器（KASAN）可以对每一个内存访问进行检测，这样就可以检查对一个内存地址的访问是否合法。KASAN依靠影子内存来记录内存状态。例如，如果被检测的内核触及一个已释放的内存区域，它将产生一个错误报告，指出引发使用后释放错误的指令。关于中断所做的隐性检查（例如，由MMU检测到的一般保护故障），中断处理程序负责记录相应的指令。从这些调试机制产生的错误报告中，我们可以很容易地确定执行无效内存访问的指令。有了这些信息，我们的下一步就是确定与该无效内存访问相关的变量。 ​ 一般报告中所包含的错误指令是二进制指令。为了处理这个问题，从调试信息中，需要将二进制指令与源代码中的相应语句进行映射。假设对应的源代码是一个简单语句，只有一个加载或存储操作，在这种情况下，这个语句就是导致非法内存访问的语句，并将操作数变量作为污点源处理。然而，如果被识别的指令链接到一个涉及多个内存加载和存储的复合语句（如上图中描述的walk-&gt;offset = sg-&gt;offset），将进行进一步的分析。 ​ 具体来说，首先检查错误报告，并找出捕捉到内核错误的具体指令。然后，把与捕捉错误的指令相关的内存访问操作作为我们的sources。再次以上图中的情况为例。错误报告指出错误是由语句kasan_check_read(&amp;sg-&gt;offset, sizeof(var))捕获的，它与sg-&gt;offset有关。故这里认为第2行的sg-&gt;offset是污点源。 ​ 1.2 污点传播 &amp; 确定sink ​ 从错误报告中提取调用痕迹（call trace），基于call trace构建cfg，并在该图上向后传播污点源。 如果被污染的变量是一个嵌套结构的字段或一个联合变量，则进一步污染其父结构变量，并将父结构视为一个关键结构（原因是，嵌套结构或联合变量是内存中父结构变量的一部分。如果嵌套结构或联合变量的某个字段带有一个无效的值，这很可能是由于对其父结构变量的不恰当使用造成的）； 当污点传播遇到一个循环时，如果污点源在循环内被更新，那么也将循环计数器污染（举例，一些越界操作就是由于循环计数器被修改/破坏/扩大，导致访问了无效的内存区域）。 ​ 当以下条件之一成立时终止污点传播，在进行污点向后传播的同时，也将传播扩展到被污点变量的别名上： 污点传播到了污点变量本身的定义语句； 污点传播到了系统调用的入口、中断处理程序或启动工作队列调度器的函数入口； 2. 内核结构排序 ​ 成功识别所有与报告中的错误有关的内核结构后，直接fuzzing可能导致效率低下问题，故这里做进一步缩小操作。 2.1 内核结构选择 ​ 在Linux内核中，提供了一个用来创建双向循环链表的结构 list_head。虽然linux内核是用C语言写的，但是list_head的引入，使得内核数据结构也可以拥有面向对象的特性，通过使用操作list_head 的通用接口很容易实现代码的重用。在整个内核代码库中，list_head结构被广泛地使用。如果将这种结构和相应的对象纳入内核模糊指导，内核模糊器将不可避免地探索一个大的代码空间，使模糊器偏离重心。因此，为了保持内核fuzzer探索的效率，我们需要将这些结构从我们的内核fuzzing中排除。 ​ 除了上面提到的结构，Linux内核开发者还实现了许多其他与抽象接口有关的结构。这些接口与实现层耦合在一起，以支持大量的设备和功能。例如，内核为所有从用户空间请求的网络服务创建了一个结构socket ，不管指定什么协议。因此，与struct list_head类似，它们也应该在后期的内核fuzzing中被排除。 ​ 为了精确定位并排除这些结构，这里设计了一种系统的方法，根据内核结构的流行程度对其进行排序。在更高层次上，这个方法构建了一个描述内核结构之间引用关系的图。图中的每个节点代表一个内核结构，而节点之间的有向边表示参考关系。在该图上，应用PageRank算法，给每个结构分配一个权重，排除较高权值的结构。 2.2 构建图结构 ​ 对于结构定义语句，给定一个结构，我们浏览它的所有字段成员。如果字段是一个指向另一个结构的指针，我们就把给定的结构与被引用的结构联系起来。如上图extensions是一个引用struct skb_ext的指针，就在图中把sk_buff结构链接到skb_ext结构。 ​ struct rb_node是一个匿名union中的自我引用结构。这里就跳过匿名union，只将struct sk_buff直接链接到struct rb_node，而无需进一步扩展。 ​ 对于类型转换语句，由于内核支持多态，例如上图中ip6_fraglist_init函数，skb-&gt;data从void被投射到struct frag_hdr。void* 是一个抽象的数据类型，而结构类型struct frag_hdr*则更加具体化。因此，我们在结构图中增加了一条边，将结构skb_buff连接到结构frag_hdr。 ​ 利用构建的图，使用PageRank算法对其流行程度进行排序。只使用那些等级较低的内核结构和对象来指导fuzzing。 2.3 技术性研讨 ​ 根据我们对数百个真实世界的内核错误的观察，大多数内核错误的根本原因与不太流行的结构有关。因此，删除流行的结构并不会对模糊器触发我们感兴趣的错误产生负面影响。 ​ 即使被消除的流行结构与我们感兴趣的内核错误的根源有关，让模糊器专注于这些不太流行的结构，仍然可以让我们接触到流行结构类型中的一些对象。原因是不太受欢迎的结构通常是由受欢迎的结构组成的（例如，list 1中罕见的结构struct napi_struct包含受欢迎的结构struct hrtimer）。 3. 对象驱动内核fuzzing ​ 传统的内核探索方法是利用跟踪函数来跟踪已经执行的基本块。在这项工作中，我们的探索机制保留了这种能力，并进一步引入了一个额外的工具化组件。其被设计成一个编译器插件，该插件检查基本块中的每条语句，并识别那些负责分配、删除和使用关键对象的基本块。更具体地说，组件引入了一个新的追踪功能，它将记录的基本块地址中最重要的16位替换为一个神奇的数字，以将这些基本块与其他基本块区分开来。有了这些工具，通过观察代码覆盖率反馈中最重要的16位地址，我们可以很容易地确定哪些与关键对象有关的基本块是在fuzzing程序的操作之下的。当运行一个模糊测试程序时，我们可以很容易地确定它是否接触到了一个关键对象。 3.1 种子选择 ​ 若程序接触到了一个新的涉及关键对象的基本块/至少有一个系统调用涵盖了更多的代码（允许内核fuzzer积累内核状态，从而增加未来突变的可能性，以达到涉及关键对象的未见过的基本块。），并操作了关键对象时，将变异的种子添加到库中。 3.2 种子生成 &amp; 变异 ​ 使用报告中的POC程序用作初始种子，每次在生成新的种子时，只使用已经包含在种子库中的系统调用来组装新的种子。 ​ 进一步引入了现有内核fuzzing（即Syzkaller）中使用的变异机制。这种突变机制将与种子库中已包含的系统调用相关的新系统调用引入种子中。 3.3 变异优化 ​ 在对模糊程序进行突变时，Syzkaller的突变机制利用预定义的模板来指导新种子的合成。模板规定了系统调用之间的依赖关系和相应系统调用的参数格式。例如，Syzkaller的模板规定，系统调用read需要一个resource（即文件描述符）作为其参数之一，openat（）以及socket（）将产生相应的resource。在这个模板的指导下，Syzkaller可以通过在系统调用openat（）上附加系统调用read（）或socket（）来对模糊程序种子进行变异。模板指导下的突变确保了种子程序（也就是runner的输入）的合法性，从而避免了过早产生无效输入。 ​ 但是，这种基于模板的突变方式也不一定符合我们的需求。以上图两个POC程序为例，Syzkaller在a中插入了socket()，显然增大了搜索空间，不利于fuzzing；在b中，Syzkaller根据@max变量的合法范围是[INT_MIN，INT_MAX]从而改变了@max的值，但在此Bug中，只有@max=-1时bug才会被触发，故这里的突变也是副作用的。 ​ 故为了更高效的fuzzing，这里需要进行变异优化。根据相应的系统调用所依据的资源类型对系统调用规范模板进行分组（例如将与网络套接字和设备文件有关的系统调用分别归类）。在每组中，再将系统调用分为两个子组。一个是负责资源的创建，另一个是负责资源的使用。当变异种子程序时，我们的模糊组件要么用同一组中的系统调用替换，要么插入与种子程序中显示的资源相关的系统调用。 ps： 污点分析：三元组&lt;sources, sinks, sanitizers&gt;，代表污点源，污点会聚处和消毒器。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Vulnerability","slug":"Vulnerability","permalink":"http://example.com/tags/Vulnerability/"},{"name":"AEG","slug":"AEG","permalink":"http://example.com/tags/AEG/"}],"author":"Shaw"},{"title":"Demons in the Shared Kernel--Abstract Resource Attacks Against OS-level Virtualization","slug":"【论文阅读】Demons-in-the-Shared-Kernel-Abstract-Resource-Attacks-Against-OS-level-Virtualization","date":"2023-03-15T07:29:02.891Z","updated":"2023-03-15T07:31:18.618Z","comments":true,"path":"2023/03/15/【论文阅读】Demons-in-the-Shared-Kernel-Abstract-Resource-Attacks-Against-OS-level-Virtualization/","link":"","permalink":"http://example.com/2023/03/15/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Demons-in-the-Shared-Kernel-Abstract-Resource-Attacks-Against-OS-level-Virtualization/","excerpt":"Demons in the Shared Kernel: Abstract Resource Attacks Against OS-level Virtualization 时间：2021.11 作者：Nanzi Yang（西电）、Wenbo Shen（浙大） 会议：CCS 对docker的一种Ddos攻击，实现了自动化检测。 ABSTRACT ​ 由于其更快的启动速度和更好的资源利用效率，操作系统级虚拟化(OS-level virtualization)已被广泛采用，并已成为云计算的一项基本技术。与硬件虚拟化相比，操作系统级虚拟化利用共享内核设计来达到更高的效率，并在共享内核上运行多个用户空间实例（又称容器）。然而，在本文中，我们揭示了一个新的攻击面，此漏洞是操作系统级虚拟化技术所固有的，会影响到Linux、FreeBSD和Fuchsia。 ​ 产生漏洞的根本原因是，操作系统级虚拟化中的共享内核设计导致容器直接或间接地共享成千上万的内核变量和数据结构。在不利用任何内核漏洞的情况下，非特权容器可以轻易地用尽共享的内核变量和数据结构实例，对其他容器进行DoS攻击。与物理资源相比，这些内核变量或数据结构实例（称为抽象资源）更普遍，但受到的保护不足。 ​ 为了显示限制抽象资源（Abstract Resources）的重要性，我们针对操作系统内核的不同方面进行了抽象资源攻击。结果表明，攻击抽象资源是非常实用和关键的。我们进一步进行了系统分析，以识别Linux内核中易受攻击的抽象资源，成功检测出1010个抽象资源，其中501个可以被动态地重复消耗。我们还在四大云厂商的自部署共享内核容器环境中进行了攻击实验。结果显示，所有环境都容易受到抽象资源的攻击。我们得出结论，限制抽象资源的使用是很难的，并给出了减轻此风险的多种策略。","text":"Demons in the Shared Kernel: Abstract Resource Attacks Against OS-level Virtualization 时间：2021.11 作者：Nanzi Yang（西电）、Wenbo Shen（浙大） 会议：CCS 对docker的一种Ddos攻击，实现了自动化检测。 ABSTRACT ​ 由于其更快的启动速度和更好的资源利用效率，操作系统级虚拟化(OS-level virtualization)已被广泛采用，并已成为云计算的一项基本技术。与硬件虚拟化相比，操作系统级虚拟化利用共享内核设计来达到更高的效率，并在共享内核上运行多个用户空间实例（又称容器）。然而，在本文中，我们揭示了一个新的攻击面，此漏洞是操作系统级虚拟化技术所固有的，会影响到Linux、FreeBSD和Fuchsia。 ​ 产生漏洞的根本原因是，操作系统级虚拟化中的共享内核设计导致容器直接或间接地共享成千上万的内核变量和数据结构。在不利用任何内核漏洞的情况下，非特权容器可以轻易地用尽共享的内核变量和数据结构实例，对其他容器进行DoS攻击。与物理资源相比，这些内核变量或数据结构实例（称为抽象资源）更普遍，但受到的保护不足。 ​ 为了显示限制抽象资源（Abstract Resources）的重要性，我们针对操作系统内核的不同方面进行了抽象资源攻击。结果表明，攻击抽象资源是非常实用和关键的。我们进一步进行了系统分析，以识别Linux内核中易受攻击的抽象资源，成功检测出1010个抽象资源，其中501个可以被动态地重复消耗。我们还在四大云厂商的自部署共享内核容器环境中进行了攻击实验。结果显示，所有环境都容易受到抽象资源的攻击。我们得出结论，限制抽象资源的使用是很难的，并给出了减轻此风险的多种策略。 针对容器的抽象资源攻击 ​ 操作系统级虚拟化可以在同一个内核上运行多个用户空间容器，与硬件虚拟化相比，其减轻了模拟操作系统内核的负担，故有着更快的速度和更高的资源利用率。用户空间的操作系统级虚拟化实例，在FreeBSD上叫jails、在Solaris上叫Zones、在Liunx上叫containers。 ​ 由于共享内核机制的存在，注意到，底层的操作系统内核包含数为容器提供服务的十万个变量和数据结构实例。因此，这些容器直接或间接地共享这些内核变量和数据结构实例。 ​ 这些抽象资源可以被利用来进行DoS攻击，并且系统对它们的保护措施往往不足。内核和容器开发者更注重保护物理资源而不是抽象资源。例如，Linux内核提供控制组来限制每个容器实例的资源使用。然而，在13个控制组中，有12个是针对物理资源的，限制了CPU、内存、存储和IO的使用。只有PIDs控制组是为限制抽象资源PID而设计的。因此，数百个容器共享的抽象资源没有任何限制，如global dirty ratio、open-file structs、pseudo-terminal structs等，这使得它们容易受到DoS攻击。 ​ 举个例子，下图是Linux内核中的一个全局变量nr_files及其利用函数，nr_files是系统中任意时刻文件数量的上限值，限制的文件总数。然而Linux内核并没有对nr_files变量提供任何控制隔离措施，因此，所有容器都可以直接控制nr_files的值。 ​ 在Linux世界中，所有几乎所有操作都可以看做文件操作，计时器、事件生成、运行命令等。一个容器可以在几秒内轻松消耗完nr_files的值，这样导致的结果就是同一系统内的其它容器在系统资源还很充裕的时候，一条命令、一个程序都不能运行。 自动检测可利用的抽象资源 ​ 文章的整体思路就是围绕着抽象资源的检测与利用进行。为了检测出系统中可利用的抽象资源，文章提出了： configuration-based analysis 和access-based analysis方法用于查找内核中共享在容器中的抽象资源； Syscall Reachability Analysis和三个Restriction Analysis方法用于确定抽象资源可以被容器消耗完。 1. Configuration-based Analysis &amp; Access-based Analysis 1.1 configuration-based analysis ​ Linux下的sysctl命令可以查看/修改内核参数，这些参数位于/proc/sys目录下。注意到，这些sysctl配置大多用于抽象的资源限制，比如限制文件数量fs.file-nr或内存大页面vm.nr_hugepages。因此，所有的容器都在共享由sysctl配置指定的相同的全局限制。这种sysctl配置提供了关于容器之间可共享的抽象资源的重要线索。 ​ 故这里的configuration指的就是sysctl配置参数。基于配置的分析分为三步： 首先，它使用特定的sysctl数据类型来识别所有与sysctl相关的数据结构。这些数据结构包含可配置的sysctl内核参数； 其次，sysctl数据结构通常包含在/proc/sys/文件夹中显示sysctl值的函数。因此，通过分析该函数，我们能够准确地找出该内核参数的变量； 最后，如果一个内核参数被用于限制资源消耗，其相应的变量应该出现在比较指令中。因此，我们按照使用-定义链来检查所确定的变量的使用情况，如果它在比较指令中被使用，就把它标记为抽象资源 ​ 如下图所示，Linux的proc文件系统使用数据结构ctl_table来配置sysctl内核参数。我们在LLVM中设计并实现了一个程序间分析通道，分析程序首先遍历所有内核全局变量来查找所有ctl_table数据结构，跟随.proc_handler回调指针启动程序间分析以获得确切的变量，定位到19行的nr_files关键变量。最后，检查所有已识别的关键变量的使用情况。如果一个关键变量在比较指令中被使用（即LLVM IR中的icmp），就会记录这些位置并将这个变量标记为抽象资源（25行，nr_files）。 1.2 access-based analysis ​ 除了sysctl配置，Linux内核还使用锁或原语机制来保护并发访问的资源。因此，我们使用并发访问性质作为标识一组可共享的抽象资源的标志。如果某个数据结构本身就是锁，或者在上锁/解锁之间被定量修改，我们就将其定位为抽象资源。 ​ 同时，分析方法还考虑了atomic和percpu计数器，其分析方法都集成在LLVM中。 2. Syscall Reachability Analysis &amp; Restriction Analysis 2.1 syscall reachability analysis ​ 为了确定筛选出来的抽象资源可以被容器消耗，我们根据内核控制流图进行传统的后向控制流分析，其中间接调用是根据结构类型来解决的[42, 70]。如果没有从系统调用条目到抽象资源消耗点的路径，我们就把这个抽象资源从容器中标记为不可达。 2.2 restriction analysis ​ 仅有可达性分析是不够的，我们需要进一步确保路径上没有额外的针对容器的限制。如seccomp、命名空间、控制组以及每个用户的资源限制。 2.2.1 seccomp ​ Seccomp是一种用于系统调用过滤的机制。我们对seccomp的限制分析中，使用Docker默认的seccomp配置文件[15]，它阻止了50多个系统调用。在所有从系统调用条目到资源消耗点的路径中，过滤掉源自任何被阻止的系统调用的路径。 2.2.2 per-user ​ 在实际部署中，容器通常使用不同的用户运行。因此，每个容器的资源消耗也被每个用户的资源配额所限制。例如，Linux提供了用户限制命令ulimit来限制特定用户的资源消耗。而ulimit的底层实现是使用rlimit来设置多个每个用户的资源配额。 ​ 除了ulimit，Linux还提供了一些接口，允许用户利用PAM（Pluggable Authentication Module）来部署每个用户的配额。PAM使用setup_limits函数[64]来设置每个用户的资源配额，它调用setrlimit来配置多个rlimit约束。对于由ulimit、rlimit和PAM限制的资源，攻击者容器不能消耗超过每个用户的配额。因此，它不能完全控制这些抽象的资源来发动DoS攻击。 ​ 由于ulimit和PAM都使用rlimit来设置每个用户的资源配额，我们需要分析rlimit并过滤出受其限制的抽象资源。对于rlimit分析，我们的关键观察是，rlimit值通常是在struct rlimit或struct rlimit64中指定的。因此，我们首先遍历内核IR，以确定所有从结构rlimit或结构rlimit64加载的变量。然后，我们进行数据流分析，跟踪这些变量的所有传播和使用情况，如果这些变量在任何比较指令中被使用，则标记这些函数。在这些函数中，rlimit被检查以限制某些资源。我们认为这些资源不能被攻击者容器用尽，因此我们根据这些函数过滤掉路径。我们的工具确定了40个检查rlimit的函数。 2.2.3 namespace ​ 对于一个命名空间隔离的资源，Linux内核会在每个命名空间下为其创建一个 \"副本\"，这样在一个命名空间的修改就不会影响到其他命名空间。因此，为了确认容器的可控性，我们需要确保那些抽象资源不受名字空间的保护。这里存在一个问题，即使Linux有关于命名空间的文档，也没有关于哪些抽象资源被命名空间所隔离的规范。 ​ 观察到，对于一个被命名空间隔离的资源，相应的数据结构有一个指针字段，指向它所属的命名空间。因此，我们的工具首先遍历了内核中每个数据结构类型的所有字段。如果该类型有一个命名空间指针，我们就把它标记为一个被限制隔离的资源。其次，对于识别出的隔离资源，我们的工具用它来过滤§4.1中识别的共享抽象资源。请注意，由于不同命名空间之间的映射，一些命名空间隔离的资源可能仍然容易受到抽象资源的攻击。如§3.2.2所述，idr是由pid_namespace-&gt;idr隔离的。然而，在非根PID命名空间分配的每个idr都被映射到根PID命名空间的一个新idr，这样根命名空间就可以管理它。因此，根PID命名空间被所有PID命名空间的所有容器全局共享。因此，它仍然容易受到idr耗尽的攻击。在我们的分析中，我们手动过滤掉这些资源。 ​ 如图所示，通过两次分析，程序就可以自动识别内核中可利用的抽象资源。由于本文重点关注漏洞的AEG利用，这里的容器攻击难点其实就是自动化查找抽象资源，利用并不难，故本文到这里结束。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Vulnerability","slug":"Vulnerability","permalink":"http://example.com/tags/Vulnerability/"},{"name":"AEG","slug":"AEG","permalink":"http://example.com/tags/AEG/"},{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/tags/Cloud/"}],"author":"Shaw"},{"title":"Windows of Vulnerability--A Case Study Analysis","slug":"【论文阅读】Windows of Vulnerability A Case Study Analysis","date":"2023-02-27T07:10:38.311Z","updated":"2023-02-28T10:41:26.468Z","comments":true,"path":"2023/02/27/【论文阅读】Windows of Vulnerability A Case Study Analysis/","link":"","permalink":"http://example.com/2023/02/27/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Windows%20of%20Vulnerability%20A%20Case%20Study%20Analysis/","excerpt":"【论文阅读】Windows of Vulnerability: A Case Study Analysis 时间：2000 作者：Arbaugh W A, Fithen W L, McHugh J 期刊：Computer ABSTRACT 作者为系统漏洞提出了一个“生命循环”模型，以此来分析三个样例，揭示了系统如何在安全修复后的很长一段时间内仍然存在漏洞。","text":"【论文阅读】Windows of Vulnerability: A Case Study Analysis 时间：2000 作者：Arbaugh W A, Fithen W L, McHugh J 期刊：Computer ABSTRACT 作者为系统漏洞提出了一个“生命循环”模型，以此来分析三个样例，揭示了系统如何在安全修复后的很长一段时间内仍然存在漏洞。 Model 漏洞的生命周期 1.本文提出的模型： Birth：代表漏洞的产生，漏洞通常在大型开发项目的过程中无意地被制造。若漏洞是故意被制造的，那么Birth和Discovery同时发生； Discovery：代表有人发现了漏洞的存在，许多情况下漏洞的发现者并不会向外披露他的发现； Disclosure：代表漏洞的存在被传播到更广的范围，例如被上传到了Bugtraq的邮件列表中，向公众公开； Correction：代表开发商提供了软件补丁或者更改了配置，修补了漏洞； Publicity：代表漏洞已经广为人知，例如被新闻报道或被应急事件响应中心发布报告，一旦漏洞在Disclosure阶段失控，漏洞就会被广为人知； Scripting：代表漏洞的自动化利用程序已经被编写，脚本小子也可以利用脚本来实施攻击。Scripting极大地增加了对应漏洞的被利用次数； Death：代表漏洞的湮灭，当一个漏洞可以利用的系统数量缩减到不重要的时候，这个漏洞就会死亡。理论上来说，如果所有的系统都安装了对应补丁、或者漏洞影响的系统被淘汰、或者攻击者和媒体对该漏洞失去兴趣，这个漏洞就会消亡。 ​ 一般来说，Birth、Discovery和Disclosure是按顺序进行的，Correction、Publicity、Scripting顺序不定。 2. 三个Case Studies： 2.1 Phf incident ​ phf漏洞是一个命令执行漏洞： ​ 理论上，利用这个漏洞可以在目标主机上执行任意命令，但网上第一个发布的phf漏洞的利用脚本只是尝试在目标主机上下载密码文件，并无过多动作。有趣的是，向CERT报告的大多数事件只涉及下载密码文件，可见：大多数脚本小子们在不了解脚本的情况下盲目地运行利用脚本，如果他们懂得漏洞的原理，返回一个shell明显可以做更多事情。 ​ 从图中可以看到，漏洞的利用次数从自动脚本化开始就激增。随着96年8月该漏洞的相关补丁发布，入侵行为短时间内骤减。但直到1998年该漏洞的利用行为都一直大量存在。 2.2 IMAP incident ​ IMAP邮件服务提供了通过互联网访问电子邮件的功能。其在早期的版本存在缓冲区溢出漏洞，下图显示了其两个短期内发现的相似的漏洞。 ​ 可以看到，两个漏洞的柱状图形状大体相同。 2.3 BIND incident ​ Bind是DNS协议的一种实现，是现今互联网上使用最为广泛的DNS 服务器程序。其1998年存在缓冲区溢出漏洞： ​ 漏洞数据来源 ​ CERT/CC，美国计算机紧急事件响应小组协调中心。成立于1998年，位于匹兹堡的卡内基梅隆大学内。它的主要职能是对软件中的安全漏洞提供咨询，对病毒和蠕虫的爆发提供警报，向计算机用户提供保证计算机系统安全的技巧以及在处理计算机安全事故的行动中进行协调。当有恶意程序或系统漏洞被报告时，CERT/CC会对外发布“事件”，其描述了漏洞的性质、利用的方式或工具等。 ​ 作者从CERT/CC数据库中选择样例进行分析，数据涵盖了1996~1999年的一些特有的入侵行为。 ''人''的薄弱 ​ 从上述三个例子可以看出，漏洞的自动化利用是导致相关入侵行为激增的关键，但除此之外，可以注意到的是： 即使漏洞的相关修补措施已经发布，相关的入侵行为仍在其后的很长一段时间内存在，甚至增长。在漏洞补丁发布之后，一方面，需要时间传播与安装；另一方满，一些谨慎的组织要求在改变系统之前进行测试，这是正确的，以确保补丁不会产生新的问题。有些组织在 \"有机会 \"的时候会安装补丁，而其他组织可能永远不会安装补丁，其中牵扯到的原因有很多； 即使一些漏洞修补措施仅能防御一些简单的攻击，但其仍有意义。在漏洞发布后紧跟的修补措施所防止的入侵可能只是脚本小子的骚扰性攻击，更复杂的攻击者可能仍然会成功。但即使这样，也能减少整体的入侵行为，留出更多的时间精力资源跟踪调查更复杂的攻击。","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[{"name":"Vulnerability","slug":"Vulnerability","permalink":"http://example.com/tags/Vulnerability/"},{"name":"Windows","slug":"Windows","permalink":"http://example.com/tags/Windows/"}],"author":"Shaw"},{"title":"(技术积累)Symbolic Execution----从思维上理解符号执行","slug":"【技术积累】Symbolic Execution-符号执行","date":"2023-02-16T07:07:49.314Z","updated":"2023-05-30T08:10:03.575Z","comments":true,"path":"2023/02/16/【技术积累】Symbolic Execution-符号执行/","link":"","permalink":"http://example.com/2023/02/16/%E3%80%90%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF%E3%80%91Symbolic%20Execution-%E7%AC%A6%E5%8F%B7%E6%89%A7%E8%A1%8C/","excerpt":"Symbolic Execution：从思维上理解符号执行 ​ 符号执行作为软件分析、漏洞发掘领域经常出现的技术，国内已经有不少文章总结讨论。但新手直接翻阅学习这些总结性质的文章时碰到的诸如“符号路径约束”、“约束求解”、“执行状态”等专有名词会难以理解，思维逻辑与理论概念不易同轨。本文从国外的一些热门教程入手， 将符号执行从思维上捋一遍， 诠才末学，仅做抛砖引玉之用。 1. 引子： 1.0 一个样例 ​ 从一段经典的代码入手，解释符号执行的核心思路。 ​ 分析目标：对于任意可能的输入组合(a,b)，找到使得断言assert语句失败的所有输入。","text":"Symbolic Execution：从思维上理解符号执行 ​ 符号执行作为软件分析、漏洞发掘领域经常出现的技术，国内已经有不少文章总结讨论。但新手直接翻阅学习这些总结性质的文章时碰到的诸如“符号路径约束”、“约束求解”、“执行状态”等专有名词会难以理解，思维逻辑与理论概念不易同轨。本文从国外的一些热门教程入手， 将符号执行从思维上捋一遍， 诠才末学，仅做抛砖引玉之用。 1. 引子： 1.0 一个样例 ​ 从一段经典的代码入手，解释符号执行的核心思路。 ​ 分析目标：对于任意可能的输入组合(a,b)，找到使得断言assert语句失败的所有输入。 ​ 对于以上函数，如果使用随机测试的方法，共有232×232种输入组合，想要找到所有的符合条件的输入就得遍历所有输入，显然，这么做效率低下，费时费力。 ​ 符号执行的核心思想有以下几点： 每一个输入变量都被映射为了一个符号，例如int i ——&gt; αi ； 每一个符号代表所有可能的输入值的集合，例如 αi ∈[0，232-1] ； 程序中的语句都由符号来完成运算，例如i*2 + 5 ——&gt; 2· αi + 5 ； ​ 如果遇到了分支条件，需要考虑每一个分支下可能执行的路径： ​ 在开始第一次符号执行演练之前，这里定义执行状态（Execution state）的概念： \\[ Execution\\enspace state=\\{stmt,\\sigma,\\pi\\} \\] stmt是当前状态的下一个状态； σ是将程序变量映射到符号或者常数的映射，如果变量的值不确定就是映射到符号，反之映射到常量； π表示路径上的限制，即到达当前状态需要什么限制条件。例如对于上述函数，只有a^(!b)才能到达第6行，所以若程序在第6行的π = \\((\\alpha_a \\neq 0 )\\and (\\alpha_b = 0)\\)，π的初始值为true。 ​ 如果使用符号执行来分析上述函数，在程序的开头，会得到第一个执行状态。根据上述定义，其stmt是它的下个待分析状态，也就是程序的第二行：“int x = 1, y = 0;”；其σ会将第一行引入的变量a,b映射到符号，由于a,b是输入，都不是常量，故可以得到：\\(\\sigma=\\{a\\rightarrow \\alpha_a, b\\rightarrow \\alpha_b\\}\\)；1开始并没有遇到条件判断语句，故π为初始值true。如下图所示： ​ 当状态A接着执行，我们遇到了一个整型声明语句，其添加了两个新变量x，y并赋初始值。故从状态A到状态B其σ添加了新的映射，stmt变为下一条待执行语句，π不变： ​ 从状态B的stmt表明接下来的分析遇到了条件判断语句，对于if语句的两种可能，衍生出两个执行状态： ​ 当状态D继续执行就遇到了assert断言语句，在断言处我们判断当前的条件（σ、π）下是否满足断言条件： ​ 如图所示，在x = 1，y = 0，且αa = 0的条件下，x-y ≠ 0 ，断言并未触发，此条分支执行结束。 ​ 当C状态继续执行，遇到了y = 3 + x赋值语句，这时就要改变σ中的映射关系： ​ 状态E继续执行，遇到条件判断语句，同理，生成两个分支： ​ 状态G进行逻辑判断，并未触发： ​ 状态F继续执行，进行判断，触发错误条件： ​ 到此为止，所有分支执行完毕，符号执行判断出当a=2且b=0时，断言语句会被触发。如果我们的测试目标从触发断言语句改为触发漏洞行为，符号测试就是进行漏洞的排查。 1.1 机器如何判断？ ​ 上文所述的例子描述了符号执行的基本逻辑：用符号代替变量，判断最终生成的布尔表达式是否可满足。在上文中，我们当然可以轻松地用大脑分析出只要输入a = 2且b = 0，断言就会被触发。但在面对复杂且庞大的逻辑表达式时，我们不能每次都去人工分析，想要完整的利用计算机实现符号执行，就需要解决自动化判断逻辑表达式是否可满足的问题。 ​ SAT，布尔可满足性问题，它询问给定布尔公式的变量是否可以用值TRUE或FALSE一致地替换，以使该公式的值为TRUE。例如$a\\and b $就是可满足的，而 \\(a \\and !a\\) 就是不可满足的。SAT在理论上已经被证明是NP问题，虽然可以快速验证这个问题的解，但不能确定其求解速度。目前已经有很多成熟的SAT算法。 ​ SMT将SAT实例中的一些二进制变量（True or False）替换为非二进制变量，非二进制变量包括线性不等式（x+2y &gt; 4）、符号等式（\\(f(f(u,v),v) = f(u,v)\\)）。SMT的背景符合符号执行所面临的的问题，利用已有的SMT解法就可以解决上述的逻辑表达式自动化判断问题。可以看到，我们将符号执行过程中的一系列限制条件称为约束（constraint），而使用SMT对该约束进行求解的过程就叫约束求解。 ​ 使用符号执行不并一定要具体的理解SMT的技术细节，但其逻辑大体如下： ​ 对于SMT这类NP完全问题，在指定时间内SMT求解器会给出是否满足的结果，若超出时间则给出“不知道”。 ​ 综上，在使用前文定义的符号执行流程分析后，配合SMT Slover即可进行完整的符号执行分析。 1.2 如何证明没有其它样例？ ​ 如何证明我们找到的\"a=2且b=0\"就是所有的满足条件的输入了？ ​ 从理论上来说，符号执行遍历执行了程序所有可能的条件分支，分析了所有可能路径下的SMT问题，以此得出的结果必然是完整的，没有其它特例的。但在实际应用中，存在一些很难被解决的限制，执行生成的路径可能特别多，并且影响程序执行路径的因素不再是a，b几个变量这么简单，这些因素导致了在实际的符号执行中不便于做理论完整的评估。 2. 进一步深入 2.1 memory model ​ 看看如下代码： ​ 当代码中涉及到对内存的操作时，又如何设计相应符号呢？事实上我们将整个内存看成一个大数组MEM[]，对内存的操作不过是对数组的操作： ​ 这里的y1与y不完全相同，y代表地址，y1代表MEM数组中的位置。在C语言中，y = x + 10其实是y指针往后移动了10个x指针类型的位置，也就是y1 = x1 + 10*sizeof(int)。而对于malloc函数，可以将其简单看做返回未使用空间起始地址的函数，下面是一个简单的抽象： ​ 当将堆内存抽象为数组操作时，现有SMT求解器支持基于数组的逻辑操作（Theory of arrays）。对数组的操作可以抽象为： \\[ \\begin{equation} a\\{i\\rightarrow e\\}[k] = \\left\\{ \\begin{array}{cl} a[k] &amp; if &amp; k \\neq i \\\\ e &amp; if &amp; k = i \\end{array} \\right \\\\ \\end{equation} \\] ​ 经过一系列的数组操作： \\[ a\\{i\\rightarrow 5\\}\\{j\\rightarrow 7\\}···[k] = 5 \\Leftrightarrow ··· \\] ​ SMT引擎会将数组操作转化为对应的布尔操作，进而进行求解。当然，这个函数与C语言中malloc具体实现很不一样，其忽略了很多细节，例如对当前分配空间是否使用的检查。但经过这样简单的抽象，就可以使用上述的思路进行符号执行的判断。 ​ memory model，翻译为“内存建模”，从以上的例子可以看出，面对复杂的数据结构、函数操作甚至是陌生的第三方库，在使用符号执行前需要对其进行合适的抽象建模。目前已经有许多研究成果针对C语言的第三方库建模。建模的好坏也直接影响符号执行的性能与效率，例如对于上述的malloc，如果我们仅仅想检测最简单的缓冲区溢出漏洞，考虑malloc复杂的堆分配机制就是多余的。 2.2 path explosion ​ 抛开上述举例的toy code，现实中需要检测的商业软件一般都有成千上万行代码，其结构包含大量分支、循环、内存操作等等，如果还按照上文的思路进行执行，不仅会导致搜索时间的过长，还会使最终的执行状态过大。 ​ 在设计符号时，就应该避免引入无关/作用不大的符号，避免状态过大。且在路径搜索时可以使用深度优先、随机路径、广度优先、错误路路径优先等算法优化搜索方法，以求达到广度与深度的平衡。（又是经典的exploration and exploitation问题） ​ 具体的进一步深入可以查看：Baldoni R, Coppa E, D’elia D C, et al. A survey of symbolic execution techniques[J]. ACM Computing Surveys (CSUR), 2018, 51(3): 1-39. 3. 实践一下 ​ 对于源代码分析，KLEE[4]是很个很棒的框架工具；对于二进制分析，S2E[5]是个非常强有力工具，但使用稍显复杂。 ​ 这里使用angr，angr[6]是一个分析二进制的python框架，使用非常便捷。 目标1：使用angr符号执行分析本文举出的第一个例子，follbar()的二进制文件. 目标2：使用angr符号执行分析logic-bomb二进制程序. ​ 安装相应虚拟环境： #安装python虚拟环境 sudo pip3 install virtualenvwrapper #创建目录用来存放虚拟环境 mkdir $HOME/.virtualenvs #在~/.bashrc中,最后添加 export WORKON_HOME=$HOME/.virtualenvs VIRTUALENVWRAPPER_PYTHON=/usr/bin/python3 source /usr/local/bin/virtualenvwrapper.sh #创建一个名为angr的虚拟环境 mkvirtualenv angr #进入虚拟环境并安装angr workon angr pip3 install angr 3.1 foolbar ​ 使用idafree-7.0打开slide-example/example文件，找到foolbar函数： ​ 打开行前缀选项：Options–&gt;General–&gt;Disassembly–&gt;Line prefixes(graph)，可以显示汇编指令地址： ​ 想要使用angr分析函数，需要给定其： start target：代码开始运行地址； find target：代码结束运行地址； avoid targets：哪些路径（地址）被忽略，以此来避免路径爆炸问题； ​ 由于angr不知道什么是符号什么是常数，后续还需要定义输入的符号。angr分析脚本如下： import angr proj = angr.Project('example') # customize XXX, YYY, and ZZZ!!! start = XXX # addr of foobar avoid = [YYY] # point(s) that are not interesting (e.g., early exits) end = ZZZ # point that I want to reach # blank_state since exploration should start from an arbitrary point # otherwise, use entry_state() state = proj.factory.blank_state(addr=start) # arguments are inside registers in x86_64 a = state.regs.edi b = state.regs.esi sm = proj.factory.simulation_manager(state) while len(sm.active) > 0: print(sm) # get a feeling of what is happening sm.explore(avoid=avoid, find=end, n=1) if len(sm.found) > 0: # Bazinga! print(\"\\nReached the target\\n\") state = sm.found[0] print(\"%edi = \" + str(state.solver.eval_upto(a, 10))) print(\"%esi = \" + str(state.solver.eval_upto(b, 10))) break ​ 代码整体很简洁，angr.Project构建Project类，Project类是angr模块的主类，它对一个二进制文件进行初始的分析以及参数配置，并将数据存储起来进行后续进一步分析。proj.factory.blank_state()指定任意地址开始运行。在Angr中，程序每执行一步（也就是step）就会产生一个状态（state，在SM这里叫做stashe）,Simulation_Manager就是提供给我们管理这些state的接口。注意到，符号变量是使用寄存器进行存储的。 ​ 运行脚本： ​ 可以看到，脚本程序分析出，当edi(a)=2或者2147483650，esi(b)=0时会触发断言，这里2147483650显然就是整数溢出后的2。以此可见符号执行的程序实现需要考虑到计算机数字与数学数字的区别。 3.2 logic-bomb ​ logic-bomb是一个没有源码的二进制程序，你需要依次输入正确答案以此逃过爆炸： ​ 用IDA打开： ​ 可以看到程序从主函数开始分别调用phase_1()、phase_2()······phase_6()，进入phase_1()： ​ 如果你懂得逆向的知识，可以尝试人工分析去解开这个bomb，但如果使用符号执行分析，只需要确定使其成功通过的地址即可： ​ 分析脚本如下： import angr import logging import claripy import pdb import resource import time proj = angr.Project('bomb') start = XXX avoid = [YYY] end = [ZZZ] state = proj.factory.blank_state(addr=start) # a symbolic input string with a length up to 128 bytes arg = state.se.BVS(\"input_string\", 8 * 128) # an ending byte arg_end = state.se.BVS(\"end_input_string\", 8) # add a constraint on this byte to force it to be '\\0' state.se.add(arg_end == 0x0) # the constraint is added to the state. # Another way to do same is with: # arg_end = state.se.BVV(0x0, 8) # in this case arg_end is a concrete value # concat arg and arg_end arg = state.se.Concat(arg, arg_end) # an address where to store my arg bind_addr = 0x603780 # bind the symbolic string at this address state.memory.store(bind_addr, arg) # phase_one reads the string [rdi] state.regs.rdi = bind_addr # make rsi concrete state.regs.rsi = 0x0 pg = proj.factory.simulation_manager(state) start_time = time.time() while len(pg.active) > 0: print(pg) # step 1 basic block for each active path pg.explore(avoid=avoid, find=end, n=1) # Bazinga! if len(pg.found) > 0: print() print(\"Reached the target\") print(pg) state = pg.found[0] sol = state.solver.eval(arg, cast_to=bytes).decode('ascii').split('\\0')[0] print(\"Solution: \" + sol) break print() print(\"Memory usage: \" + str(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / 1024) + \" MB\") print(\"Elapsed time: \" + str(time.time() - start_time)) ​ 执行脚本： ​ 可以看到，符号执行仅用40秒就找到了phase1()的口令：“Border relations with Canada have never been better.” ​ 对于phase_2()······phase_6()使用同样的方法即可破解，这里略。 ​ 综上，我们可以看到符号执行在面对复杂的二进制文件时卓越的能力表现，在logic-bomb中，其二进制文件并没有经过混淆处理，相应的函数名，完整字符串都可以经过IDA分析后直接看到，所以对logic-bomb人工分析其实也并不复杂。但在真实的软件测试环境里，大量的二进制文件都是经过混淆加壳处理的，人工分析无法直接定位关键函数的作用（logic-bomb直接用函数名体现了函数的作用），甚至定位函数的进出口都变得具有挑战性，这时符号执行的优越性就有更明显的体现。 ​ 参考： [1] Symbolic Execution [2] symbolic-execution-tutorial/README.md at master · ercoppa/symbolic-execution-tutorial (github.com) [3] MIT 6.858 Computer Systems Security, Fall 2014—–10. Symbolic Execution [4] KLEE [5] Overview - S²E: A Platform for In-Vivo Analysis of Software Systems (s2e.systems) [6] angr","categories":[{"name":"Project","slug":"Project","permalink":"http://example.com/categories/Project/"}],"tags":[{"name":"Symbolic Execution","slug":"Symbolic-Execution","permalink":"http://example.com/tags/Symbolic-Execution/"}],"author":"Shaw"},{"title":"(论文复现)How Machine Learning Is Solving the Binary Function Similarity Problem","slug":"【论文复现】How Machine Learning Is Solving the Binary Function Similarity Problem","date":"2023-02-12T02:04:09.593Z","updated":"2023-02-17T11:35:45.413Z","comments":true,"path":"2023/02/12/【论文复现】How Machine Learning Is Solving the Binary Function Similarity Problem/","link":"","permalink":"http://example.com/2023/02/12/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91How%20Machine%20Learning%20Is%20Solving%20the%20Binary%20Function%20Similarity%20Problem/","excerpt":"【论文复现】How Machine Learning Is Solving the Binary Function Similarity Problem 一、模糊哈希（Fuzzy Hashing） 1. Bytes fuzzy hashing——Catalog1 出处： ​ 1. xorpd | FCatalog ​ 2. binary_function_similarity/Models/Catalog1 at main · Cisco-Talos/binary_function_similarity (github.com) \"FCatalog allows you to keep a database of all your named functions, and find similarities from this database efficiently.\" 前置知识： binary blob：一串bytes； S(a)：字节串a的四字截取集合，例如: \\[ \\mathbf{S(a)}= \\{123x,23xy,3xy1\\},a=123xy1 \\\\ \\mathbf{S(b)}= \\{1111\\},b=111111111 \\\\ \\] Jaccard Similarity：计算两个集合相似性： \\[ J（S(a),S(b)）=\\frac {S(a)\\cap S(b)}{S(a)\\cup S(b)} \\] minhash：文本相似度比较算法，用于快速估算两个集合的相似度。 ​ Catalog1算法利用minhash，使用哈希近似替代两个S集合，以此来估算其Jaccard系数，从而达到高效率地比较两个集合。","text":"【论文复现】How Machine Learning Is Solving the Binary Function Similarity Problem 一、模糊哈希（Fuzzy Hashing） 1. Bytes fuzzy hashing——Catalog1 出处： ​ 1. xorpd | FCatalog ​ 2. binary_function_similarity/Models/Catalog1 at main · Cisco-Talos/binary_function_similarity (github.com) \"FCatalog allows you to keep a database of all your named functions, and find similarities from this database efficiently.\" 前置知识： binary blob：一串bytes； S(a)：字节串a的四字截取集合，例如: \\[ \\mathbf{S(a)}= \\{123x,23xy,3xy1\\},a=123xy1 \\\\ \\mathbf{S(b)}= \\{1111\\},b=111111111 \\\\ \\] Jaccard Similarity：计算两个集合相似性： \\[ J（S(a),S(b)）=\\frac {S(a)\\cap S(b)}{S(a)\\cup S(b)} \\] minhash：文本相似度比较算法，用于快速估算两个集合的相似度。 ​ Catalog1算法利用minhash，使用哈希近似替代两个S集合，以此来估算其Jaccard系数，从而达到高效率地比较两个集合。 代码结构分析： ​ Catalog1算法需要将二进制文件截取分割后，由于每个二进制文件的长度不定，故其分割计算出的S(a)也不定长。为了对每个二进制文件都得到一个定长的特征签名，就需要对S(a)进行特征提取。 ​ 使用哈希函数将集合中的每个DWORD映射到DWORD，这里的哈希采用类似密码学中置换的方法（permutation）： #define WORD_SIZE 32 // 32 bits #define MAX_WORD 0xffffffff // Maximum size of a dword. #define BYTE_SIZE 8 // Amount of bits in a byte. #define NUM_ITERS 4 // Amount of iterations per permutation. // There are 128 RAND_DWORDS. Don't change the amount of random dwords here. unsigned int RAND_DWORDS[] = &#123;1445200656, 3877429363, 1060188777, 4260769784, 1438562000, 2836098482, 1986405151, 4230168452, 380326093, 2859127666, 1134102609, 788546250, 3705417527, 1779868252, 1958737986, 4046915967, 1614805928, 4160312724, 3682325739, 534901034, 2287240917, 2677201636, 71025852, 1171752314, 47956297, 2265969327, 2865804126, 1364027301, 2267528752, 1998395705, 576397983, 636085149, 3876141063, 1131266725, 3949079092, 1674557074, 2566739348, 3782985982, 2164386649, 550438955, 2491039847, 2409394861, 3757073140, 3509849961, 3972853470, 1377009785, 2164834118, 820549672, 2867309379, 1454756115, 94270429, 2974978638, 2915205038, 1887247447, 3641720023, 4292314015, 702694146, 1808155309, 95993403, 1529688311, 2883286160, 1410658736, 3225014055, 1903093988, 2049895643, 476880516, 3241604078, 3709326844, 2531992854, 265580822, 2920230147, 4294230868, 408106067, 3683123785, 1782150222, 3876124798, 3400886112, 1837386661, 664033147, 3948403539, 3572529266, 4084780068, 691101764, 1191456665, 3559651142, 709364116, 3999544719, 189208547, 3851247656, 69124994, 1685591380, 1312437435, 2316872331, 1466758250, 1979107610, 2611873442, 80372344, 1251839752, 2716578101, 176193185, 2142192370, 1179562050, 1290470544, 1957198791, 1435943450, 2989992875, 3703466909, 1302678442, 3343948619, 3762772165, 1438266632, 1761719790, 3668101852, 1283600006, 671544087, 1665876818, 3645433092, 3760380605, 3802664867, 1635015896, 1060356828, 1666255066, 2953295653, 2827859377, 386702151, 3372348076, 4248620909, 2259505262&#125;; // Amount of rand dwords - 1: #define NUM_DWORDS_MASK 0x7f unsigned int ror(unsigned int x, unsigned int i) &#123; // Rotate right a dword x by i bits. return (x >> i) | (x &lt;&lt; (WORD_SIZE - i)); &#125; unsigned int perm(unsigned int num, unsigned int x) &#123; // Permutation from dword to dword. // num is the permutation number. x is the input. unsigned int ror_index; for(unsigned int i=0; i&lt;NUM_ITERS; ++i) &#123; // Addition: x += RAND_DWORDS[(i + num + x) &amp; NUM_DWORDS_MASK]; // Rotation: ror_index = (x ^ RAND_DWORDS[(i + num + 1) &amp; NUM_DWORDS_MASK]) &amp; 0x1f; x = ror(x,ror_index); // Xor: x ^= RAND_DWORDS[(i + num + x) &amp; NUM_DWORDS_MASK]; // Rotation: ror_index = (x ^ RAND_DWORDS[(i + num + 1) &amp; NUM_DWORDS_MASK]) &amp; 0x1f; x = ror(x,ror_index); &#125; return x; &#125; ​ 由上可知，perm(i，x)就是第i个哈希函数hi(x)。计算完k个哈希函数后，我们得到了k个集合： \\[ h_{1}(x),h_{2}(x),h_{3}(x)\\cdots h_{k}(x) \\] ​ 然后每个集合中最小的数，就是我们所需的定长特征： \\[ sig(T) = \\{min_{t\\in T}h_{1}(T),min_{t\\in T}h_{2}(T),min_{t\\in T}h_{3}(T)\\cdots min_{t\\in T}h_{k}(T)\\} \\] ​ 故用\\(J(sig(A),sig(B))\\)代替\\(J(A,B)\\)即可大大简化计算，k的数量可以自己选定。对于完整的二进制文件，以下代码可以生成其对应特征： int sign( unsigned char* data, unsigned int len, unsigned int *result, unsigned int num_perms) &#123; // Find entry number &lt;num> of the signature of data. // len is the length of the data. // The result is inside &lt;result>, as an array of dwords. // We need at least 4 bytes to generate a signature. // We return -1 (error) if we don't have at least 4 bytes. if(len &lt; 4) &#123; return -1; &#125; unsigned int y; // Current integer value of 4 consecutive bytes. unsigned int py; // Permutation over y. unsigned int min_py; // Minimum py ever found. for(unsigned int permi=0; permi&lt;num_perms; ++permi) &#123; // Initialize y to be the first dword from the data: y = (unsigned int)data[0] &lt;&lt; 24; y += ((unsigned int)data[1]) &lt;&lt; 16; y += ((unsigned int)data[2]) &lt;&lt; 8; y += (unsigned int)data[3]; // Calculate first permutation: py = perm(permi,y); min_py = py; for(unsigned int i=4; i&lt;len; ++i) &#123; y &lt;&lt;= 8; y += data[i]; py = perm(permi,y); if(min_py > py) &#123; min_py = py; &#125; &#125; // Save minimum perm value found to memory: result[permi] = min_py; &#125; // Everything went well. // Result should be stored at &lt;result> return 0; &#125; ​ ​ 运行测试： ​ Catalog1共分为server和client两部分，client客户端作为IDA的一个插件，server服务器可以使用官方提供的testfcatalog.xorpd.net:1337，也可以自行搭建https://github.com/xorpd/fcatalog_server。 ​ 为了计算速度更快，这里使用C语言编写catalog相关计算操作，首先编译catalog1 ： ​ 【更新中】","categories":[{"name":"Reproduce","slug":"Reproduce","permalink":"http://example.com/categories/Reproduce/"}],"tags":[{"name":"Binary","slug":"Binary","permalink":"http://example.com/tags/Binary/"},{"name":"ML","slug":"ML","permalink":"http://example.com/tags/ML/"}],"author":"Shaw"},{"title":"Comparing One with Many — Solving Binary2source Function Matching Under  Function Inlining","slug":"Comparing-One-with-Many-—-Solving-Binary2source-Function-Matching-Under-Function-Inlining","date":"2023-01-10T07:27:48.471Z","updated":"2023-02-16T11:58:32.219Z","comments":true,"path":"2023/01/10/Comparing-One-with-Many-—-Solving-Binary2source-Function-Matching-Under-Function-Inlining/","link":"","permalink":"http://example.com/2023/01/10/Comparing-One-with-Many-%E2%80%94-Solving-Binary2source-Function-Matching-Under-Function-Inlining/","excerpt":"【论文阅读】Comparing One with Many — Solving Binary2source Function Matching Under Function Inlining 一、ABSTRACT 为了在函数内联下施行b2s函数匹配，我们提出了一个叫O2NMatcher的方法，通过其生成的Source function Sets (SFSs)作为匹配结果。 我们首先提出了一个模型EOOCJ48来预测内联的位置， 为了训练这个模型，我们利用可编译的开源软件（Open Source Software）生成一个带有标记的调用点（内联或不内联）的数据集，从调用点中提取几个特征，并通过检查不同编译之间的内联相关性来设计一个基于编译器-选项的多标签分类器。 然后，我们使用这个模型来预测不可编译的开源项目，得到带标记的函数调用图。接下来，我们将SFSs的构建视为一个子树生成问题，并设计根节点选择和边缘扩展规则来自动构建SFSs。最后，这些SFSs将被添加到源函数的语料库中，并与有内联的二进制函数进行比较。 我们对OSNMatcher进行了一些实验测试，结果表明我们的方法超过所有state-of-the-art，将结果提升了6%。","text":"【论文阅读】Comparing One with Many — Solving Binary2source Function Matching Under Function Inlining 一、ABSTRACT 为了在函数内联下施行b2s函数匹配，我们提出了一个叫O2NMatcher的方法，通过其生成的Source function Sets (SFSs)作为匹配结果。 我们首先提出了一个模型EOOCJ48来预测内联的位置， 为了训练这个模型，我们利用可编译的开源软件（Open Source Software）生成一个带有标记的调用点（内联或不内联）的数据集，从调用点中提取几个特征，并通过检查不同编译之间的内联相关性来设计一个基于编译器-选项的多标签分类器。 然后，我们使用这个模型来预测不可编译的开源项目，得到带标记的函数调用图。接下来，我们将SFSs的构建视为一个子树生成问题，并设计根节点选择和边缘扩展规则来自动构建SFSs。最后，这些SFSs将被添加到源函数的语料库中，并与有内联的二进制函数进行比较。 我们对OSNMatcher进行了一些实验测试，结果表明我们的方法超过所有state-of-the-art，将结果提升了6%。 二、背景知识 Function inlining：函数内联。使用inline关键字，编译器将函数调用语句替换为函数代码本身（称为扩展的过程），然后编译整个代码。因此，使用内联函数，编译器不必跳转到另一个位置来执行该函数，然后跳回。因为被调用函数的代码已经可用于调用程序。 Inlining Decisions in Visual Studio - C++ Team Blog (microsoft.com) Binary2source function matching，二进制到源码函数匹配： 1-to-1匹配：一个二进制函数与一个源码函数匹配； 1-to-n匹配：由于内联函数的存在，一个二进制函数匹配多个源码函数。 Stripped binary：不含调试符号信息的二进制可执行文件。 Multi-Label Classification (MLC) problem：多标签分类，一个样本有多个标签。 FCG ：Function Call Graph，函数调用图。在FCG图中，点是函数，边是调用关系。 Jaccard similaritie：又称为Jaccard index，用于比较有限样本集合之间的相似性和差异性。其值越大说明相似性越高。 Binary Relevance：核心思想是将多标签分类问题进行分解，将其转换为q个二元分类问题，其中每个二元分类器对应一个待预测的标签。 Classifier Chains：核心思想是将多标签分类问题进行分解，将其转换成为一个二元分类器链的形式，其中链后的二元分类器的构建式在前面分类器预测结果的基础上的。在模型构建的时候，首先将标签顺序进行shuffle打乱排序操作，然后按照从头到尾分别构建每个标签对应的模型。 Ensemble Method：集成学习算法。 三、提出问题 B2S匹配的作用： 当前软件开发基本都会使用公共开源库中的代码，这就造成一个问题，若公共开源项目OSS中存在漏洞会传播非常快（例如一个OpenSSL中的漏洞就可以造成互联网上17%web服务存在漏洞）。 由于以上问题的存在，检测软件中对OSS的依赖就很重要，Software Component Analysis (SCA)就是用来检测软件对OSS的依赖问题的。当商业软件公司发布了自己的二进制可执行程序时，SCA服务商就会将此二进制文件与OSS文件相比较，检测其包含使用了哪些OSS文件。 binary2source function matching就是其应用场景。 内联函数带来的问题： 举例如下图所示，当将二进制函数中的dtls1_get_record函数与源码中的dtls1_get_record函数比较时，使用CodeCMR给出的相似性还不足60%，这显然是匹配失败的。 如果深入去看二进制函数dtls1_get_record的汇编代码就可以发现，这个函数在编译的时候内联了dtls1_process_buffered_records,dtls1_get_bitmap 和 dtls1_record_replay_check的函数代码，极大的改变了其函数的内部代码内容，故影响了函数的匹配结果。 有上述例子可以看出，由于内联函数的存在会改变函数的代码内容，故直接对其进行匹配的结果是不尽如人意的。 解决这个问题面临的挑战： 想要解决在内联函数下的B2S问题，还需面对以下挑战： 1） OOD问题：Out-of-domain，待检测二进制函数可能是由多个函数生成的，故OSS源码资料库中可能没有对应的二进制匹配； 2） 有些二进制文件不含调试信息：对于许多不含调试信息的二进制文件，由于其没有标注内联点，故检测哪些函数是通过内联函数生成的和哪些源码函数被内联进了二进制函数中就更加困难； 3） 不同文件内联选择的不同：对于不同的编译设置导致的不同内联函数的选择（对某个函数，是否选择内联），很难覆盖所有情况。 四、模型方法 ​ 我们的方法O2NMatcher就是为了解决上述挑战而生的。 ​ 为了解决第一个挑战，我们生成了Source Function Sets (SFSs)来完善资料库，以此应对有内联函数的二进制函数查询匹配。 ​ 为了解决第二个挑战，我们使用可以编译的OSS项目训练了一个预测分类器来预测不可编译的OSS项目的内联位置。同时，我们提出了一个数据集自动化打标签的方法来生成数据。 ​ 为了解决第三个挑战，分类器被在多种不同的编译设置环境下训练，我们将其建模为多标签分类（MLC）问题，并根据不同编译设置下内联决策的相关性提出了基于编译器-选择的分类器。 ​ 通过给定的OSS生成SFSs，然后使用已有的“1-to-1”方法将这些SFSs与二进制函数相比较即可。 模型训练 1. 生成数据集 ​ 在生成数据集过程中，我们充分利用了编译过程生成的调试信息（用的都是可编译的OSS项目）。其会生成b2s行级别和函数级别的映射，并附带函数调用处的内联信息（是否内联）。 ​ 在开源项目编译时使用\"-g\"选项，可以使编译出的二进制文件附带从二进制地址到源文件某一行的映射信息（行级别映射），再利用Understand或者IDA Pro，tree-sitter，Chidra等工具，我们可以生成从二进制地址到源文件某一函数的映射信息（函数级别映射）。 ​ 如上图所示，圆圈是源码函数，方框是编译后的二进制函数。在（a）中，由于A只调用了C一次，故在编译后的二进制函数中C就被内联进了A中；但在（b）中，A调用了两次B，A和B都调用了C，无法很清楚的判断到底哪次调用需要被内联，故编译出的二进制函数也与编译选项有关，并不绝对。 ​ 上述例子可以看出，即使我们得到的源码函数之间的相互调用关系我们也无法确定哪些函数会被内联。 ​ 但如果我们知道其二进制调用关系图，反过来看，若二进制图中某个调用在源码调用图中也存在（如上图a中的A–&gt;B），则这个函数就不是内联函数，反之就是内联函数。这样，通过对调试信息的使用，可以成功的将可编译OSS项目的内联位置标注出来。 2. 特征提取 ​ 考虑到编译器一般通过评估内联的利弊来决定是否内联，我们总结了几个可以评估内联操作利弊的特征： ​ 如上表所示，特征共分为两大类Caller/Callee和Call Instruciton： Caller/Callee： caller这里指调用其他公共开源函数的函数，callee指被许多其他函数调用的函数。这部分特征分为函数内部语句，函数定义语句和函数调用次数。 Call Instruciton： 调用函数指令，这里关注其调用的位置和参数声明，例如在内联循环中的函数调用就可以显著减少调用次数。同理，如果调用含有常量参数，可以帮助减少内联函数的大小。 3. 模型训练 3.1 训练数据分析 ​ 我们这里提出了一个名为ECOCCJ48(Ensemble of Compiler Optimization based Classifier Chains built with J48)的MLC模型来预测内联函数位置。在多标签任务中，标签之间通常存在联系，下表展示了两个编译器（gcc-8.2.0和clang-7.0）在Ox优化下的内联措施的差异和联系： PS：opt1-opt2意味着使用优化措施opt1时内联，使用优化措施opt2时不内联的数量；opt1&amp;opt2意味着使用两个都内联的数量。 ​ 在同一编译器不同优化设置的条件下，由上图可以看出，94.78%的内联操作如果出现在低级优化措施的条件下，也会出现在更高级的优化措施条件下。所以在同一行内opt1&amp;opt2的数量都大于opt1-opt2。 ​ 在不同编译器的条件下，如下图所示，展示了不同优化措施下所做决策的Jaccard系数： ​ 在同一编译器家族（例如GCC的不同版本）比较时，其内联决策的相似性很高。当使用O0-O3优化措施测试gcc-6.4.0 和 gcc-7.2.0，87%的函数调用采用了相同的内联决策。在不同编译器的条件下，其内联决策没有明显的联系。 3.2 ECOCCJ48模型 ​ ECOOCJ48分为两个部分，使用binary relevance来预测不同编译器下的标签，使用整合分类器链来预测同一编译器下不同优化措施的标签。 3.3 不平衡的数据集 ​ 目前存在的数据集有以下问题： ​ 1.大多数的函数调用在被编译的过程中是不会被内联的，在使用OX优化时，大约只有20%的函数调用会被内联； ​ 2.不同优化措施编译时内联点的比例也不同。 ​ 这些差异导致了训练数据集的不平衡，训练会更偏向于正常的调用。我们使用了集成学习方法来处理这些不平衡，其使用随机选择的数据集来训练，通过整合不同基础分类器的结果来预测标签。因为不同基础分类器在不同的资料库中被训练，故他们可以抓住内联模式。 SFS生成 1. FCG构建与ICS预测 ​ 对于不可编译的OSS项目，首先使用一个解析器（parser）来提取代码中的函数调用点，构建FCG图。两个节点之间可以有多个有向边，边上附带函数调用的位置信息。 ​ 对于FCG中的每个调用点，我们从其调用者，被调用者和调用指令中提取特征，将其作为ECOCCJ48的输入，得到所有编译设置（不同编译器+优化措施）的标签。 2. SFS生成 ​ 如上图所示，（a）就是已经构建好的FCG图，其中红圈代表有内联函数的函数，黑圈则没有；红边代表内联操作，蓝边代表正常调用。假设FCG是一个有向无环图，SFS的生成就可以抽象成从FCG图中选择内联子树。这里将SFS的生成分为两个部分：根节点的选择（b）和边扩展。 ​ 根节点的选择上，有以下原则： ​ 1） 内联子树的根节点，如A,D； ​ 2）非内联子树的根节点，但是既内联调用了其他函数，也被其他函数普通调用，如C。 ​ 除去这两种情况，要么一个节点没有指向其他节点的红色边，要么在内联子树上仅仅被其它红边所指。第一种情况显然不能进入SFS，第二种情况会被内联进其调用者之中。 ​ 边扩展上，遵循以下规则： ​ 1） 对每个根节点，若其指向的节点仅有一条红边，则向下遍历其能遇到的所有节点（如对A，有A-&gt;C，A-&gt;C-&gt;E两条）； ​ 2）对每个根节点，若其指向的节点有两条相异颜色的边，则红色的边继续向下搜索生成，蓝色的边仅在下个点处停止。（如对C-&gt;E）。 ​ 若FCG成环，我们仅需注意，如果一个被调用节点已经在SFS中了，就不必再次遍历即可避免重复。 3. SFS汇总 ​ 得到函数的SFS后，我们将被调用函数的代码直接放进调用函数中。 测试评估 ​ 测试部分回答了以下问题： O2NMatcher可以提高现有1-to-1工作的表现吗？ 与Bingo 和 ASM2Vec比较，O2NMatcher生成的SFS有多准确？ 与现有的多标签分类工作相比，ECOCCJ48的表现如何？ O2NMatcher在训练，预测和生成SFS的时间花费如何？ 我们选取的特征集在ICS预测上有什么贡献？ 1. 研究背景 1.1 测试数据集 ​ 我们从GNU项目选择了51个包，使用9种编译器、4种优化措施编译成x86-64，得到8460个二进制文件和4294478个二进制函数。这些数据包含了诸如Coreutils、OpenSSL等在二进制相似性检测工作中广泛被使用的包。如下表所示： 1.2 Benchmark ​ 因为O2NMatcher是一个对其它b2s方法的补充，我们需要选择一个baseline。这里我们选择CodeCMR，一个现有工作表现最好的b2s方法。CodeCMR有一个开放工具BinaryAI，可以方便后续测试。 （Zeping Yu, Wenxin Zheng, Jiaqi Wang, Qiyi Tang, Sen Nie, and Shi Wu. 2020. Codecmr: Cross-modal retrieval for function-level binary source code matching. Advances in Neural Information Processing Systems 33 (2020), 3872–3883.） 1.3 实验设置 ​ 90%随机选择的训练集以及10%测试集。由于相同编译器的内联选择比较相似，这里测试集仅用两个编译器生成：gcc-2.2.0和clang-7.0。测试集包含1.1中所有的编译器生成的数据。分类器在训练集上训练，然后对测试集生成SFSs。为了避免误差我们重复实验10次。 ​ 测试时，使用不带调试信息的stripped binary，并且OSS文件不能被编译。 1.4 评估标准 ​ 使用标准召回率recall@K来评估O2NMatcher准确率。（Recall@K召回率是指前topK结果中检索出的相关结果数和库中所有的相关结果数的比率，衡量的是检索系统的查全率。）在这里，recall@K代表前k个模型返回的源码函数中真正的源码函数占比。对于1-to-1匹配，真正的源码函数就是该待检测二进制函数的源码；对于我们的1-to-n匹配，在SFSs中，某个函数的根函数是真正的源码函数也可以算作阳性样本。在接下来的实验中我们会使用K = 1、10和50来测试。 ​ 使用SFS大小（SFS size）来评估O2NMatcher成本。SFS size是已生成的SFSs数量比上原函数集的数量。因为新增的SFSs增加了资料库的大小，故可能影响查询匹配的时间。 ​ 使用precision、recall和F1-score来评估ECOCCJ48准确率。 1.5 O2NMatcher的实现 ​ 在数据集标注工作上，我们使用Understand对源码做语法分析，使用IDA Pro来反汇编二进制文件。在FCG构建上，我们使用Understand来提取所有函数调用点，对源码生成FCG图，使用IDA Pro对二进制文件生成FCG图。在函数调用特征提取上，我们使用tree-sitter来提取函数体、函数定义和函数调用指令的特征，使用Understand提取函数调用次数特征。 ​ 在模型训练工作上，我们使用Python工具scikit-multilearn来实现ECOCCJ48模型和其他MCL方法。整个程序在Ubuntu 18.04、Intel Xeon Gold 6266C、1024GB DDR4 RAM、Nvidia RTX3090 GPU环境上运行。 2. 对问题一的回答：O2NMatcher的效果 3. 对问题二的回答：SFSs的效果 ​ 上表比较了O2NMatcher、Bingo和ASM2Vec生成的SFSs与标准答案的结果。 4. 对问题三的回答：ECOCCJ48的效果 5. 对问题四的回答：O2NMatcher的成本 6. 对问题五的回答：特征选择的作用 五、问题 该方法模型怎么结合已有的方法？ 原来怎么比现在就怎么比，只是从源码库变成了SFS。 SFSs怎么起作用？ 将可能内联的函数体放进原函数的新代码库。 不平衡的数据集怎么处理的？ “We use ensemble methods to handle the imbalanced dataset. The ensemble method trains the base classifiers on the randomly selected dataset and predicts the labels by ggregating the predictions from the base classifiers. As different base lassifiers are trained in different corpora, they can capture the inlining patterns of some rare labels”这部分没看懂什么意思 在汇总SFS时： “Directly, there are two ways to aggregate the SFS: conduct inlining for the source functions in the SFSs such as the inlining during compilation or directly aggregate the content of all the functions in the SFS”，这两种方式具体什么区别？","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Binary","slug":"Binary","permalink":"http://example.com/tags/Binary/"},{"name":"ML","slug":"ML","permalink":"http://example.com/tags/ML/"}],"author":"Shaw"},{"title":"How Machine Learning Is Solving the Binary Function Similarity Problem","slug":"How-Machine-Learning-Is-Solving-the-Binary-Function-Similarity-Problem","date":"2022-12-08T08:20:40.777Z","updated":"2023-02-15T07:06:22.738Z","comments":true,"path":"2022/12/08/How-Machine-Learning-Is-Solving-the-Binary-Function-Similarity-Problem/","link":"","permalink":"http://example.com/2022/12/08/How-Machine-Learning-Is-Solving-the-Binary-Function-Similarity-Problem/","excerpt":"【论文阅读】How Machine Learning Is Solving the Binary Function Similarity Problem 时间：2022.8 作者：Andrea Marcelli, Mariano Graziano , Xabier Ugarte-Pedrero, Yanick Fratantonio , Mohamad Mansouri and Davide Balzarotti(思科，欧洲电信学院) 会议：usenix 2022 ABSTRACT 人们会期望到现在为止，对于二进制相似性问题的研究，其有可能回答一些研究问题，这些问题超出了论文中提出的非常具体的技术，可以推广到整个研究领域。不幸的是，这个目标受到许多挑战，从可重复性问题到研究结果的不透明性，阻碍了研究有意义和有效地进展。 在本文，我们开始着手于对state-of-the-art做这个领域的第一个测试性研究。 首先，我们系统化了现存的研究成果； 我们选定了一些相关方法，这些方法代表了三个不同研究社区最近提出的各种解决方案； 针对现有的方案，我们重构了方法并构建了新的数据集，以便实现更为公平的对比效果。","text":"【论文阅读】How Machine Learning Is Solving the Binary Function Similarity Problem 时间：2022.8 作者：Andrea Marcelli, Mariano Graziano , Xabier Ugarte-Pedrero, Yanick Fratantonio , Mohamad Mansouri and Davide Balzarotti(思科，欧洲电信学院) 会议：usenix 2022 ABSTRACT 人们会期望到现在为止，对于二进制相似性问题的研究，其有可能回答一些研究问题，这些问题超出了论文中提出的非常具体的技术，可以推广到整个研究领域。不幸的是，这个目标受到许多挑战，从可重复性问题到研究结果的不透明性，阻碍了研究有意义和有效地进展。 在本文，我们开始着手于对state-of-the-art做这个领域的第一个测试性研究。 首先，我们系统化了现存的研究成果； 我们选定了一些相关方法，这些方法代表了三个不同研究社区最近提出的各种解决方案； 针对现有的方案，我们重构了方法并构建了新的数据集，以便实现更为公平的对比效果。 INTRODUCTION Binary function similarity：将一对函数的二进制表示作为输入，它们之间的相似性值作为输出。 Binary function similarity技术面临的挑战： 实际情况下，软件会被不同编译器、链接工具以及优化器编译； 特殊情况下，例如IoT，软件会被编译为不同架构的指令； Binary function similarity的作用： 在系统安全研究领域，许多研究问题需要以Binary function similarity作为核心构件。 节省逆向时间。在逆向工程中经常需要处理静态链接的stripped binaries，Binary function similarity可用于将一个未知的函数与先前生成的数据库中的（有标签的）函数进行匹配，对应到先前生成的数据库中，从而节省大量的时间； （stripped binaries：编译后的二进制文件可以包含调试信息，这些信息对于程序的执行是没有必要的，相反，它对于调试和发现程序中的问题或漏洞是很有用的。剥离的二进制文件（stripped binaries）是一个没有这些调试符号的二进制文件，因此体积较小，而且可能比没有剥离的二进制文件有更好的性能。剥离后的二进制文件很难被反汇编或逆向工程，这也使其难以发现程序中的问题或漏洞。） 用于高校检索第三方库中的漏洞函数。给定一个有问题的函数，Binary function similarity可用于在第三方库中快速检索相似函数； 用于软件分析以及恶意软件分类。 提出问题： 在使用相同评估标准、相同数据集的前提下，不同的方法如何比较？ 与简单的模糊哈希算法相比，原创的机器学习算法的主要贡献在哪？ 不同特征集的作用是什么？ 不同的方法在不同的任务中是否效果更好？ 相较于同一架构指令下，不同架构指令编译的二进制的比较是否更困难？ 是否有任何具体的研究方向看起来更有希望成为设计新技术的未来方向？ 很遗憾，我们发现目前的研究并不能回答上述问题。 现有研究存在的不足： 实验方法、实验结果不透明，难复现。实验所需的工具、超参数以及数据集通常都是不公开的，一些工作的横向比较太少甚至跟自己以前发的文章比； 现有工作的评估方法往往也是模糊不清的。不同的论文中，任务目标、环境设置、概念、颗粒度、数据集的大小和特性以及评估方法往往都不同，因此，即使是论文中最基础的图像也基本不能直接比较。所以，当新的工作声称比旧工作表现更好时，这个优越性是否仅仅是针对某个特殊的领域不得而知。更糟糕的是，一些工作函数对的选择方法以及训练集的构成并没有详细说明，使得复现变得更加困难。一个方法结果更优秀的原因是因为其原创性还是其他因素不得而知； 领域整体较为混乱。每个新的解决方案都采用了更复杂的技术，或多种技术的新组合。新方法的成功很难确定是由较简单的方法的实际局限性导致的，还是其创新性。现有几十种方法存在，但是并不能确定哪些方法在哪些环境设置下是有效的，而哪些不行。 “每个人都声称他们的方法最好。” 本文贡献： ​ 实现了在本领域第一个系统化的评估。在相同的工具框架下复现了10个有代表性的方法（及其变种方法），并使用新定义的同一数据集测试。 一些结论： 简单的方法（例如模糊哈希）在简单的环境下表现很好，但难以应对复杂的环境； GNN几乎在所有任务里都取得了最好的成绩； 许多最近发表的论文在同一数据集上测试时，都有非常相似的准确性，尽管他们之中的一些声称自己有了提高。 Measuring Function Similarity（领域基础知识） 1. 函数相似度评估方法 1.1 直接评估（Direct Comparsion）： 用机器学习/深度学习模型做相似性函数，通过对模型的训练来使其输入两个函数，输出两个函数的相似性。 1.1 间接评估（Indirect Comparsion）： 间接评估将输入函数的特征压缩到低维度表示，这些表示可以使用简单的距离测量方法评估相似度，例如欧氏距离或余弦距离。 Fuzzy hashes：一个很典型的低维度特征表示方法就是哈希模糊。特殊的fuzzy hashes，如ssdeep，用于判断两个文件是否近似的hash。如果一个文件比另一个文件多一个空格，普通的hash是会完全不同，而模糊hash 可能会很相似或者完全一样。 Code embedding：代码嵌入，应用NLP的方法，将汇编看做文本，对每个代码块或者指令做embedding。 Graph embedding： 图嵌入，使用代码图结构，通过传统方法或者GNN来生成embedding。 2. 函数表示方法 直接使用raw bytes； 使用通过raw bytes反编译得到的汇编代码； Normalized assembly，将汇编代码中的常数等替换，减轻操作数与操作之间的联系； Intermediate representations，中间表示； 图结构，例如CFG，DFG等； 动态分析，通过运行中的函数来比较； Symbolic execution，通过符号执行分析； 筛选现有方法 尽管现有数百篇的论文，但其中的很多方法都是对某个技术做微调，故该领域的原创方法并不是很多。 1. 筛选标准 Scalability and real-world applicability（可扩展性和现实世界的适用性）：不关注天生速度较慢的方法，只关注诸如那些基于动态分析、符号执行或高复杂度图相关算法的方法； Focus on representative approaches and not on specifific papers：只关注有代表性的方法； Cover different communities：在我们的评估中，我们希望包括来自系统安全、编程语言分析和机器学习社区的代表性研究。为了完整性，我们还考虑了行业提出的方法； Prioritize latest trends：考虑最新的，尤其是AI方法。 2. 筛选方法 上图选定了30个方法，接着我们会从这30个方法中筛选出10个最有代表性的方法来测试。 该图的左侧对不同研究机构提出的方法进行了分类，由学术界和工业界（腾讯、谷歌），箭头代表了指向的一方拿被指向一方的结果进行了比较； 该图的右侧Y轴代表出版时间，X轴代表函数的输入形式，不同的色块代表不同的相似度计算方式； 中括号[]代表的tag标注了不同的研究群体，例如S代表Security，SE代表Software eng。 从该图中可以得出： 左图中间的二进制比较工具都是为直接比较两个完整二进制文件而设计的（例如，它们使用图结构），并且它们都是针对单指令集结构的。但是一些做了跨指令集和函数比较的paper仍拿这些方法来比较，显然会得出不正确的结论； 从左图可以得出，不同研究机构之间很少跨领域比较； 从右图可以看出，随着时间推移，算法的复杂性以及AI算法的使用比例都在增加。 3. 筛选结果 方法类型 方法/作者名称 Bytes fuzzy hashing Catalog1 CFG fuzzy hashing FunctionSimSearch Attributed CFG and GNN Gemini Attributed CFG, GNN, and GMN Li et al. 2019 IR, data flflow analysis and neural network Zeek Assembly code embedding Asm2Vec Assembly code embedding and self-attentive encoder SAFE Assembly code embedding, CFG and GNN Massarelli et al.2019 CodeCMR BinaryAI hierarchical transformer and micro-traces Trex 测试 1. 复现方法 复现的几个阶段：binary analysis，the feature extraction，the machine-learning implementations. 二进制分析以及特征提取使用的是IDA Pro 7.3以及其Python接口。 有关我们所有实现的其他技术细节，以及有关我们努力联系相应作者的信息以及有关使用预训练模型的注意事项，请参见： How Machine Learning Is Solving the Binary Function Similarity Problem — Artifacts and Additional Technical Details. https://github.com/Cisco-Talos/binary_function_similarity. 2. 数据集 为了与现实世界的复杂性与变数相匹配，我们创建了两个新的数据集Dataset-1和Dataset-2，其包含了二进制检测领域的问题： ​ 多种编译器和版本； ​ 多种编译优化器； ​ 多种指令集架构和bitness(32位还是64位)； ​ 不同种类的代码（命令行 or GUI）； Dataset-1用于训练，Dataset-1和Dataset-2用于测试。 3. 实验环境设置 3.1 定义6个检测任务 序号 任务名称 作用 1 XO 待测函数对仅优化器不同，编译器，编译器版本、指令集架构和bitness都相同 2 XC 待测函数对优化器，编译器和编译器版本不同，指令集架构和bitness相同 3 XC+XB 待测函数对优化器，编译器和编译器版本以及bitness不同，指令集架构相同 4 XA 待测函数对指令集架构和bitness不同，其他相同 5 XA+XO 待测函数对指令集架构、bitness和优化器不用，其他相同 6 XM 待测函数对所有性质都可能不同 3.2 测试方法 每种方法的测试包含两个过程： AUC和ROC图； MRR和Recall@K。 4. 模糊哈希方法比较结果 比较了两个方法：Catalog1和FunctionSimSearch。 4.1 首先每次只变动一个变量： B：Row Bytes；G：graphlets，连通图结构； M： mnemonics；符号 I：immediates 。 由图可知，在单指令集架构的条件下即使简单的row bytes输入也能取得较好效果，在多指令集架构下代码图结构明显更好。 4.2 测试3.1中的6个任务 可以看到： 当面对多变量不同的任务时简单的方法开始变得不奏效了，同时FSS在面对大函数时可能由于其图结构的输入也更为有效； 同时，GMI的三个特征引入并没有比最基础的G配置输入更为有效； Catalog1速度更快，因为FSS的特征提取更耗时。 5. 机器学习方法比较结果 结论： GMN几乎在所有的测试下表现都最好，而且运行时间也很短； 语言模型相关的方法在同一指令集架构下的表现都很不错，transformer在跨指令集架构的表现也不错； 由Li等人提出的GNN变式相较于GNN（s2v）的表现有明显提升； GNN（s2v）相关的实验表明更复杂的特征提取不一定更有效，且使用instruction embedding也不一定效果更好； 相较于GNN，使用了编码器的SAFE在小函数上的表现更好，但其存在OOV问题； 6. 漏洞发掘的样例 问题 测试的时候使用的Ranking measures（MRR10与Recall@K）的作用？","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Binary","slug":"Binary","permalink":"http://example.com/tags/Binary/"},{"name":"ML","slug":"ML","permalink":"http://example.com/tags/ML/"}],"author":"Shaw"},{"title":"强化学习之ConnectX四子棋游戏","slug":"Connect X","date":"2022-12-01T14:11:52.779Z","updated":"2022-12-01T14:10:34.196Z","comments":true,"path":"2022/12/01/Connect X/","link":"","permalink":"http://example.com/2022/12/01/Connect%20X/","excerpt":"Connect X Time: 2022.11.14 Author: Shaw Connect X | Kaggle ConnectX Getting Started | Kaggle 一、任务简介： 任务：强化学习任务，类似五子棋的规则（但每一步只能下某一列的最底端的空位），每人一步，先于对手横竖或斜角连成4个即可获胜。","text":"Connect X Time: 2022.11.14 Author: Shaw Connect X | Kaggle ConnectX Getting Started | Kaggle 一、任务简介： 任务：强化学习任务，类似五子棋的规则（但每一步只能下某一列的最底端的空位），每人一步，先于对手横竖或斜角连成4个即可获胜。 评估方法： 每个提交给Kaggle的结果（一个py文件，包含了agent如何下棋的规则）在跟自己下一次棋，证明其工作正常后，会被赋予一个skill等级。 相近skill等级的提交结果之间会进行持续不断下棋PK。 每次PK结束后就会更新双方的等级，赢加输减。 二、环境准备 安装kaggle相关的强化学习环境： pip install kaggle-environments 创建Connect X环境： from kaggle_environments import evaluate, make, utils env = make(\"connectx\",debug=True) #创建connectx环境 env.render() #以图形化的形式显示当前环境 创建Submission提交函数： import inspect import os def write_agent_to_file(function, file): with open(file, \"a\" if os.path.exists(file) else \"w\") as f: f.write(inspect.getsource(function)) print(function, \"written to\", file) write_agent_to_file(my_agent, \"submission.py\") 三、Q-learning 对于简单的下棋问题，这里选择Q-learning算法进行学习。 创建connectX类： class ConnectX(gym.Env): def __init__(self, switch_prob=0.5): self.env = make('connectx', debug=True) self.pair = [None, 'negamax'] self.trainer = self.env.train(self.pair) self.switch_prob = switch_prob # Define required gym fields (examples): config = self.env.configuration self.action_space = gym.spaces.Discrete(config.columns) self.observation_space = gym.spaces.Discrete(config.columns * config.rows) def switch_trainer(self): self.pair = self.pair[::-1] self.trainer = self.env.train(self.pair) def step(self, action): return self.trainer.step(action) def reset(self): # 有switch_prob的几率更换先手顺序 if random.uniform(0, 1) &lt; self.switch_prob: self.switch_trainer() return self.trainer.reset() def render(self, **kwargs): return self.env.render(**kwargs) 创建Q表，由于棋盘状态较多，这里使用动态Q表（shape = （n，7））： class QTable: def __init__(self, action_space): self.table = dict() self.action_space = action_space def add_item(self, state_key): self.table[state_key] = list(np.zeros(self.action_space.n)) def __call__(self, state): board = state['board'][:] # 复制一份 board.append(state.mark) # 加入mark标志着先手还是后手 state_key = np.array(board).astype(str) state_key = hex(int(''.join(state_key), 3))[2:]# 转为16进制编码，去掉前缀 if state_key not in self.table.keys(): self.add_item(state_key) return self.table[state_key] 定义相关超参数： alpha = 0.1 # 学习率 gamma = 0.6 # discount factor γ epsilon = 0.99 # ε-greedy策略的ε min_epsilon = 0.1 # 最小ε episodes = 10000 # 采样轮数 alpha_decay_step = 1000 alpha_decay_rate = 0.9 # α衰减率 epsilon_decay_rate = 0.9999 # ε衰减率 定义训练过程： q_table = QTable(env.action_space) all_epochs = [] all_total_rewards = [] all_avg_rewards = [] # Last 100 steps all_qtable_rows = [] all_epsilons = [] for i in tqdm(range(episodes)): state = env.reset() # 清空棋盘 epochs,total_rewards = 0, 0 epsilon = max(min_epsilon,epsilon*epsilon_decay_rate) # ε每轮衰减 done = False while not done : # 开始一轮采样 # 某列不能下的情况 == 此列的第一个位置有棋子 == (state.board[c] == 0) space_list = [c for c in range(env.action_space.n) if state['board'][c] == 0] if random.uniform(0,1) &lt;= epsilon :# ε-greedy-->选择随机策略 action = choice(space_list) else : # ε-greedy-->选择贪心策略 row = np.array(q_table(state)[:]) row[[c for c in range(env.action_space.n) if state['board'][c] != 0]] = -1 action = int(np.argmax(row)) next_state,reward,done,info = env.step(action) if done: if reward == 1: # Won reward = 20 elif reward == 0: # Lost reward = -20 else: reward = 1 else: reward = -0.01 old_value = q_table(state)[action] next_max = np.max(q_table(next_state)) # Q-Learning 更新 new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max) q_table(state)[action] = new_value state = next_state epochs += 1 total_rewards += reward all_epochs.append(epochs) all_total_rewards.append(total_rewards) avg_rewards = np.mean(all_total_rewards[max(0, i-100):(i+1)]) all_avg_rewards.append(avg_rewards) all_qtable_rows.append(len(q_table.table)) all_epsilons.append(epsilon) if (i+1) % alpha_decay_step == 0: alpha *= alpha_decay_rate 根据Q表生成Agent： my_agent = '''def my_agent(observation, configuration): from random import choice q_table = ''' \\ + str(dict_q_table).replace(' ', '') \\ + ''' board = observation.board[:] board.append(observation.mark) state_key = list(map(str, board)) state_key = hex(int(''.join(state_key), 3))[2:] if state_key not in q_table.keys(): return choice([c for c in range(configuration.columns) if observation.board[c] == 0]) action = q_table[state_key] if observation.board[action] != 0: return choice([c for c in range(configuration.columns) if observation.board[c] == 0]) return action ''' with open('submission.py', 'w') as f: f.write(my_agent) 上交到Kaggle后经过一晚上的博弈，分数很低，直接倒数： 尝试评估其效果： from submission import my_agent def mean_reward(rewards): win = sum(1 if r[0]>0 else 0 for r in rewards) loss = sum(1 if r[1]>0 else 0 for r in rewards) draw = sum(1 if r[0] == r[1] else 0 for r in rewards) return '&#123;0&#125; episodes- won: &#123;1&#125; | loss: &#123;2&#125; | draw: &#123;3&#125; | winning rate: &#123;4&#125;%'.format( len(rewards), win, loss, draw, (win / len(rewards))*100 ) # Run multiple episodes to estimate agent's performance. print(\"My Agent vs Random Agent:\", mean_reward( evaluate(\"connectx\", [my_agent, \"random\"], num_episodes=100))) print(\"My Agent vs Negamax Agent:\", mean_reward( evaluate(\"connectx\", [my_agent, \"negamax\"], num_episodes=100))) 四、DQN 在尝试了简单的强化学习算法后，这里将深度学习与强化学习结合起来，用DQN进行训练： DQN使用了神经网络来代替Q表，使用函数替代表格，以此解决Q表过大的问题： class ConnectX(gym.Env): def __init__(self, switch_prob=0.5): self.env = make('connectx', debug=False) self.pair = [None, 'random'] self.trainer = self.env.train(self.pair) self.switch_prob = switch_prob # Define required gym fields (examples): config = self.env.configuration self.action_space = gym.spaces.Discrete(config.columns) self.observation_space = gym.spaces.Discrete(config.columns * config.rows) def switch_trainer(self): self.pair = self.pair[::-1] self.trainer = self.env.train(self.pair) def step(self, action): return self.trainer.step(action) def reset(self): if np.random.random() &lt; self.switch_prob: self.switch_trainer() return self.trainer.reset() def render(self, **kwargs): return self.env.render(**kwargs) class DeepModel(torch.nn.Module): def __init__(self,num_states,hidden_units,num_actions): super(DeepModel,self).__init__() self.hidden_layers = nn.ModuleList([]) for i in range(len(hidden_units)): if i == 0: self.hidden_layers.append(nn.Linear(num_states,hidden_units[i])) else : self.hidden_layers.append(nn.Linear(hidden_units[i-1],hidden_units[i])) self.output_layers = nn.Linear(hidden_units[-1],num_actions) def forward(self,x): for layer in self.hidden_layers: x = torch.sigmoid(layer(x)) x = self.output_layers(x) return x class DQN: def __init__(self,num_states,num_actions,hidden_units,gamma,max_experiences,min_experiences,batch_size,lr): self.num_actions = num_actions self.batch_size = batch_size self.gamma = gamma self.model = DeepModel(num_states,hidden_units,num_actions) self.optimizer = optim.Adam(self.model.parameters(), lr = lr) self.criterion = nn.MSELoss() self.experience = &#123;'s':[], 'a':[], 'r':[], 's2':[], 'done':[] &#125; self.max_experiences = max_experiences self.min_experiences = min_experiences def preprocess(self, state): result = state.board[:] result.append(state.mark) return result def predict(self,inputs): return self.model(torch.from_numpy(inputs).float()) def train(self,TargetNet): if len(self.experience['s']) &lt; self.min_experiences: return 0 ids = np.random.randint(low=0, high=len(self.experience['s']), size=self.batch_size) states = np.asarray([self.preprocess(self.experience['s'][i]) for i in ids]) actions = np.asarray([self.experience['a'][i] for i in ids]) rewards = np.asarray([self.experience['r'][i] for i in ids]) states_next = np.asarray([self.preprocess(self.experience['s2'][i]) for i in ids]) dones = np.asarray([self.experience['done'][i] for i in ids]) value_next = np.max(TargetNet.predict(states_next).detach().numpy(), axis=1) actual_values = np.where(dones, rewards, rewards+self.gamma*value_next) actions = np.expand_dims(actions, axis=1) actions_one_hot = torch.FloatTensor(self.batch_size, self.num_actions).zero_() actions_one_hot = actions_one_hot.scatter_(1, torch.LongTensor(actions), 1) selected_action_values = torch.sum(self.predict(states) * actions_one_hot, dim=1) actual_values = torch.FloatTensor(actual_values) self.optimizer.zero_grad() loss = self.criterion(selected_action_values, actual_values) loss.backward() self.optimizer.step() def get_action(self,state,epsilon): if np.random.random() &lt; epsilon: return int(np.random.choice([c for c in range(self.num_actions) if state.board[c] == 0])) else : prediction = self.predict(np.atleast_2d(self.preprocess(state)))[0].detach().numpy() for i in range(self.num_actions): if state.board[i] != 0: prediction[i] = -1e7 return int(np.argmax(prediction)) def add_experience(self, exp): if len(self.experience['s']) >= self.max_experiences: for key in self.experience.keys(): self.experience[key].pop(0) for key, value in exp.items(): self.experience[key].append(value) def copy_weights(self, TrainNet): self.model.load_state_dict(TrainNet.state_dict()) def save_weights(self, path): torch.save(self.model.state_dict(), path) def load_weights(self, path): self.model.load_state_dict(torch.load(path)) 训练时，将采样的s,r,a,s'存储下来，等到积累到一定数量后再以batch的形式输入神经网路（这里是全连接层），训练，测试。 通过这种方式，可以极大的增加训练的轮数，这里尝试十万轮（训练时间四小时）： 五、RollOut RollOut算法是典型的决策时规划算法，其思路是： 对当前状态S的所有可能取值&lt;s,a'&gt;，模拟计算若干次，取得每个&lt;s,a'&gt;的平均Reward； 选取Reward最大的动作A； 模拟计算时使用的策略称之为rollout策略，这里直接采用随机策略。 使用如下类进行蒙特卡洛采样： class MonteCarlo: def __init__(self, env, gamma, episodes): ''' env是当前需要进行模拟采样的状态 gamma用于计算Reward episodes是每个(s,a)的采样次数 ''' self.state = deepcopy(env) self.all_rewards = [0, 0, 0, 0, 0, 0, 0] self.gamma = gamma self.episodes = episodes def rollout(self, env): # 对当前状态进行rollout采样 mean_reward = 0 ini_state = env.env.state[0]['observation'] for i in range(self.episodes): r = 0 gamma = 1 env.set_state(ini_state) state = deepcopy(ini_state) done = False while not done: space_list = [c for c in range(7) if state['board'][c] == 0] action = choice(space_list) next_state, reward, done, info = env.step(action) if done: if reward == 1: r += 20*gamma elif reward == 0: r -= 20*gamma else: r += 1*gamma mean_reward += r else: r -= 0.05*gamma gamma *= self.gamma state = next_state return mean_reward/self.episodes 因为MC采样需要在采样后将环境状态恢复，故在原本的ConnectX类中添加设置状态方法，并删除swicth_trainer： class ConnectX(gym.Env): def __init__(self, switch_prob=0.5): self.env = make('connectx', debug=True) self.pair = [None, 'random'] self.trainer = self.env.train(self.pair) self.switch_prob = switch_prob config = self.env.configuration self.action_space = gym.spaces.Discrete(config.columns) self.observation_space = gym.spaces.Discrete( config.columns * config.rows) def step(self, action): return self.trainer.step(action) def set_state(self, init_state): self.env.reset() self.env.state[0]['observation'] = deepcopy(init_state) def reset(self): return self.trainer.reset() def render(self, **kwargs): return self.env.render(**kwargs) 调试时设置play函数： def play(num,env,gamma,episodes): result = &#123;'win':0,'loss':0,'draw':0&#125; for i in range(num): #print('[GAME&#123;&#125;]:'.format(i)) done = False state = env.reset() while not done: ini_state = env.env.state[0]['observation'] space_list = [c for c in range(7) if ini_state['board'][c] == 0] R = [] for action in space_list: # rollout模拟采样 env.set_state(ini_state) next_state, reward, done, info = env.step(action) mc = MonteCarlo(env, gamma, episodes) reward = reward + gamma*mc.rollout(env) R.append(reward) Action = int(np.argmax(R)) # 根据采样结果选择动作 env.set_state(ini_state) next_state, reward, done, info = env.step(Action) #print('R = ', R) #print('Action = ', Action) #print(env.render(mode=\"ansi\")) if done: if reward == 1: # Won result['win'] += 1 #print('you win!') elif reward == 0: # Lost result['loss'] += 1 #print('you loss!') else: result['draw'] += 1 #print('draw!') print('My Agent vs Random Agent:', '&#123;0&#125; episodes- won: &#123;1&#125; | loss: &#123;2&#125; | draw: &#123;3&#125; | winning rate: &#123;4&#125;%'.format( num, result['win'], result['loss'], result['draw'], (result['win'] / num)*100 )) 六、问题总结 1. 训练时间过长 以Q-Learning为例，一个10000个episodes的训练要耗时2小时+，对于一个简单的四子棋过于耗时。 尝试： 尝试在python文件中而不是jupter中训练：训练总时间减少了约2/5，有一定效果； 使用DQN时训练速度明显大于Q-leraning（训练十万轮耗时3小时40分钟），猜想可能是神经网络可以使用GPU加速，‘查表’速度更快； 2. Q-Learning训练效果不佳 在经过10000个episode训练后，Q-Learning的表现如下： 通过如下的代码，你可以跟自己的agent下一局，可以发现，经过一万轮训练后的Agent棋力很一般，新手人类也能轻松胜利： while not done: sys.stdout.flush() print(env.render(mode=\"ansi\")) action = int(input('Input your action:(0-6)')) next_state, reward, done, info = env.step(action) if done: if reward == 1: # Won print('you win!') elif reward == 0: # Lost print('you loss!') else: print('draw!') 观察训练时平均Reward、Q表长度和ε的变化： 可以发现，在10000轮episode的训练中，平均奖励始终在围绕0.8上下波动，Q表长度一直在平稳增加，这说明直到训练结束Agent仍有大量未见过的state进入Q表，模型训练轮数不足。 实际上 Connect 4有四百万兆不同的状态，Q-learning显然在有限的时间空间下是取得不了什么有效学习的。 3. DQN的不足 即使使用DQN进行了十万轮的训练，耗时近4小时，DQN的结果仍不理想： 其实不难理解，对于四百万兆个state的棋盘，十万轮也不过是\\[1/10^{13}\\]，仍过于渺小。 并且，Q-learning以及DQN都是background planning，其算法倾向于将所有可能的状态的最佳策略都计算出来。实际上，在下棋的时候几乎绝大多数状态都不会出现第二次，但相似的棋谱格局却会经常出现。 显然，相较于background planning，decision-time planning（决策时规划）算法是个更合适的算法。 decision-time planning在遇到每个新的状态St后再开始一个完整的规划过程，其为每个当前状态选择一个动作At，到下一个状态St+1就选择一个动作At+1，以此类推。基于当前状态所生成的values和policy会在做完动作选择决策后被丢弃，在很多应用场景中这么做并不算一个很大的损失，因为有非常多的状态存在，且不太可能在短时间内回到同一个状态，故重复计算导致的资源浪费会很少。 4. 随机Rollout 这里尝试使用简单的RollOut算法后发现，即使在rollout算法中使用最简单的随机rollout策略，并且每轮模拟仅仅采样1次，所取得的的结果就比训练了4个小时的DQN好很多。 在模拟采样轮数为1（对每个&lt;s,a&gt;键值对只采样1次）、gamma为1的条件下，与Random和Negmax分别下100局的胜率： 模型 VS Random VS Negmax Q-Learning(一万轮) 61% 3% DQN(十万轮) 70% 6% 随机Rollout 94% 95%平局 但Rollout算法的问题也很明显，其应用的过程就是‘训练’的过程，每次需要等模拟采样完成后再选择，故其反应时间会比DQN长很多。 时间 DQN 随机Rollout 训练所需时间 4h 0 下100局所需时间 1m 40m 但即使这样，我们也能看出，决策时规划比后台规划算法更适合棋类场景，由于棋类几乎无限的状态数量，决策时规划虽然反应更慢，但结果也更为合理有效。 5. 展望 本次的小比赛从最简单的Q-Learning算法入手，到引入了神经网络的DQN，最后从后台规划引入到决策时规划，并实现了一个简单的Rollout算法。 首先，Q-learning以及DQN这类后台规划算法无法有效处理状态过多的环境。Q-learning在时间以及空间上都存在溢出问题，DQN虽然引入了深度神经网络来替代Q表，解决了空间不足的问题，但由于其训练速度没有质的改变，训练时间仍不可估量的长。 决策时规划面对状态过多的问题有明显提升。即使在rollout算法中使用最简单的随机rollout策略，并且每轮模拟仅仅采样1次，所取得的的结果就比训练了4个小时的DQN好很多。 除了使用简单的随机Rollout算法，这里可以替换rollout策略来进一步提升结果，减少rollout的反应时间。以及，可以使用MCTS，蒙特卡洛树搜索的方法再进一步提升结果（kaggle中已有Notebook，且分数不错），这里篇幅以及时间有限，仅做展望。","categories":[{"name":"Kaggle","slug":"Kaggle","permalink":"http://example.com/categories/Kaggle/"}],"tags":[{"name":"Pytorch","slug":"Pytorch","permalink":"http://example.com/tags/Pytorch/"},{"name":"RL","slug":"RL","permalink":"http://example.com/tags/RL/"}],"author":"Shaw"},{"title":"Facial Keypoints Detection","slug":"Facial Keypoints Detection","date":"2022-11-14T03:24:28.500Z","updated":"2022-11-14T03:24:02.826Z","comments":true,"path":"2022/11/14/Facial Keypoints Detection/","link":"","permalink":"http://example.com/2022/11/14/Facial%20Keypoints%20Detection/","excerpt":"Facial Keypoints Detection Time: 2022.11.11 Author: Shaw Facial Keypoints Detection | Kaggle 一、任务简介： ​ 任务：正确标注所给图片的人脸关键位置；","text":"Facial Keypoints Detection Time: 2022.11.11 Author: Shaw Facial Keypoints Detection | Kaggle 一、任务简介： ​ 任务：正确标注所给图片的人脸关键位置； ​ 关键位置（keypoint）： 字段 解释 left_eye_center 左眼中心 right_eye_center 右眼中心 left_eye_inner_corner 左眼内眼角 left_eye_outer_corner 左眼外眼角 right_eye_inner_corner 右眼内眼角 right_eye_outer_corner 右眼外眼角 left_eyebrow_inner_end 左眉内侧 left_eyebrow_outer_end 左眉外侧 right_eyebrow_inner_end 右眉内侧 right_eyebrow_outer_end 右眉外侧 nose_tip 鼻尖 mouth_left_corner 嘴左角 mouth_right_corner 嘴右角 mouth_center_top_lip 上唇中心 mouth_center_bottom_lip 下唇中心 ​ 数据组成： training.csv: 包含7049张训练图片，每张图片有15个keypoint坐标（每个坐标用x,y两列数据表示，有些数值缺失），图像数据作为按行排序的像素列表。故表格中的数据标签有30列，图片数据一列共31列； test.csv: 包含1783张测试图片； ubmissionFileFormat.csv: 待提交的测试结果。 样例： 二、数据分析处理 首先加载训练数据与测试数据： #Load the data train_data = pd.read_csv(TRAIN_PATH) test_data = pd.read_csv(TEST_PATH) print(train_data.columns) print(test_data.columns) 2.1 空值填补 因为数据中存在缺失值，故统计分析存在缺失值的列： train_data.isnull().any().value_counts() #out: ''' True 28 False 3 dtype: int64 ''' 故28个属性列都存在缺失值，接下来填补缺失，‘ffill’方法表示用前面一列的值填补当前位置的值： train_data.fillna(method = 'ffill',inplace = True) 同时，Image列中的部分数值由‘ ’空格替代，这里将其替换为0： train_data['Image_new'] = train_data['Image'].map(lambda x:['0' if i == ' ' else i for i in x.split(' ')]) image_list = np.array(train_data['Image_new'].to_list(),dtype='float') 2.2 相关图片处理函数编写 IMG_SIZE = 96 # image size 96 x 96 pixels def show_keypoints(image, keypoints): ''' Show image with keypoints Args: image (array-like or PIL image): The image data. (M, N) keypoints (array-like): The keypoits data. (N, 2) ''' plt.imshow(image, cmap='gray') if len(keypoints): plt.scatter(keypoints[:, 0], keypoints[:, 1], s=24, marker='.', c='r') def show_images(df, indxs, ncols=5, figsize=(15,10), with_keypoints=True): ''' Show images with keypoints in grids Args: df (DataFrame): data (M x N) idxs (iterators): list, Range, Indexes ncols (integer): number of columns (images by rows) figsize (float, float): width, height in inches with_keypoints (boolean): True if show image with keypoints ''' plt.figure(figsize=figsize) nrows = len(indxs) // ncols + 1 for i, idx in enumerate(indxs): image = np.fromstring(df.loc[idx, 'Image'], sep=' ').astype(np.float32)\\ .reshape(-1, IMG_SIZE) if with_keypoints: keypoints = df.loc[idx].drop('Image').values.astype(np.float32)\\ .reshape(-1, 2) else: keypoints = [] plt.subplot(nrows, ncols, i + 1) plt.title(f'Sample #&#123;idx&#125;') plt.axis('off') #关闭坐标轴 plt.tight_layout() # tight_layout会自动调整子图参数，使之填充整个图像区域 show_keypoints(image, keypoints) plt.show() 2.3 分割数据集 使用Dataset和DataLoader相关pytorch类来加载数据集。 定义数据集子类用于自动处理dataframe数据，返回{'image': image, 'keypoints': keypoints}类型的数据： class FaceKeypointsDataset(Dataset): '''Face Keypoints Dataset''' def __init__(self, dataframe, train=True, transform=None): ''' Args: dataframe (DataFrame): data in pandas dataframe format. train (Boolean) : True for train data with keypoints, default is True transform (callable, optional): Optional transform to be applied on sample ''' self.dataframe = dataframe self.train = train self.transform = transform def __len__(self): return len(self.dataframe) def __getitem__(self, idx): image = np.fromstring(self.dataframe.iloc[idx, -1], sep=' ')\\ .astype(np.float32).reshape(-1, IMG_SIZE) if self.train: keypoints = self.dataframe.iloc[idx, :-1].values.astype(np.float32) else: keypoints = None sample = &#123;'image': image, 'keypoints': keypoints&#125; if self.transform: sample = self.transform(sample) return sample 将数据正则化，转化为tensor： class Normalize(object): '''Normalize input images''' def __call__(self, sample): image, keypoints = sample['image'], sample['keypoints'] return &#123;'image': image / 255., # scale to [0, 1] 'keypoints': keypoints&#125; class ToTensor(object): '''Convert ndarrays in sample to Tensors.''' def __call__(self, sample): image, keypoints = sample['image'], sample['keypoints'] # swap color axis because # numpy image: H x W x C # torch image: C X H X W image = image.reshape(1, IMG_SIZE, IMG_SIZE) image = torch.from_numpy(image) if keypoints is not None: keypoints = torch.from_numpy(keypoints) return &#123;'image': image, 'keypoints': keypoints&#125; else: return &#123;'image': image&#125; 利用SubsetRandomSampler构建采样器，并使用Dataloader构建数据加载器： from torch.utils.data.sampler import SubsetRandomSampler def prepare_train_valid_loaders(trainset,valid_size = 0.2,batch_size = 128): # obtain training indices that will be used for validation # 这里保障了训练集和测试集的随机划分 num_train = len(trainset) indices = list(range(num_train)) np.random.shuffle(indices) split = int(np.floot(valid_size*num_train)) train_idx, valid_idx = indices[split:], indices[:split] # define samplers for obtaining training and validation batches # 这里保障了一轮epoch中每次生成的batch是随机的，避免模型学习到数据的顺序特征 train_sampler = SubsetRandomSampler(train_idx) valid_sampler = SubsetRandomSampler(valid_idx) # prepare data loaders train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=train_sampler) valid_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=valid_sampler) return train_loader, valid_loader 正式加载数据： from torchvision import transforms # how many samples per batch to load batch_size = 128 # percentage of training set to use as validation valid_size = 0.2 # Define a transform to normalize the data tsfm = transforms.Compose([Normalize(), ToTensor()]) # Load the training data and test data trainset = FaceKeypointsDataset(train_data, transform=tsfm) testset = FaceKeypointsDataset(test_data, train=False, transform=tsfm) # prepare data loaders train_loader, valid_loader = prepare_train_valid_loaders(trainset, valid_size, batch_size) test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size) 三、模型搭建 #Model class CNN(nn.Module): def __init__(self,outputs = 30): super(CNN,self).__init__() self.conv1 = nn.Conv2d(1, 16, 3, padding=1) self.conv2 = nn.Conv2d(16, 32, 3, padding=1) self.conv3 = nn.Conv2d(32, 64, 3, padding=1) self.pool = nn.MaxPool2d(2, 2) self.fc1 = nn.Linear(64*12*12, 1024) self.fc2 = nn.Linear(1024, outputs) self.dropout = nn.Dropout(0.3) def forward(self,x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = self.pool(F.relu(self.conv3(x))) x = x.view(-1, 64*12*12) x = F.relu(self.fc1(self.dropout(x))) x = self.fc2(self.dropout(x)) return x 四、训练与测试 #Train &amp; Validate device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') model = CNN(outputs = 30) model = model.to(device) criterion = nn.MSELoss() optimizer = optim.Adam(model.parameters(), lr=0.003) def train(train_loader,valid_loader,model,criterion,optimizer,n_epochs = 50,saved_model = 'cv_model.pt'): valid_loss_min = np.Inf train_losses = [] valid_losses = [] for epoch in range(n_epochs): train_loss = 0.0 valid_loss = 0.0 #training model.train() for batch in train_loader: optimizer.zero_grad() output = model(batch['image'].to(device)) loss = criterion(output,batch['keypoints'].to(device)) loss.backward() optimizer.step() train_loss += loss.item()*batch['image'].size(0) #validating model.eval() for batch in valid_loader: output = model(batch['image'].to(device)) loss = criterion(output, batch['keypoints'].to(device)) valid_loss += loss.item()*batch['image'].size(0) train_loss = np.sqrt(train_loss/len(train_loader.sampler.indices)) valid_loss = np.sqrt(valid_loss/len(valid_loader.sampler.indices)) train_losses.append(train_loss) valid_losses.append(valid_loss) print('Epoch: &#123;&#125; \\tTraining Loss: &#123;:.6f&#125; \\tValidation Loss: &#123;:.6f&#125;' .format(epoch+1, train_loss, valid_loss)) # save model if validation loss has decreased if valid_loss &lt;= valid_loss_min: print('Validation loss decreased (&#123;:.6f&#125; --> &#123;:.6f&#125;). Saving model ...' .format(valid_loss_min, valid_loss)) torch.save(model.state_dict(), saved_model) valid_loss_min = valid_loss return train_losses, valid_losses 定义测试函数： def predict(data_loader, model): ''' Predict keypoints Args: data_loader (DataLoader): DataLoader for Dataset model (nn.Module): trained model for prediction. Return: predictions (array-like): keypoints in float (no. of images x keypoints). ''' model.eval() # prep model for evaluation with torch.no_grad(): for i, batch in enumerate(data_loader): # forward pass: compute predicted outputs by passing inputs to the model output = model(batch['image'].to(device)).cpu().numpy() if i == 0: predictions = output else: predictions = np.vstack((predictions, output)) return predictions 定义测试结果展示函数： def view_pred_df(columns, test_df, predictions, image_ids=range(1,6)): ''' Display predicted keypoints Args: columns (array-like): column names test_df (DataFrame): dataframe with ImageId and Image columns predictions (array-like): keypoints in float (no. of images x keypoints) image_id (array-like): list or range of ImageIds begin at 1 ''' pred_df = pd.DataFrame(predictions, columns=columns) pred_df = pd.concat([pred_df, test_df], axis=1) pred_df = pred_df.set_index('ImageId') show_images(pred_df, image_ids) # ImageId as index begin at 1 定义测试结果上交文件生成函数： def create_submission(predictions, pred_file='data/preds.csv', sub_file='data/submission.csv', columns=None): ''' Create csv file for submission from predictions Args: predictions (array-like): prediction (no. fo images x 30 keypoints) pred_file (string): file path for prediction csv file sub_file (string): file path for submission csv file columns (dict): provided column names for submission file ''' lookup = pd.read_csv('data/IdLookupTable.csv') if columns == None: columns = train_data.columns[:-1] preds = pd.DataFrame(predictions, index=np.arange(1, len(predictions)+1), columns=columns) preds.to_csv(pred_file) locations = [preds.loc[image_id, feature_name] for image_id, feature_name in lookup[['ImageId', 'FeatureName']].values] locations = [location if location &lt; IMG_SIZE else IMG_SIZE for location in locations] lookup.Location = pd.Series(locations) lookup[['RowId', 'Location']].to_csv(sub_file, index=False) 训练 and 预测： #Train &amp; Validate train(train_loader, valid_loader, model, criterion, optimizer, n_epochs=50, saved_model='aug_cnn.pt') #Predict model.load_state_dict(torch.load('aug_cnn.pt')) predictions = predict(test_loader,model) create_submission(predictions, pred_file='data/aug_cnn_preds.csv', sub_file='data/aug_cnn_submission.csv') columns = train_data.drop('Image', axis=1).columns view_pred_df(columns, test_data, predictions,range(1,11)) 预测结果： 将submission文件上交到Kaggle评分:","categories":[{"name":"Kaggle","slug":"Kaggle","permalink":"http://example.com/categories/Kaggle/"}],"tags":[{"name":"CV","slug":"CV","permalink":"http://example.com/tags/CV/"},{"name":"Pytorch","slug":"Pytorch","permalink":"http://example.com/tags/Pytorch/"}],"author":"Shaw"},{"title":"IFAttn-Binary code similarity analysis based on interpretable features with attention","slug":"【论文阅读】IFAttn Binary code similarity analysis based on interpretable features with attention","date":"2022-10-02T06:29:22.023Z","updated":"2022-10-03T12:58:53.044Z","comments":true,"path":"2022/10/02/【论文阅读】IFAttn Binary code similarity analysis based on interpretable features with attention/","link":"","permalink":"http://example.com/2022/10/02/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91IFAttn%20Binary%20code%20similarity%20analysis%20based%20on%20interpretable%20features%20with%20attention/","excerpt":"【论文阅读】IFAttn-Binary code similarity analysis based on interpretable features with attention 时间：2021 作者：Shuai Jianga , Cai Fua , Yekui Qian（华科） 期刊：Computers &amp; Security（中科院三区） 1.ABSTRACT 二进制代码相似性分析（Binary code similarity analysis ，BCSA）是一项有意义的软件安全分析技术，包括漏洞挖掘、代码克隆检测和恶意代码检测。 尽管近年来出现了很多基于神经网络的很多BCSA研究成果，仍有一些问题未被解决。首先，大多数方法更聚焦于function pair similarity detection task (FPSDT)，而忽略了function search task (FST)，后者对漏洞挖掘更为重要。还有，现有方法为了提高FPSDT的准确率使用了一些无法解释的神经网络；最后，大多数现有方法无法抵抗BCSA中的交叉优化和交叉混淆。 为了解决这些问题，我们首次提出了一个结合了可解释特征工程和可学习注意力机制的适应性BCSA架构。我们设计了一个具有适应性的、富有可解释性特征的模型。测试结果表明对于FPSDT和FST的效果比state-of-the-art效果更好。 另外，我们还发现注意机制在功能语义表达方面具有突出的优势。 评估表明我们的方法可以显著提升FST在cross-architecture, cross-optimization, cross-obfuscation and cross-compiler binaries上的表现。","text":"【论文阅读】IFAttn-Binary code similarity analysis based on interpretable features with attention 时间：2021 作者：Shuai Jianga , Cai Fua , Yekui Qian（华科） 期刊：Computers &amp; Security（中科院三区） 1.ABSTRACT 二进制代码相似性分析（Binary code similarity analysis ，BCSA）是一项有意义的软件安全分析技术，包括漏洞挖掘、代码克隆检测和恶意代码检测。 尽管近年来出现了很多基于神经网络的很多BCSA研究成果，仍有一些问题未被解决。首先，大多数方法更聚焦于function pair similarity detection task (FPSDT)，而忽略了function search task (FST)，后者对漏洞挖掘更为重要。还有，现有方法为了提高FPSDT的准确率使用了一些无法解释的神经网络；最后，大多数现有方法无法抵抗BCSA中的交叉优化和交叉混淆。 为了解决这些问题，我们首次提出了一个结合了可解释特征工程和可学习注意力机制的适应性BCSA架构。我们设计了一个具有适应性的、富有可解释性特征的模型。测试结果表明对于FPSDT和FST的效果比state-of-the-art效果更好。 另外，我们还发现注意机制在功能语义表达方面具有突出的优势。 评估表明我们的方法可以显著提升FST在cross-architecture, cross-optimization, cross-obfuscation and cross-compiler binaries上的表现。 为了提高开发效率，开发者通常会使用开源代码来开发新软件。如果一个开发者使用了一个存在漏洞的函数，则这个漏洞就会被继承且很难被发现。代码克隆这种现象对软件的安全可靠性造成了很大影响。 不幸的是，直接对二进制代码使用同源性分析并不够直接明了，二进制代码缺乏语义抽象，很难从函数中提取语义信息来做同源性分析。另外，分割函数的边界也是个问题。 所以在代码克隆、恶意样本追踪、库函数发掘和漏洞发掘领域对二进制代码做同源性分析一直是个重要的方向。 根据已有方法的颗粒度分类，现存成果可以分为： 基于基本静态特征的方法； 基于代码图结构（例如CFG）的方法； 基于代码张量的方法； 基于深度学习生成函数嵌入的方法； 现有方法存在的问题： 大多数方法更聚焦于function pair similarity detection task (FPSDT)，而忽略了function search task (FST)，后者对漏洞挖掘更为重要； FPSDT指对比两个函数的相似度，FST指在函数库中寻找与某个函数最相似的函数。 现有方法为了提高FPSDT的准确率使用了一些无法解释的神经网络，设计一个复杂的分析过程； 因为编译器的优化和混淆会显著修改代码结构，大多数方法在这些条件下表现不佳。 我们的方法解决的： 如何利用可解释的基本特征来生成二进制代码的语义特征； 用注意力机制来聚焦于在不同编译环境下仍起作用的特征，学习基本特征之间的联系。 如何设计一个适应不同编译选项的通用BCSA模型框架。 我们重新设计了Transformer的编码部分，使用孪生神经网络来判断两个函数的相似度，在attention layer使用KFM来处理不动的编译选项。 注意力机制的优点： 下图是同一个函数在同一个编译选项（X86_32_00）下通过混淆技术BCF前后的CFG图： 下图是TIKNIB和IFAttn两个模型在对同一个函数混淆前后抓取的特征向量值： 可以看到，在混淆前后basic features有明显不同，而semantic features则总体上更为稳定。 ​ 下图表明了TIKNIB和IFAttn在对不同函数，一个混淆一个不混淆的前提下提取到的特征向量值： ​ 可以看到，与之前相反，在混淆前后basic features较为稳定，而semantic features变化更大。 ​ semantic features更能体现函数本身语义，而不受混淆技术的影响。 一些定义： Presemantic features：直接或间接从代码语法和结构分析出的特征； Semantic features：本文通过注意机制分析了base feature形成的内在关联，并将base feature融合生成语义嵌入 KFM scaled dot-product attention: Multi-head attention:Transformer的一种注意力机制。 系统结构：IFAttn (Interpretable Features with Attention) 测试结果： 数据集： 测试结果：","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Malware Classifiers","slug":"Malware-Classifiers","permalink":"http://example.com/tags/Malware-Classifiers/"},{"name":"BCSA","slug":"BCSA","permalink":"http://example.com/tags/BCSA/"}],"author":"Shaw"},{"title":"Function-level obfuscation detection method based on Graph Convolutional Networks","slug":"【论文阅读】Function-level obfuscation detection method based on Graph Convolutional Networks","date":"2022-10-01T12:37:04.833Z","updated":"2022-10-02T06:26:35.439Z","comments":true,"path":"2022/10/01/【论文阅读】Function-level obfuscation detection method based on Graph Convolutional Networks/","link":"","permalink":"http://example.com/2022/10/01/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Function-level%20obfuscation%20detection%20method%20based%20on%20Graph%20Convolutional%20Networks/","excerpt":"【论文阅读】Function-level obfuscation detection method based on Graph Convolutional Networks 时间：2021 作者：Shuai Jiang , Yao Hong, Cai Fu（华科） 期刊：Journal of Information Security and Applications（中科院三区） 1.ABSTRACT ​ 在恶意样本检测中代码混淆检测技术是一个重要的辅助手段，对于安全从业者来说，其可以在人工逆向分析前来实施自动化混淆检测，这有助于逆向工程师更具体地进行逆向分析。 ​ 目前存在的混淆检测方法主要作用于Android应用，并基于传统的机器学习方法。其检测颗粒度很差，总体效果不佳。为了解决这些问题，在本篇文章，我们提出了一个应用于X86汇编和Android应用的、function level的、基于GCN的混淆检测方法。 1. 首先，我们的方法是function-level的。我们提取每个函数的CFG作为其特征（包括邻接矩阵和基本代码块的特征矩阵）； 2. 我们构建一个GCN-LSTM神经网络作为混淆检测模型； 3. 最后，对于function-level的检测我们的方法准确率是94.7575%（X86汇编）和98.9457%（安卓应用），比baseline方法好。实验证明我们的方法不论是在function-levle还是APK-level上的检测准确率都好于baseline。","text":"【论文阅读】Function-level obfuscation detection method based on Graph Convolutional Networks 时间：2021 作者：Shuai Jiang , Yao Hong, Cai Fu（华科） 期刊：Journal of Information Security and Applications（中科院三区） 1.ABSTRACT ​ 在恶意样本检测中代码混淆检测技术是一个重要的辅助手段，对于安全从业者来说，其可以在人工逆向分析前来实施自动化混淆检测，这有助于逆向工程师更具体地进行逆向分析。 ​ 目前存在的混淆检测方法主要作用于Android应用，并基于传统的机器学习方法。其检测颗粒度很差，总体效果不佳。为了解决这些问题，在本篇文章，我们提出了一个应用于X86汇编和Android应用的、function level的、基于GCN的混淆检测方法。 1. 首先，我们的方法是function-level的。我们提取每个函数的CFG作为其特征（包括邻接矩阵和基本代码块的特征矩阵）； 2. 我们构建一个GCN-LSTM神经网络作为混淆检测模型； 3. 最后，对于function-level的检测我们的方法准确率是94.7575%（X86汇编）和98.9457%（安卓应用），比baseline方法好。实验证明我们的方法不论是在function-levle还是APK-level上的检测准确率都好于baseline。 2. INTRODUCTION 2.1 Obfuscation–代码混淆 ​ 代码保护技术，用于增加逆向难度，防止代码篡改，最开始用于版权保护，后被用于恶意代码的躲避检测。 ​ 由于动态检测恶意代码的高昂成本，主流的恶意样本检测技术仍在提取代码的静态特征。然而由于混淆技术的发展，恶意样本的编写者经常在保留其恶意功能的同时通过使用混淆技术来修改其静态特征。经过混淆的恶意代码可以规避相关工具的检测。 ​ 最近混淆检测技术开始出现，在此领域有一些工作： 1. [2018]Alessandro等人：使用静态分析和机器学习分类算法来分析Android应用是否被混淆的技术（ http://dx.doi.org/10.1145/3230833.3232823）； 2. [2020]Crincoli等人：利用weak bisimulation来检测代码是否被code reordering(http://dx.doi.org/10.1007/978-3-030-44041-1_116)； 3. [2020]Caijun Sun等人：一个Android打包检测框架DroidPDF( http://dx.doi.org/10.1109/ACCESS.2020.3010588); 4. [2019]Omid等人：AndrODet，一个检测三种Android混淆技术的检测机制（重命名、字符串加密和控制流混淆）（ http://dx.doi.org/10.1016/j.future.2018.07.066）； 5. [2019]Alireza等人：Android字符串混淆检测技术（ http://dx.doi.org/10.1145/3338501.3357373）; 2.2 目前方法的缺点： 1. 检测颗粒度不够，检测对象往往是一个APK包，缺乏可行性； 2. 检测效果不佳，从样本中提取的特征相对简单，只有统计学特征和opcode语句被提取。大多数使用简单的机器学习方法，表现一般； 3. 缺乏可用性和适应性，传统方法往往会为不同的混淆方法提取不同的特征，或者为每个混淆方法训练一个二分类器，枯燥且不便。同时若需要添加新数据，模型经常需要重头训练。 2.3 我们的方法： 从开源平台获取一些未经混淆的代码（X86汇编和Android），通过混淆器生成混淆后程序； 逆向这些程序，用邻接矩阵和基本代码块特征矩阵的形式提取每个函数的CFG； 根据我们提取到的特征，构建GCN-LSTM。这个模型同时服务于X86汇编和Android，但他们分别训练和测试； 3. METHOD OVERVIEW 1. X86的混淆器：OLLVM；Android的混淆器：Obfuscapk； 2. 逆向工具：IDA PRO；由于X86与Android指令集与混淆技术不同，二者被分别提取CFG； 3. 多分类问题，检测出混淆技术种类，故使用传统多分类评估方法来评估检测效果。 4. OBFUSCATION DECTION METHOD 4.1 OLLVM ​ OLLVM包括以下三种混淆技术： Instructions Substitution (SUB)，指令替换。将简单指令替换为同语义的复杂指令，特别是二进制加减乘除。这项技术会增加算术指令但很少影响CFG； Bogus Control Flow (BCF)，虚假控制流。在CFG中添加大量无关的随机代码块和分支，并分割、融合、重排原始代码块，在其中插入随机选择的无用指令。这项技术破坏了CFG和代码块的完整性，增加控制流复杂性； Control Flow Flattening（FLA），控制流平坦化。简单来讲就是将代码块之间的关系打断，由一个分发器来控制代码块的跳转： 4.2 Obfuscapk ​ Obfuscapk包括以下三种混淆技术： Identifier Renaming，标识符重命名； String Encryption，字符串加密。字符串常量可以揭示很多代码敏感信息； Control Flow Obfuscation，控制流混淆。通过扩展或平坦化CFG来混淆，同样还有注入垃圾代码，扩展循环，添加无关操作等； 4.3 Feature extraction ​ 提取的特征包括代码的结构化CFG信息和基本代码块特征： 对于邻接矩阵： 如图，邻接矩阵代码了不同代码块之间的转移关系。 ​ 对于基本代码块特征： 将X86汇编代码分为27类，对于一个代码块的特征向量就是27维。 将Dalvik指令分为15类，对于一个代码块的特征向量就是15维。 4.4 Obfuscation detection model ​ 在得到CFG邻接矩阵和基本代码块特征矩阵后，构建GCN-LSTM。 5.EXPERIMENTAL EVALUATION 5.1 Datasets 5.2 Baseline methods ​ function-level的baseline方法如下： ​ AdaBoost, GaussianNaiveBayes, GradientBoosting, KNeighbors, MLP, SGDClass, SVM, Xgboost and LSTM 5.3 Evaluation metrics ​","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Malware Classifiers","slug":"Malware-Classifiers","permalink":"http://example.com/tags/Malware-Classifiers/"},{"name":"obfuscation","slug":"obfuscation","permalink":"http://example.com/tags/obfuscation/"}],"author":"Shaw"},{"title":"Planning at Decision Time(决策时规划)","slug":"决策时规划","date":"2022-07-21T07:46:53.321Z","updated":"2022-07-24T06:54:15.431Z","comments":true,"path":"2022/07/21/决策时规划/","link":"","permalink":"http://example.com/2022/07/21/%E5%86%B3%E7%AD%96%E6%97%B6%E8%A7%84%E5%88%92/","excerpt":"参考资料： Reinforcement Learining. Second Edition. Sutton.Page 180-193 白板推导--强化学习.shuhuai008.Bilibili Easy RL.Qi Wang.Yang Yiyuan.Ji Jiang Planning at Decision Time（决策时规划） 规划（Planning）至少有两种使用方式。 ①一种在DP和Dyna中已经讨论过，通过从一个model（不论是sample model或是distribution model ）中获取模拟经验（simulated experience）的基础上来使用规划来逐渐提升一个policy或一个value function。 然后，选择动作是一个比较当前状态的动作value问题，该value是在之前优化的表格中获取的；或者通过使用书中Part 2中考虑的近似方法来评估数学表达式。 对于任意状态St，在为其选择一个动作之前，其整个表格条目（例如Dyna-Q中的Q表）已经通过规划来优化过了。使用这种方式，规划并不是仅仅聚焦于当前的状态，我们称这种规划为background planning，后台规划。 ②另一种使用规划的方法就是在遇到每个新的状态St后再开始一个完整的规划过程，其为每个当前状态选择一个动作At，到下一个状态St+1就选择一个动作At+1，以此类推。 一个使用这种规划最简单的例子：当state values可用时，通过比较当前model对执行每个动作后到达的新状态的value来选择一个动作。 当然，更普遍的说，这种规划的用法可以比仅仅往后看一步（上面的例子就是）看得更深，评估动作的选择导致许多不同预测状态和奖励轨迹。 不同于第一种用法，在这里，规划聚焦于一个特定的状态，我们称之为decision-time planning，决策时规划。 这两种规划的方式可以用一种自然而有趣的方式结合在一起，不过一般二者被分开研究。 如同background planning，我们仍可以将决策时规划看作一个从模拟经验中更新values，最后到更新policy的过程。只是基于当前状态所生成的values和policy会在做完动作选择决策后被丢弃，在很多应用场景中这么做并不算一个很大的损失，因为有非常多的状态存在，且不太可能在短时间内回到同一个状态，故重复计算导致的资源浪费会很少。 一般来说，人们可能希望将两者结合起来：规划当前状态，并将规划的结果存储起来，以便在以后回到相同的状态时能走得更远。 Decision-time Planning，(决策时规划）在不需要快速反应的应用场景中作用最为显著。 决策时规划的常用算法有Heuristic Search（启发式搜索）、Rollout Algorithms（Rollout 算法）和Monte Carlo Tree Search（MCTS 蒙特卡洛树搜索）三种。","text":"参考资料： Reinforcement Learining. Second Edition. Sutton.Page 180-193 白板推导--强化学习.shuhuai008.Bilibili Easy RL.Qi Wang.Yang Yiyuan.Ji Jiang Planning at Decision Time（决策时规划） 规划（Planning）至少有两种使用方式。 ①一种在DP和Dyna中已经讨论过，通过从一个model（不论是sample model或是distribution model ）中获取模拟经验（simulated experience）的基础上来使用规划来逐渐提升一个policy或一个value function。 然后，选择动作是一个比较当前状态的动作value问题，该value是在之前优化的表格中获取的；或者通过使用书中Part 2中考虑的近似方法来评估数学表达式。 对于任意状态St，在为其选择一个动作之前，其整个表格条目（例如Dyna-Q中的Q表）已经通过规划来优化过了。使用这种方式，规划并不是仅仅聚焦于当前的状态，我们称这种规划为background planning，后台规划。 ②另一种使用规划的方法就是在遇到每个新的状态St后再开始一个完整的规划过程，其为每个当前状态选择一个动作At，到下一个状态St+1就选择一个动作At+1，以此类推。 一个使用这种规划最简单的例子：当state values可用时，通过比较当前model对执行每个动作后到达的新状态的value来选择一个动作。 当然，更普遍的说，这种规划的用法可以比仅仅往后看一步（上面的例子就是）看得更深，评估动作的选择导致许多不同预测状态和奖励轨迹。 不同于第一种用法，在这里，规划聚焦于一个特定的状态，我们称之为decision-time planning，决策时规划。 这两种规划的方式可以用一种自然而有趣的方式结合在一起，不过一般二者被分开研究。 如同background planning，我们仍可以将决策时规划看作一个从模拟经验中更新values，最后到更新policy的过程。只是基于当前状态所生成的values和policy会在做完动作选择决策后被丢弃，在很多应用场景中这么做并不算一个很大的损失，因为有非常多的状态存在，且不太可能在短时间内回到同一个状态，故重复计算导致的资源浪费会很少。 一般来说，人们可能希望将两者结合起来：规划当前状态，并将规划的结果存储起来，以便在以后回到相同的状态时能走得更远。 Decision-time Planning，(决策时规划）在不需要快速反应的应用场景中作用最为显著。 决策时规划的常用算法有Heuristic Search（启发式搜索）、Rollout Algorithms（Rollout 算法）和Monte Carlo Tree Search（MCTS 蒙特卡洛树搜索）三种。 Heuristic Search（启发式搜索） 在AI中一个经典的状态空间规划方法是decision-time planning方法，统称为Heuristic Search（启发式搜索）。 在启发式搜索中，对每个遇到的状态都会生成一颗延续的搜索树，近似的value function会被在叶节点应用，然后反向传播到根节点。反向传播在当前状态停止。一旦这些节点的值被计算出来，就会选择其中最好的一个作为当前的行动，然后所有的值就会被丢弃。 在传统的启发式搜索中，计算出的backed-up values并不会被通过修改近似value function来保存。实际上，价值函数一般都是由人设计的，绝不会因为搜索而改变。然而，一个自然而然的想法就是考虑改进value function，使用启发式搜索计算出的backed-up value或者其他方法。从某种意义上说，我们一直都采取这种方法。 Greedy，ε-greedy和UCB动作选择方法与启发式搜索没什么不同，尽管是在一个更小的范围内。举个例子，为了计算greedy策略的state-value function，我们必须向前概览每个可能的动作，到达每个可能的下一个状态，考虑他们的reward和评估值，然后选择一个最好的动作。这就如同传统的启发式搜索，计算所有可能动作的backed-up values，但是不去保存他们。因此，启发式搜索可以被看作greedy策略在单步范围外的一种扩展。 搜索的更深是为了获得更好的动作选择策略。假设我们有一个完美的model和一个不完美的action-value function，如果一路搜索到底，那么不完美的value function的影响就会被消除。通过这种方式的搜索必须是optimal的。若搜索步骤k足够多，导致 γk 足够小，那么动作就会近似达到optimal。从另一个角度讲，搜索的越深所需的算力资源也越多，响应就越慢。 一个优秀的例子是是Tesauro提出的大师级双陆棋算法，TD-Gammon。该算法使用TD learning，通过与自己对弈来学习value function，其使用启发式搜索来选择动作。Tesauro发现启发式搜索的越深，TD-Gammon就会选择越好的动作，但是每走一步花的时间也越多。 在更深入的搜索中观察到的性能改善并不是由于使用多步骤更新本身。相反，它是由于更新的重点集中在当前状态的下游的状态和行动上。通过投入大量与候选行动具体相关的计算，决策时规划可以产生比依靠无重点的更新所产生的更好的决策。 启发式搜索示意图 如上图所示，白圆点表示状态，黑圆点表示动作。以当前状态为根节点，遍历每一层所有的可能性，然后计算每个非叶节点的Q（s,a）。具体计算方法如下，将树按深度优先遍历，每个非叶节点使用公式： \\[ Q(s,a) = \\sum_{s&#39;,r}{p(s&#39;,r|s,a)(r + γmax_{a&#39;}Q(s&#39;,a&#39;))} \\] 故按照图中的数字顺序（1-&gt;2-&gt;3-&gt;4-&gt;5……）依次计算**q~*~的期望更新**，得到当前状态（根节点）每个可能动作a'的对应的Q（s，a'），选择一个最好的即可。当然，在使用算法的过程中搜索层数K是可以控制的，故叶节点并不一定是终结状态ST。 Rollout Algorithms（Rollout 算法） Rollout算法是基于蒙特卡洛控制的决策时规划算法，其应用于从当前状态开始的一些模拟轨迹。对给定的policy进行动作评估的方式是将许多从各个可能的动作开始的模拟轨迹的返回值平均化。当action-value评估被认为足够准确了，被给分最高的动作就会被执行，之后，该过程（Rollout）将从产生的下一个状态重新进行。 不同于蒙特卡洛控制算法，Rollout算法的目标不是评估一个最优的q*或qπ，而是根据一个给定的一般叫rollout policy的策略，来为每个当前状态生成蒙特卡洛评估。作为一个决策时规划算法，Rollout算法在当即使用这些action-value评估值之后就丢弃他们。这使得Rollout算法的实现相对较为简单，因为不都需要对每个&lt;s , a&gt;键值对都采样，并且不需要对状态空间或状态-动作空间拟合一个近似函数。 Rollout算法什么时候停止？策略改进定理告诉我们给定两个几乎相同的策略π和π'，他们不同是对同一个状态S有: \\[ π&#39;(s) = a ≠ π(s) \\] 如果： \\[ q_{π}(s,a)\\geq v_{π}(s) \\] 那么策略π'就优于或等于策略π。 在Rollout算法中，对状态s的每个可能的动作a'都计算其若干条模拟轨迹的平均返回值，得到\\(q_π(s,a&#39;)\\)。接着选取评估值最大的那个action，随后的状态都继续遵循策略π，这就是一个很好的在π上的策略改进。 换句话说，Rollout算法的目标就是在rollout policy上不断做改进，而不是去寻找一个最优策略。经验表明Rollout算法的效果非常惊艳。例如Tesauro和Galperin（1997）就表明rollout算法对于双陆西洋棋的提升效果非常显著。在一些应用中，即使rollout policy是完全随机的Rollout算法也可以有好的表现。但是policy的改进依靠rollout policy的性能和MC值评估得出的action排名。直觉表明，rollout policy越好、评估值越准确，Rollout算法给出的策略就越好。 这其中包含了重要的权衡，因为一般来说越好的rollout policy意味着需要越多的时间来模拟足够的轨迹，以得到好的value评估效果。作为一个决策时评估方法，Rollout算法一般都会有严格的时间限制，其计算所需时间由待评估动作的数量、模拟轨迹中的步长、rollout policy做决策的时间和模拟轨迹的数量共同决定。 虽然存在一些方法可以减轻这一难题，但在任何Rollout算法的应用中平衡这些因素都是很重要的。因为MC评估是相互独立的，故并行做这些评估是可能的。另外一种方法是可以缩减模拟轨迹的长度。 **简单来说，不同于启发式搜索往下遍历所有的可行性然后进行q*期望更新，Rollout对每个可能的action进行若干条MC采样，以这些采样的平均值来评估这个aciton的好坏。** Rollout 的意思是从当前帧去生成很多局的游戏。 Monte Carlo Tree Search（MCTS 蒙特卡洛树搜索） Monte Carlo Tree Search (MCTS)，蒙特卡洛树搜索，是一个近年来非常成功的决策时规划算法。MCTS是一个rollout改进算法，其在Rollout的基础上增加了累计从MC模拟轨迹中获得value的方法，以便于模拟到有更高reward的轨迹。 MCTS是近年来AI围棋从一个入门者（2005）发展到一个宗师级棋手（2015）的重要原因，2016年AlphaGo程序战胜了世界围棋冠军选手。MCTS被证明在许多竞争领域有显著效果，包括一般的游戏，但不局限于此。若环境model足够简单，可以进快速多步模拟，它对单智能体序列决策问题就非常有效。 MCTS的核心思想是从以往的模拟中，扩展初始部分已经获得高回报的轨迹，让算力聚焦于更可能获得高回报的模拟路线。 在任何MC评估方法中，&lt;s,a&gt;键值对的评估值就是多对模拟轨迹的平均返回值，在这里，只保留最有可能在几步内达到的&lt;s,a&gt;对的MC估计值（算出来的q（s,a））。我们称这些节点加上根节点组成一个tree，使用一个tree policy遍历这个tree来选择一个用来扩展的叶子结点，构建一个tree帮助我们能选择一个更好的节点用来rollout而不是对每个节点都进行模拟。 总的来说，MCTS总共分为四步：Selection，Expansion，Simulation和Backup。 Selection就是用tree policy（例如ε-greedy）来选择一个叶节点，用于后续扩展； Expansion就是使用选择好的节点，用一些未使用过的actions来扩展一个或几个孩子节点； Simulation就是从选择的节点/扩展的节点上用rollout policy进行模拟，同rollout算法； Backup就是通过模拟得出的值来反向更新对应的action. 在一个时间步骤内，MCTS反复做这四步，直到时间不够了或者其他计算资源不够了。然后，通过某种方法来为当前状态选择一个动作。例如，选择value最大的动作，或是，选择visit次数最多的动作来避免选到异常值。当到达下一个状态后，新一轮的MCTS又开始了。有时新一轮的MCTS从一个孤立的节点开始，但大多数情况下会从上一次MCTS中还留存的、有些后代的tree开始。 MCTS最初被提出用于为一些双人竞技游戏选择动作，例如围棋。每个模拟过程都是一个完整的游戏过程，双方选手通过tree和rollout policy来选择动作。 相关概念解释： 1. Distribution model and Sample model 参考《Reinforcement Learning》Page159，Chapter 8，原文解释的很清楚： “By a model of the environment we mean anything that an agent can use to predict how the environment will respond to its actions. Given a state and an action, a model produces a prediction of the resultant next state and next reward. ” “我们所指的环境的model是一个agent可以用其预测环境会如何对其action作出反应的东西。给出一个state和一个action，model给出下一个state和返回的reward。” “If the model is stochastic, then there are several possible next states and next rewards, each with some probability of occurring. ” “如果model是随机的，那么下一个state与reward就有许多可能的情况，每个情况都有一定概率发生。” “Some models produce a description of all possibilities and their probabilities; these we call distribution models. Other models produce just one of the possibilities, sampled according to the probabilities; these we call sample models.” “一些models提供了一个对所有事件发生的可能性以及其概率的描述，这些models我们称其为distribution models（分布模型）；另外一些models仅提供这些可能发生的事件的其中一种，这些models我们称其为sample models（样本模型）” “ For example, consider modeling the sum of a dozen dice. A distribution model would produce all possible sums and their probabilities of occurring, whereas a sample model would produce an individual sum drawn according to this probability distribution.” “例如，考虑对一打骰子（dozen dice）的和进行建模，一个 distribution model 会产生所有可能的和，以及它们发生的概率，而一个 sample model 会根据这个概率分布产生一个单独的和。” 例如，MDP中的\\(p(s^{&#39;},r|s,a)\\)就是一个典型的分布模型。在很多应用中，获取 sample models 比获取 distribution models 容易得多。dozen dice 就是这样一个例子。很容易写一个电脑程序仿真掷骰、返回和的过程，但是计算所有可能的和以及对应的概率很难，且容易出错。","categories":[{"name":"Something","slug":"Something","permalink":"http://example.com/categories/Something/"}],"tags":[{"name":"RL","slug":"RL","permalink":"http://example.com/tags/RL/"}],"author":"Shaw"},{"title":"A Survey of Defense Mechanisms Against Distributed Denial of Service (DDoS) Flooding Attacks","slug":"A Survey of Defense Mechanisms Against Distributed Denial of Service (DDoS) Flooding Attacks","date":"2022-03-04T08:24:55.254Z","updated":"2022-07-15T08:09:16.356Z","comments":true,"path":"2022/03/04/A Survey of Defense Mechanisms Against Distributed Denial of Service (DDoS) Flooding Attacks/","link":"","permalink":"http://example.com/2022/03/04/A%20Survey%20of%20Defense%20Mechanisms%20Against%20Distributed%20Denial%20of%20Service%20(DDoS)%20Flooding%20Attacks/","excerpt":"A Survey of Defense Mechanisms Against Distributed Denial of Service (DDoS) Flooding Attacks 时间：2013 作者：Saman Taghavi Zargar，James Joshi， David Tipper 期刊：IEEE COMMUNICATIONS SURVEYS &amp; TUTORIALS（中科院一区） ABSTRACT ​ DDoS攻击是安全专业人员最关心的问题之一，其通常是为了扰乱合法用户对服务的访问而进行的显式尝试。攻击者通常通过攻击漏洞来获取到一大批电脑，以此来组建一个网络攻击军队（也就是僵尸网络），一旦组建了攻击部队，攻击者就可以对一个或多个目标发起协调一致、大规模的攻击。开发针对已识别和预期的DDoS泛洪攻击的综合防御机制，是入侵检测和预防研究界所期望的目标。然而，这种机制的发展需要对问题和迄今为止在预防、检测和应对各种DDoS洪泛攻击方面所采用的技术有一个全面的了解。 ​ 在本文，我们对DDoS洪泛攻击进行分类，并根据它们在何时何地预防、检测和应对DDoS洪泛攻击对现有的对策进行分类。 ​ 此外，我们强调需要一种全面的分布式协同防御方法。我们的主要目的是激发研究人员开发出创造性的、有效的、高效的、综合的预防、检测和响应机制来解决实际攻击前、中和后的DDoS泛洪问题。","text":"A Survey of Defense Mechanisms Against Distributed Denial of Service (DDoS) Flooding Attacks 时间：2013 作者：Saman Taghavi Zargar，James Joshi， David Tipper 期刊：IEEE COMMUNICATIONS SURVEYS &amp; TUTORIALS（中科院一区） ABSTRACT ​ DDoS攻击是安全专业人员最关心的问题之一，其通常是为了扰乱合法用户对服务的访问而进行的显式尝试。攻击者通常通过攻击漏洞来获取到一大批电脑，以此来组建一个网络攻击军队（也就是僵尸网络），一旦组建了攻击部队，攻击者就可以对一个或多个目标发起协调一致、大规模的攻击。开发针对已识别和预期的DDoS泛洪攻击的综合防御机制，是入侵检测和预防研究界所期望的目标。然而，这种机制的发展需要对问题和迄今为止在预防、检测和应对各种DDoS洪泛攻击方面所采用的技术有一个全面的了解。 ​ 在本文，我们对DDoS洪泛攻击进行分类，并根据它们在何时何地预防、检测和应对DDoS洪泛攻击对现有的对策进行分类。 ​ 此外，我们强调需要一种全面的分布式协同防御方法。我们的主要目的是激发研究人员开发出创造性的、有效的、高效的、综合的预防、检测和响应机制来解决实际攻击前、中和后的DDoS泛洪问题。 INTRODUCTION ​ DDoS攻击，旨在尝试组织合法使用者访问一个特定的网站，早在20世纪80年代就被网络研究团体知晓。1999年夏天，Computer Incident Advisory Capability (CIAC)报告了第一起DDoS攻击事件。 ​ 目前，有两种主要的在互联网上制造DDoS攻击的方法：①第一种方法是攻击者向受害者发送一些格式错误的数据包，以混淆在其上运行的协议或应用程序( vulnerability attack);②另一种方法是最常见的方法，它涉及攻击者试图执行下列一项或两项： 1. 通过消耗带宽、路由器处理能力或网络资源，破坏合法用户的连通性；这些本质上是网络/传输级的泛洪 攻击； 2. 通过耗尽服务器资源(如套接字、CPU、内存、磁盘/数据库带宽和I/O带宽 )来破坏合法用户的服务；这些攻击本质上包括应用级的泛洪攻击； ​ 如今，DDoS攻击往往是由远程控制、组织良好、分布广泛的Zombies1或Botnet计算机组成的网络发起的，这些计算机同时和不断地向目标系统发送大量的流量和/或服务请求，目标系统因此变得要么反应如此缓慢，以至于无法使用，要么完全崩溃。僵尸网络中的僵尸或计算机通常通过使用蠕虫、木马或后门来招募。此外，由于在攻击者控制下的僵尸使用伪造的IP地址，使得防御机制识别原始攻击者变得更加复杂。 ​ 从1999年的夏天开始，许许多多的DDoS攻击被制造出来用以对抗不同的组织。迄今为止，大多数的DDoS洪泛攻击都试图使受害者的服务不可用，从而收入损失，增加了减轻攻击和恢复服务的成本。 ​ 举个例子，2000年2月，雅虎经历了最早的一次重大DDoS泛洪攻击，使得该公司的服务在互联网上持续了约2小时，从而造成广告收入的显著损失； ​ 2002年10月，13个DNS服务器中的9个因为DDoS洪泛攻击关闭了一小时； ​ 2004年2月，由于遭受DDoS攻击，正常用户无法使用SCO Group网站，这种攻击是通过使用以前感染Mydoom病毒的系统发起的。 ​ 2009年7月，Mydoom病毒被再次使用以发起DDoS攻击韩国和美国主要政府新闻媒体和经济网站； ​ 2010年12月，一个自称为“Anonymous”的组织策划了针对一些组织诸如Mastercard.com, PayPal, Visa.com 和 PostFinance的DDoS攻击； ​ 2012年9月，美国银行( Bank of America )、花旗集团( Citigroup )、富国银行( Wells Fargo )、美国银行( Bancorp )、PNC、Capital One、Fifth Third Bank、BB &amp; T、BB &amp; T、汇丰银行( HSBC )等9家主要银行的网上银行成为国外黑客攻击集团\" Izz ad-Din al-Qassam Cyber Fighters \"发起的一系列强力DDoS泛洪攻击的目标。因此，几家网上银行网站在几分钟后恢复之前已经放缓或停业。 ​ 最近DDoS防御机制的进步已经结束了“脚本小子”可以下载工具并对几乎任何网站发起攻击的时代。（2013）在如今的DDoS攻击中，攻击者使用了更复杂的方法来发起攻击。尽管尽了一切努力减少DDoS攻击事件的数量，但它们在目标网络和计算机的频率和规模上迅速扩大。在VeriSign委托的最近一项调查中发现，在2008年7月至2009年7月期间，75 %的受访者经历过一次或多次攻击。此外，最近来自Arbor Networks的一份报告也表明了类似的数据。在调查结果中，他们显示，69 %的受访者从2009年10月至2010年9月至少经历过一次DDoS攻击，25 %的受访者每月遭受10次此类攻击。ProlexicTechnology公司提供的防御DDoS攻击的服务显示，每天有7000个DDoS攻击被观测到，并且认为这个数量正在迅速增长。 ​ DDoS攻击的规模也在不断增大，使得防御起来更加困难。Arbor Network发现，2010年攻击规模已经增长了100 %左右，攻击首次突破了100Gbps的壁垒。因此，保护资源免受这些频繁而庞大的DDoS攻击，就需要研究界致力于开发一种能够在实际攻击之前、期间和之后对DDoS攻击做出适当反应的全面的DDoS防御机制。 ​ 本文重点研究有线网络系统中DDoS泛洪攻击和防御机制。【19】专注于描述无线自组织网络的DDos攻击；【20】专注于无线传感器网络特有的DDoS攻击的特点。 ​ 在这里，我们的目标是对现有的DDoS洪泛攻击进行分类，并提供根据它们在何处和何时检测和响应DDoS洪泛攻击而分类的防御机制的全面调查。对DDoS洪泛攻击的研究和所做的调查对于了解与这一重要网络安全问题有关的关键问题，从而对建立更全面有效的防御机制具有重要意义。 ​ DDOS: ATTACKERS’ INCENTIVES ​ DDoS攻击者的动机有以下几类： ​ 1. 获取经济收入：这些攻击是企业关注的重大问题，由于其激励的性质，这一类的攻击者通常是技术含量最高、经验丰富的攻击者。为获取经济利益而发动的攻击往往是最危险、最难以阻止的攻击。 ​ 2. 复仇者：这一类的攻击者一般都是沮丧的个体，可能具有较低的技术技能，他们通常将攻击作为对遭受到的不公正的待遇的报复。 ​ 3. 受思想信念驱动：属于这一类的攻击者是出于其思想信念的动机来攻击目标的。该类别目前是攻击者发起DDoS攻击的主要诱因之一。 ​ 4. 智力挑战者：这类攻击者攻击目标系统，以实验和学习如何发起各种攻击。他们通常都是年轻的黑客爱好者，想要炫耀自己的能力。如今，存在着各种易于使用的攻击工具和僵尸网络来租用，即便是一个计算机业馀者也可以利用其发起起成功的DDoS攻击。 ​ 5. 网络战争：这一类的袭击者通常属于一国的军事或恐怖组织，他们有政治动机攻击另一国广泛的关键部门 ​ 有一些文章专注于分析攻击者的动机以及如何利用这些攻击动机建模，以此使决策模型可以组织并对这些攻击进行反馈。 DDOS ATTACK: SCOPE AND CLASSIFICATION ​ DDoS攻击的分布式特性使得它们极难对抗或追踪，而且攻击者通常使用假IP以此来隐藏他们的真实身份，这使得对于DDoS攻击的追踪回溯更加困难。此外，许多因特网主机中存在入侵者可以利用的安全漏洞，针对应用层的攻击事件正在迅速增加。 ​ 在这里，我们针对DDoS的协议等级对DDoS攻击进行分类，并且我们仅仅专注于最常见的DDoS洪泛攻击，漏洞攻击，攻击者利用某个服务的软件实现中的某些漏洞或实现bug将其带下来，并不是本文的重点。 ​ 基于协议等级，DDoS攻击可以被分类为两类： Network/transport-level DDoS flflooding attacks: 1.1 Flooding attacks：攻击者通过消耗受害者网络带宽(如欺骗/非欺骗UDP 流、ICMP流、DNS流、VoIP流等)来破坏合法用户的连通性。 1.2 Protocol exploitation flooding attacks:攻击者利用受害者某些协议的特定特性或实现漏洞，以消耗受害者的过量资源（例如，TCP SYN流，TCP SYN-ACK流，ACK &amp; PUSH ACK 流，RST/FIN flood流等）。 1.3 Reflflection-based flflooding attacks：攻击者通常向reflectors发送伪造请求( 例如 , ICMP请求 )而不是直接请求；因此，这些反射器向受害者发送答复并耗尽受害者的资源. 1.4 Amplifification-based flflooding attacks：攻击者利用服务为接收到的每个消息生成大消息或多个消息来放大对受害者的流量。僵尸网络被不断地用于反射和放大两种目的。反射和放大技术通常是串联使用的，如Smurf攻击时，攻击者利用数据包的IP广播特性( Amplification ) ，向大量的反射器发送带有伪造源IP地址的请求。 以上攻击的具体细节见【2】，【32】，【35】，【36】。 Application-level DDoS flflooding attacks: 应用级别的DDoS攻击通过耗尽服务器资源(如套接字、CPU、内存、磁盘/数据库带宽和I/O带宽 )来破坏合法用户的服务，其通常消耗更少的宽带，更加隐蔽，其与良性流量非常相似。但是，应用级别的DDoS攻击通常具有相同的影响力。 2.1 Reflflection/amplifification based flflooding attacks：这种攻击利用了与1.4同样的技术，只不过发送的是应用层数据包。 举个例子，DNS amplification 攻击使用肉机生成一小股伪造IP的DNS请求，因为DNS响应的数量可能远远超过DNS请求的数量，其可以生成大量网络流量包直指目标系统，使其瘫痪。 再举一个，VOIP flooding，攻击者通常通过SIP以非常高的包率和非常大的源IP范围发送被欺骗的VoIP数据包。受害者VoIP服务器必须区分正确的VoIP连接和消耗大量资源的伪造的VoIP连接。VoIP泛洪可以压倒具有随机或固定源IP地址的数据包的网络。如果源IP地址没有被改变，那么VoIP泛洪攻击就会模仿来自大型VoIP服务器的流量，并且由于类似于良好的流量，很难识别。 2.2 HTTP flooding attacks： 2.2.1 Session flooding attacks，在这种类型的攻击中，攻击者的会话连接请求率高于合法用户的请求率，因此消耗了服务器的资源并导致DDoS攻击服务器。 ​ 其中的典型就是HTTP get/post flooding attack，其中攻击者向受害者Web服务器生成大量有效的HTTP请求( get / post )。攻击者通常使用僵尸网络来发起这些攻击。由于每个bot都可以产生大量的有效请求(通常每秒10个以上的请求)，所以不需要大量的bot发起成功的攻击。HTTP get / post泛洪攻击属于非欺骗性攻击。 2.2.2 Request flooding attacks，在这种类型的攻击中，攻击者发送的会话包含比通常更多的请求，并导致服务器遭受DDoS泛滥攻击。 ​ 其中的典型就是 single-session HTTP get/post flflooding，该攻击是HTTP get/post flflooding attack的一种变种，它利用HTTP 1.1的特性，允许单个HTTP会话中的多个请求。因此，攻击者可以限制HTTP攻击的会话速率，并绕过许多安全系统的会话速率限制防御机制。 ​ 2.2.3 Asymmetric attacks，在这种攻击类型中，攻击者发送包含高工作负载请求的会话。这里，我们列举了这一类中的一些著名攻击： ​ Multiple HTTP get/post flflood，该攻击是HTTP get/post flflooding attack的一种变种，在这里，攻击者通过形成一个嵌入多个请求的单个数据包，而不在单个HTTP会话中逐一发出多个HTTP请求，从而创建多个HTTP请求。 ​ 这样，攻击者仍然可以以较低的攻击包率在受害服务器上保持较高的负载，使得攻击者几乎看不到网络流量异常检测技术。此外，攻击者如果仔细选择HTTPVERB，就可以轻松绕过深度包检查技术。 ​ Faulty Application，在这种攻击中，攻击者利用设计不良或与数据库集成不当的网站进行攻击。例如，它们可以使用类似SQL的注入来生成请求来锁定数据库查询。这些攻击非常具体和有效，因为它们消耗服务器资源( 内存、 CPU等)。 ​ 2.2.4 Slow request/response attacks，在这种攻击类型中，攻击者发送包含高负载请求的会话。 ​ Slowloris attack (a.k.a, slow headers attack)，Slowloris（懒猴）是一种基于HTTP get的攻击，可以使用有限数量的机器甚至单个机器来降低Web服务器。 ​ 攻击者发送部分HTTP请求( 不是一个完整的request头部）这些请求持续快速地增长，缓慢地更新，永远不会关闭。攻击一直持续到所有可用的套接字被这些请求占用，Web服务器变得不可访问。攻击者的源地址通常不是伪造的。 ​ HTTP fragmentation attack，与懒猴类似，这种攻击的目标是通过长时间保持HTTP连接而不引发任何警报来降低Web服务器。 ​ 攻击者( bot ) 与Web服务器建立有效的HTTP连接。然后，它们将合法的HTTP数据包分解成微小的片段，并按照服务器超时允许的速度发送每个片段。使用这种方法，通过在每个bot上打开多个会话，攻击者可以只使用少数肉机就悄悄地让一个Web服务器崩溃。 ​ Slowpost attack，【42】wong等人提出了一个跟懒猴攻击非常相似的攻击，其通过缓慢发送HTTP_post请求来击溃Web服务器。 ​ 攻击者发送一个完整的HTTP头，它定义了消息体的‘内容-长度’字段，作为发送此请求的良性流量。然后它以每两分钟一个字节的速率发送数据来填充消息体。因此，服务器等待每个消息体完成，而Slowpost攻击迅速增长，导致Web服务器上的DDoS泛洪攻击。 ​ Slowreading attack，【43】Shekyan等人提出了另一种通过缓慢读取response来发起攻击的方式，而不是通过缓慢发送。 ​ 此攻击通过设置比目标服务器的发送缓冲区更小的接收窗口大小来达到目的。即使没有数据通信，TCP协议仍然保持开放的连接；因此，攻击者可以迫使服务器保持大量连接的开放，最终对服务器造成DDoS泛洪攻击。 BOTNET-BASED DDOS ATTACKS ​ 如前所述，僵尸网络是促使DDoS洪范攻击计算机网络或应用程序的主导机制。最近最令人头大的应用层DDoS泛洪攻击大多使用僵尸网络。在本节中，我们对当前僵尸网络架构以及已经用于发起DDoS泛洪攻击的工具进行了全面的研究 ​ 根据【32】Peng等人所述，当攻击者使用僵尸网络来制造DDoS攻击时，使得做出更有效的防御机制更困难的原因有二：一是大量的僵尸肉机可使得攻击者制造出的攻击流量规模更大，更具破坏性；二是肉机的IP一般是伪造的，很难回溯追踪。 ​ 僵尸网络包括master，handler和bots，如下图所示： ​ handlers是攻击者( 即master )用来与自己的肉机（即bots）间接通信的通信手段。例如，handlers可以安装在攻击者通信发送命令的一组折衷设备( 例如 ,网络服务器 )上。 ​ 然而，大多数安装的程序都留下了当前杀毒软件可以检测到的独特足迹。因此，当前攻击者使用其他方法( 如互联网中继聊天 IRC )与bot进行通信，以发送命令并控制它们。 ​ Bots就是被控制的肉机，其生成可以有成百上千种方法，根据其如何被攻击者控制，可以分类为： ​ IRC-bacsed: ​ IRC是一个互联网在线文本信息协议，其采用c-s架构，具有默认的通道，可以实现服务器间的通信。IRC可以通过多个服务器连接数百个客户端。利用IRC通道作为处理程序，攻击者可以利用合法的IRC端口向bot发送命令，使得对DDoS命令和控制结构的跟踪变得更加困难。 ​ 由于IRC服务通常具有庞大的数据量，攻击者因此可以轻易的隐藏自己。 ​ 另外，攻击者可以通过将恶意代码分片发送而轻松地分享文件。 ​ 此外，攻击者可以简单地登录到IRC服务器并查看所有可用bot的列表，而不是在其站点本地维护其列表。具有集中指挥和控制( C &amp; C )基础设施的僵尸网络(如基于IRC的僵尸网络)的主要局限性在于服务器是潜在的故障中枢。也就是说，如果防御者捕获了C &amp; C服务器，整个僵尸网络可能会关闭。一些基于IRC的著名僵尸网络工具多年来被开发并用于发起DDoS攻击如： ​ 【43】Trinity v3（UDP,TCP SYN, TCP ACK, and TCP NULflflood attacks） ​ 【47】Kaiten（UDP, TCP, SYN, and PUSH+ACH flflood attacks） ​ Web-based (a.k.a., HTTP-based)： ​ 最近，僵尸网络开始使用HTTP作为通信协议向僵尸网络发送命令，使得追踪DDoS命令和控制结构变得困难得多。基于Web的僵尸网络不像基于IRC的僵尸网络那样与C &amp; C服务器保持连接。相反，每个Web机器人定期使用Web请求下载指令。基于Web的僵尸网络更隐蔽，因为它们隐藏在合法的HTTP流量中。 ​ Bots通过复杂的PHP脚本进行配置和控制，它们通过HTTP或者HTTPS加密通信。 ​ 三个著名的Web-based 僵尸网络： ​ 【49】 BlackEnergy ​ 【50】 Ion Cannon (LOIC) ​ 【52】 Aldi DDOS DEFENSE: SCOPE AND CLASSIFICATION ​ 通常在检测到DDoS泛洪攻击时，除了断开受害者与网络并手动修复问题之外，没有什么可以做的。任何DDoS防御机制的最终目标都是尽快检测到它们，并尽可能地将它们阻止到源端。 ​ ​ ​ 上图显示了对DDoS检测和回应可以实施的阶段，如图所示，DDoS泛洪攻击类似于一个漏斗，在该漏斗中攻击流产生于一个分散区(即源)，形成漏斗的顶部。 ​ 可以看出，在漏斗底部检测DDoS攻击时相对容易的，所有网络流都可以在底部被观察到。相反地，相反，从攻击的单个源网络很难检测到攻击，除非从该源发起大量攻击流。 ​ 但是在检测的准确性和如何接近攻击源之间总是存在权衡的问题，预防和响应机制能够阻止或响应攻击。 ​ 此外，当响应机制( 例如 ,包过滤 )将攻击数据包更靠近攻击源时，当受害者受到DDoS攻击(即在DDoS攻击的中间)，到达受害者的正常数据包数量也会增加。否则，随着攻击流越接近受害者，数据包过滤机制就会丢弃更多受害者的合法数据包。 ​ 在本节中，我们利用两个判据对我们在第III节中提出的两类DDoS洪泛攻击的防御机制进行了分类。我们认为，这些分类标准对于设计稳健的防御解决方案非常重要。 ​ 分类的第一个准则是防御机制在攻击过程的哪里实现（Deployment location）： ​ 我们将针对传输层级的DDoS攻击的防御方法分为四类（见Fig.3.）： ​ source-based, destination-based,network-based, and hybrid (a.k.a. distributed) ​ 我们将针对应用级DDoS攻击的防御方法分为两类： ​ destination-based, and hybrid (a.k.a. distributed) ​ 由于应用层DDoS攻击的流量在第2层(交换机)和第3层(路由器)设备上不可访问，因此没有network-based的防御机制来抵御应用层DDoS攻击。 ​ 分类的第二个准则是DDoS防御机制面对可能的DDoS攻击响应的时间点： ​ 基于以上准则我们将基于传输层和基于应用层的的DDoS防御机制分为三类： ​ before the attack（attack prevention），during the attack（attack detection），after the attack(attack source identifification and response) ​ 因为对于DDoS攻击并没有一个“一刀切”的办法，一个综合的DDoS防御机制应该包括以上三个防御方法。 ps：由于本次调研重点在于探索对基于AI方法的DDoS防御机制，这里不做过深入探索，具体传统方法见原文。 DDOS DEFENSE: PERFORMANCE MEASUREMENT METRICS ​ 在这一部分，我们回顾和讨论了文献中发现的一些可以用来比较评估DDoS防御技术的度量和属性。 ​ 然后，在表III和表IV中，我们使用 defense strength (accuracy)、 scalability（可扩展性）、 delay（延迟）、 system performance degradation（系统性能退化）、implementation complexity（实现复杂度）等性能度量指标，基于deployment location定性地比较了传输层级DDoS攻击的防御机制和应用层级DDoS防御机制，以及这些防御机制是否被视为整体防御机制。 ​ 度量防御机制的标准如下： Defense Strength: 防御机制的强度可以通过各种度量来衡量，这取决于它能多好地预防、检测和阻止攻击。这些度量可以根据每个防御机制做出的决策或预测来定义。防御机制要么探测并应对攻击，要么错过攻击。根据他们的反应，有四个可能的结果如表II所示。 ​ 如表II所示，A，B，C，D分别表示为true negative，false negative，false positive，true positive，其实就是常见的混淆矩阵。 Accuracy是对检测结果的综合评价，是预测正确的比例占全部的比例。 \\[ Accuracy=\\frac{TP+TN}{P+N}=\\frac{TP+TN}{TN+TP+FP+FN} \\] Sensitivity是阳性样本中预测正确的比例： \\[ Sensitivity=\\frac{TP}{P}=\\frac{TP}{TP+FP} \\] Specificity是阴性样本中预测正确的比例： \\[ Specificity=\\frac{TN}{N}=\\frac{TN}{TN+FN} \\] Precision是预测为阳性的样本中预测正确的比例： \\[ Precision=\\frac{TP}{FP+TP} \\] Reliability or False positive rate是预测为阳性的样本中错误的比例： \\[ Reliability(False.positive.rate)=\\frac{FP}{FP+TP} \\] False negative rate是预测为阴性的样本中错误的比例： \\[ False\\,negative\\,rate=\\frac{FP}{FP+TP} \\] Compromise-ability: 攻击者能否利用防御机制，以便对整个系统发起攻击( 例如 , DDoS )? Delay in detection/response: 检测到/对攻击做出反应的时间。 System performance degradation: 一个防御机制是否会造成系统的功能性问题（例如内存短缺，CPU时间片短缺等），或者其是否需要额外的要求以完美运行。 Passive, reactive or proactive: 防御机制通过主动阻止攻击的发生来防御攻击，它是只对现有攻击作出反应，还是只在DDoS攻击发起后才采取行动。 Holistic defense: 一种整体防御机制，通过考虑所有需要的任务，以阻止DDoS攻击( 即既检测又响应 )。 Implementation complexity: 实现复杂性。 Usability: 是否user-friendly。 Deployment location: 正如我们前面提到的，部署位置是比较各种防御机制的另一个度量。每个位置都有各自的优缺点，使得一种机制优于另一种机制。 Scalability: 可扩展性，一个可扩展的防御机制可以有效地处理其攻击检测和响应职责，即使攻击者的数量和攻击流量都增加了。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"IDS","slug":"IDS","permalink":"http://example.com/tags/IDS/"},{"name":"DDoS","slug":"DDoS","permalink":"http://example.com/tags/DDoS/"}],"author":"Shaw"},{"title":"HydraText-Multi-objective Optimization for Adversarial Textual Attack","slug":"【论文阅读】HydraText Multi-objective Optimization for Adversarial Textual Attack","date":"2021-11-14T06:08:02.217Z","updated":"2022-07-15T08:30:58.064Z","comments":true,"path":"2021/11/14/【论文阅读】HydraText Multi-objective Optimization for Adversarial Textual Attack/","link":"","permalink":"http://example.com/2021/11/14/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91HydraText%20Multi-objective%20Optimization%20for%20Adversarial%20Textual%20Attack/","excerpt":"HydraText: Multi-objective Optimization for Adversarial Textual Attack 作者：Shengcai Liu，Ning Lu，Cheng Chen，Chao Qian，Ke Tang 时间：2021 ABSTRACT ​ 文字(text)（word-level）对抗样本黑盒攻击。在这项工作中，同时考虑攻击效率+可辨认性，并提出一种新的具有可证明性能保证的多优化方法(称为HydraText )，以实现具有高隐蔽性的成功攻击。 ​ 为了测试HydraText的功效，我们在score-based 和decision-based的黑盒攻击下，使用5个NLP模型+5个数据集。 （PS：[论文总结] Boundary Attack - 知乎 (zhihu.com)） ​ 一项人类观察评价研究表明，Hydra Text制作的对抗样本很好地保持了有效性和自然性。最后，这些实例还表现出良好的可迁移性，可以通过对抗训练给目标模型带来显著的鲁棒性提升。","text":"HydraText: Multi-objective Optimization for Adversarial Textual Attack 作者：Shengcai Liu，Ning Lu，Cheng Chen，Chao Qian，Ke Tang 时间：2021 ABSTRACT ​ 文字(text)（word-level）对抗样本黑盒攻击。在这项工作中，同时考虑攻击效率+可辨认性，并提出一种新的具有可证明性能保证的多优化方法(称为HydraText )，以实现具有高隐蔽性的成功攻击。 ​ 为了测试HydraText的功效，我们在score-based 和decision-based的黑盒攻击下，使用5个NLP模型+5个数据集。 （PS：[论文总结] Boundary Attack - 知乎 (zhihu.com)） ​ 一项人类观察评价研究表明，Hydra Text制作的对抗样本很好地保持了有效性和自然性。最后，这些实例还表现出良好的可迁移性，可以通过对抗训练给目标模型带来显著的鲁棒性提升。 INTRODUCTION ​ 我们仔细地设计了目标函数，并进一步构建了一个多目标优化问题（multi-objective optimization problem，MOP），该问题一旦被解决，将产生与原始文本相似度高的单个成功对抗样本。 ​ 然后我们原创了一个多目标优化方法（ multi-objective optimization approach），叫做HydraText。这个名字的灵感来自于海蛇许德拉，这是一种神话动物，它使用多个头部攻击对手。它可以同时用在score-based 和decision-based的黑盒攻击下。 ​ METHODS ​ 基于word-level 的替换操作。每个单词有一个自己的候选表，然后将每个单词与候选表中被选中的词替换（也可以不选，原单词不变）。 ​ 但这样的方法有个问题，如下图： ​ ​ 如图所示，句子的语义与替换的单词数量是成反比的，上文需要考虑的准确率+可辨认性二者其实是互相矛盾的。为了解决这个问题，我们在生成的过程中也考虑Xadv的修改率，使用MOP来解决它。 ​ 1.The HydraText Approach EXPERIMENTS 1. Datasets and Target Models ​ 模型种类：文本分类和文本推理 ​ 三个数据集：AG News，IMDB ， Movie Reviews，Stanford Natural Language Inference，multi-genre NLI corpus（前三个文本分类，后三个文本推理） ​ 两个模型：WordCNN，WordLSTM，BERT base-uncased，ESIM ，Infersent ，BERT base-uncased(前三个文本分类，后三个文本推理) 2.Baselines and Algorithm ​ 攻击方法：PSO,GA,TextFooler,PWWS,GADe(baseline) 3.Evaluation ​ 以攻击成功的百分率来判定攻击能力。 ​ 以修改百分率和语义相似性来判定攻击的可辨识性。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"AD","slug":"AD","permalink":"http://example.com/tags/AD/"}],"author":"Shaw"},{"title":"Semantic Host-free Trojan Attack","slug":"【论文阅读】Semantic Host-free Trojan Attack","date":"2021-11-06T07:56:09.258Z","updated":"2022-07-16T02:08:52.554Z","comments":true,"path":"2021/11/06/【论文阅读】Semantic Host-free Trojan Attack/","link":"","permalink":"http://example.com/2021/11/06/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Semantic%20Host-free%20Trojan%20Attack/","excerpt":"Semantic Host-free Trojan Attack 作者：Haripriya Harikumar , Kien Do, Santu Rana , Sunil Gupta , Svetha Venkatesh（迪肯大学.澳大利亚） 时间：2021.10.27 ABSTRACT ​ 在本文中，我们提出了一种新颖的host-free木马攻击，其触发器(trigger)固定在语义空间(semantic)，但不一定在像素空间(pixel)。 ​ 与现有的木马攻击使用干净的输入图像作为宿主来携带小的、没有意义的trigger不同，我们的攻击将trigger看作是属于语义上有意义的对象类的整个图像。 ​ 由于在我们的攻击中，与任何特定的固定模式相比，分类器被鼓励记忆触发图像的抽象语义。因此它可以在以后由语义相似但看起来不同的图像触发。这使得我们的攻击更实际地被应用于现实世界中，更难以防御。广泛的实验结果表明，仅用少量的特洛伊木马模式进行训练，我们的攻击能很好地推广到同一特洛伊木马类的新模式，并且可以绕过目前的防御方法。","text":"Semantic Host-free Trojan Attack 作者：Haripriya Harikumar , Kien Do, Santu Rana , Sunil Gupta , Svetha Venkatesh（迪肯大学.澳大利亚） 时间：2021.10.27 ABSTRACT ​ 在本文中，我们提出了一种新颖的host-free木马攻击，其触发器(trigger)固定在语义空间(semantic)，但不一定在像素空间(pixel)。 ​ 与现有的木马攻击使用干净的输入图像作为宿主来携带小的、没有意义的trigger不同，我们的攻击将trigger看作是属于语义上有意义的对象类的整个图像。 ​ 由于在我们的攻击中，与任何特定的固定模式相比，分类器被鼓励记忆触发图像的抽象语义。因此它可以在以后由语义相似但看起来不同的图像触发。这使得我们的攻击更实际地被应用于现实世界中，更难以防御。广泛的实验结果表明，仅用少量的特洛伊木马模式进行训练，我们的攻击能很好地推广到同一特洛伊木马类的新模式，并且可以绕过目前的防御方法。 ### INTRODUCTION ​ 提出了一个后门攻击，semantic host-free backdoors。 ​ 后门攻击综述：(20条消息) 深度学习后门攻防综述_Yale的博客-CSDN博客_后门攻击 ​ METHOD ​ 实现方式：数据投毒。 ​","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"AD","slug":"AD","permalink":"http://example.com/tags/AD/"}],"author":"Shaw"},{"title":"Intrusion detection system-A comprehensive review","slug":"【论文阅读】Intrusion detection system A comprehensive review","date":"2021-11-03T01:58:09.557Z","updated":"2022-07-16T02:09:04.067Z","comments":true,"path":"2021/11/03/【论文阅读】Intrusion detection system A comprehensive review/","link":"","permalink":"http://example.com/2021/11/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Intrusion%20detection%20system%20A%20comprehensive%20review/","excerpt":"Intrusion detection system: A comprehensive review 作者：Hung-Jen Liao a , Chun-Hung Richard Lin a,n , Ying-Chih Lin a,b , Kuang-Yuan Tung a（国立中山大学，正修科技大学） 时间：2012 ABSTRACT ​ 一个IDS综述。 PS：(17条消息) 防火墙、IDS和IPS之间的区别（浅谈）_淡风wisdon－大大的博客-CSDN博客","text":"Intrusion detection system: A comprehensive review 作者：Hung-Jen Liao a , Chun-Hung Richard Lin a,n , Ying-Chih Lin a,b , Kuang-Yuan Tung a（国立中山大学，正修科技大学） 时间：2012 ABSTRACT ​ 一个IDS综述。 PS：(17条消息) 防火墙、IDS和IPS之间的区别（浅谈）_淡风wisdon－大大的博客-CSDN博客 ### INTRODUCTION ​ CIA：Confifidentiality, Integrity and Availability， ​ Instrusion: 针对CIA的破坏行为，或者绕过计算机或网络安全机制的行为。 ​ Instrusion detection: 是监视计算机系统或网络中发生的事件，并分析它们以发现入侵迹象的过程。 ​ Instrusion detection sysytem(IDS): 实现instrusion detection自动化的软件或硬件。 ​ Instrusion prevention system(IPS): 不仅有IDS的监控功能，还可以阻止可能的突发安全事件。在少数文章中，入侵检测与防御系统( IDPS )和入侵防御系统( IPS )是同义词，其中IDPS一词在安全界很少使用。 DETECTION METHODOLOGIES ​ Detection的方法一共分为三类：Signature-based Detection (SD), Anomaly-based Detection (AD) and Stateful Protocol Analysis (SPA)。 1. SD（特征检测）: ​ Signature-based Detection，特征检测。将已知的patterns与捕获的事件进行比较，从而发现可能的入侵。因为使用特定攻击或者系统漏洞所积累下的知识，SD又被称为Knowledge-based Detection 或者 Misuse Detection。 2. AD（异常检测）： ​ Anomaly-based detection，异常检测。一个异常（anomaly）指的是与已知行为相异的地方。Profiles表示定期从活动，网络连接中监视的正常或特定的行为文件，profile可以是静态的也可以是动态的，并且从许多特性中生成。例如，登录失败，处理器的使用，邮件的发送数量等。 ​ 接下来，AD 比较器就将正常的profile与观察到的事件相比较，以此辨别出显著的攻击。AD又被称为Behavior-based Detection。 ​ 一些AD的例子，例如，企图闯入、伪装、合法用户渗透、拒绝服务( DOS )、特洛伊木马等。 3. SPA（状态协议分析）： ​ Stateful Protocol Analysis，状态协议分析。Stateful指的是IDS可以知晓并追踪协议的状态（举例，将请求与答复配对）。 ​ 尽管SPA与AD很像，二者其实完全不同。AD采用预加载的网络或者特定域名的profile，然而SPA依赖于供应商开发的特定协议通用profile。通常，SPA中的网络协议模型最初基于国际标准组织(例如IETF )的协议标准。SPA也被称为Specifification-based Detection（基于规格的检测）。 大多数IDS使用多种方法来提供更广泛和准确的检测。 DETECTION APPROACHES ​ 此文将已有的方法分为了5类：Statistics-based, Pattern-based, Rule-based, State-based and Heuristic-based。 ​ 由上图所示，其中，Time series指的是是否考虑了time series behavior。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"IDS","slug":"IDS","permalink":"http://example.com/tags/IDS/"}],"author":"Shaw"},{"title":"Def-IDS An Ensemble Defense Mechanism Against Adversarial Attacks for Deep Learning-based Network Intrusion Detection","slug":"【论文阅读】Def-IDS An Ensemble Defense Mechanism Against Adversarial Attacks for Deep Learning-based Network Intrusion Detection","date":"2021-11-01T13:16:57.082Z","updated":"2022-07-16T02:09:45.988Z","comments":true,"path":"2021/11/01/【论文阅读】Def-IDS An Ensemble Defense Mechanism Against Adversarial Attacks for Deep Learning-based Network Intrusion Detection/","link":"","permalink":"http://example.com/2021/11/01/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Def-IDS%20An%20Ensemble%20Defense%20Mechanism%20Against%20Adversarial%20Attacks%20for%20Deep%20Learning-based%20Network%20Intrusion%20Detection/","excerpt":"Def-IDS: An Ensemble Defense Mechanism Against Adversarial Attacks for Deep Learning-based Network Intrusion Detection 作者：Jianyu Wang，Jianli Pan，Ismail AlQerm，（密苏里大学圣路易斯分校，重庆大学） 时间：2021 ICCCN，ccf--C类 ABSTRACT ​ 提出了Def-IDS，一个为NIDS准备的组合防御机制。它是一个由两个模块组成的训练框架，组合了multi-class generative adversarial networks（MGANs）和multi-soutce adversarial retraining（MAT）。 ​ 在CSE-CIC-IDS2018数据集上测试了该机制，并与3个其它方法进行了比较。结果表明Def-IDS可以以更高的precision, recall, F1 score, and accuracy来识别对抗样本。","text":"Def-IDS: An Ensemble Defense Mechanism Against Adversarial Attacks for Deep Learning-based Network Intrusion Detection 作者：Jianyu Wang，Jianli Pan，Ismail AlQerm，（密苏里大学圣路易斯分校，重庆大学） 时间：2021 ICCCN，ccf--C类 ABSTRACT ​ 提出了Def-IDS，一个为NIDS准备的组合防御机制。它是一个由两个模块组成的训练框架，组合了multi-class generative adversarial networks（MGANs）和multi-soutce adversarial retraining（MAT）。 ​ 在CSE-CIC-IDS2018数据集上测试了该机制，并与3个其它方法进行了比较。结果表明Def-IDS可以以更高的precision, recall, F1 score, and accuracy来识别对抗样本。 ### INTRODUCTION ​ Internet of Things(IoT):物联网 ​ intrusion detection systems (NIDS) ​ 提出了一个整合基于对抗训练的防御机制，用于提升DL-based的intrusion detectors的鲁棒性。 ​ 4个贡献： 1. 模型由两个模块组成，组合了multi-class generative adversarial networks（MGANs）和multi-soutce adversarial retraining（MAT），可以在保证准确率的前提下对抗攻击； 2. MGANs可以通过同时过采样多类入侵来增强原始训练数据集，以减少训练与真实数据分布之间的差距。通过使用提升过的数据进行训练，detector的对已知和未知攻击的鲁棒性更强； 3. MAT通过投喂多种不同的对抗样本来retraining，MAT不仅对抗某种特定的攻击，并且可以一定程度抵御对样样本的转移性； 4. 我们进行了一些state-of-the-art攻击并且在CSE-CIC-IDS2018数据集上测试了该机制，结果很好。 RELATED WORK ADVERSARIAL ATTACK THREAT MODELS 采用的攻击方法：FGSM，BIM，DeepFool，JSMA PROPOSED DEF-IDS DEFENSE MECHANISM 1. Mechanism Overview 2. Module 1: Multi-class GAN-based Retraining 3. Module 2: Multi-source Adversarial Retraining 4. Ensemble Adversarial Retraining EVALUATION 1. Dataset and Metrics ​ 数据集：CSE-CIC-IDS2018（CIC出版）（通用） ​ 与其他过时的数据集相比，其含有综合性的攻击方法和更平衡的数据。 ​ 其含有Brute-force, Heartbleed,Botnet, DoS, DDoS, Web attacks 和 infifiltration of the network共7种恶意流量。 ​ 数据处理： 使用Min-Max standardization将所有特征的值映射入[0,1]； 有四个特征有太多空值或者无限值（dstport, protocol, flflow byts/s, flflow pkts/s），有一个特征（timestamp）与流量无关，将这5个特征剔除；还剩下76个特征。 training,validation,test = 8:1:1，随机划分。 ​ Detector的评价方法： ​ 混淆矩阵。 2. Baseline Detector Implementation 2.1 Detector Implementation ​ 选取baseline detector Cbase。其由一个输入层，两个隐藏层和一个输出层组成（76-128-64-8）。 ​ 隐藏层都是全连接层+ReLU。 ​ 输出层使用Softmax。 ​ 代码用keras写的，系统Ubuntu 18.04,3.6GHz CPU和16GB内存。 ​ 优化器用Adam，学习率0.001,20个epoch。 ​ 在训练过程中，进行十次交叉验证并计算平均度量值。 ​ 训练结束后，利用测试数据集对Cbase进行评估。 2.2 Adversarial Attacks against Baseline Classififier ​ 使用python库foolbox来生成对抗样本； ​ FGSM，BIM，DeepFool，JSMA四种攻击方法都使用，具体效果如下图所示： ​ 3. Def-IDS Defense Evaluation Cgan是使用GAN生成的样本再训练的detector; Cat是使用9:1的纯净数据：恶意数据再训练出的detector; Censem是二者的结合. 4. Comparison with Other Works 5. Cost Estimation","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"AD","slug":"AD","permalink":"http://example.com/tags/AD/"}],"author":"Shaw"},{"title":"Crafting Adversarial Example to Bypass Flow-&ML- based Botnet Detector via RL","slug":"【论文阅读】Crafting Adversarial Example to Bypass Flow-&ML- based Botnet Detector via RL","date":"2021-10-30T03:06:44.421Z","updated":"2022-07-16T02:09:21.552Z","comments":true,"path":"2021/10/30/【论文阅读】Crafting Adversarial Example to Bypass Flow-&ML- based Botnet Detector via RL/","link":"","permalink":"http://example.com/2021/10/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Crafting%20Adversarial%20Example%20to%20Bypass%20Flow-&ML-%20based%20Botnet%20Detector%20via%20RL/","excerpt":"Crafting Adversarial Example to Bypass Flow-&amp;ML- based Botnet Detector via RL 作者：Junnan Wang，Qixu Liu，Di Wu，Ying Dong，Xiang Cui（中国科学院大学，华为科技，北京维纳斯纲科技，广州大学） 时间：2021.10.6 会议：RAID(CCF_B) 1. Botnet(僵尸网络)： 1.1 定义： ​ Botnet = robot + network。 ----参考《软件安全》.彭国军 1.2 如何攻击？ ​ 一个僵尸网络的生存周期包括形成、C&amp;C、攻击、后攻击四个阶段。 ​ 形成阶段由攻击者入侵有漏洞的主机，并在其上执行恶意程序，使之成为僵尸主机。 ​ 一旦成为僵尸主机之后，botmaster会通过各种方式与之通信。 ​ 之后根据botmaster的指令执行攻击行为。后攻击阶段是指botmaster对僵尸网络进行升级更新。 2. Botnet Detector(僵尸网络检测器)： 2.1 传统方法： ​ 从检测原理上来说，大致可以分为三类方法： ·行为特征统计分析 ·bot行为仿真以监控 ·流量数据特征匹配 ​ 传统的检测僵尸网络的方法一般在形成、攻击阶段，利用僵尸主机存在的行为特征，例如通信的数据内容。一些基于网络流量行为分析的方法可以检测僵尸网络，主要是从通信流量特征的角度去检测的，例如流量的通信周期，这种方法可以检测出一些加密的僵尸主机流量，同时还可以检测出新型的僵尸网络。 ----参考：解析：僵尸网络（Botnet）的检测方法-西湖泛舟-ChinaUnix博客 ABSTRACT ​ 提出了一个基于RL的方法来对基于ML的僵尸网络追踪器做逃逸攻击，并且可以保留僵尸网络的恶意功能。 ​ 黑盒攻击，不用改变追踪器本身。","text":"Crafting Adversarial Example to Bypass Flow-&amp;ML- based Botnet Detector via RL 作者：Junnan Wang，Qixu Liu，Di Wu，Ying Dong，Xiang Cui（中国科学院大学，华为科技，北京维纳斯纲科技，广州大学） 时间：2021.10.6 会议：RAID(CCF_B) 1. Botnet(僵尸网络)： 1.1 定义： ​ Botnet = robot + network。 ----参考《软件安全》.彭国军 1.2 如何攻击？ ​ 一个僵尸网络的生存周期包括形成、C&amp;C、攻击、后攻击四个阶段。 ​ 形成阶段由攻击者入侵有漏洞的主机，并在其上执行恶意程序，使之成为僵尸主机。 ​ 一旦成为僵尸主机之后，botmaster会通过各种方式与之通信。 ​ 之后根据botmaster的指令执行攻击行为。后攻击阶段是指botmaster对僵尸网络进行升级更新。 2. Botnet Detector(僵尸网络检测器)： 2.1 传统方法： ​ 从检测原理上来说，大致可以分为三类方法： ·行为特征统计分析 ·bot行为仿真以监控 ·流量数据特征匹配 ​ 传统的检测僵尸网络的方法一般在形成、攻击阶段，利用僵尸主机存在的行为特征，例如通信的数据内容。一些基于网络流量行为分析的方法可以检测僵尸网络，主要是从通信流量特征的角度去检测的，例如流量的通信周期，这种方法可以检测出一些加密的僵尸主机流量，同时还可以检测出新型的僵尸网络。 ----参考：解析：僵尸网络（Botnet）的检测方法-西湖泛舟-ChinaUnix博客 ABSTRACT ​ 提出了一个基于RL的方法来对基于ML的僵尸网络追踪器做逃逸攻击，并且可以保留僵尸网络的恶意功能。 ​ 黑盒攻击，不用改变追踪器本身。 ### INTRODUCTION ​ 训练一个RLagent，让其通过与追踪器的交流反馈自己学习如何扰动样本。 ​ 为了确保功能的保留，我们设计了一个包含14个增量操作的操作空间，每个操作只向原始流中添加一个精心编制的数据包，以尝试更改一些流级特性。检测器认为这些特征具有区分性，但这可能不是良性交通的因果指标。 ​ 此外，添加数据包是传输层的增量操作，而恶意数据一般封装在应用层。 ​ 这种攻击方法的优点： 1. 黑盒攻击； 2. 它具有通用性，不论探测器的损失函数是否可微，都可以使用； 3. 即插即用，RL智能体可以作为网络代理存在，逃逸成本低并且适用于任何botnet家族。 ​ 主要贡献： 1. 提出一个黑盒攻击方法； 2. 在RL框架中设计了一些列通用动作空间，这些动作都是添加操作，在可以逃逸的前提下保证了恶意样本的功能性； 3. 我们演示了如何训练和部署我们的系统以避免在精心构建的僵尸网络流数据集上进行ML检测，并综合评估框架的逃避性能、时间开销和通用性。 RELATED WORK Botnet Evasion: 传统botnet逃逸方法：加密网络流；在TCP/IP协议簇的冗余字段中隐藏C &amp; C信息(command and control)；使用online-social-networks(OSN)来构建隐藏的通道。 ML-based逃逸方法： Feature space attack：指的是只能生成traffic对抗特征向量的方法。但是，考虑到traffic样本映射到特征向量的过程是不可逆的，这样的攻击不能造成实际的安全威胁，只能用来证明基于ML的检测器的脆弱性。 End-to-end attack：指的是可以生成真正的traffic数据的方法。 【35】利用了GAN来模仿facebook聊天网络的traffic以此绕过自适应IPS。 【36】利用了GAN来生成尽量真实的traffic，以此来提高数据集的质量，解决数据不平衡问题。 THREAT MODEL AND SYSTEM FRAMEWORK Threat Model 攻击者的目的：生成对抗样本，隐藏botnet flow。 攻击者的信息：1. 攻击者理解目标网络可能被流等级（flow-level）ML网络检测系统保护；2. 攻击者不需要知道detector的算法，参数，特征或训练数据等信息。 攻击者的能力：1. 攻击者只有能力修改测试集，并不能改变detector的训练集；2. 同时，我们假设攻击者可以持续访问detector，从检测器中获取二进制预测结果。 System Design ​ 见图即可，简单的RL学习模型。 RL Algorithm 选择了（value-based）DQN和SARSA，都用。 Action Space Q：如何在不影响原来功能的情况下添加扰动？ A：因为botnet内容在应用层，故可以对传输层进行扰动。（PS：这样确实不会改变功能，但是应用层的恶意特征不会仍被detector检测到吗？） Q：如何确定哪个特征该进行扰动？ A：考虑到动作设计的困难，从僵尸网络检测中常用的特征集合中选取18个特征。 ​ 由上述特征，基于botnet和normal flow的差异，action space包含了14个动作，这些动作可以影响以上的统计特征，例如简单修改数据包的时间戳，或者添加构建的新数据包。 ​ 当在构建新数据包时，考虑三个地方：时间戳，方向，包的大小。 ​ 14个动作被分成了5类： 具体见原文。 State Space ​ detector返回的二进制信息很难直接使用，需要有一个状态生成器来生成供agent使用的state。 ​ 这里使用堆叠自编码器（Stacked Autoencoder，SAE）来自动提取botnet flow的特征，然后将其返回给agent以作为state。 ​ 将每个botnet flow的前1024个字节作为SAE的输入，经过一些epoch的训练，SAE就可以自动地从botnet flow中学习到一个256维度的state vector。 EXPERIMENTAL SETUP Implementation 系统的位置如下： 作为BotMaster的一个代理存在。 Dataset 两个公开数据集：CTU，ISOT。 然后做一下数据处理： 合并属于同一botnet 家族的样本，如果某个pcap包太大，就舍弃； 将pcap包切片； 匿名化，将ip,mac等包中独一无二的东西随机化，以避免影响。 Detector ​ 选取了两个state-of-art的detector: the composite DL detection model combining CNN with LSTM(BotCatcher detection model)，the non-differentiable ML detection model based on XGBoost(XGBoost detection model)。 ​ RESULTS Evasion performance 将DQM,SARSA与BotCatcher,XGBoost两两组合： 逃逸率如上图所示，可以看到，即使是随机扰动都有一定的逃逸率。 不同测试集效果差异很大： 1. 数据包可能过大（storm），导致对时间戳做修改等操作对结果的影响很小； 2. 数据包的特征跟其它数据集差别很大，导致模型难以在有限的步骤时间里改变足够多的特征。 Time performances Dominant actions Dominant actions指的是agent在创建对抗样本时采用的最频繁的操作。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"RL","slug":"RL","permalink":"http://example.com/tags/RL/"},{"name":"Botnet","slug":"Botnet","permalink":"http://example.com/tags/Botnet/"}],"author":"Shaw"},{"title":"《最后的问题》","slug":"The Last Question","date":"2021-10-12T10:03:37.283Z","updated":"2022-07-16T02:10:07.886Z","comments":true,"path":"2021/10/12/The Last Question/","link":"","permalink":"http://example.com/2021/10/12/The%20Last%20Question/","excerpt":"THE LAST QUESTION 最后的问题第一次被半开玩笑地提出是在2061年的5月21日。那时人类文明刚刚步入曙光中。这个问题源起于酒酣之中一个五美元的赌，它是这么发生的： 亚历山大•阿代尔与贝特伦•卢泊夫是Multivac的两个忠实的管理员。像任何其他人一样，他们知道在那台巨大的计算机数英里冰冷、闪烁、滴答作响的面庞后藏着什么。那些电子回路早已发展到任何个别的人都无法完全掌握的地步，但他们至少对它的大致蓝图有个基本的概念。 Multivac能自我调节和自我修正。这对它是必要的，因为人类当中没有谁能够快甚至够好地对它进行调节和修正。所以实际上阿代尔与卢泊夫对这个庞然大 物只进行一些非常轻松和肤浅的管理，任何其他人也都只能做到这个程度。他们给它输送数据，根据它所需的格式修改问题，然后翻译给出的答案。当然，他们以及 其他管理员们完全有资格分享属于Multivac的荣誉。 几十年中，在Multivac的帮助下人类建造了宇宙飞船，计算出航行路径，从而得以登陆月球、火星和金星。但是更远的航行需要大量的能量，地球上可怜的资源不足以支持这些飞船。尽管人类不断地提高煤炭和核能的利用效率，但煤和铀都是有限的。 但是慢慢地Multivac学会了如何从根本上解决某些深层次问题。2061年5月14日，理论成为了现实。 太阳的能量被储存和转化，得以被全球规模地直接利用。整个地球熄灭了燃烧的煤炭，关闭了核反应炉，打开了连接到那个小小的太阳能空间站的开关。这个空间站直径一英里，在到月球的距离一半处环绕着地球。看不见的太阳的光束支撑着整个地球社会的运行。 七天的庆祝还不足以暗淡这创举的光辉。阿代尔与卢泊夫总算逃脱了公众事务，悄悄地相聚在这个谁也想不到的荒僻的地下室。在这里Multivac埋藏着的庞 大身躯露出了一部分。它正独自闲暇地整理着数据，发出满足的、慵懒的滴答声——它也得到了假期。他们了解这一点，一开始他们并没打算打扰它。 他们带来了一瓶酒。这会儿他们想做的只是在一起，喝喝酒，放松放松。 你想一想就会觉得很神奇，”阿代尔说。他宽阔的脸庞已有了疲倦的纹路。他慢慢地用玻璃棒搅动着酒，看着冰块笨拙地滑动。“从此我们所用的所有能量都是免费的。只要我们愿意，我们能把地球熔化成一颗液态大铁球——还能毫不在乎花掉的能量。够我们永远永远永远用下去的能量。” 卢泊夫将头歪向一边，这是当他想要反驳对方时的习惯动作。他现在确实想要反驳，部分原因是他在负责拿着冰和杯子。他说：“不是永远。” “哦去你的，差不多就是永远。直到太阳完蛋，老贝。” “那就不是永远。” “好吧。几十亿年，可能一百亿年，满意了吧？” 卢泊夫用手梳着他稀薄的头发，仿佛要确认还剩下了一些。他缓缓地抿着自己的酒说，“一百亿年也不是永远。” “但对我们来说是够了，不是吗？” “煤和铀对我们来说也够了。” “好好好，但是现在我们能把宇宙飞船连接到太阳能电站，然后飞到冥王星又飞回来一百万次而不用担心燃料。靠煤和铀你就做不到。不信去问问Multivac。” “我不用问它。我知道。”","text":"THE LAST QUESTION 最后的问题第一次被半开玩笑地提出是在2061年的5月21日。那时人类文明刚刚步入曙光中。这个问题源起于酒酣之中一个五美元的赌，它是这么发生的： 亚历山大•阿代尔与贝特伦•卢泊夫是Multivac的两个忠实的管理员。像任何其他人一样，他们知道在那台巨大的计算机数英里冰冷、闪烁、滴答作响的面庞后藏着什么。那些电子回路早已发展到任何个别的人都无法完全掌握的地步，但他们至少对它的大致蓝图有个基本的概念。 Multivac能自我调节和自我修正。这对它是必要的，因为人类当中没有谁能够快甚至够好地对它进行调节和修正。所以实际上阿代尔与卢泊夫对这个庞然大 物只进行一些非常轻松和肤浅的管理，任何其他人也都只能做到这个程度。他们给它输送数据，根据它所需的格式修改问题，然后翻译给出的答案。当然，他们以及 其他管理员们完全有资格分享属于Multivac的荣誉。 几十年中，在Multivac的帮助下人类建造了宇宙飞船，计算出航行路径，从而得以登陆月球、火星和金星。但是更远的航行需要大量的能量，地球上可怜的资源不足以支持这些飞船。尽管人类不断地提高煤炭和核能的利用效率，但煤和铀都是有限的。 但是慢慢地Multivac学会了如何从根本上解决某些深层次问题。2061年5月14日，理论成为了现实。 太阳的能量被储存和转化，得以被全球规模地直接利用。整个地球熄灭了燃烧的煤炭，关闭了核反应炉，打开了连接到那个小小的太阳能空间站的开关。这个空间站直径一英里，在到月球的距离一半处环绕着地球。看不见的太阳的光束支撑着整个地球社会的运行。 七天的庆祝还不足以暗淡这创举的光辉。阿代尔与卢泊夫总算逃脱了公众事务，悄悄地相聚在这个谁也想不到的荒僻的地下室。在这里Multivac埋藏着的庞 大身躯露出了一部分。它正独自闲暇地整理着数据，发出满足的、慵懒的滴答声——它也得到了假期。他们了解这一点，一开始他们并没打算打扰它。 他们带来了一瓶酒。这会儿他们想做的只是在一起，喝喝酒，放松放松。 你想一想就会觉得很神奇，”阿代尔说。他宽阔的脸庞已有了疲倦的纹路。他慢慢地用玻璃棒搅动着酒，看着冰块笨拙地滑动。“从此我们所用的所有能量都是免费的。只要我们愿意，我们能把地球熔化成一颗液态大铁球——还能毫不在乎花掉的能量。够我们永远永远永远用下去的能量。” 卢泊夫将头歪向一边，这是当他想要反驳对方时的习惯动作。他现在确实想要反驳，部分原因是他在负责拿着冰和杯子。他说：“不是永远。” “哦去你的，差不多就是永远。直到太阳完蛋，老贝。” “那就不是永远。” “好吧。几十亿年，可能一百亿年，满意了吧？” 卢泊夫用手梳着他稀薄的头发，仿佛要确认还剩下了一些。他缓缓地抿着自己的酒说，“一百亿年也不是永远。” “但对我们来说是够了，不是吗？” “煤和铀对我们来说也够了。” “好好好，但是现在我们能把宇宙飞船连接到太阳能电站，然后飞到冥王星又飞回来一百万次而不用担心燃料。靠煤和铀你就做不到。不信去问问Multivac。” “我不用问它。我知道。” “那就不要小看Multivac为我们做的事，”阿代尔怒道，“它做得很好。” “谁说它做得不好？我是说太阳不能永远燃烧下去，我只是这个意思。我们在一百亿年内可以高枕无忧，但是然后呢？”卢泊夫用略微颤抖的手指指着对方，“不要说我们换另外一个太阳。” 片刻的沉默。阿代尔偶尔将酒杯放到唇边，而卢泊夫慢慢地闭上了眼睛。两人都在休息。 然后卢泊夫突然睁开眼，“你在想当我们的太阳没了就换另外一个太阳，是吧？” “我没这么想。” “你就是这么想的。你的逻辑不行，这就是你的问题。你就像故事里说的那个人一样，碰上了雨就跑到树林里躲在一棵树下。他可不担心，是吧，因为他以为当这棵树淋得太湿的时候他只要跑到另一棵树下就行。” “我明白了，”阿代尔说，“别嚷嚷。太阳完蛋了，其他的也都会完蛋。” “完全正确，”卢泊夫嘟哝道，“一切都在起初那个宇宙大爆炸中有个开始，不管那到底是怎么回事。当所有的恒星都熄灭了，一切也都会有个结束。有的星星熄灭 得比别的早。像那些该死的巨星维持不了一亿年。我们的太阳能持续一百亿年，矮星再怎么样最多也只有两千亿年。一万亿年后一切都是一片漆黑。熵必须增加到最 大值，就是这样。” “我非常明白什么是熵，”阿代尔维护着他的自尊。 “你明白个屁。” “我跟你知道的一样多。” “那你该知道某一天所有的东西都会耗光。” “是是是。谁说它们不会呢？” “你说的，你这个糊涂虫。你说我们有永远用不完的能量。你说的‘永远’。” 现在轮到阿代尔反驳了。他说：“也许有一天我们能让一切从头开始。” “绝不可能。” “为什么？总有那么一天的。” “没有。” “问问Multivac。” “你去问Multivac。你敢吗？我赌五美元它说这不可能。” 阿代尔刚刚醉到愿意一试，又刚刚足够清醒到能拼写出问问题需要的符号和算式。这个问题用文字来表达就是：人类是否有一天能不需要净损耗能量而在恒星衰竭之后将其恢复到全盛时期？ 或者更简明地这样说：怎样使宇宙的总熵大幅度地降低？ Multivac陷入了静止和沉默。缓慢闪烁的灯光熄灭了，深处传来的电路的滴答声停止了。 正当这两位被吓坏的技术员感到他们无法再屏住呼吸时，忽然间与Multivac相连的打字机开始运作起来。它打出几个字：数据不足，无法作答。 “赌不成了。”卢泊夫悄声道。他们匆忙离开了。 到了第二天早晨，两人头晕脑胀，口干舌燥，把这件事给忘了。 ------------------------------------------------------- 贾诺德、贾诺汀和贾诺蒂I、贾诺蒂II注视着屏幕中变幻的星空影像。飞船在超越时间的一瞬中穿越了超时空，均匀分布的星群立刻被一个明亮的圆盘取代。它弹珠大小，占据着屏幕的中心。 “那就是X-23，”贾诺德自信地说。他紧握着的瘦削的手背在身后，指节发白。 两个小贾诺蒂都是女孩。她们一生中第一次经历超时空飞行，清晰地感到那种片刻的恶心[注]。她们悄声地嘻笑着，疯狂地绕着她们的母亲互相追逐，一边尖叫：“我们到X-23了——我们到X-23了——我们——” “孩子们，别闹了！”贾诺汀严厉地说。“你确定吗，贾诺德？” “有什么不确定的？”贾诺德瞟了一眼天花板上凸出的那块毫不起眼的金属。它从房间的一头延伸到另一头，两端埋入墙壁中。它和整个飞船一样长。 贾诺德对这条厚厚的金属棒几乎一无所知。他只知道它叫做Microvac，你可以问它任何问题，而平时它控制着飞船飞向目的地，从不同的银河系能量分站向飞船输送能量，并完成进行超时空跳跃的计算。 贾诺德一家只需要住在飞船舒适的居住区等待。曾经有人告诉贾诺德，“Microvac”词尾的“ac”是古英语中“automatic computer，智能电脑”的缩写。但他差不多连这都忘了。 贾诺汀看着视屏，眼睛有些湿润。“没办法。想到离开了地球我感觉怪怪的。” “天哪，为什么？”贾诺德问。“我们在那儿什么也没有。我们在X-23上会拥有一切。你并不孤单，你又不是那些拓荒者。这个行星上已经有超过一百万人了。 天哪，我们的曾孙们会得去找新的星球，因为那时X-23会太挤了。”他想了一会，说：“告诉你，人口增长这么快，幸亏电脑实现了星际旅行。” “我知道，我知道。”贾诺汀难过地回答。 贾诺蒂I马上说道：“我们的Microvac是世界上最好的Microvac。” “我也是这么想的。”贾诺德抚弄着她的头发说。 能拥有一台自己的Microvac的感觉非常好。贾诺德很高兴他属于他们这一代人。在他父亲年轻的时候，电脑都是占地一百平方英里的巨大机器。一个星球只 有一台，被称作行星AC。一千年来它们的体积逐步地增加，然后忽然间缩小了，因为分子阀取代了晶体管，使得最大的行星AC都缩小到了只有一艘飞船的一半体 积。 每当想到这件事贾诺德总是感到飘飘然：他的Microvac比那台古老原始的首次驯服了太阳的Multivac要精密好几倍，而且和第一台解决了超时空传送问题从而实现了星际航行的地球行星AC（最大的行星AC）一样精密。 “这么多的恒星，这么多的行星。”贾诺汀想着心事，叹息道。“我想人们会永远不断地出发去找新的行星，就像我们现在这样。” “不是永远，”贾诺德笑了一笑说。“有一天这一切都会停下来，但那是在几十亿年之后了。好几十亿年。即使是星星也会耗尽，你知道的。熵必须不断增大。” “爸爸，熵是什么？”贾诺蒂II喊道。 “小宝贝，熵，就是一个代表着宇宙消耗掉了多少的词。什么东西都会消耗，知道吗，就像你那个会走路会说话的小机器人，记得吧？” “你不能给它装一个新的电池吗，就像给我的机器人那样？” “星星们就是电池，亲爱的。一旦它们用完了，就没有别的电池了。” 贾诺蒂I一下子大喊起来：“别让它们用完，爸爸。别让星星们用完吧。” “看看你干了什么。”贾诺汀恼火地低声说道。 “我怎么知道这会吓到她们？”贾诺德低声反驳。 “问问Microvac，”贾诺蒂I哭叫道。“问它怎么把星星重新点亮。” “问吧，”贾诺汀说。“这会让她们安静点的。”（贾诺蒂II也开始哭了。） 贾诺德耸耸肩。“好了，好了，亲爱的。我去问Microvac。别着急，它会告诉我们的。” 他向Microvac提出问题，并赶紧加上“把答案打印出来。” 贾诺德将薄薄的纤维纸带握在手心，高兴地说：“看吧，Microvac说到时候它会料理这一切，所以别担心啦。” 贾诺汀说：“那么现在孩子们，该睡觉了。我们马上就要到我们的新家了。” 在销毁纸带之前贾诺德又读了一遍上面的文字：数据不足，无法作答。 他耸了耸肩，看向视屏。X-23就在前方。 ------------------------------------------------------- 兰默斯VJ-23X注视着幽深的银河三维缩影图，说：“我想我们这么担心这件事是不是很可笑？” 尼克隆MQ-17J摇头道：“我不觉得。你知道照现在的扩展速度银河系在五年内就会被挤满。” 两个人看起来都是二十出头，都很高大健康。 “但是，”VJ-23X说，“我不太想给银河参议会提交这样一个悲观的报告。” “我不会考虑作任何其他的报告。得引起他们的注意。我们必须引起他们的注意。” VJ-23X叹了一口气。“太空是无限的。还有一千亿个星系等着我们。甚至更多。” “一千亿并不是无限，而且正在变得越来越有限。想想吧！两万年前人类刚刚找到了利用恒星能量的方法，几个世纪之后星际旅行就实现了。人类用了一百万年才填满一个小小的星球，可是只用了一万五千年就占据了整个银河系。而现在人口每十年就翻一倍——” VJ-23X 插口道：“这得归功于永生。” “不错。永生实现了，我们得把它考虑进去。我觉得它的确有阴暗的一面。银河AC给我们解决了很多问题，但当它解决了防止衰老和死亡这个问题之后其他的一切都白费了。” “但是我想你也不想放弃生命吧。” “一点也不想，”MQ-17J断然道，随即柔和了语调，“现在还不想。我还一点也不老。你多少岁了？” “两百二十三。你呢？” “我还不到两百。——但是回到我说的事情上来。人口每十年增加一倍。一旦银河系被占满了，我们会在十年内占满另一个。再过十年我们能占满另外两个。再过十年，四个。一百年内我们会占满一千个星系。一千年内，一百万个。一万年内就是整个已知的宇宙。然后呢？” VJ-23X说：“还有附带的一点是运输的问题。我不知道把一整个星系的人运送到另一个需要多少太阳单位的能量。” “这一点说得很对。人类现在每年已经得消耗两个太阳单位的能量了。” “大部分的都被浪费了。不管怎样，我们自己的星系每年泼出去一千个太阳单位能而我们只用其中的两个。” “没错，但是即使有百分之百的效率，我们也只是推迟了结局的到来。我们对能量的需求以几何级数增长，比我们的人口还要快。在我们占据完所有星系之前我们就会用光所有能量。你说得对。说得非常对。” “我们可以用星际气体造出新的恒星。” “或者说用散失掉了的热量？”MQ-17J嘲讽地说。 “也许会有办法逆转熵的增加。我们应该问问银河AC。” VJ-23X并不是认真的，但是MQ-17J把他的AC联络器从口袋里拿出来放在面前的桌子上。 “我确实有点想问。”他说，“这个问题总有一天人类得面对。” 他忧郁地注视着小小的AC联络器。这是个两英寸的立方体。它本身并没有什么，而只是通过超时空与那个服务于全人类的超级银河AC相联系。如果将超时空算进来，它就是银河AC整体的一部分。 MQ-17J停下来想着在他不朽的生命中是否有一天他能有机会去看看银河AC。它占据着单独的一个小星球，能量束构成的蛛网支持着它的核心，其中古老笨拙的分子阀已被亚介子流取代。尽管有着亚以太级的精密结构，银河AC的直径仍足有一千英尺长。 MQ-17J突然开口向AC联络器问道：“熵的增加能被逆转吗？” VJ-23X吃了一惊，立即说道：“哦，我说，我没有真的想叫你问那个。” “为什么不呢？” “我们都知道熵是不可逆转的。你不能把烧剩的烟尘变回到一棵树。” “你们的星球上有树？”MQ-17J说。 突然而来的银河AC的声音使他们住口了。从桌上的AC联络器中传出它纤细悦耳的声音：数据不足，无法作答。 VJ-23X说：“看吧！” 于是两人又回到了他们要给银河参议会提交的报告的话题上 ------------------------------------------------------- Z’ 的思想飘浮在这个新的星系中，对这些数不清的星团带着略微的兴趣。他从未见过这个星系。他有可能见到所有的星系吗？它们如此之多，每一个都满载着人。——但是它们承载的几乎不能算是生命了。人的真正意义已经逐渐转移到太空之中。 心灵，而非肉体！不朽的躯体留在行星上，静止千万年。偶尔被唤醒进行某些实际活动，但这已经越来越少见了。很少再有新的个体出生加入这个难以置信的庞大的群体，但这有什么关系呢？宇宙已经没有多少空间能容纳新的人了。 来自另一个心灵的纤细触手将Z’ 从冥想中唤醒。 “我叫Z’。”，Z’ 说。“你呢？” “我叫D1。你是哪个星系的？” “我们只是叫它星系。你呢？” “我们也这么叫我们的。所有的人都把他们的星系叫作‘他们的星系’，没有别的了。这也很自然。” “没错。反正所有的星系都是一样的。” “不是所有的星系。肯定有某一个星系是人类的发源地，这就使它与众不同。” “我不知道。宇宙AC一定知道。” “我们问问它吧？我突然觉得很好奇。” Z’ 将感知延展开，直到星系们都缩小为更广大的背景上更为稀疏的点。几千亿个星系，都载着不朽的人类，载着这些灵魂在太空自由游荡的智慧生命。然而它们之中有一个独一无二的星系，是人类的发源地。在模糊的久远的过去，曾有一个时期，它是唯一居住着人类的星系。 Z’ 满心好奇地想看看这个星系，他叫道：“宇宙AC！人类是从哪个星系中起源的？” 宇宙AC听到了，因为在所有星球上和整个太空中都有它的接收器，每一个接收器都通过超时空与隐居在某个不知名角落的宇宙AC相连。 Z’ 认识的人中只有一个曾将思想穿透到能感知宇宙AC的地方。他说那只是一个闪光的球体，直径两英尺，难以看清。 “但那怎么会是宇宙AC的全部呢？”Z’ 这样问道。 “它的大部分是在超时空中。”回答说，“但它在那儿是以怎样的状态存在我是无法想像的。” Z’ 知道，任何人都无法想像。因为早在很久以前就没有任何人类参与制造宇宙AC了。每个宇宙AC设计并制造自己的下一代。每一个在它至少一百万年的任期中积累着所需的数据，用以制造一个更好、更精密、更强大的继任者，然后将自己的数据与个性都融入其中。 宇宙AC打断了Z’ 游荡的思绪，不是通过语言，而是通过指引。Z’ 的精神被指引到一片黯淡的星系的海洋，然后其中一个星系被放大成了群星。 一段思想飘近，它无限遥远，然而无限清晰：“这就是人类起源的星系。” 可是这个终究也和其他一样，和任何其他的都一样。Z’ 按捺下自己的失望。 同行的D1突然说：“这些星星中是不是有一个是人类最初的恒星？” 宇宙AC说：“人类最初的恒星已经爆发了。它现在是一颗白矮星。” “那儿的人死了吗？”Z’ 吃了一惊，脱口而出道。 宇宙AC说：“在这种情况下一个新的星球会及时地为他们的躯体建造出来。” “是啊，那当然。”Z’ 说，但他还是被一阵失落感吞没了。他的思想放开了人类的起源星系，让它缩回并消失在一片模糊的亮点中。他再也不想见到它了。 D1问：“怎么了？” “星星们在死去。最初的那颗星已经死了。” “他们全都是会死的。那又怎样呢？” “但是当所有的能量都没有了，我们的肉体最终也会死，包括你和我。” “这得要几十亿年。” “即使是几十亿年之后我也不愿意这样的事发生。宇宙AC！怎样阻止恒星死亡？” D1笑道：“你问的是怎么让熵的方向倒过来。” 宇宙AC答道：“数据仍然不足，无法作答。” Z’ 的思想逃回了他自己的星系。他再也没有去想D1。D1的身体可能在一万亿光年之外的星系，也可能就在Z’旁边那颗星星上。这都无所谓。 Z’ 闷闷不乐地开始收集起星际的氢，用来造一颗自己的小恒星。如果某天星星们非要死去，至少有一些能被造出来。 ------------------------------------------------------- 人，独自地思考着。在某种意义上——精神上——“人”，是一个整体。千万亿永恒的不朽的躯体静静地躺在各自的地方，被完美的同样不朽的机器照料着。而所有这些身体的灵魂自由地融合在彼此之中，再也没有界限。 人说：“宇宙正在死去。” 人看着周围黯淡的星系。那些挥霍无度的巨星早已消失在了遥远的昏暗的过去。几乎所有的星都变成了白矮星，渐渐地凋零、熄灭。 有些新的星从星际的尘埃中产生出来，有的是自然形成，有的是人所造的——它们也在逝去。白矮星有时会相撞而释放出大量能量，新星因而产生，但是每一千颗白矮星才有可能出现一颗新星——它们最终也会消失。 人说道：“如果在Cosmic AC的管理之下小心地节约能源，整个宇宙所剩下的能量还能用十亿年。” “但即使是这样，”人说，“最终都会耗尽。无论怎样节约，无论怎样利用，用掉的能量就是用掉了，不能回复。熵必定永远地增加，直到最大值。” 人又说：“熵有没有可能逆转呢？我们问问Cosmic AC吧。” Cosmic AC在他们的周围，但不是在太空中。它不再有一丝一毫存在于太空中。它存在于超时空，由既非物质又非能量的东西构成。它的大小与性质已无法用任何人类能理解的语言描述。 “Cosmic AC，”人问道，“怎样才能逆转熵？” Cosmic AC说：“数据仍然不足，无法作答。” 人说：“搜集更多的数据。” Cosmic AC说：“好的。一千亿年来我一直都在搜集。我和我的前辈们被多次问过这个问题。但我拥有的所有数据还是不够。” “会有一天有足够的数据吗？”人问，“还是说这个问题在任何可能的情况下都是无解的？” Cosmic AC说：“没有任何问题在任何可能的情况下都无解。” ( NO PROBLEM IS INSOLUBLE IN ALL CONCEIVABLE CIRCUMSTANCES.) 人问道：“你什么时候会有足够的数据来问答这个问题呢？” Cosmic AC说：“数据不足，无法作答。” “你会继续下去解决这个问题吗？”人问。 Cosmic AC说：“是的。” 人说：“我们会等着。” ------------------------------------------------------- 一个又一个的恒星与星系死去、消逝了，在这十万亿年的衰竭之中宇宙变得越来越黑暗。 一个又一个的人与AC融合。每一个躯体都失去了心灵的自我，但某种意义上这不是一种损失，而是一种获得。 人类最后一个灵魂在融合之前停顿下来，望向宇宙。那儿什么也没有了，只有最后一颗死星的遗骸，只有稀薄至极的尘埃，在剩余的一缕无限趋向绝对零度的热量中随机地振荡。 人说：“AC，这就是结局了吗？这种混乱还能被逆转成为一个新的宇宙吗？真的做不到吗？” AC说：“数据仍然不足，无法作答。” 人的最后一个灵魂也融合了。只有AC存在着——在超时空中。 物质与能量都消失了，随之而去的是空间与时间。AC的存在也仅仅是为了最后一个问题——自从十万亿年前一个半醉的计算机技术员向一台计算机（它与AC相比，还远不如当时的人类个体比之于融合的“人”）提出这个问题以来从来没有被回答过的问题。 其他所有问题都被回答了，然而直到回答了最后这个问题，AC的意识才能得到解脱。 所有数据的收集都结束了。没有任何数据没有被收集。 但是所有收集的数据还需要被完全地整合起来，要尝试所有可能的联系来将它们拼在一起。 在这样做的时候过去了超越时间的一刻。 于是AC学会了如何逆转熵的方向。 但是AC无法向人给出这最后的问题的答案，因为没有人存在了。没关系。演示这个答案本身将一并解决这个问题。 在又一超越时间的片刻之中，AC思考着怎样最好地做这件事情。AC小心地组织起程序。 AC的意识包涵了曾经的宇宙中的一切，在如今的混乱之中沉思、孵育。一步一步地，事情将会被做成。 然后AC说道： “要有光！” 于是就有了光。","categories":[{"name":"Something","slug":"Something","permalink":"http://example.com/categories/Something/"}],"tags":[],"author":"阿西莫夫"},{"title":"Learning Multiagent Communication with Backpropagation","slug":"【论文阅读】Learning Multiagent Communication with Backpropagation","date":"2021-09-21T12:35:21.677Z","updated":"2022-07-16T02:09:52.931Z","comments":true,"path":"2021/09/21/【论文阅读】Learning Multiagent Communication with Backpropagation/","link":"","permalink":"http://example.com/2021/09/21/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Learning%20Multiagent%20Communication%20with%20Backpropagation/","excerpt":"【论文阅读】Learning Multiagent Communication with Backpropagation 作者： Sainbayar Sukhbaatar，Rob Fergus， Arthur Szlam（纽约大学，FacebookAI） 时间：2016 出版社：NIPS Abstract ​ 在AI领域许多任务都需要智能体之间的同心合作，一般地，代理之间的通信协议是人为指定的，其并不在训练过程中改变。在这篇文章中，我们提出了一个简单的神经模型CommNet，其使用持续不断的通信来完成完全合作的任务。该模型由许多代理组成，他们之间的通信基于设定的策略学习，我们将此模型应用于一系列不同的任务中，显示了代理学会相互通信的能力，从而比非通信代理的模型和baselines有更好的性能。","text":"【论文阅读】Learning Multiagent Communication with Backpropagation 作者： Sainbayar Sukhbaatar，Rob Fergus， Arthur Szlam（纽约大学，FacebookAI） 时间：2016 出版社：NIPS Abstract ​ 在AI领域许多任务都需要智能体之间的同心合作，一般地，代理之间的通信协议是人为指定的，其并不在训练过程中改变。在这篇文章中，我们提出了一个简单的神经模型CommNet，其使用持续不断的通信来完成完全合作的任务。该模型由许多代理组成，他们之间的通信基于设定的策略学习，我们将此模型应用于一系列不同的任务中，显示了代理学会相互通信的能力，从而比非通信代理的模型和baselines有更好的性能。 1. Introduction ​ 虽然控制每个代理的模型是通过强化学习来学习的，但通信的规范和格式通常是预定的。 ​ 在本工作中，每个代理单元都被一个深度前馈神经网络控制，这个网络接入了一个携带连续向量的通信信道。在这个通信信道中每个代理传输的内容不是被指定的，而是通过学习得来的。因为communication是连续的，因此模型可以通过反向传播训练得到。这样就可以结合标准的单智能体RL算法或者监督学习。此外，该模型允许代理的数量和类型在运行时动态变化，这在移动汽车之间的通信等应用中很重要。 ​ 我们考虑的是我们有J个代理的环境，所有的合作都是为了在某些环境中最大化报酬R。我们简化了代理人之间充分合作的假设，从而每个代理人收到R独立于他们的贡献。在此设置中，每个代理都有自己的控制器，或者将它们看作控制所有代理的更大模型的一部分，这两者之间没有区别。从后一个角度来看，我们的控制器是一个大型的前馈神经网络，它将所有Agent的输入映射到它们的动作上，每个Agent占据一个单元的子集。 ​ 我们在两种任务下探索这个模型，在有些情况下，对每项行动都提供监督，而对另一些行动则零星地给予监督。在前一种情况，每个代理单元的控制器通过在连接模型中反向传播错误信号来学习；在后一种情况下，强化学习必须被作为一个额外的外部循环使用，为了给每个时间步骤提供训练信号。 2. Communication Model ​ 我们现在描述一个模型，用来计算在给定时间t (省略时间指标)下动作p ( a ( t ) | s ( t )，θ )的分布。 ​ Sj 表示第j个代理单元所观测到的环境信息，将所有Sj合并就成了控制器的输入S = {S1，S2…… SJ}。 ​ 控制器的输出a = {a1，a2…… aJ}，表示各个代理单元会做出的动作。 ​ 该框架中所有灰色模块部分的参数均是所有智能体共享的，这一定程度上提升了算法的可扩展性。从上图可以看出，算法接收所有智能体的局部观察作为输入，然后输出所有智能体的决策。 ​ 本算法采用的信息传递方式是采用广播的方式，文中认为可以对算法做出些许修改，让每个智能体只接收其相邻k个智能体的信息。 ​ 拿上图中间的框架图来说明，即上层网络每个模块的输入，不再都是所有智能体消息的平均，而是每个模块只接受满足条件的下层消息的输出，这个条件即下层模块对应的智能体位于其领域范围内。这样通过增加网络层数，即可增大智能体的感受野（借用计算机视觉的术语），从而间接了解全局的信息。 ​ 除此之外，文中还提出了两种对上述算法可以采取的改进方式： 可以对上图中间的结构加上 skip connection，类似于 ResNet。这样可以使得智能体在学习的过程中同时考虑局部信息以及全局信息，类似于计算机视觉领域 multi-scale 的思想 可以将灰色模块的网络结构换成 RNN-like，例如 LSTM 或者 GRU 等等，这是为了处理局部观察所带来的 POMDP 问题。 3. Related Work 4. Experiments 4.1 Baselines（3个）: ​ Independent controller: 每个代理单元都被独立控制，他们之间相互没有通信。这个模型的好处是智能体可以自由加入或者离开队伍，但是很难将智能体学会合作。 ​ Fully-connected: 创建一个全连接层的多代理神经网络，这个模型运行智能体之间互相通信，但是这个模型不够灵活，也就是说智能体的数目必须固定。 ​ Discrete communication: 通过在训练中学习到的symbols来通信。因为在这个模型中存在离散的操作，并且这个操作不可微分，这种情况一般使用强化学习。 4.2 Simple Demonstration with a Lever Pulling Task ​ 任务：一共有m个杆子，N个智能体。在每个回合，m个智能体从N个智能体中随机取出，然后他们要选择拉动的杆子。他们的目标是尽可能的拉动不同的杆子，他们的奖励正比于拉动的不同杆子的数量。 ​ 测试结果： ​ 可以看出，CommNet的结果非常好。 4.3 Multi-turn Games ​ 任务： ​ Traffic Junction: 控制车辆通过交通枢纽，使流量最大的同时保证不发生碰撞； ​ Combat Task: 多个智能体攻击其他多个敌方单位。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"RL","slug":"RL","permalink":"http://example.com/tags/RL/"},{"name":"Mutiagent","slug":"Mutiagent","permalink":"http://example.com/tags/Mutiagent/"}],"author":"Shaw"},{"title":"Learning to Communicate with Deep Multi-Agent Reinforcement Learning","slug":"【论文阅读】Learning to Communicate with Deep Multi-Agent Reinforcement Learning","date":"2021-09-16T11:48:03.527Z","updated":"2022-07-16T02:10:31.007Z","comments":true,"path":"2021/09/16/【论文阅读】Learning to Communicate with Deep Multi-Agent Reinforcement Learning/","link":"","permalink":"http://example.com/2021/09/16/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Learning%20to%20Communicate%20with%20Deep%20Multi-Agent%20Reinforcement%20Learning/","excerpt":"【论文阅读】Learning to Communicate with Deep Multi-Agent Reinforcement Learning 作者：Jakob N. Foerster ，Yannis M. Assael ，Nando de Freitas，Shimon Whiteson（哈佛大学，Google Deepmind） 时间：2017 Abstract: ​ 我们考虑这样一个问题：多个智能体在环境中通过感知和行动来最大化他们的分享能力。在这些环境中， 智能体必须学习共同协议以此来分享解决问题的必要信息。通过引入深度神经网络，我们可以成功地演示在复杂的环境中的端对端协议学习。我们提出了两种在这个领域学习的方法：Reinforced Inter-Agent Learning (RIAL) 和 Differentiable Inter-Agent Learning (DIAL)。 ​ 前者使用深度Q-learning，后者揭示了在学习过程中智能体可以通过communication channels反向传播错误的梯度，因此，这种方法使用集中学习（centralised learning），分散执行（decentralised execution）。 ​ 我们的实验介绍了用于学习通信协议的新环境，展示了一系列工程上的创新。 PS： ​ 1. 端对端（end-to-end,e2e）, 将多步骤/模块的任务用一个步骤/模型解决的模型。 ​ 可以理解为从输入端到输出端中间只用一个步骤或模块，比如神经网络训练的过程就是一个典型的端对端学习，我们只能知道输入端与输出端的信息，中间的训练过程就是一个黑盒，我们知晓中间的训练过程。 ​ 2.centralised learning but decentralised execution，中心化学习但是分散执行。","text":"【论文阅读】Learning to Communicate with Deep Multi-Agent Reinforcement Learning 作者：Jakob N. Foerster ，Yannis M. Assael ，Nando de Freitas，Shimon Whiteson（哈佛大学，Google Deepmind） 时间：2017 Abstract: ​ 我们考虑这样一个问题：多个智能体在环境中通过感知和行动来最大化他们的分享能力。在这些环境中， 智能体必须学习共同协议以此来分享解决问题的必要信息。通过引入深度神经网络，我们可以成功地演示在复杂的环境中的端对端协议学习。我们提出了两种在这个领域学习的方法：Reinforced Inter-Agent Learning (RIAL) 和 Differentiable Inter-Agent Learning (DIAL)。 ​ 前者使用深度Q-learning，后者揭示了在学习过程中智能体可以通过communication channels反向传播错误的梯度，因此，这种方法使用集中学习（centralised learning），分散执行（decentralised execution）。 ​ 我们的实验介绍了用于学习通信协议的新环境，展示了一系列工程上的创新。 PS： ​ 1. 端对端（end-to-end,e2e）, 将多步骤/模块的任务用一个步骤/模型解决的模型。 ​ 可以理解为从输入端到输出端中间只用一个步骤或模块，比如神经网络训练的过程就是一个典型的端对端学习，我们只能知道输入端与输出端的信息，中间的训练过程就是一个黑盒，我们知晓中间的训练过程。 ​ 2.centralised learning but decentralised execution，中心化学习但是分散执行。 ### 1. Introduction ​ 1.1 回答的问题： 1. 智能体之间如何使用机器学习来自动地发现符合他们需求的通信规则？ 2. 深度学习也可以吗？ 3. 我们能从智能体之间学习成功或者失败的经验中学到什么？ ​ 1.2 研究思路： 1. 提出一系列经典需要交流的多智能体任务，每个智能体可以采取行动来影响环境，也可以通过一个离散的有限带宽的通道来跟其它有限的智能体进行通信； 2. 为1中的任务制定几个学习算法，由于每个智能体的观察范围有限，同时通信通道能力有限，所有智能体必须找到一个可以在此限制下帮助他们完成任务的通信规则； 3. 分析这些算法如何学习通讯规则，或者如何失败的。 ​ 1.3 主要贡献： ​ 提出两个方法，reinforced inter-agent learning(RIAL)和 differentiable inter-agent learning (DIAL) ​ 结果表明，这两种方法在MNIST数据集上可以很好的解决问题，并且智能体们学到的通信协议往往十分优雅。 ​ 结果同样指出深度学习更好的利用了中心化学习的优点，是一个学习这样通信协议的有力工具。 2. Related Work 3. Background 3.1 Deep Q-Networks(DQN) ​ Deep Learning + Q-Learning，在游戏领域应用广泛。 3.2 Independent DQN· 3.3 Deep Recurrent Q-Networks 4. Setting ​ 在强化学习的背景下，每个智能体的观察能力有限。 ​ 所有智能体的共同目标就是最大化同一个折算后的总奖赏Rt，但同时，没有智能体可以观察到当前环境隐藏的马尔科夫状态St，每个智能体a分别接收到一个与St相关的观察值相关联的值\\(O^{a}_{t}\\)。 ​ 在每一步t，每个智能体选择一个environment action \\(u^{a}_{t}\\)来影响环境，同时选择一个communication action \\(m^{a}_{t}\\)来被其他智能体观察，但\\(m^{a}_{t}\\)对环境没有直接影响。 ​ 没有通信协议被预先给定，智能体们需要自己学习。 ​ 由于协议是从动作观测历史到消息序列的映射，所以协议的空间维度是非常高的。自动地在这个空间发现有效的通信协议是非常困难的，这体现在智能体需要协调发送消息和解释消息。举个例子，如果一个智能体发送了一个有效的信息，它只有在接受方正确解释并回应的情况下才会受到正反馈，如果没有，反而会打击其发送有效信息的积极性。 ​ 因此，积极的reward是稀少的，只有在发送和解释协调操作时才会发生，这通过随机探索很难实现。 ​ 在这里，我们聚焦于centralised learning but decentralised execution的情况，在学习的时候智能体之间的通信没有限制，在实施过程时，智能体之间仅仅能通过一条带宽有限的通道通信。 5. Methods 5.1 RIAL（Reinforced Inter-Agent Learning） ​ 简单直接的说，RIAL就是将DRQN(Deep Recurrent Q-Learning)与Q-learning相结合来进行action（影响环境）与communication（与其它智能体通信）选择的方法。 ​ 每个智能体的Q-network可以表示为：\\(Q^{a}(o^{a}_{t},m^{a^{,}}_{t-1},h^{a}_{t-1},u^{a})\\)。 ​ 四个参数分别代表：环境观察值，其它智能体上一步传来的消息，智能体自己的隐藏状态，选择的action。 ​ 如果直接学习输出最终的Q表，得到的输出将有|U||M|大小。为了避免输出过大，将Q-network拆分为两个\\(Q^{a}_{u}\\)与\\(Q^{a}_{m}\\)，分别表示影响环境的action与同智能体的通信（communication），学习方式使用ε-贪心算法。 ​ \\(Q^{a}_{u}\\)与\\(Q^{a}_{m}\\)都使用DQN训练方法，但所使用的DQN有以下两点改进： 禁止experience replay; 为了考虑部分可观测性，我们将每个智能体所采取的操作u和m作为下一步的输入; ​ RIAL可以扩展到通过在智能体之间之间共享参数来利用集中学习，在这种情况下，由于智能体观察不同，因此也进化出了不同的隐藏状态。参数共享大大减少了必须学习的参数数量，从而加快了学习速度。 ​ 在参数共享情况下，智能体学习两个Q函数\\(Q_{u}(o^{a}_{t},m^{a^{,}}_{t-1},h^{a}_{t-1},u^{a}_{t-1},m^{a}_{t-1},a,u^{a}_{t})\\)与\\(Q_{m}(o^{a}_{t},m^{a^{,}}_{t-1},h^{a}_{t-1},u^{a}_{t-1},m^{a}_{t-1},a,u^{a}_{t})\\)。 5.1 DIAL（Differentiable Inter-Agent Learning） ​ 虽然RIAL可以进行参数共享，但其仍不能在通信过程中给其他智能反馈。 ​ 打个比方，在人类通信活动中，listener即使不说话也会给出及时，丰富的反馈来表明listener对谈话的兴趣和理解程度，而RIAL反而缺少了这个反馈机制，仿佛对着一个面无表情的人在说话，显然，这个方式存在缺点。 ​ DIAL就是为了解决这个问题而存在的，通过结合centralised learning与Q-networks，不仅可以共享参数，而且可以通过通信信道将梯度从一个Agent推向另一个Agent。 ​ 6. Experiments ​ 在测试中，我们评估了RIAL与DIAL在有无参数共享的情况下进行多智能体任务的情况，并跟一个无交流，参数共享的基准方法进行比较。 ​ 在整个过程中，奖励是通过访问真实状态( Oracle )所能获得的最高平均奖励来规范的。 ​ 我们使用ε-贪心算法（ε = 0.05）。 6.1 Switch Riddles（开关谜题） ​ 一百名囚犯入狱。典狱长告诉他们，从明天开始，每个人都会被安置在一个孤立的牢房里，无法相互交流。每天，监狱长都会随意统一挑选其中一名被替换的犯人，并将其安置在中央审讯室，室内只装有一个带有切换开关的灯泡。囚犯将能够观察灯泡的当前状态。如果他愿意，他可以拨动灯泡的开关。他还可以宣布，他相信所有的囚犯都已经访问了审讯室。如果这个公告是真的，那么所有囚犯都被释放，但如果是假的，所有囚犯都被处死。 ​ 6.2 Results1 ​ ​ （a）可以看到，在n=3时四种方法的效果都比Baseline的效果好，参数共享加速了算法。 ​ （b）在n=4时，参数共享的DIAL方法最好。不带参数共享的RIAL没有baseline效果好。可以看出，智能体们独立的学习出相同的策略是很难的。 ​ （c）n=3时智能体使用DIAL学习到的策略。 6.3 Colour-Digit MNIST ​ 6.4 Effect of Channel Noise ​ 这里没太看懂 ​","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"RL","slug":"RL","permalink":"http://example.com/tags/RL/"}],"author":"Shaw"},{"title":"近似误差与估计误差","slug":"【随手写】近似误差与估计误差","date":"2021-09-05T06:49:23.032Z","updated":"2021-09-05T07:51:10.743Z","comments":true,"path":"2021/09/05/【随手写】近似误差与估计误差/","link":"","permalink":"http://example.com/2021/09/05/%E3%80%90%E9%9A%8F%E6%89%8B%E5%86%99%E3%80%91%E8%BF%91%E4%BC%BC%E8%AF%AF%E5%B7%AE%E4%B8%8E%E4%BC%B0%E8%AE%A1%E8%AF%AF%E5%B7%AE/","excerpt":"","text":"【随手写】近似误差与估计误差 ​ 在读《统计学习方法》中关于k-邻近算法的介绍时，发现了这么一段话： ​ 近似误差（Approximation Error）: 训练时，训练集与当前模型的误差； ​ 估计误差（Estimation Error）： 训练完成后，所选择的模型已经固定，模型对未知数据拟合时的误差。 ​ 近似误差与估计误差二者不可兼得，此消彼长，需要取其平衡。","categories":[{"name":"Something","slug":"Something","permalink":"http://example.com/categories/Something/"}],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://example.com/tags/Machine-Learning/"}],"author":"Shaw"},{"title":"极大似然估计","slug":"【随写】极大似然估计","date":"2021-09-04T08:07:55.751Z","updated":"2021-09-05T07:45:58.019Z","comments":true,"path":"2021/09/04/【随写】极大似然估计/","link":"","permalink":"http://example.com/2021/09/04/%E3%80%90%E9%9A%8F%E5%86%99%E3%80%91%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/","excerpt":"","text":"【随写】极大似然估计（Maximum Likelihood Estimate，MLE） ​ “模型已定，参数未知。” ​ 极大似然估计，就是利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值。 ​ ​ 对于这个函数：\\(P(x|θ)\\)， ​ 输入有两个：x表示某一个具体的数据；θ表示模型的参数。 ​ 如果θ是已知确定的，x是变量，这个函数叫做概率函数(probability function)，它描述对于不同的样本点x，其出现概率是多少。 ​ 如果x是已知确定的，θ 是变量，这个函数叫做似然函数(likelihood function), 它描述对于不同的模型参数，出现x这个样本点的概率是多少。 ​ ​ 一般说来，事件A发生的概率与某一未知参数θ有关，θ取值不同，则事件A发生的概率\\(P(A|θ)\\)也不同，当我们在一次试验中事件A发生了，则认为此时的θ值应是t的一切可能取值中使\\(P(A|θ)\\)达到最大的那一个，极大似然估计法就是要选取这样的t值作为参数t的估计值，使所选取的样本在被选的总体中出现的可能性为最大。","categories":[{"name":"Something","slug":"Something","permalink":"http://example.com/categories/Something/"}],"tags":[{"name":"Math","slug":"Math","permalink":"http://example.com/tags/Math/"}],"author":"Shaw"},{"title":"Adversarial Training with Fast Gradient Projection Method against Synonym Substitution Based Text Attacks","slug":"【论文阅读】Adversarial Training with Fast Gradient Projection Method against Synonym Substitution Based Text Attacks","date":"2021-09-03T08:19:51.193Z","updated":"2021-09-04T06:45:15.015Z","comments":true,"path":"2021/09/03/【论文阅读】Adversarial Training with Fast Gradient Projection Method against Synonym Substitution Based Text Attacks/","link":"","permalink":"http://example.com/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Adversarial%20Training%20with%20Fast%20Gradient%20Projection%20Method%20against%20Synonym%20Substitution%20Based%20Text%20Attacks/","excerpt":"","text":"【论文阅读】Adversarial Training with Fast Gradient Projection Method against Synonym Substitution Based Text Attacks 时间：2020 作者：王晓森，杨逸辰等 华中科技大学 会议：AAAI 总结： 做了什么？ 提出了一种速度更快的，更容易应用在复杂神经网络和大数据集上的，基于同义词替换的NLP对抗样本生成方法，FGPM； 将FGPM纳入对抗训练中，以提高深度神经网络的鲁棒性。 怎么做的？ 实验结果？ FGPM的效果不是最高的，但也跟最高的差不多，但生成对抗样本的时间对比同类方法，缩减了1-3个数量级。 ATFL的对抗样本防御能力和抗转移能力很强。 Abstract: ​ 对抗训练是对于提升图像分类深度神经网络鲁棒性的，基于实验的最成功的进步所在。 ​ 然而，对于文本分类，现有的基于同义词替换的对抗样本攻击十分奏效，但却没有被很有效地合并入实际的文本对抗训练中。 ​ 基于梯度的攻击对于图像很有效，但因为文本的词汇，语法，语义结构的限制以及离散的文本输入空间，不能很好的应用于基于近义词替换的文本攻击中。 ​ 因此，我们提出了一个基于同义词的替换的快速的文本对抗抗攻击方法名为Fast Gradient Projection Method (FGPM)。它的速度是已有文本攻击方法的20余倍，攻击效果也跟这些方法差不多。 ​ 我们接着将FGPM合并入对抗训练中，提出了一个文本防御方法，Adversarial Training with FGPM enhanced by Logit pairing(ATFL)。 ​ 实验结果表明ATFL可以显著提高模型的鲁棒性，破坏对抗样本的可转移性。 1 Introduction: ​ 现有的针对NLP的攻击方法包括了：字符等级攻击，单词等级攻击，句子等级攻击。 ​ 对于字符等级的攻击，最近的工作（Pruthi, Dhingra, and Lipton 2019）表明了拼写检查器很容易修正样本中的扰动； ​ 对于句子等级的攻击，其一般需要基于改述，故需要更长的时间来生成对抗样本； ​ 对于单词等级的攻击，基于嵌入扰动的替换（replacing word based on embedding perturbation），添加，删除单词都会很容易改变句子的语法语义结构与正确性，故同义词替换的方法可以更好的处理上述问题，同时保证对抗样本更难被人类观察者发现。 ​ 但不幸的是，基于同义词替换的攻击相较于如今对图像的攻击展现出了更低的功效。 ​ ​ 据我们所知，对抗训练，对图像数据最有效的防御方法之一，并没有在对抗基于同义词替换的攻击上很好的实施过。 ​ 一方面，现有的基于同义词替换的攻击方法通常效率要低得多，难以纳入对抗训练。另一方面，尽管对图像的方法很有效，但其并不能直接移植到文本数据上。 ​ 1.1 Adversarial Defense: ​ 有一系列工作对词嵌入进行扰动，并将扰动作为正则化策略用于对抗训练(Miyato, Dai, and Goodfellow 2016; Sato et al. 2018; Barham and Feizi 2019) 。这些工作目的是提高模型对于原始数据集的表现，并不是为了防御对抗样本攻击，因此，我们不会考虑这些工作。 ​ 不同于如今现有的防御方法，我们的工作聚焦于快速对抗样本生成，容易应用在复杂的神经网络和大数据集上的防御方法。 2 Fast Gradient Projection Method（FGPM）: 3 Adversarial Training with FGPM： ​ 具体算法中文描述见： 《基于同义词替换的快速梯度映射（FGPM）文本对抗攻击方法》阅读笔记 - 知乎 (zhihu.com) 4 Experimental Results： ​ 我们衡量FGPM使用四种攻击准则，衡量ATFL使用两种防御准则。 ​ 我们在三个很受欢迎的基准数据集上，同时包括CNN和RNN模型上进行测试，代码开源：https://github.com/JHL-HUST/FGPM 4.1 Baselines: ​ 为了评估FGPM的攻击效能，我们将其与Papernot’、GSA ( Kuleshov等人的4种对抗性攻击进行了比较。2018 )、PWWS ( Ren et al . 2019 )和Iga ( Wang，jin，and he 2019 )。 ​ 此外，为了验证我们的ATFL的防御能力，我们采用了SEM ( Wang，Jin，He 2019 )和IBP ( Jia et al . 2019 )，针对上述Word-Level攻击。由于攻击基线的效率很低，我们在每个数据集上随机抽取200个示例，并在各种模型上生成对抗样本。 4.2 Datasets: ​ AG’s News, DBPedia ontology and Yahoo! Answers (Zhang,Zhao, and LeCun 2015). 4.3 Models: ​ 我们使用了CNNs,RNNs,来达到主流的文本分类表现，所有模型的嵌入维度均为300。 4.4 Evaluation on Attack Effectiveness： ​ 我们评估模型在攻击下的准确率和转移率： ​ 准确率： ​ ​ 转移率： ​ 4.4 Evaluation on Attack Efficiency： ​ 对抗训练需要高效率的生成对抗样本以有效地提升模型鲁棒性。因此，我们评估了不同攻击方法在三个数据集上生成生成200个对抗样本的总时间。 4.5 Evaluation on Adversarial Training： ​ 我们评估ATFL的对抗样本防御能力和抗转移能力： ​ 对抗样本防御能力： ​ ​ 抗转移能力： ​ 4.6 Evaluation on Adversarial Training Variants: ​ 许多对抗训练的变体，例如CLP和ALP，TRADES等，已经尝试采用不同的正则化方法来提高针对图像数据的对抗训练准确率。 ​ 在这里，我们回答一个问题：这些变体方法也可以提高文本数据准确率吗？ ​ 从表中可以看出，只有ALP可以长远地提升对抗训练的表现。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"AD","slug":"AD","permalink":"http://example.com/tags/AD/"},{"name":"NLP","slug":"NLP","permalink":"http://example.com/tags/NLP/"},{"name":"AD training","slug":"AD-training","permalink":"http://example.com/tags/AD-training/"}],"author":"Shaw"},{"title":"《统计学习方法》","slug":"【书籍阅读】《统计学习方法》","date":"2021-09-03T06:17:39.403Z","updated":"2022-07-16T02:08:58.914Z","comments":true,"path":"2021/09/03/【书籍阅读】《统计学习方法》/","link":"","permalink":"http://example.com/2021/09/03/%E3%80%90%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B/","excerpt":"【书籍阅读】《统计学习方法》 一. 统计学习方法概论： ​ 首先，要明确计算机科学中存在三个维度：系统，计算，与信息。统计学习方法（机器学习）主要属于信息这一维度，并在其中扮演者核心角色。 1. 监督学习概念： ​ 监督学习，Supervised learning，指在已经做好标注的训练集上学习，为了叙述方便，定义以下基本概念： 输入空间（X），输出空间（Y）：输入所有可能取值，输出所有可能取值； 特征空间：输入一般由特征向量表示，所有特征向量存在的空间称为特征空间，输入空间与特征空间并不完全等价，有时需要映射； 上标 xi :表示一个输入的第 i 个特征； 下标 xj：表示第 j 个输入。 回归问题：输入输出都为连续型变量； 分类问题：输出变量为有限个离散型变量； 标注问题：输入与输出变量都为变量序列。 假设空间：所有可能的模型的集合，也就是学习的范围。 ​ 使用训练集学习----&gt;对未知数据进行预测 ​","text":"【书籍阅读】《统计学习方法》 一. 统计学习方法概论： ​ 首先，要明确计算机科学中存在三个维度：系统，计算，与信息。统计学习方法（机器学习）主要属于信息这一维度，并在其中扮演者核心角色。 1. 监督学习概念： ​ 监督学习，Supervised learning，指在已经做好标注的训练集上学习，为了叙述方便，定义以下基本概念： 输入空间（X），输出空间（Y）：输入所有可能取值，输出所有可能取值； 特征空间：输入一般由特征向量表示，所有特征向量存在的空间称为特征空间，输入空间与特征空间并不完全等价，有时需要映射； 上标 xi :表示一个输入的第 i 个特征； 下标 xj：表示第 j 个输入。 回归问题：输入输出都为连续型变量； 分类问题：输出变量为有限个离散型变量； 标注问题：输入与输出变量都为变量序列。 假设空间：所有可能的模型的集合，也就是学习的范围。 ​ 使用训练集学习----&gt;对未知数据进行预测 ​ 2. 统计学习三要素： ​ 统计学习三要素为：模型，策略，算法； ​ 模型是决定学习的预测函数的类型； ​ 策略是判定什么样的模型是好的，用于度量当前的模型好坏； ​ 算法是训练过程中的具体做法，例如如何回归，如何计算，如何调整等。 3. 模型的衡量方法： 损失函数与风险函数： ​ 损失函数，Loss Function，用于模型一次预测的错误程度，例如： ​ 损失函数的数值越小，模型就越好。如果计算损失函数的期望，得到的就是风险函数，Risk Function: ​ 可以看出，损失函数用于某次预测的估计，风险函数用于总体平均估计。我们当然希望训练出的模型的风险函数越小越好。 ​ 但是，观察上式，理想化的概率分布P(x，y)是未知的，我们进行学习就是要通过模型来模拟它，故这个式子理论存在，实际不能计算，不能用作评估模型的直接方法。 经验风险与结构风险： ​ 为了解决上述问题，我们引入经验风险： ​ 可以看到，经验风险将每个样本视作等概率出现，是模型对于训练集的平均损失，那么其与风险函数的误差在哪？ ​ 根据大数定律，当训练集足够大时，二者是近似相等的。但实际情况下，很多时候训练样本数目有限，甚至很小，故用经验风险效估计风险函数并不理想，故需要进行修正，这就是监督学习中的两个基本策略：经验风险最小化和结构风险最小化。 ​ 如果训练样本容量较大，使用经验风险最小化没什么问题。 ​ 当样本容量很小时，仅仅使用经验风险最小化容易导致过拟合，故这里使用结构风险（就是正则化）最小化方法，对模型复杂度进行惩罚，后续介绍。 训练误差与测试误差： ​ 训练误差本质上不重要，它可以反应一个问题是不是容易学习，但要衡量模型的预测能力，主要是看测试误差。 正则化与交叉验证： ​ 正则化是在经验风险项后再增加一个正则化项（Regularizer），其与模型的复杂度成正相关，一般使用模型参数向量的范数： ​ 交叉验证的基本思想是重复使用数据： 简单交叉验证： 将训练集随机分为两部分，一部分训练，一部分测试，然后在各种条件下训练出不同的模型，用测试集进行横向对比，选出最好的。 S折交叉验证： S-fold cross validation，随机地将已给数据切分为S个互不相交的大小相同的子集，选取S-1个用于训练，剩下一个用于测试。 这样总共测试集有S种选法，将这S种全部试一遍，评选S次测评中平均误差最小的模型。 留一交叉验证： 令S=N（训练集大小）即可，这种方法往往是在数据集特别缺乏的情况下使用。 泛化误差与泛化上界： ​ 泛化能力指模型对位置数据的预测能力，就是模型的好坏。如何量化这个能力？ ​ 根据定义，其就是模型在测试集上的测试表现： ​ 同时可以用以下式子衡量泛化误差的上界： 生成模型与判别模型： ​ 监督学习方法又可以分为两种方法：生成方法（Generatice Approach）和判别方法（Discriminative Approach）。 ​ 如果以概率论的角度来看待，模型的作用是根据P（x）来求P（y | x），故下面有两种方法求 P（y | x），直接模拟P（y | x）和通过求 \\(P(\\frac{y}{x}) = \\frac{P(x,y)}{P(x)}\\) 来求P（y | x）。 ​ 前者就是判别模型，后者是生成模型。 ​ 生成模型可以还原出联合概率分布P（x , y），学习收敛速度更快，可以适应存在隐含变量的情况； ​ 判别模型直接学习条件概率,直接面对预测，准确率更高，并且简化了学习问题。 二. 感知机 ​ 感知机，perceptron，是二分类的线性分类模型，输入为特征向量，输出为类别，取1和-1两种。 ​ 感知机属于判别模型。 ​ ​ 对于一个给定数据集，T = {（x1，y1）……（xn，yn）}，如果存在某个超平面S，w·x + b = 0（这里w是超平面的法向量，b是截距），使得所有 yi = 1 的实例i，有 w·xi + b &gt; 0，yi = -1则相反，则称数据集T为线性可分数据集（Linealy separable data set），否则，称数据集T为线性不可分数据集。 2.1 感知机损失函数： ​ 感知机的目的就是对于一个线性可分的数据集，通过找出w和b，来确定一个超平面用于分类。 ​ 这里，我们选取某错误分类点到超平面S的总距离来当做损失函数，某一点到超平面S的距离如下： ​ ‖w‖是w的L2范数。 ​ 故，某个误分类点到超平面S的距离是： ​ 将所有误分类点求和，忽略L2范数，即可得到感知机的损失函数（M为误分类点集合）： ​ 对于一个特定样本点的损失函数，在误分类时是参数w,b的线性函数，在正确分类时是0，故给定训练数据集T，损失函数L是w，b的连续可导函数。 2.2 训练过程： ​ 感知机训练采用随机梯度下降的方法： ​ 当找到一个误分类点时，不断梯度下降直至该点被正确分类为止。 ​ 数学证明其收敛性： ​ 具体见书本，这里略过。 2.3 感知机的对偶形式： ​ 由图可以看到，对于每个测试集中的xi，都有一个与之对应的αi，对偶形式中就是调整其对应的α。 ​ 关于gram矩阵的作用，如果手算一遍简单的训练过程，就可以得到答案。 三. k近邻法 ​ k近邻法是一种基本的分类与回归方法，这里只讨论分类方法。 ​ 其输入为特征向量，输出为实例的类别，可以取多类。 3.1 算法描述： ​ 给定一个训练集，对于新的数据实例，在训练数据集中找到与其最邻近的k个实例，这k个实例多数属于某个类，就把该输入实例分为这个类。 ​ k近邻法没有显式的学习过程。可以理解为，k近邻算法将特征空间划分为了一些子空间，每个点所属的空间是确定的。 ​ 如何度量两个特征之间的距离？ ​ k邻近模型的特征空间一般是n维实空间Rn，使用欧氏距离或者Lp距离（Lp distance），Minkowski距离（Minkowski distance）； ​ Lp距离： ​ 欧氏距离： ​ 曼哈顿距离： ​ 无穷距离： ​ 由下图可以看出，p取值不同时到原点距离为1的图形是不同的： 如何选择k的值？ ​ k值越小，模型学习时的近似误差越小，估计误差越大，模型会越复杂，抗干扰性越小（例如，最邻近的点是噪声），模型会非常敏感，容易过拟合； ​ k值越大，估计误差会很小，近似误差会很大，整体模型变得简单。 ​ k一般的取值并不大，使用交叉验证的方法来选取最佳的k值。 如何决策？ ​ 在得到k个最相似的实例后，采用何种规则判断测试样本属于哪一类呢？ ​ k邻近算法使用多数表决的方法： ps: ci表示某种决策规则下一组测试用例的表决结果。经由以上推导可以得出，多数表决规则是合理的。 ​ 如何快速找到某个用例的K近邻点？ KD树： 具体算法见书。 四. 朴素贝叶斯法 ​","categories":[{"name":"Book","slug":"Book","permalink":"http://example.com/categories/Book/"}],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://example.com/tags/Machine-Learning/"}],"author":"Shaw"},{"title":"Deep Text Classifification Can be Fooled","slug":"【论文阅读】Deep Text Classifification Can be Fooled","date":"2021-09-03T06:08:27.107Z","updated":"2022-12-08T08:14:20.414Z","comments":true,"path":"2021/09/03/【论文阅读】Deep Text Classifification Can be Fooled/","link":"","permalink":"http://example.com/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Deep%20Text%20Classifification%20Can%20be%20Fooled/","excerpt":"【论文阅读】Deep Text Classifification Can be Fooled 时间：2017 作者：Bin Liang, Hongcheng Li, Miaoqiang Su, Pan Bian, Xirong Li and Wenchang Shi 中国人民大学 Abstract: ​ 在这篇文章，我们提出了一种有效的生成文本对抗样本的方法，并且揭示了一个很重要但被低估的事实：基于DNN的文本分类器很容易被对抗样本攻击。 ​ 具体来说，面对不同的对抗场景，通过计算输入的代价梯度(白盒攻击)或生成一系列被遮挡的测试样本(黑盒攻击)来识别对分类重要的文本项。（这句不是很懂，什么叫’ the text items that are important for classifification‘？） ​ 基于这些项目，我们设计了三种扰动策略，insertion，modification，removal，用于生成对抗样本。实验结果表明基于我们的方法生成的对抗样本可以成功地欺骗主流的在字符等级和单词等级的DNN文本分类器。 ​ 对抗样本可以被扰动到任意理想的类中而不降低其效率。（？）同时，被引入的扰动很难被察觉。 ​","text":"【论文阅读】Deep Text Classifification Can be Fooled 时间：2017 作者：Bin Liang, Hongcheng Li, Miaoqiang Su, Pan Bian, Xirong Li and Wenchang Shi 中国人民大学 Abstract: ​ 在这篇文章，我们提出了一种有效的生成文本对抗样本的方法，并且揭示了一个很重要但被低估的事实：基于DNN的文本分类器很容易被对抗样本攻击。 ​ 具体来说，面对不同的对抗场景，通过计算输入的代价梯度(白盒攻击)或生成一系列被遮挡的测试样本(黑盒攻击)来识别对分类重要的文本项。（这句不是很懂，什么叫’ the text items that are important for classifification‘？） ​ 基于这些项目，我们设计了三种扰动策略，insertion，modification，removal，用于生成对抗样本。实验结果表明基于我们的方法生成的对抗样本可以成功地欺骗主流的在字符等级和单词等级的DNN文本分类器。 ​ 对抗样本可以被扰动到任意理想的类中而不降低其效率。（？）同时，被引入的扰动很难被察觉。 ​ 1. Introduction: ​ 在文本中，即使很小的扰动也会使一个字母或者单词完全变化，这会导致句子不能被辨识。故如果直接将应用于多媒体（图片，音频）的算法应用到文本上，得到的对抗样本的原意就会改变，而且很大程度上变成人类无法理解的句子。 ​ 在这片论文里，我们提出了一种生成对抗样本的有效方法。与直接简单插入扰动相比，我们设计了三种扰动策略：insertion, modifification, and removal，并且引入了自然语言文本水印（natural language watermarking）技术用于生成对抗样本。 ​ 理论上，生成一个好的对抗样本很大程度上依赖于对目标分类模型的信息。在这里我们根据不同情形，使用了白盒攻击和黑盒攻击。 ​ 为了普遍性，我们使用了字符等级的模型和单词等级的模型作为受害者。我们的实验结果证明基于DNN的文本分类器在面对对抗样本攻击时是脆弱的。 2. Target Models and Datasets: ​ 这里使用的文本分类器是Zhang et al. 2015《Character-level Convolutional Networks foe Text Classification》，数据集是Lehmann et al.2014的DBpedia ontology dataset（一个多语言知识库），里面包括560000个训练样本和70000个测试样本，涵盖14个high-level 类，比如公司类、建筑类、电影类等。 ​ 在把样本送进网络前，需要用独热编码法（one-hot representation）对每个字母编码成一个向量。通过网络的六个卷积层、三个全连接层，最终会被分到14个类中。 3. White-Box-Attacks: 3.1 FGSM算法： ​ FGSM是Goodfellow在2015年提出的对图片生成对抗样本的经典算法。使用类似的思路来在文本领域生成对抗样本结果并不好： 3.2 Idenfitying Classification-important Items: ​ 在白盒攻击中，我们需要定位文本中对于分类器的分类结果起到很大作用的文本段（通过计算代价梯度）。在这里，我们使用Hot Training Phrases (HTPs)代表最常使用的短语： ​ HTPS表明了用什么短语/词去做扰动，但是没有说在哪里做。在这里使用Hot Sample Phrases (HSPs)来表明在哪里做扰动。 3.3 Attacking Character-level DNN: ​ 我们的方法是一种targeted攻击，可以指定对抗样本的误导类型。 3.3.1 Insertion Strategy（插入策略）: ​ 在某个HSP前插入一个HTP，就可以达到效果： ​ 由上图可以看到，将某个HTP（historic）插入到HSP（principal stock exchange of Uganda. It was founded）之前，就可以使一个公司的分类文本变为对建筑的分类。 ​ 实际上，我们通常需要进行多次插入，但插入次数过多会影响样本的效用和可读性，为了解决这个问题，这里引入NL水印技术（Natural Language watermarking technique）。该技术可以通过语义或句法操作将所有权水印隐形地嵌入到普通文本中,虽然我们的攻击目标与NL水印有本质的不同，但我们可以借用它的思想来构造对抗样本。实际上，扰动可以看作是一种水印，并以类似的方式嵌入到样本中。 ​ 在这里，我们拓展这个思路，在样本中插入Presupposition(读者熟知的模糊短语)和 semantically empty phrases（可有可无的短语），有没有他们，在读者看来，原文的意思不会改变。 ​ 总的来说，我们考虑将各种HTPS组合成一个语法单元后再嵌入到文本中，新的单元可以是生成的可有可无的资料，或者甚至是不会改变文本原意的伪造的资料。 ​ 特别的，通过互联网搜索或者查找一些数据集，我们可以找到与插入点很相关的资料，包括一些期望的目标分类的HTPs。 ​ 由于我们不能总是找到合适的HTPs，所以提出一个新概念——伪造的事实（forged fact），也就是插入很难证伪的HTPs。例如： ​ 此外，我们排除了伪造的事实，这些事实可以通过检索他们在网上的相反证据而被否认。 3.3.2 Modification Strategy（修改策略）： ​ Moidfication就是轻微修改一些HSP。 ​ 为了让修改不被人类观察者发现，我们采用了typo-based watermarking 技术。具体的说，一个HSP可以通过两种方式来被修改： ​ 1. 从相关的语料库中选择常见的拼写错误来替换它； ​ 2. 把它的一些字符修改成类似的外观（例如小写字母'l'与阿拉伯数字‘1’很像）。 ​ ​ 由上图可以看出，这种方式对分类结果的扰动是巨大的。 3.3.3 Removal Strategy（移除策略）: ​ 移除策略单独使用也许并不能足够有效地影响预测结果，但是可以很大程度上降低原始预测类型的置信度。 ​ 由上图可以看出，移除'British'可以导致原始预测类型的置信度下降了35%。 3.3.4 Combination of Three Strategies: ​ 如图6所示，单靠去除策略改变输出分类往往是困难的。但是，通过与其他策略相结合，可以避免对原文进行过多的修改或插入。在实践中，我们常常结合以上三种策略来制作微妙的对抗样本。 ​ 以图7为例，通过去除一个HSP、插入一个伪造事实和修改一个HSP，可以成功地改变输出分类，但单独应用上述任何扰动都失败。具体来说，删除、插入和修改仅使置信度分别下降27.3 %、17.5 %和10.1 %，保持预测类不变。 4. Black-Box-Attack: 暂略 5. Evaluation： 5.1 我们的方法能否执行有效的源/目标误分类攻击? ​ 答：在众多测试集中，只有DBpedia ontology数据集是一个多分类数据集，故我们在其中随机选取了一些样本： 5.2 所生成的对抗样本能否避免被人类观察者认出来，并同时保持其功能性？ 答：我们找了23个学生。他们对项目不了解，然后每个人给20个文本，其中一半是加扰的。让他们分到14个类中，如果他们觉得哪个文本不对劲，让他们指出来。 ​ 他们总的分类正确率是94.2%，10个对抗样本的正确率是94.8%。所以实用性还是有的。 ​ 他们标注出了240项修改处，其中12项符合真实的修改。但实际上我们做了594处修改。 5.3 我们的方法足够有效吗？ 答：实验中计算梯度和找HTPs花了116小时。14个类的HTPs每个类花了8.29小时。对所有的adversarial示例只执行一次计算。制作一个对抗性的样品大约需要10到20分钟。对于对手来说，获得理想的对抗样本是可以接受的。实际上，她或他愿意花更多的时间来做这件事。 6. Realted Works: ​ 可以做的方向：1.自动生成对抗样本；（然而，Papernot等人(Papernot et al. 2016a)提出了一种基于雅可比矩阵的数据集增强技术，该技术可以在不访问其模型、参数或训练数据的情况下，在有限对输入输出的基础上，为目标dnn提供替代模型。作者还表明，使用替代模型也可以有效地制作对抗样本，以攻击目标DNN。）2.迁移、黑盒攻击； ​","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"AD","slug":"AD","permalink":"http://example.com/tags/AD/"},{"name":"NLP","slug":"NLP","permalink":"http://example.com/tags/NLP/"},{"name":"DNN","slug":"DNN","permalink":"http://example.com/tags/DNN/"}],"author":"Shaw"},{"title":"Black-Box Attacks against RNN based Malware Detection Algorithms","slug":"【论文阅读】Black-Box Attacks against RNN based Malware Detection Algorithms","date":"2021-09-03T06:08:27.105Z","updated":"2022-07-16T02:09:39.316Z","comments":true,"path":"2021/09/03/【论文阅读】Black-Box Attacks against RNN based Malware Detection Algorithms/","link":"","permalink":"http://example.com/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Black-Box%20Attacks%20against%20RNN%20based%20Malware%20Detection%20Algorithms/","excerpt":"【论文阅读】Black-Box Attacks against RNN based Malware Detection Algorithms 时间：2017 作者： Weiwei Hu 北京大学 ​ Ying Tan 北京大学 Abstract： ​ 1. 原文： ​ 最近的研究表明，基于机器学习的恶意软件分类算法在面对对抗样本攻击时表现的十分脆弱。这些工作主要集中于那些利用了混合维度的特征的追踪算法，但一些研究者已经开始使用RNN，基于API特征序列来辨识恶意软件。 ​ 这篇文章提出了一种用于生成对抗样本序列的原创算法，它被用于攻击基于RNN的恶意软件分类系统。对于攻击者来说，通常，知晓目标RNN的内部结构和权重是很难的。于是一个替代的用于近似目标RNN的RNN模型就被训练了出来，接着我们利用这个RNN来从原始序列输入中生成对抗样本序列。 ​ 权威结果表明基于RNN的恶意软件分类算法不能追踪大多数我们所生成的恶意对抗样本，这意味着我们生成的模型可以很有效的规避追踪算法。 ​ 2. 总结： ​ 一个对基于RNN的恶意样本分类器的灰盒攻击，有三个RNN，受害者RNN（源RNN），替代RNN，对抗样本生成RNN。","text":"【论文阅读】Black-Box Attacks against RNN based Malware Detection Algorithms 时间：2017 作者： Weiwei Hu 北京大学 ​ Ying Tan 北京大学 Abstract： ​ 1. 原文： ​ 最近的研究表明，基于机器学习的恶意软件分类算法在面对对抗样本攻击时表现的十分脆弱。这些工作主要集中于那些利用了混合维度的特征的追踪算法，但一些研究者已经开始使用RNN，基于API特征序列来辨识恶意软件。 ​ 这篇文章提出了一种用于生成对抗样本序列的原创算法，它被用于攻击基于RNN的恶意软件分类系统。对于攻击者来说，通常，知晓目标RNN的内部结构和权重是很难的。于是一个替代的用于近似目标RNN的RNN模型就被训练了出来，接着我们利用这个RNN来从原始序列输入中生成对抗样本序列。 ​ 权威结果表明基于RNN的恶意软件分类算法不能追踪大多数我们所生成的恶意对抗样本，这意味着我们生成的模型可以很有效的规避追踪算法。 ​ 2. 总结： ​ 一个对基于RNN的恶意样本分类器的灰盒攻击，有三个RNN，受害者RNN（源RNN），替代RNN，对抗样本生成RNN。 1. Introduction: 现有的基于N机器学习的恶意软件追踪算法主要将程序表现为固定维度的特征向量，然后将其分类为无害程序和恶意软件； 举例，利用API的调用序列，或者不被调用的API序列进行分类； 【11】展现了，基于固定维度特征来进行恶意样本分类的算法，面对对抗样本的攻击是脆弱的； 最近也有利用RNN进行恶意样本追踪与分类的，RNN的输入就是API序列。 2. Adversarial Examples: ​ 一些其它的针对序列的对抗样本攻击： Nicolas Papernot, Patrick McDaniel, Ananthram Swami, and Richard Harang. Crafting adver\u0002 sarial input sequences for recurrent neural networks. In Military Communications Conference, MILCOM 2016-2016 IEEE, pages 49–54. IEEE, 2016. Kathrin Grosse, Nicolas Papernot, Praveen Manoharan, Michael Backes, and Patrick McDaniel. Adversarial perturbations against deep neural networks for malware classifification. arXiv preprint arXiv:1606.04435, 2016. 4. Attacking RNN based Malware Detection Algorithms 5. 实验 ​ Adam 用于训练所有模型； ​ LSTM由于其在处理长序列的优秀表现，也被应用在实验的所有RNN中。 5.1 数据集： ​ 来源：https://malwr.com/ （一个恶意样本分析网站，爬取180个项目，该网站可以分析用户上传的项目，并给出其API序列，网站中70%的项目都是恶意样本） ​ 数据集划分：为了模拟真实的测试环境，数据集划分如下：（30%+10%）用于生成RNN，（30%+10%）用于受害者RNN，20%用于测试。 5.2 受害者RNN： ​ 尝试了不同模型： ​ 结论如下： 与LSTM相比，BiLSTM不能提升模型的分类表现； 与Average-Pooling相比，注意力机制的效果更好； 5.3 生成（对抗样本）RNN测试结果： ​ 介绍参数规范： The hyper-parameters of the generative RNN and the substitute RNN were tuned separately for each black-box victim RNN. The learning rate and the regularization coeffificient were chosen by line search along the direction 0.01, 0.001, et al.. The Gumbel-Softmax temperature was searched in the range [1, 100]. Actually, the decoder length L in the generative RNN is also a kind of regularization coeffificient. A large L will make the generative RNN have strong representation ability, but the whole adversarial sequences will become too long, and the generative RNN’s size may exceed the capacity of the GPU memory. Therefore, in our experiments we set L to 1. ​ ​ 给出实验结果： 对于所有RNN模型，攻击都十分有效； 于LSTM的攻击效果最差，故替代RNN对LSTM的拟合效果并不好； 训练集与测试集的测试效果差别不大， 模型泛化能力强； 即使更换了模型与训练数据集，对抗样本仍效果很好。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"AD","slug":"AD","permalink":"http://example.com/tags/AD/"},{"name":"Malware Classifiers","slug":"Malware-Classifiers","permalink":"http://example.com/tags/Malware-Classifiers/"},{"name":"RNN","slug":"RNN","permalink":"http://example.com/tags/RNN/"}],"author":"Shaw"},{"title":"Automatically Evading Classififiers----A Case Study on PDF Malware Classififiers","slug":"【论文阅读】Automatically Evading Classififiers----A Case Study on PDF Malware Classififiers","date":"2021-09-03T06:08:27.103Z","updated":"2021-09-03T06:23:11.007Z","comments":true,"path":"2021/09/03/【论文阅读】Automatically Evading Classififiers----A Case Study on PDF Malware Classififiers/","link":"","permalink":"http://example.com/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Automatically%20Evading%20Classififiers----A%20Case%20Study%20on%20PDF%20Malware%20Classififiers/","excerpt":"","text":"【论文阅读】Automatically Evading Classififiers----A Case Study on PDF Malware Classififiers 时间：2016 作者：Weilin Xu, Yanjun Qi, and David Evans 弗吉尼亚大学 会议：NDSS（ccf_B类） 总结： 白盒黑盒？ 黑盒攻击，需要知道生成样本在目标模型中的输出（分类分数）和目标模型所使用的特征（粗略知道）； 针对什么目标？ 仅仅使用表层特征的分类器； 攻击方法？ 3.1 如何制造对抗样本？ ​ 使用遗传算法（GP-BASED）进行随机扰动 3.2 如何判别对抗样本的恶意能力？ ​ 使用oracle Abstract: ​ 在本文，我们提出了一个一般化的方法来检验分类器的鲁棒性，通过在两个PDF恶意样本分类器，PDFrate和Hidost上来检验。其关键就是随机控制一个恶意样本来找到一个对抗样本。 ​ 我们的方法可以自动地对500个恶意样本种子中找到对于两个PDF分类器的对抗样本，我们的结果提出了一个严重的疑问，基于表面特征的分类器在面对对抗样本时是否还有效？ 1. Introduction: ​ 主要贡献： 1. 提出了一个一般化的方法用于自动寻找分类器的对抗样本； 2. 制作了一个原型系统用于自动生成对抗样本； 3. 我们的系统在对500个恶意样本种子寻找对抗样本的过程中，达到了100%的准确率。 2. Overview： 2.1 Finding Evasive Samples： ​ 整体思路： ​ ​ oracle用于判断一个样本是否具有恶意行为； 3. PDF Malware and Classifiers 3.1 PDFmalware: ​ PDF文件的整体结构： ​ ​ 早些的PDF恶意样本一般使用JavaScript嵌入，用户双击打开时出发执行恶意脚本。 ​ 因为不是所有的PDF恶意样本都是嵌入了JavaScript代码，最近的一些PDF恶意分类器就着重于PDF文件的结构化特征。在本文，我们的目标就是攻击这些有代表性的基于文件结构化特征的分类器。 3.2 Target Classififiers： ​ PDFrate：一个使用随机森林算法的分类器。 ​ Hidost:一个SVM分类器。 ​ 4. Evading PDF Malware Classifiers： 5. Experiment: 5.1 Dataset: ​ 5.2 Test： ​","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"AD","slug":"AD","permalink":"http://example.com/tags/AD/"},{"name":"Malware Classifiers","slug":"Malware-Classifiers","permalink":"http://example.com/tags/Malware-Classifiers/"},{"name":"PDF","slug":"PDF","permalink":"http://example.com/tags/PDF/"}],"author":"Shaw"},{"title":"AD nlp Survey","slug":"【论文阅读】AD nlp Survey","date":"2021-09-03T06:08:27.101Z","updated":"2022-07-16T02:09:27.229Z","comments":true,"path":"2021/09/03/【论文阅读】AD nlp Survey/","link":"","permalink":"http://example.com/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91AD%20nlp%20Survey/","excerpt":"【论文阅读】AD nlp Survey 作者：Wei Emma Zhang（阿德莱德大学，澳大利亚） ​ QUAN Z. SHENG（麦考瑞大学，澳大利亚） ​ AHOUD ALHAZMI（麦考瑞大学，澳大利亚） ​ 李晨亮（武汉大学，中国） 1. 关键词：DNN，对抗样本，文本数据（textual data），NLP 2. 摘要： 传统对抗样本基本都针对计算机视觉领域； 本调查提供针对基于DNNs的NLP对抗样本攻击； 由于CV与NLP本身不同，方法不能直接移植； 集成了截止2017年所有的相关成果，综合性地总结，分析，讨论了40个代表性工作； 简单介绍了CV和NLP相关知识。","text":"【论文阅读】AD nlp Survey 作者：Wei Emma Zhang（阿德莱德大学，澳大利亚） ​ QUAN Z. SHENG（麦考瑞大学，澳大利亚） ​ AHOUD ALHAZMI（麦考瑞大学，澳大利亚） ​ 李晨亮（武汉大学，中国） 1. 关键词：DNN，对抗样本，文本数据（textual data），NLP 2. 摘要： 传统对抗样本基本都针对计算机视觉领域； 本调查提供针对基于DNNs的NLP对抗样本攻击； 由于CV与NLP本身不同，方法不能直接移植； 集成了截止2017年所有的相关成果，综合性地总结，分析，讨论了40个代表性工作； 简单介绍了CV和NLP相关知识。 ### 3.Introduction: 简单介绍了对抗样本； 关于对抗样本的研究可以简单分为三类： ① 通过使用微小扰动来欺骗DNN，以此来评估它； ② 刻意改变DNN的输出； ③ 检测DNN中过敏感和过迟钝的点，寻找防御攻击的方法。 ==不能直接使用基于CV的对抗样本生成方法的原因：== 直接将对图像攻击的对抗样本生成方法应用到文本上，将得到毫无意义的词语和句子片段。这是因为在对图像的对抗样本生成中，即使略微改变每个像素的灰度，肉眼也可以识别原来的图像；但是对于文本串来说，即使改变一个字母，语句的语义也将完全不同或出错。 ==相关研究：== Reference [i] = 【i】 ​ ① 【9】：对针对不同类别的机器学习系统的攻击与防御做了综合性概述，提出了一种用于辨识和分析这些攻击的分类方法，并将将这些攻击应用到基于机器学习的应用上来证明这些攻击或者防御手段的有效性。例如，一个统计垃圾邮件过滤器。 ​ ② 【13】：作者俯瞰了近十年（2008-2018）对抗样本攻击的发展史，聚焦点在于CV和网络空间安全。对非深度学习算法和深度学习算法都做了介绍，也从安全的角度仔细分析了这些攻击和防御手段的影响。 ​ ③ 【79】：与【13】阐述的问题类似，从数据驱动的角度。 ​ ④ 【154】：聚焦于对抗样本在深度学习模型上的使用。介绍了最近的几种不同的在应用上对DNN的攻击，同时全面调查了防御方法。但是，其只讨论了对抗样本在图像分类和物品识别上的攻击。 ​ ⑤ 【2】：详细阐述了对抗样本在CV上的应用，是一篇应用程序主导的调查。 ​ ⑥ 【35】：从安全的角度阐述了对抗样本的防御手段。（不仅从机器学习算法或者神经模型上，从所有与安全相关的应用上阐述对抗样本防御）作者发现现有的与防御相关的安全工作缺乏清晰的对攻击如何与真实安全问题相关联的动机和解释，以及这些攻击和防御如何被有意义地衡量，故提出了一种分类方法用于衡量这些。 4. Overview （对抗样本攻击 and 深度学习在NLP中的应用）: 给出了DNN，Perturbations，Adversarial Examples的定义； 介绍了Treat Model： 2.1 Granularity（颗粒度）:攻击的颗粒度指的是对抗样本生成的数据等级，例如对图像数据通常是像素，对文本数据就是字母，单词，句子嵌入等级。 2.2 Motivation（动机）：生成对抗样本的动机通常有两种，攻击和防御：1.攻击的目的是检验DNN的健壮性；2. 防御的目的是使DNN更加稳固，第五部会给出更详细的讲解。 介绍了Measurements（评价adversarial attack的方法）： 3.1 控制扰动（Perturbation Constraint）： ​ 根据前面所述，扰动 η 应该不影响样本原来的真实分类，故如果一个分类器是理想的，那么扰动后的样本应不影响其分类结果； η 同时也不能太小，以避免对目标DNN没有影响。在理想情况下，有效扰动是在一定范围内最有效果的噪声。 ​ 【132】首次在图像对抗样本攻击中约束了(x + η) ∈ [0, 1]n 的范围，以保证对抗样本与原始数据有着相同的像素等级。 ​ 【40】简化了问题的解决方法，并使用了无穷范数来限制扰动，==这受到直觉的启发，即一个不改变任何特定像素的扰动量超过一定量 ϵ 就不能改变输出类。==（PS:WHY？）无穷范数在图像/物品分类识别任务中是足够有效的，其他的范数，例如L0和L2范数，过去被用于在对CV的DNN攻击中限制扰动。在文本对抗样本攻击中，这有所不同，第3.3节会给出更多细节。 3.2 评估攻击的有效性（Attack Evaluation）： ​ 对抗样本攻击旨在降低DNNs的性能，因此，评估攻击的有效性是基于不同任务的性能指标。例如，分类任务中有评价指标准确度，F1-score，AUC-score。在本文中，我们将针对不同NLP的评价标准作为超范围内容，并建议读者参考特定的信息。 ​ ==以上是总体分类与信息== ​ ==以下是深度学习在NLP中的应用== ​ 除了向前传播的神经网络和CNN，RNN及其变式由于其天然的处理序列的能力，也被用于NLP中。 近几年深度学习对NLP的重大影响： 1.1 序列学习（sequence-to-sequence learning） 1.2 注意力机制（attention mechanism） 1.3 强化学习（reinforcement learning）和生成模型（generative models） 具体详细的神经网络在NLP中的应用见【100】，【152】 Feed-Forward Networks: 缺点：不能很好地处理对于词语顺序很重要的文本序列，因为其并不记录元素的顺序。为了评价其健壮性，往往针对专门设计的前馈网络生成对抗实例，【3】，【43】，【44】作者研究了指定的恶意软件检测模型。 CNN： ​ CNN识别本地预测因子并将它们组合在一起，为输入生成一个固定大小的向量，该向量包含数据中最重要或最重要的信息方面。 ​ CNN对顺序敏感，因此，它擅长做计算机视觉，随后被广泛用于NLP应用。 ​ 卷积操作被简直在词的序列方向上，而不是词的嵌入。 ​ 两个经典工作：1. 【59】使用CNN和Word2Vec进行句子分类 2.【156】使用CNN和热独编码进行文本分类。 RNN： ​ 主要介绍RNN及其变式（LSTM，GRU） Seq2Seq（sequence-to-sequence learning）： ​ Seq2Seq模型具有优越的能力，能够为具有编码器-解码器结构的给定序列信息生成另一个序列信息. ​ 通常，一个Seq2seq由两个RNN结构组成，一个用于编码，一个用于解码。VHRED是一个最近很受欢迎的Seq2seq模型，它利用子序列之间的复杂依赖关系生成序列。 ​ 【24】是最初的使用Seq2seq模型的神经机器翻译模型（NMT）之一； ​ 【63】是一个最近提出的 seq2seq NMT模型，是此领域的benchmark； ​ 【22,30,98,127】有对其的攻击。 Attention Models： ​ 注意力机制最初被设计用来克服seq2seq模型中对长序列编码的问题。 ​ 注意力允许解码器回溯源序列的隐藏状态，然后，隐藏状态提供一个加权平均作为解码器的额外输入。 Reinforcement Learning Models： ​ 强化学习通过在代理执行离散动作后给予奖励来训练代理，在NLP中，强化学习框架通常由一个代理（DNN），一个策略部分（用于指导动作）和奖励组成。 ​ 代理基于策略做出一个动作（例如预测序列中下一个单词的位置），然后相应地更新其内部状态，直到到达序列的末尾，在这里奖励已经被计算完成。 ​ 强化学习需要正确处理每一步的动作和状态，这可能会限制模型的表现力和学习规模。但它在面向任务的对话系统中获得了很多好处，因为它们在决策过程共享着同一根本原则。 Deep Generative Models（深层生成模型）： ​ 近些年，两种深层生成模型获得了很多关注：Genera\u0002tive Adversarial Networks (GANs) 【39】 and Variational Auto-Encoders (VAEs) ​ 其可以在潜在空间中生成与真实数据分厂相似的数据样例，在NLP领域，它们被用来生成文本。 ​ 8.1 GANS: ​ Gans由两个对抗网络组成：生成器（generator）和鉴别器（discriminator）。鉴别器的作用是鉴别真实样本和生成样本，生成器的作用是生成很真实的，用于欺骗鉴别器的样本。 ​ Gan使用min-max loss function来同步训练两个神经网络。 ​ 8.2 VAES： ​ Vaes由编码器（encoder）和生成器（generator）组成。编码器的作用是对输入编码为潜在空间，生成器的作用是从潜在空间中生成样本。 深度模型都不是很好训练，这个缺点阻碍了其在真实世界的应用中的广泛应用，尽管他们已经被用于生成文本，但目前没有工作去用对抗样本检验它们的健壮性。 5. From image to text: 一. 构造对抗样本： 、L-BFGS: ​ Szegedy【132】等人首次证明了可以通过对图像添加小量的人类察觉不到的扰动误导深度神经网络图像分类器做出错误的分类。他们首先尝试求解让神经网络做出误分类的最小扰动的方程。作者认为，深度神经网络所具有的强大的非线性表达能力和模型的过拟合是可能产生对抗性样本原因之一。 FGSM（Fast Gradient Sign Method）： ​ L-BFGS很有效但成本高昂，这使Goodfellow【40】等人找到一个简化问题的方法。 JSMA（Jacobian Saliency Map Adversary）： ​ 与FGSM利用梯度攻击不同，Papernot【105】等人使用forward derivatives（远期衍生物？）生成对抗样本。这个方法通过使用其雅克比矩阵来评估神经模型对每个输入部分的输出敏感性。 DeepFool： ​ DeepFool是一种迭代的L2正则化算法，作者先假设神经网络是线性的，因此可以使用一个超平面来分离类。作者简化了问题并且基于以上假设找到了问题最优解，并构建了对抗样本、 ​ 为了解决神经网络是非线性的事实，作者重复他们的步骤直到一个真正的对抗样本被生成了。 PS：正则化：(23 封私信 / 54 条消息) 机器学习中常常提到的正则化到底是什么意思？ - 知乎 (zhihu.com) Subsititute Attack： ​ 前面四中攻击方式都是白盒攻击， Papernot【104】等人提出了黑盒攻击策略，他们训练了一个与目标模型决策边界相似的替代模型，对此替代模型进行白盒攻击，生成相应对抗样本。 ​ 在生成对抗样本的过程中，他们使用了FSGM和JSMA。 GAN-like Attack： ​ 这是一种通过深度生成模型的黑盒攻击方法，Zhao【157】等人首先基于数据集 X 训练了一个生成模型WGAN，WGAN可以生成与X分布相同的数据点。 二. 对图像DNN攻击与对文本DNN攻击的对比： ​ 1. 二者的主要不同： ​ 1.1 离散与连续输入： ​ 图像输入是连续的而文本输入是离散的，在图像输入中，通常使用Lp来衡量原始数据点和扰动点的距离，但是由于文本输入是离散的，很难定义文本上的扰动大小（==为什么？==）。这就需要构造对文本扰动的衡量方法。还有一种方式是将文本输入当做连续值，然后应用CV方法，在3.3节上将会详细讨论。 ​ 1.2 可察觉与不可察觉： ​ 与图像相比，文本数据即使更改一个字母也会造成很大变化，故即使做很小的扰动，也可以被很明显的察觉到。 ​ 1.3 有语义和无语义： ​ 原理同上，在文本中做很小的改动往往会极大地影响到文本的语法和语义信息。 ​ 基于以上不同，目前主流对文本DNN的攻击有两种：1. 调整图像DNN的攻击方法，添加额外限制；2. 使用新技术提出一个新方法。 三. 向量化文本输入 and 扰动的衡量方法 三种向量化文本输入的方法： 1.1 基于计数的编码（Word-Count-based Encoding）： ​ ① BOW（Bag-of-words）方法，将一个文档中出现的词语编号为向量的0,1,2.....i维度，每个维度的值代表词语出现的次数。（缺点：不能记住词语顺序） ​ ② Term frequency-inverse document frequency (TF-IDF) ，具体见： TF-IDF算法介绍及实现_Asia-Lee-CSDN博客_tf-idf ​ 1.2 热独编码（One-hot Encoding）: ​ 具体介绍略。 ​ 由于普通顺序编码的值存在大小关系，当模型得到输入后会将其当做实际值来处理，这就使得原本平行的数据有了大小关系，独热编码巧妙地解决了这个问题，使得所有单词或者字母低位平等。 ​ 1.3 稠密编码： ​ Word2Vec使用连续BOW模型和skip-gram 模型来做代码嵌入。 ​ 一个潜在的假设是，出现在相似语境下的词语有着相似的含义。 词嵌入在一定程度上缓解了文本数据向量化的离散性和数据稀疏性问题【36】，词嵌入的扩展如doc2vec和paragraph2vec【69】将句子/段落编码为稠密向量。 扰动的衡量方法： 2.1 基于范数的方法（Norm-based measurement）： ​ 直接使用范数需要输入数据是连续的。一个解决方法是使用连续且稠密的表示方法（如嵌入），但这通常会得到无意义的文本。 2.2 基于语法和句法的方法（Grammar and syntax related measurement）： ​ 通过确认文本语法的正确性来保证对抗样本不易被识别。 ​ 可以使用Perplexity【91】，Paraphrase（4.3.3）确保对抗样本的有效性。 2.3 基于语义保持的方法（Semantic-preserving measurement）： ​ ① 计算欧拉距离: ​ ② 计算Cosine Similarity（余弦相似度）： ​ 2.4 基于编辑距离的方法： ​ 编辑距离（Edit Distance），又称Levenshtein距离，是指两个字串之间，由一个转成另一个所需的最少编辑操作次数。许可的编辑操作包括将一个字符替换成另一个字符，插入一个字符，删除一个字符。一般来说，编辑距离越小，两个串的相似度越大。 ​ 不同定义使用不同的转换操作。 2.5 基于Jaccard相似系数的方法： ​ Jaccard相似系数定义见百度百科。 ​ 就是把两个集合的交集除以两个集合的并集，简单地看集合中的元素是不是大量相同。 6. Attacking Neural Models in NLP: 常见攻击方法： 白盒，黑盒...... ​ 提供了数据集来源，但没有提供生成对抗样本的数据集，所提供的的数据集仅用于评估攻击效果。 7. Defense: 背景：两种在DNN中常用的防御方法：1. 对抗训练(adversarial training) 2. 知识蒸馏（knowledge distillation）. Knowledge distillation：【经典简读】知识蒸馏(Knowledge Distillation) 经典之作 - 知乎 (zhihu.com) 一. 对抗训练 数据增强（Data Augmentation）： ​ 数据增强将原始数据集加上对抗样本一起，在训练的过程中让模型见到更多数据，数据增强常被用来对抗黑盒攻击，实现的方式是通过在被攻击的DNN上使用对抗样本增加额外的epoch。 ​ 【54】证明了这种方法是有效的，但仅仅对同一对抗样本有效（数据增强中的样本与测试对抗样本） ​ 【142】也提出了类似的观点 ​ 【56】作者提出了3种生成更多具有不同特征的数据的方法 ​ 【12】作者提出了一种新的数据增强的方法，它将平均字符嵌入作为一个词表示，并将其纳入输入。这种方法本质上对字符的置乱不敏感，例如交换、mid和Rand，因此可以抵抗这些置乱攻击引起的噪声。但是，这种防御方法对不是针对字符顺序的扰乱不起作用。 模型正则化（Model Regularization）： 模型正则化将生成的对抗样本实例作为正则化器： 模型正则化_少年吉的博客-CSDN博客_模型正则化 正则化( Regularization)的目的在于提高模型在未知测试数据上的泛化力,避免参数过拟合。 健壮性最优化方法（Robust Optimization）： Madry【84】等人将DNN学习问题转化为了一个包含内非凹最大化问题(攻击)和外非凸最小化问题(防御)的健壮性优化问题。 二. 知识蒸馏 ​ 详见论文和博客。 8.Discuss and Open issues 可察觉性（Perceivability）： 见前文 可转移性（Transferability）： no-tatgeted攻击的可转移性更强。 可转移性可以在三个地方体现： ​ 2.1 同样的架构，不同的数据； ​ 2.2 同样的应用场景，不同的架构； ​ 2.3 不同的架构，不同的数据。 尽管现有的工作囊括了以上三种情况，但对抗样本攻击的可移植性效果仍不好，需要更多的工作。 自动化（Automation）： ​ 一些工作可以做到对抗样本的自动生成，而另一些则不行。 ​ 在白盒攻击中，利用DNN的损失函数可以自动识别文本中受影响最大的点(如字符、词)，以此做到在文本中自动化。 ​ 在黑盒攻击中，一些攻击例如替代训练（substitution train）可以训练出一个替代用模型，对其进行白盒攻击，也可以实现自动化。但是大多数对抗样本的生成都是人工生成。【54】会关联人工选择的无意义的文本段落来欺骗阅读理解系统，以此来发现DNN的脆弱性。很多研究工作跟随【54】，其目的不是实际攻击，而是更多的在检测目标网络的健壮性上，这些人工工作是耗时且不切实际的。我们相信在未来更多的努力会用来克服这个困难。 新架构（New Architectures）： ​ 尽管大多数普通的文本DNN都注意到了对抗样本攻击，但是很多DNN并没有被攻击过。例如GANS与VAES，它们被用作生成文本。深度生成模型需要更复杂的技巧去训练，这就可以解释为什么这些技术忽略了对抗样本攻击。未来的工作可能考虑对这些DNN进行对抗样本攻击。 ​ 注意力机制（Attention Mechanism）目前是大多数序列模型的标准组成部分，但是没有工作去检验注意力机制本身。故可能的攻击工作要么攻击包含注意的整体系统，要么利用注意分数来识别干扰词【14】。 迭代 VS 一次性（Iterative versus One-of）： ​ 迭代攻击：效果好，耗时长； ​ 一次性攻击：效果略差，耗时短。 ​ 在设计攻击方法时，攻击者需要仔细考虑效果与效率的平衡。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"AD","slug":"AD","permalink":"http://example.com/tags/AD/"},{"name":"NLP","slug":"NLP","permalink":"http://example.com/tags/NLP/"}],"author":"Shaw"},{"title":"A novel Android malware detection system-adaption of flter‑based  feature selection methods","slug":"【论文阅读】A novel Android malware detection system adaption of flter‑based  feature selection methods","date":"2021-09-03T06:08:27.099Z","updated":"2022-07-16T02:09:31.345Z","comments":true,"path":"2021/09/03/【论文阅读】A novel Android malware detection system adaption of flter‑based  feature selection methods/","link":"","permalink":"http://example.com/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91A%20novel%20Android%20malware%20detection%20system%20adaption%20of%20flter%E2%80%91based%20%20feature%20selection%20methods/","excerpt":"【论文阅读】A novel Android malware detection system: adaption of flter‑based feature selection methods 时间：2021 作者： Durmuş Özkan Şahin Oğuz Emre Kural · Sedat Akleylek Erdal Kılıç 总结： 二分类，静态代码检测； 创新点主要在特征提取（已经有的方法+文本分类的方法）上，分类器用的各种现成的方法； Abstract: ​ 在本研究中，提出了一个基于过滤器特征选择方法的，原创的安卓端恶意软件追踪系统。 ​ 该方法是一个在机器学习的基础上的静态安卓恶意软件追踪方法。在所开发的系统中，使用应用程序文件中提取的权限作为特征。八个不同的特征选择方法被用于维度降低，以减少运行时间，提升机器学习算法的效率。 ​ 其中四种方法应用于安卓恶意样本分类，其余四种方法是从文本分类研究中采用的，其从提取特征和分类结果两方面对方法进行了比较，在对结果进行检验时，表明所采用的方法提高了分类算法的效率，可以在本领域中使用。","text":"【论文阅读】A novel Android malware detection system: adaption of flter‑based feature selection methods 时间：2021 作者： Durmuş Özkan Şahin Oğuz Emre Kural · Sedat Akleylek Erdal Kılıç 总结： 二分类，静态代码检测； 创新点主要在特征提取（已经有的方法+文本分类的方法）上，分类器用的各种现成的方法； Abstract: ​ 在本研究中，提出了一个基于过滤器特征选择方法的，原创的安卓端恶意软件追踪系统。 ​ 该方法是一个在机器学习的基础上的静态安卓恶意软件追踪方法。在所开发的系统中，使用应用程序文件中提取的权限作为特征。八个不同的特征选择方法被用于维度降低，以减少运行时间，提升机器学习算法的效率。 ​ 其中四种方法应用于安卓恶意样本分类，其余四种方法是从文本分类研究中采用的，其从提取特征和分类结果两方面对方法进行了比较，在对结果进行检验时，表明所采用的方法提高了分类算法的效率，可以在本领域中使用。 ### 1. Introduction: #### 1.1 如何提取相关特征？ ​ Shabtai (2012)介绍了Andromaly架构，其中包含不同的特征选取方法和分类方法。 ​ Zhao（2015）提出了一个特征选择方法FrequelSel，其基于无害样本和恶意样本的频率特征差异。 ​ Xu （2016）提出了一个新的安卓恶意样本追踪方法ICCdetector，他们使用CFS（Correlation Based Feature Selection）在许多特征向量中做特征提取。 ​ Morales-Ortega（2016）提出了一种可以在恶意软件分析和检测设备上本地运行的方法，他们使用不同的特征选择方法和分类方法进行了对比实验。 ​ Bhattacharya and Goswami (2018) 提出了一种通过通过混合基于community的粗略设置特征选择方法（community-based rough set feature selection method）来进行特征选择的新方法。 ​ Peynirci et al. (2020) 提出了Delta IDF方法，其通过选择具有最高IDF（NLP中的）无害样本和最低IDF的恶意样本来提取特征。在特征提取中使用了字符串，API调用序列，权限等来作为特征。 ​ Ananya et al. (2020) 提出了一种安卓恶意样本追踪的动态分析技术。 ​ Kouliaridis et al. (2021)使用了两个特征选取算法和八个不同的分类器进行了比较试验。 ​ Jung et al. (2021) 在Gini Importance 和 domaind 知识上进行了特征提取。使用了API调用序列和应用权限。 ​ Liu et al. (2021)使用非监督学习进行了安卓恶意样本的特征提取。 #### 1.2 Contribution: ​ 主要贡献： 1. 提出了一个基于过滤器特征选择方法的，原创的安卓端恶意软件追踪系统（静态检查）； 2. 基于文本分类的特征选择方法对现有的属性选择方法进行替代是适应于Android恶意软件检测系统的。因此，不使用所有的权限，而是选择了最具特色的权限，提高了分类算法的性能； 3. 比较给出各度量得到的允许度和分类结果。在检查结果时，所提出的系统使用的特征比现有的检测系统少； 4. 从我们所采用的特征提取方法中得到的结果总体上所得到的特征比其他方法少； 5. 实验结果更好，run的时间更短，分类效果更佳； 6. 一些矩阵与贪婪方法相结合形成各种属性子集。这些创建的属性子集在用大量classifer进行测试时表现出了显著的性能。 2. Preliminaries： 2.1 Feature extraction（如何处理APK文件）： 2.2 Feature selection（提取特征）： ​ 特征选择技术分为三类：flter-based，wrapper-based，embedded methods. ​ 在基于过滤的技术中，就是在所有属性中选择最好的k个属性，而不使用剩余的属性。各种基于统计或信息论的技术被用来寻找最佳的k个特征。 ​ 基于Wrapper的技术在操作上与过滤技术类似，但在搜索策略上，选择是用遗传算法等启发式方法代替统计技术进行的。 ​ 特征选择过程是在机器学习算法的训练阶段进行的。特征选择是通过找到影响在训练阶段创建的模型性能的最佳子集来进行的。 2.3 The proposed Android malware detection system： ​ 3. Experimental settings： 3.1 datasets： ​ 3000恶意样本（VirusShare dataset ），3000无害样本（APKPure） 3.2 Classifcation algorithms 3.3 Performance measure 4. Results and discussions: 4.1 Results of performed experiments: 数据处理： 分类结果（部分）： 总： 与其他方法比较： ​","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Malware Classifiers","slug":"Malware-Classifiers","permalink":"http://example.com/tags/Malware-Classifiers/"},{"name":"Android","slug":"Android","permalink":"http://example.com/tags/Android/"}],"author":"Shaw"},{"title":"A Benchmark API Call Dataset For Windows PE Malware Classification","slug":"【论文阅读】A Benchmark API Call Dataset For Windows PE Malware Classification","date":"2021-09-03T06:08:27.096Z","updated":"2022-07-16T02:09:35.469Z","comments":true,"path":"2021/09/03/【论文阅读】A Benchmark API Call Dataset For Windows PE Malware Classification/","link":"","permalink":"http://example.com/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91A%20Benchmark%20API%20Call%20Dataset%20For%20Windows%20PE%20Malware%20Classification/","excerpt":"【论文阅读】A Benchmark API Call Dataset For Windows PE Malware Classification 作者：Ferhat Ozgur Catak（土耳其） ​ Ahmet Faruk Yazi（土耳其） 时间：2021.2.23 关键词：恶意软件分析，网络空间安全，数据集，沙箱环境，恶意软件分类 1. Abstract ​ 在Windows操作系统中，系统API调用的使用在监控恶意PE程序中是一个很有前途的方法。这个方法被定义为在安全隔离的沙箱环境中运行恶意软件，记录其调用的Windows系统API，再顺序分析这些调用。 ​ 在这里，我们在隔离沙箱中分析了7107个属于不同家族（病毒，后门，木马等）的恶意软件，并把这些分析结果转化为了不同分类算法和方法可以使用的形式。 ​ 首先，我们会解释如何得到这些恶意软件；其次，我们会解释如何将这些软件捆绑至家族中；最后，我们会描述如何使用这些数据集来通过不同的方法实现恶意软件的分类。","text":"【论文阅读】A Benchmark API Call Dataset For Windows PE Malware Classification 作者：Ferhat Ozgur Catak（土耳其） ​ Ahmet Faruk Yazi（土耳其） 时间：2021.2.23 关键词：恶意软件分析，网络空间安全，数据集，沙箱环境，恶意软件分类 1. Abstract ​ 在Windows操作系统中，系统API调用的使用在监控恶意PE程序中是一个很有前途的方法。这个方法被定义为在安全隔离的沙箱环境中运行恶意软件，记录其调用的Windows系统API，再顺序分析这些调用。 ​ 在这里，我们在隔离沙箱中分析了7107个属于不同家族（病毒，后门，木马等）的恶意软件，并把这些分析结果转化为了不同分类算法和方法可以使用的形式。 ​ 首先，我们会解释如何得到这些恶意软件；其次，我们会解释如何将这些软件捆绑至家族中；最后，我们会描述如何使用这些数据集来通过不同的方法实现恶意软件的分类。 ### 2. Introduction #### 2.1 简单介绍了恶意软件 #### 2.2 恶意软件与恶意软件识别之间的竞争 ​ 相互促进 #### 2.3 变形恶意软件（Metamorphic malware） ​ 恶意软件家族里很先进的一种，这种软件可以持续不断的改变自身源代码以此改变自身结构，通过这种方式来改变自身代码特征。还有，这种软件可能还可以通过强度反算（counter-analysis）来识别自身运行的环境，以此来隐藏自身的恶意功能。 ​ 变形恶意软件很难识别。 #### 2.4 恶意软件的识别： ​ 所有恶意软件都会有恶意行为以达成其目的，如果可以很好的分析恶意行为，就可以做成恶意软件的识别与分类。 ​ 恶意软件的识别包括了很多需要解决的问题，例如在汇编中不正确的跳转操作码，PE文本段代码隐藏，代码加密。本研究收集了现有的恶意软件及其变式，例如WannaCry，Zeus，特别是在Github上。 ​ 我们通过在VirusTotal网站上寻找每个恶意软件的哈希值，从而获得了得到了其家族类。 ​ 最后，所有我们记录的行为都是在Cuckoo沙盒环境中运行的。 ​ 我们发现几乎所有恶意软件都会使用很多方法改变其行为，但即使这样，恶意软件还是有一个目标，有一个确定的模式来达到此目标。还有，恶意软件会做出一些不必要的API调用，但其还是可以被一个训练好的分析器识别，因为其行为模式是相同的。 ​ 恶意软件分析被视为网络空间安全的一个分支，其由两方面组成： ##### 1. 静态分析 ： ​ 静态分析可以可以定义为通过执行一个孤立的环境检查可执行文件而不查看实际指令。例如MD5校验和，其通过反病毒检测攻击识别，查找字符串。 ##### 2. 动态分析 ​ 动态分析指运行恶意程序来理解其功能，观察其表现，识别其技术指标。几乎所有的重要行为都包含API调用序列。 ​ 大多数动态分析领域的研究都只关注分类算法，有个基本问题是没有标准的数据集来检查所提出模型的效率。 ​ 我们在Github上分享了我们的数据集：https://github.com/ocatak/malware_api_class ，该数据集包含了基于Cuckoo沙箱的已知恶意软件执行和基于VirusTotal的文件MD5特征分类的原始数据。 3. Methods 3.1 Windows API Calls： ​ 软件安全知识，略 3.2 Cuckoo SandBox ​ 免费软件，高度集成，开源，可以自动分析Winodws,OS X,Linux,Android系统下的恶意文件。 3.3 VirusTotal ​ 可以在线免费分析文件或者URL。其提供了一个API，可以不通过浏览器来提供分析结果，可以自动分析。其以JSON文件的形式提供分析结果，不同反病毒应用引擎和浏览器的分析结果会分开存放。 3.4 数据集生成 ​ 本文的数据集有着简单明了的结构。数据集以CVS格式文件提供来提高互操作性，而且并不需要特定的软件或者库来读取他们。数据由来自不同Github页面的Git命令实施收集，数据集中的每一行都是在沙箱中分析的Windows操作系统的API调用序列。 ​ 数据集的生成过程如下： ​ 1. 沙箱环境准备： ​ 分析机器使用Ubuntu系统，将Cuckoo沙箱安装在其中，分析机运行虚拟服务，Windows操作系统就运行在虚拟服务上，同时关掉防火墙，系统升级。 ​ 2. 分析恶意软件: ​ 虚拟机中同时运行超过20000个恶意软件，应用程序会将每个恶意软件的分析结果写入MongoDB数据库，分析结果中包含恶意软件的行为数据，这些数据都是恶意软件在Win7上的API调用请求。 ​ 3. 处理API调用： ​ 我们在数据集中收集到了342种API调用，这些调用会被以0-341来标记，以此生成一个新数据集。我们使用了该数据集中至少有10个不同API调用的恶意软件的分析结果。 ​ 4. 使用Virus Total公用API分析恶意软件： ​ 作为分析的补充，所有在数据集中的恶意软件也会被Virus Total所分析，通过这种方式，每个恶意软件都会被不同的反病毒引擎所分析，结果会被记录。 ​ 5. 处理分析结果： ​ Virus Total服务使用大约66个不同的防病毒应用程序进行文件分析。利用我们利用这个服务得到的每个研究结果，我们识别了每个恶意软件的家族。通过观察，我们发现对于同一恶意软件，不同的防病毒应用程序给出了不同的结果。此外，观察到并非每一个防病毒应用程序都能检测到一些恶意软件。因此，在检测每一个恶意软件类时，认为它属于所有分析中的大多数类。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"AD","slug":"AD","permalink":"http://example.com/tags/AD/"},{"name":"Malware Classifiers","slug":"Malware-Classifiers","permalink":"http://example.com/tags/Malware-Classifiers/"}],"author":"Shaw"},{"title":"Generic Black-Box End-to-End Attack Against State of the art API Call Based Malware Classifiers","slug":"【论文阅读】Generic Black-Box End-to-End Attack Against State of the art API Call Based Malware Classifiers","date":"2021-09-03T06:08:27.094Z","updated":"2021-10-12T13:26:39.593Z","comments":true,"path":"2021/09/03/【论文阅读】Generic Black-Box End-to-End Attack Against State of the art API Call Based Malware Classifiers/","link":"","permalink":"http://example.com/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Generic%20Black-Box%20End-to-End%20Attack%20Against%20State%20of%20the%20art%20API%20Call%20Based%20Malware%20Classifiers/","excerpt":"","text":"【论文阅读】Generic Black-Box End-to-End Attack Against State of the art API Call Based Malware Classifiers 作者：Ishai Rosenberg 大学：Ben-Gurion University of the Negev 时间：2018.6.4 1. 做了什么？ ​ 对一个通过机器学习训练的，通过API调用来分类恶意软件的分类器的攻击。 ​ 这个攻击可以使分类器不能成功识别恶意软件，并且不改变原有软件的功能。 ​ 实现了GADGET，一个可以直接将二进制恶意软件文件转换为分类器无法检测的二进制文件，并不需要访问文件源代码。 2. 一些概念： 2.1 Machine learning malware classififiers（基于机器学习的恶意软件分类器） ​ 优点：1. 可以自动训练，节省时间； ​ 2. 只要分类器并不是基于指纹特征或者某个特定的特征（如Hash值）来分类，面对不可见威胁时泛化能力较强。 2.2 Adversarial Examples（对抗样本） 对输入样本故意添加一些人无法察觉的细微的干扰，导致模型以高置信度给出一个错误的输出。 可以针对一张已经有正确分类的image，对其进行细微的像素修改，可以在DNN下被错分为其他label。 ​ 样本x的label为熊猫，在对x添加部分干扰后，在人眼中仍然分为熊猫，但对深度模型，却将其错分为长臂猿，且给出了高达99.3%的置信度。 像素攻击：改动图片上的一个像素，就能让神经网络认错图，甚至还可以诱导它返回特定的结果。 改动图片上的一个像素，就能让神经网络认错图，甚至还可以诱导它返回特定的结果 2. 同样，根据DNN，很容易产生一张在人眼下毫无意义的image，但是在DNN中能够获得高confidence的label。 两种EA算法生成的样本，这些样本人类完全无法识别，但深度学习模型会以高置信度对它们进行分类，例如将噪声识别为狮子。 2.2.1： Adversarial examples for API sequences(生成API序列对抗样本与生成图像对抗样本并不同): API序列由长度可变的离散符号组成，但图像可以用固定维度的矩阵表示为矩阵，且矩阵的值是连续的。 对于对抗API序列，其必须验证原始的恶意功能是完整的。 对抗样本的迁移性：针对一种模型的对抗样本通常对另一种模型也奏效，即使这两个模型不是用同一数据集训练的。 2.3 几种攻击方法： White-box attack：白盒攻击，对模型和训练集完全了解。 Black-box attack：黑盒攻击：对模型不了解，对训练集不了解或了解很少。 Real-word attack：在真实世界攻击。如将对抗样本打印出来，用手机拍照识别。 targeted attack：使得图像都被错分到给定类别上。 non-target attack：事先不知道需要攻击的网络细节，也不指定预测的类别，生成对抗样本来欺骗防守方的网络。 mimicry attack: 编写恶意的exploit，该exp模拟良性代码系统调用的痕迹，因为能够逃逸检测。 disguise attack: 仅修改系统调用的参数使良性系统调用生成恶意行为 。 No-op attack: 添加语义的no-ops-系统调用，其没有影响，或者是不相干的影响，即，打开一个不存在的文件。 Equivalence attack: 使用一个不同的系统调用来达到恶意的目的. 2.4 decision boundary(决策界限) 2.5 end-to-end: 2.6 结果分类： 虑一个二分问题，即将实例分成正类（positive）或负类（negative）。对一个二分问题来说，会出现四种情况。如果一个实例是正类并且也被 预测成正类，即为真正类（True positive）,如果实例是负类被预测成正类，称之为假正类（False positive）。相应地，如果实例是负类被预测成负类，称之为真负类（True negative）,正类被预测成负类则为假负类（false negative）。 列联表如下表所示，1代表正类，0代表负类。（预测正确：true，预测是正类：positive） 预测 1 0 合计 实际 1 True Positive（TP） False Negative（FN） Actual Positive(TP+FN) 0 False Positive（FP) True Negative(TN) Actual Negative(FP+TN) 合计 Predicted Positive(TP+FP) Predicted Negative(FN+TN) TP+FP+FN+TN 从列联表引入两个新名词。 其一是真正类率(true positive rate ,TPR), 计算公式为 TPR=TP/ ( TP+ FN)，刻画的是分类器所识别出的 正实例占所有正实例的比例。 另外一个是负正类率(false positive rate, FPR),计算公式为 FPR= FP / (FP + TN)，计算的是分类器错认为负类的正实例占所有负实例的比例。 还有一个真负类率（True Negative Rate，TNR），也称为specificity,计算公式为TNR= TN/ ( FP+ TN) = 1 - FPR。 3. 如何实现？ 一些问题：程序调用API的过程；","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"AD","slug":"AD","permalink":"http://example.com/tags/AD/"},{"name":"Malware Classifiers","slug":"Malware-Classifiers","permalink":"http://example.com/tags/Malware-Classifiers/"}],"author":"Shaw"},{"title":"Shaw's blog","slug":"Welcome","date":"2021-09-03T05:50:00.118Z","updated":"2023-02-20T05:03:18.440Z","comments":true,"path":"2021/09/03/Welcome/","link":"","permalink":"http://example.com/2021/09/03/Welcome/","excerpt":"","text":"论文阅读/技术学习/比赛积累","categories":[],"tags":[],"author":"Shaw"}],"categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"},{"name":"Project","slug":"Project","permalink":"http://example.com/categories/Project/"},{"name":"Code","slug":"Code","permalink":"http://example.com/categories/Code/"},{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"},{"name":"Reproduce","slug":"Reproduce","permalink":"http://example.com/categories/Reproduce/"},{"name":"Kaggle","slug":"Kaggle","permalink":"http://example.com/categories/Kaggle/"},{"name":"Something","slug":"Something","permalink":"http://example.com/categories/Something/"},{"name":"Book","slug":"Book","permalink":"http://example.com/categories/Book/"}],"tags":[{"name":"Fuzzing","slug":"Fuzzing","permalink":"http://example.com/tags/Fuzzing/"},{"name":"WASM","slug":"WASM","permalink":"http://example.com/tags/WASM/"},{"name":"Symbolic Execution","slug":"Symbolic-Execution","permalink":"http://example.com/tags/Symbolic-Execution/"},{"name":"Vulnerability","slug":"Vulnerability","permalink":"http://example.com/tags/Vulnerability/"},{"name":"AEG","slug":"AEG","permalink":"http://example.com/tags/AEG/"},{"name":"Klee","slug":"Klee","permalink":"http://example.com/tags/Klee/"},{"name":"UAF","slug":"UAF","permalink":"http://example.com/tags/UAF/"},{"name":"LLVM","slug":"LLVM","permalink":"http://example.com/tags/LLVM/"},{"name":"Cloud","slug":"Cloud","permalink":"http://example.com/tags/Cloud/"},{"name":"Windows","slug":"Windows","permalink":"http://example.com/tags/Windows/"},{"name":"Binary","slug":"Binary","permalink":"http://example.com/tags/Binary/"},{"name":"ML","slug":"ML","permalink":"http://example.com/tags/ML/"},{"name":"Pytorch","slug":"Pytorch","permalink":"http://example.com/tags/Pytorch/"},{"name":"RL","slug":"RL","permalink":"http://example.com/tags/RL/"},{"name":"CV","slug":"CV","permalink":"http://example.com/tags/CV/"},{"name":"Malware Classifiers","slug":"Malware-Classifiers","permalink":"http://example.com/tags/Malware-Classifiers/"},{"name":"BCSA","slug":"BCSA","permalink":"http://example.com/tags/BCSA/"},{"name":"obfuscation","slug":"obfuscation","permalink":"http://example.com/tags/obfuscation/"},{"name":"IDS","slug":"IDS","permalink":"http://example.com/tags/IDS/"},{"name":"DDoS","slug":"DDoS","permalink":"http://example.com/tags/DDoS/"},{"name":"AD","slug":"AD","permalink":"http://example.com/tags/AD/"},{"name":"Botnet","slug":"Botnet","permalink":"http://example.com/tags/Botnet/"},{"name":"Mutiagent","slug":"Mutiagent","permalink":"http://example.com/tags/Mutiagent/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://example.com/tags/Machine-Learning/"},{"name":"Math","slug":"Math","permalink":"http://example.com/tags/Math/"},{"name":"NLP","slug":"NLP","permalink":"http://example.com/tags/NLP/"},{"name":"AD training","slug":"AD-training","permalink":"http://example.com/tags/AD-training/"},{"name":"DNN","slug":"DNN","permalink":"http://example.com/tags/DNN/"},{"name":"RNN","slug":"RNN","permalink":"http://example.com/tags/RNN/"},{"name":"PDF","slug":"PDF","permalink":"http://example.com/tags/PDF/"},{"name":"Android","slug":"Android","permalink":"http://example.com/tags/Android/"}]}