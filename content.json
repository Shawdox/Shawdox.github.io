{"meta":{"title":"Shaw","subtitle":"@hust","description":"积沙成塔","author":"Shaw","url":"http://example.com","root":"/"},"pages":[{"title":"ShawWu","date":"2022-07-15T06:28:08.560Z","updated":"2022-07-15T06:28:08.560Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"邮箱：asdiop123321@qq.com； @华中科技大学 网络空间安全学院 Email: asdiop123321@qq.com ； @ School of Cyberspace Security, Huazhong University of science and technology"},{"title":"All archives","date":"2021-09-03T03:39:45.000Z","updated":"2021-09-03T03:40:04.450Z","comments":true,"path":"archives/index.html","permalink":"http://example.com/archives/index.html","excerpt":"","text":""},{"title":"","date":"2022-07-15T07:10:17.486Z","updated":"2022-07-15T07:10:17.486Z","comments":true,"path":"book/home.html","permalink":"http://example.com/book/home.html","excerpt":"","text":"More is different，宏观与微观的审视哲学，量变产生质变。 ​ ----Shaw的，一些记录，一些随手写。"},{"title":"","date":"2022-07-15T07:39:37.754Z","updated":"2022-07-15T07:39:37.754Z","comments":true,"path":"book/menu.html","permalink":"http://example.com/book/menu.html","excerpt":"","text":"Home Changelog h Categories Elements Excerpts Gallery Post Hello World Images Untitled Link Post Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam justo turpis, tincidunt ac convallis id. Untitled Tag Plugins Tags Videos 中文測試 日本語テスト"},{"title":"All categories","date":"2021-09-03T03:22:06.577Z","updated":"2021-09-03T03:22:06.577Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"友链","date":"2021-06-14T09:40:37.000Z","updated":"2021-06-14T09:55:02.256Z","comments":true,"path":"friends/index.html","permalink":"http://example.com/friends/index.html","excerpt":"","text":""},{"title":"All tags","date":"2021-06-14T09:39:05.000Z","updated":"2021-09-03T03:22:24.928Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""},{"title":"contact","date":"2021-06-14T09:40:01.000Z","updated":"2021-06-14T09:40:14.806Z","comments":true,"path":"contact/index.html","permalink":"http://example.com/contact/index.html","excerpt":"","text":""}],"posts":[{"title":"Function-level obfuscation detection method based on Graph Convolutional Networks","slug":"【论文阅读】Function-level obfuscation detection method based on Graph Convolutional Networks","date":"2022-10-01T12:37:04.833Z","updated":"2022-10-02T06:23:32.301Z","comments":true,"path":"2022/10/01/【论文阅读】Function-level obfuscation detection method based on Graph Convolutional Networks/","link":"","permalink":"http://example.com/2022/10/01/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Function-level%20obfuscation%20detection%20method%20based%20on%20Graph%20Convolutional%20Networks/","excerpt":"","text":"【论文阅读】Function-level obfuscation detection method based on Graph Convolutional Networks 时间：2021 作者：Shuai Jiang , Yao Hong, Cai Fu（华科） 期刊：Journal of Information Security and Applications（中科院三区） 1.ABSTRACT ​ 在恶意样本检测中代码混淆检测技术是一个重要的辅助手段，对于安全从业者来说，其可以在人工逆向分析前来实施自动化混淆检测，这有助于逆向工程师更具体地进行逆向分析。 ​ 目前存在的混淆检测方法主要作用于Android应用，并基于传统的机器学习方法。其检测颗粒度很差，总体效果不佳。为了解决这些问题，在本篇文章，我们提出了一个应用于X86汇编和Android应用的、function level的、基于GCN的混淆检测方法。 1. 首先，我们的方法是function-level的。我们提取每个函数的CFG作为其特征（包括邻接矩阵和基本代码块的特征矩阵）； 2. 我们构建一个GCN-LSTM神经网络作为混淆检测模型； 3. 最后，对于function-level的检测我们的方法准确率是94.7575%（X86汇编）和98.9457%（安卓应用），比baseline方法好。实验证明我们的方法不论是在function-levle还是APK-level上的检测准确率都好于baseline。 2. INTRODUCTION 2.1 Obfuscation–代码混淆 ​ 代码保护技术，用于增加逆向难度，防止代码篡改，最开始用于版权保护，后被用于恶意代码的躲避检测。 ​ 由于动态检测恶意代码的高昂成本，主流的恶意样本检测技术仍在提取代码的静态特征。然而由于混淆技术的发展，恶意样本的编写者经常在保留其恶意功能的同时通过使用混淆技术来修改其静态特征。经过混淆的恶意代码可以规避相关工具的检测。 ​ 最近混淆检测技术开始出现，在此领域有一些工作： 1. [2018]Alessandro等人：使用静态分析和机器学习分类算法来分析Android应用是否被混淆的技术（ http://dx.doi.org/10.1145/3230833.3232823）； 2. [2020]Crincoli等人：利用weak bisimulation来检测代码是否被code reordering(http://dx.doi.org/10.1007/978-3-030-44041-1_116)； 3. [2020]Caijun Sun等人：一个Android打包检测框架DroidPDF( http://dx.doi.org/10.1109/ACCESS.2020.3010588); 4. [2019]Omid等人：AndrODet，一个检测三种Android混淆技术的检测机制（重命名、字符串加密和控制流混淆）（ http://dx.doi.org/10.1016/j.future.2018.07.066）； 5. [2019]Alireza等人：Android字符串混淆检测技术（ http://dx.doi.org/10.1145/3338501.3357373）; 2.2 目前方法的缺点： 1. 检测颗粒度不够，检测对象往往是一个APK包，缺乏可行性； 2. 检测效果不佳，从样本中提取的特征相对简单，只有统计学特征和opcode语句被提取。大多数使用简单的机器学习方法，表现一般； 3. 缺乏可用性和适应性，传统方法往往会为不同的混淆方法提取不同的特征，或者为每个混淆方法训练一个二分类器，枯燥且不便。同时若需要添加新数据，模型经常需要重头训练。 2.3 我们的方法： 从开源平台获取一些未经混淆的代码（X86汇编和Android），通过混淆器生成混淆后程序； 逆向这些程序，用邻接矩阵和基本代码块特征矩阵的形式提取每个函数的CFG； 根据我们提取到的特征，构建GCN-LSTM。这个模型同时服务于X86汇编和Android，但他们分别训练和测试； 3. METHOD OVERVIEW 1. X86的混淆器：OLLVM；Android的混淆器：Obfuscapk； 2. 逆向工具：IDA PRO；由于X86与Android指令集与混淆技术不同，二者被分别提取CFG； 3. 多分类问题，检测出混淆技术种类，故使用传统多分类评估方法来评估检测效果。 4. OBFUSCATION DECTION METHOD 4.1 OLLVM ​ OLLVM包括以下三种混淆技术： Instructions Substitution (SUB)，指令替换。将简单指令替换为同语义的复杂指令，特别是二进制加减乘除。这项技术会增加算术指令但很少影响CFG； Bogus Control Flow (BCF)，虚假控制流。在CFG中添加大量无关的随机代码块和分支，并分割、融合、重排原始代码块，在其中插入随机选择的无用指令。这项技术破坏了CFG和代码块的完整性，增加控制流复杂性； Control Flow Flattening（FLA），控制流平坦化。简单来讲就是将代码块之间的关系打断，由一个分发器来控制代码块的跳转： 4.2 Obfuscapk ​ Obfuscapk包括以下三种混淆技术： Identifier Renaming，标识符重命名； String Encryption，字符串加密。字符串常量可以揭示很多代码敏感信息； Control Flow Obfuscation，控制流混淆。通过扩展或平坦化CFG来混淆，同样还有注入垃圾代码，扩展循环，添加无关操作等； 4.3 Feature extraction ​ 提取的特征包括代码的结构化CFG信息和基本代码块特征： 对于邻接矩阵： 如图，邻接矩阵代码了不同代码块之间的转移关系。 ​ 对于基本代码块特征： 将X86汇编代码分为27类，对于一个代码块的特征向量就是27维。 将Dalvik指令分为15类，对于一个代码块的特征向量就是15维。 4.4 Obfuscation detection model ​ 在得到CFG邻接矩阵和基本代码块特征矩阵后，构建GCN-LSTM。 5.EXPERIMENTAL EVALUATION 5.1 Datasets 5.2 Baseline methods ​ function-level的baseline方法如下： ​ AdaBoost, GaussianNaiveBayes, GradientBoosting, KNeighbors, MLP, SGDClass, SVM, Xgboost and LSTM 5.3 Evaluation metrics ​","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Malware Classifiers","slug":"Malware-Classifiers","permalink":"http://example.com/tags/Malware-Classifiers/"},{"name":"obfuscation","slug":"obfuscation","permalink":"http://example.com/tags/obfuscation/"}],"author":"Shaw"},{"title":"Planning at Decision Time(决策时规划)","slug":"决策时规划","date":"2022-07-21T07:46:53.321Z","updated":"2022-07-24T06:54:15.431Z","comments":true,"path":"2022/07/21/决策时规划/","link":"","permalink":"http://example.com/2022/07/21/%E5%86%B3%E7%AD%96%E6%97%B6%E8%A7%84%E5%88%92/","excerpt":"参考资料： Reinforcement Learining. Second Edition. Sutton.Page 180-193 白板推导--强化学习.shuhuai008.Bilibili Easy RL.Qi Wang.Yang Yiyuan.Ji Jiang Planning at Decision Time（决策时规划） 规划（Planning）至少有两种使用方式。 ①一种在DP和Dyna中已经讨论过，通过从一个model（不论是sample model或是distribution model ）中获取模拟经验（simulated experience）的基础上来使用规划来逐渐提升一个policy或一个value function。 然后，选择动作是一个比较当前状态的动作value问题，该value是在之前优化的表格中获取的；或者通过使用书中Part 2中考虑的近似方法来评估数学表达式。 对于任意状态St，在为其选择一个动作之前，其整个表格条目（例如Dyna-Q中的Q表）已经通过规划来优化过了。使用这种方式，规划并不是仅仅聚焦于当前的状态，我们称这种规划为background planning，后台规划。 ②另一种使用规划的方法就是在遇到每个新的状态St后再开始一个完整的规划过程，其为每个当前状态选择一个动作At，到下一个状态St+1就选择一个动作At+1，以此类推。 一个使用这种规划最简单的例子：当state values可用时，通过比较当前model对执行每个动作后到达的新状态的value来选择一个动作。 当然，更普遍的说，这种规划的用法可以比仅仅往后看一步（上面的例子就是）看得更深，评估动作的选择导致许多不同预测状态和奖励轨迹。 不同于第一种用法，在这里，规划聚焦于一个特定的状态，我们称之为decision-time planning，决策时规划。 这两种规划的方式可以用一种自然而有趣的方式结合在一起，不过一般二者被分开研究。 如同background planning，我们仍可以将决策时规划看作一个从模拟经验中更新values，最后到更新policy的过程。只是基于当前状态所生成的values和policy会在做完动作选择决策后被丢弃，在很多应用场景中这么做并不算一个很大的损失，因为有非常多的状态存在，且不太可能在短时间内回到同一个状态，故重复计算导致的资源浪费会很少。 一般来说，人们可能希望将两者结合起来：规划当前状态，并将规划的结果存储起来，以便在以后回到相同的状态时能走得更远。 Decision-time Planning，(决策时规划）在不需要快速反应的应用场景中作用最为显著。 决策时规划的常用算法有Heuristic Search（启发式搜索）、Rollout Algorithms（Rollout 算法）和Monte Carlo Tree Search（MCTS 蒙特卡洛树搜索）三种。","text":"参考资料： Reinforcement Learining. Second Edition. Sutton.Page 180-193 白板推导--强化学习.shuhuai008.Bilibili Easy RL.Qi Wang.Yang Yiyuan.Ji Jiang Planning at Decision Time（决策时规划） 规划（Planning）至少有两种使用方式。 ①一种在DP和Dyna中已经讨论过，通过从一个model（不论是sample model或是distribution model ）中获取模拟经验（simulated experience）的基础上来使用规划来逐渐提升一个policy或一个value function。 然后，选择动作是一个比较当前状态的动作value问题，该value是在之前优化的表格中获取的；或者通过使用书中Part 2中考虑的近似方法来评估数学表达式。 对于任意状态St，在为其选择一个动作之前，其整个表格条目（例如Dyna-Q中的Q表）已经通过规划来优化过了。使用这种方式，规划并不是仅仅聚焦于当前的状态，我们称这种规划为background planning，后台规划。 ②另一种使用规划的方法就是在遇到每个新的状态St后再开始一个完整的规划过程，其为每个当前状态选择一个动作At，到下一个状态St+1就选择一个动作At+1，以此类推。 一个使用这种规划最简单的例子：当state values可用时，通过比较当前model对执行每个动作后到达的新状态的value来选择一个动作。 当然，更普遍的说，这种规划的用法可以比仅仅往后看一步（上面的例子就是）看得更深，评估动作的选择导致许多不同预测状态和奖励轨迹。 不同于第一种用法，在这里，规划聚焦于一个特定的状态，我们称之为decision-time planning，决策时规划。 这两种规划的方式可以用一种自然而有趣的方式结合在一起，不过一般二者被分开研究。 如同background planning，我们仍可以将决策时规划看作一个从模拟经验中更新values，最后到更新policy的过程。只是基于当前状态所生成的values和policy会在做完动作选择决策后被丢弃，在很多应用场景中这么做并不算一个很大的损失，因为有非常多的状态存在，且不太可能在短时间内回到同一个状态，故重复计算导致的资源浪费会很少。 一般来说，人们可能希望将两者结合起来：规划当前状态，并将规划的结果存储起来，以便在以后回到相同的状态时能走得更远。 Decision-time Planning，(决策时规划）在不需要快速反应的应用场景中作用最为显著。 决策时规划的常用算法有Heuristic Search（启发式搜索）、Rollout Algorithms（Rollout 算法）和Monte Carlo Tree Search（MCTS 蒙特卡洛树搜索）三种。 Heuristic Search（启发式搜索） 在AI中一个经典的状态空间规划方法是decision-time planning方法，统称为Heuristic Search（启发式搜索）。 在启发式搜索中，对每个遇到的状态都会生成一颗延续的搜索树，近似的value function会被在叶节点应用，然后反向传播到根节点。反向传播在当前状态停止。一旦这些节点的值被计算出来，就会选择其中最好的一个作为当前的行动，然后所有的值就会被丢弃。 在传统的启发式搜索中，计算出的backed-up values并不会被通过修改近似value function来保存。实际上，价值函数一般都是由人设计的，绝不会因为搜索而改变。然而，一个自然而然的想法就是考虑改进value function，使用启发式搜索计算出的backed-up value或者其他方法。从某种意义上说，我们一直都采取这种方法。 Greedy，ε-greedy和UCB动作选择方法与启发式搜索没什么不同，尽管是在一个更小的范围内。举个例子，为了计算greedy策略的state-value function，我们必须向前概览每个可能的动作，到达每个可能的下一个状态，考虑他们的reward和评估值，然后选择一个最好的动作。这就如同传统的启发式搜索，计算所有可能动作的backed-up values，但是不去保存他们。因此，启发式搜索可以被看作greedy策略在单步范围外的一种扩展。 搜索的更深是为了获得更好的动作选择策略。假设我们有一个完美的model和一个不完美的action-value function，如果一路搜索到底，那么不完美的value function的影响就会被消除。通过这种方式的搜索必须是optimal的。若搜索步骤k足够多，导致 γk 足够小，那么动作就会近似达到optimal。从另一个角度讲，搜索的越深所需的算力资源也越多，响应就越慢。 一个优秀的例子是是Tesauro提出的大师级双陆棋算法，TD-Gammon。该算法使用TD learning，通过与自己对弈来学习value function，其使用启发式搜索来选择动作。Tesauro发现启发式搜索的越深，TD-Gammon就会选择越好的动作，但是每走一步花的时间也越多。 在更深入的搜索中观察到的性能改善并不是由于使用多步骤更新本身。相反，它是由于更新的重点集中在当前状态的下游的状态和行动上。通过投入大量与候选行动具体相关的计算，决策时规划可以产生比依靠无重点的更新所产生的更好的决策。 启发式搜索示意图 如上图所示，白圆点表示状态，黑圆点表示动作。以当前状态为根节点，遍历每一层所有的可能性，然后计算每个非叶节点的Q（s,a）。具体计算方法如下，将树按深度优先遍历，每个非叶节点使用公式： \\[ Q(s,a) = \\sum_{s&#39;,r}{p(s&#39;,r|s,a)(r + γmax_{a&#39;}Q(s&#39;,a&#39;))} \\] 故按照图中的数字顺序（1-&gt;2-&gt;3-&gt;4-&gt;5……）依次计算**q~*~的期望更新**，得到当前状态（根节点）每个可能动作a'的对应的Q（s，a'），选择一个最好的即可。当然，在使用算法的过程中搜索层数K是可以控制的，故叶节点并不一定是终结状态ST。 Rollout Algorithms（Rollout 算法） Rollout算法是基于蒙特卡洛控制的决策时规划算法，其应用于从当前状态开始的一些模拟轨迹。对给定的policy进行动作评估的方式是将许多从各个可能的动作开始的模拟轨迹的返回值平均化。当action-value评估被认为足够准确了，被给分最高的动作就会被执行，之后，该过程（Rollout）将从产生的下一个状态重新进行。 不同于蒙特卡洛控制算法，Rollout算法的目标不是评估一个最优的q*或qπ，而是根据一个给定的一般叫rollout policy的策略，来为每个当前状态生成蒙特卡洛评估。作为一个决策时规划算法，Rollout算法在当即使用这些action-value评估值之后就丢弃他们。这使得Rollout算法的实现相对较为简单，因为不都需要对每个&lt;s , a&gt;键值对都采样，并且不需要对状态空间或状态-动作空间拟合一个近似函数。 Rollout算法什么时候停止？策略改进定理告诉我们给定两个几乎相同的策略π和π'，他们不同是对同一个状态S有: \\[ π&#39;(s) = a ≠ π(s) \\] 如果： \\[ q_{π}(s,a)\\geq v_{π}(s) \\] 那么策略π'就优于或等于策略π。 在Rollout算法中，对状态s的每个可能的动作a'都计算其若干条模拟轨迹的平均返回值，得到\\(q_π(s,a&#39;)\\)。接着选取评估值最大的那个action，随后的状态都继续遵循策略π，这就是一个很好的在π上的策略改进。 换句话说，Rollout算法的目标就是在rollout policy上不断做改进，而不是去寻找一个最优策略。经验表明Rollout算法的效果非常惊艳。例如Tesauro和Galperin（1997）就表明rollout算法对于双陆西洋棋的提升效果非常显著。在一些应用中，即使rollout policy是完全随机的Rollout算法也可以有好的表现。但是policy的改进依靠rollout policy的性能和MC值评估得出的action排名。直觉表明，rollout policy越好、评估值越准确，Rollout算法给出的策略就越好。 这其中包含了重要的权衡，因为一般来说越好的rollout policy意味着需要越多的时间来模拟足够的轨迹，以得到好的value评估效果。作为一个决策时评估方法，Rollout算法一般都会有严格的时间限制，其计算所需时间由待评估动作的数量、模拟轨迹中的步长、rollout policy做决策的时间和模拟轨迹的数量共同决定。 虽然存在一些方法可以减轻这一难题，但在任何Rollout算法的应用中平衡这些因素都是很重要的。因为MC评估是相互独立的，故并行做这些评估是可能的。另外一种方法是可以缩减模拟轨迹的长度。 **简单来说，不同于启发式搜索往下遍历所有的可行性然后进行q*期望更新，Rollout对每个可能的action进行若干条MC采样，以这些采样的平均值来评估这个aciton的好坏。** Rollout 的意思是从当前帧去生成很多局的游戏。 Monte Carlo Tree Search（MCTS 蒙特卡洛树搜索） Monte Carlo Tree Search (MCTS)，蒙特卡洛树搜索，是一个近年来非常成功的决策时规划算法。MCTS是一个rollout改进算法，其在Rollout的基础上增加了累计从MC模拟轨迹中获得value的方法，以便于模拟到有更高reward的轨迹。 MCTS是近年来AI围棋从一个入门者（2005）发展到一个宗师级棋手（2015）的重要原因，2016年AlphaGo程序战胜了世界围棋冠军选手。MCTS被证明在许多竞争领域有显著效果，包括一般的游戏，但不局限于此。若环境model足够简单，可以进快速多步模拟，它对单智能体序列决策问题就非常有效。 MCTS的核心思想是从以往的模拟中，扩展初始部分已经获得高回报的轨迹，让算力聚焦于更可能获得高回报的模拟路线。 在任何MC评估方法中，&lt;s,a&gt;键值对的评估值就是多对模拟轨迹的平均返回值，在这里，只保留最有可能在几步内达到的&lt;s,a&gt;对的MC估计值（算出来的q（s,a））。我们称这些节点加上根节点组成一个tree，使用一个tree policy遍历这个tree来选择一个用来扩展的叶子结点，构建一个tree帮助我们能选择一个更好的节点用来rollout而不是对每个节点都进行模拟。 总的来说，MCTS总共分为四步：Selection，Expansion，Simulation和Backup。 Selection就是用tree policy（例如ε-greedy）来选择一个叶节点，用于后续扩展； Expansion就是使用选择好的节点，用一些未使用过的actions来扩展一个或几个孩子节点； Simulation就是从选择的节点/扩展的节点上用rollout policy进行模拟，同rollout算法； Backup就是通过模拟得出的值来反向更新对应的action. 在一个时间步骤内，MCTS反复做这四步，直到时间不够了或者其他计算资源不够了。然后，通过某种方法来为当前状态选择一个动作。例如，选择value最大的动作，或是，选择visit次数最多的动作来避免选到异常值。当到达下一个状态后，新一轮的MCTS又开始了。有时新一轮的MCTS从一个孤立的节点开始，但大多数情况下会从上一次MCTS中还留存的、有些后代的tree开始。 MCTS最初被提出用于为一些双人竞技游戏选择动作，例如围棋。每个模拟过程都是一个完整的游戏过程，双方选手通过tree和rollout policy来选择动作。 相关概念解释： 1. Distribution model and Sample model 参考《Reinforcement Learning》Page159，Chapter 8，原文解释的很清楚： “By a model of the environment we mean anything that an agent can use to predict how the environment will respond to its actions. Given a state and an action, a model produces a prediction of the resultant next state and next reward. ” “我们所指的环境的model是一个agent可以用其预测环境会如何对其action作出反应的东西。给出一个state和一个action，model给出下一个state和返回的reward。” “If the model is stochastic, then there are several possible next states and next rewards, each with some probability of occurring. ” “如果model是随机的，那么下一个state与reward就有许多可能的情况，每个情况都有一定概率发生。” “Some models produce a description of all possibilities and their probabilities; these we call distribution models. Other models produce just one of the possibilities, sampled according to the probabilities; these we call sample models.” “一些models提供了一个对所有事件发生的可能性以及其概率的描述，这些models我们称其为distribution models（分布模型）；另外一些models仅提供这些可能发生的事件的其中一种，这些models我们称其为sample models（样本模型）” “ For example, consider modeling the sum of a dozen dice. A distribution model would produce all possible sums and their probabilities of occurring, whereas a sample model would produce an individual sum drawn according to this probability distribution.” “例如，考虑对一打骰子（dozen dice）的和进行建模，一个 distribution model 会产生所有可能的和，以及它们发生的概率，而一个 sample model 会根据这个概率分布产生一个单独的和。” 例如，MDP中的\\(p(s^{&#39;},r|s,a)\\)就是一个典型的分布模型。在很多应用中，获取 sample models 比获取 distribution models 容易得多。dozen dice 就是这样一个例子。很容易写一个电脑程序仿真掷骰、返回和的过程，但是计算所有可能的和以及对应的概率很难，且容易出错。","categories":[{"name":"Something","slug":"Something","permalink":"http://example.com/categories/Something/"}],"tags":[{"name":"RL","slug":"RL","permalink":"http://example.com/tags/RL/"}],"author":"Shaw"},{"title":"A Survey of Defense Mechanisms Against Distributed Denial of Service (DDoS) Flooding Attacks","slug":"A Survey of Defense Mechanisms Against Distributed Denial of Service (DDoS) Flooding Attacks","date":"2022-03-04T08:24:55.254Z","updated":"2022-07-15T08:09:16.356Z","comments":true,"path":"2022/03/04/A Survey of Defense Mechanisms Against Distributed Denial of Service (DDoS) Flooding Attacks/","link":"","permalink":"http://example.com/2022/03/04/A%20Survey%20of%20Defense%20Mechanisms%20Against%20Distributed%20Denial%20of%20Service%20(DDoS)%20Flooding%20Attacks/","excerpt":"A Survey of Defense Mechanisms Against Distributed Denial of Service (DDoS) Flooding Attacks 时间：2013 作者：Saman Taghavi Zargar，James Joshi， David Tipper 期刊：IEEE COMMUNICATIONS SURVEYS &amp; TUTORIALS（中科院一区） ABSTRACT ​ DDoS攻击是安全专业人员最关心的问题之一，其通常是为了扰乱合法用户对服务的访问而进行的显式尝试。攻击者通常通过攻击漏洞来获取到一大批电脑，以此来组建一个网络攻击军队（也就是僵尸网络），一旦组建了攻击部队，攻击者就可以对一个或多个目标发起协调一致、大规模的攻击。开发针对已识别和预期的DDoS泛洪攻击的综合防御机制，是入侵检测和预防研究界所期望的目标。然而，这种机制的发展需要对问题和迄今为止在预防、检测和应对各种DDoS洪泛攻击方面所采用的技术有一个全面的了解。 ​ 在本文，我们对DDoS洪泛攻击进行分类，并根据它们在何时何地预防、检测和应对DDoS洪泛攻击对现有的对策进行分类。 ​ 此外，我们强调需要一种全面的分布式协同防御方法。我们的主要目的是激发研究人员开发出创造性的、有效的、高效的、综合的预防、检测和响应机制来解决实际攻击前、中和后的DDoS泛洪问题。","text":"A Survey of Defense Mechanisms Against Distributed Denial of Service (DDoS) Flooding Attacks 时间：2013 作者：Saman Taghavi Zargar，James Joshi， David Tipper 期刊：IEEE COMMUNICATIONS SURVEYS &amp; TUTORIALS（中科院一区） ABSTRACT ​ DDoS攻击是安全专业人员最关心的问题之一，其通常是为了扰乱合法用户对服务的访问而进行的显式尝试。攻击者通常通过攻击漏洞来获取到一大批电脑，以此来组建一个网络攻击军队（也就是僵尸网络），一旦组建了攻击部队，攻击者就可以对一个或多个目标发起协调一致、大规模的攻击。开发针对已识别和预期的DDoS泛洪攻击的综合防御机制，是入侵检测和预防研究界所期望的目标。然而，这种机制的发展需要对问题和迄今为止在预防、检测和应对各种DDoS洪泛攻击方面所采用的技术有一个全面的了解。 ​ 在本文，我们对DDoS洪泛攻击进行分类，并根据它们在何时何地预防、检测和应对DDoS洪泛攻击对现有的对策进行分类。 ​ 此外，我们强调需要一种全面的分布式协同防御方法。我们的主要目的是激发研究人员开发出创造性的、有效的、高效的、综合的预防、检测和响应机制来解决实际攻击前、中和后的DDoS泛洪问题。 INTRODUCTION ​ DDoS攻击，旨在尝试组织合法使用者访问一个特定的网站，早在20世纪80年代就被网络研究团体知晓。1999年夏天，Computer Incident Advisory Capability (CIAC)报告了第一起DDoS攻击事件。 ​ 目前，有两种主要的在互联网上制造DDoS攻击的方法：①第一种方法是攻击者向受害者发送一些格式错误的数据包，以混淆在其上运行的协议或应用程序( vulnerability attack);②另一种方法是最常见的方法，它涉及攻击者试图执行下列一项或两项： 1. 通过消耗带宽、路由器处理能力或网络资源，破坏合法用户的连通性；这些本质上是网络/传输级的泛洪 攻击； 2. 通过耗尽服务器资源(如套接字、CPU、内存、磁盘/数据库带宽和I/O带宽 )来破坏合法用户的服务；这些攻击本质上包括应用级的泛洪攻击； ​ 如今，DDoS攻击往往是由远程控制、组织良好、分布广泛的Zombies1或Botnet计算机组成的网络发起的，这些计算机同时和不断地向目标系统发送大量的流量和/或服务请求，目标系统因此变得要么反应如此缓慢，以至于无法使用，要么完全崩溃。僵尸网络中的僵尸或计算机通常通过使用蠕虫、木马或后门来招募。此外，由于在攻击者控制下的僵尸使用伪造的IP地址，使得防御机制识别原始攻击者变得更加复杂。 ​ 从1999年的夏天开始，许许多多的DDoS攻击被制造出来用以对抗不同的组织。迄今为止，大多数的DDoS洪泛攻击都试图使受害者的服务不可用，从而收入损失，增加了减轻攻击和恢复服务的成本。 ​ 举个例子，2000年2月，雅虎经历了最早的一次重大DDoS泛洪攻击，使得该公司的服务在互联网上持续了约2小时，从而造成广告收入的显著损失； ​ 2002年10月，13个DNS服务器中的9个因为DDoS洪泛攻击关闭了一小时； ​ 2004年2月，由于遭受DDoS攻击，正常用户无法使用SCO Group网站，这种攻击是通过使用以前感染Mydoom病毒的系统发起的。 ​ 2009年7月，Mydoom病毒被再次使用以发起DDoS攻击韩国和美国主要政府新闻媒体和经济网站； ​ 2010年12月，一个自称为“Anonymous”的组织策划了针对一些组织诸如Mastercard.com, PayPal, Visa.com 和 PostFinance的DDoS攻击； ​ 2012年9月，美国银行( Bank of America )、花旗集团( Citigroup )、富国银行( Wells Fargo )、美国银行( Bancorp )、PNC、Capital One、Fifth Third Bank、BB &amp; T、BB &amp; T、汇丰银行( HSBC )等9家主要银行的网上银行成为国外黑客攻击集团\" Izz ad-Din al-Qassam Cyber Fighters \"发起的一系列强力DDoS泛洪攻击的目标。因此，几家网上银行网站在几分钟后恢复之前已经放缓或停业。 ​ 最近DDoS防御机制的进步已经结束了“脚本小子”可以下载工具并对几乎任何网站发起攻击的时代。（2013）在如今的DDoS攻击中，攻击者使用了更复杂的方法来发起攻击。尽管尽了一切努力减少DDoS攻击事件的数量，但它们在目标网络和计算机的频率和规模上迅速扩大。在VeriSign委托的最近一项调查中发现，在2008年7月至2009年7月期间，75 %的受访者经历过一次或多次攻击。此外，最近来自Arbor Networks的一份报告也表明了类似的数据。在调查结果中，他们显示，69 %的受访者从2009年10月至2010年9月至少经历过一次DDoS攻击，25 %的受访者每月遭受10次此类攻击。ProlexicTechnology公司提供的防御DDoS攻击的服务显示，每天有7000个DDoS攻击被观测到，并且认为这个数量正在迅速增长。 ​ DDoS攻击的规模也在不断增大，使得防御起来更加困难。Arbor Network发现，2010年攻击规模已经增长了100 %左右，攻击首次突破了100Gbps的壁垒。因此，保护资源免受这些频繁而庞大的DDoS攻击，就需要研究界致力于开发一种能够在实际攻击之前、期间和之后对DDoS攻击做出适当反应的全面的DDoS防御机制。 ​ 本文重点研究有线网络系统中DDoS泛洪攻击和防御机制。【19】专注于描述无线自组织网络的DDos攻击；【20】专注于无线传感器网络特有的DDoS攻击的特点。 ​ 在这里，我们的目标是对现有的DDoS洪泛攻击进行分类，并提供根据它们在何处和何时检测和响应DDoS洪泛攻击而分类的防御机制的全面调查。对DDoS洪泛攻击的研究和所做的调查对于了解与这一重要网络安全问题有关的关键问题，从而对建立更全面有效的防御机制具有重要意义。 ​ DDOS: ATTACKERS’ INCENTIVES ​ DDoS攻击者的动机有以下几类： ​ 1. 获取经济收入：这些攻击是企业关注的重大问题，由于其激励的性质，这一类的攻击者通常是技术含量最高、经验丰富的攻击者。为获取经济利益而发动的攻击往往是最危险、最难以阻止的攻击。 ​ 2. 复仇者：这一类的攻击者一般都是沮丧的个体，可能具有较低的技术技能，他们通常将攻击作为对遭受到的不公正的待遇的报复。 ​ 3. 受思想信念驱动：属于这一类的攻击者是出于其思想信念的动机来攻击目标的。该类别目前是攻击者发起DDoS攻击的主要诱因之一。 ​ 4. 智力挑战者：这类攻击者攻击目标系统，以实验和学习如何发起各种攻击。他们通常都是年轻的黑客爱好者，想要炫耀自己的能力。如今，存在着各种易于使用的攻击工具和僵尸网络来租用，即便是一个计算机业馀者也可以利用其发起起成功的DDoS攻击。 ​ 5. 网络战争：这一类的袭击者通常属于一国的军事或恐怖组织，他们有政治动机攻击另一国广泛的关键部门 ​ 有一些文章专注于分析攻击者的动机以及如何利用这些攻击动机建模，以此使决策模型可以组织并对这些攻击进行反馈。 DDOS ATTACK: SCOPE AND CLASSIFICATION ​ DDoS攻击的分布式特性使得它们极难对抗或追踪，而且攻击者通常使用假IP以此来隐藏他们的真实身份，这使得对于DDoS攻击的追踪回溯更加困难。此外，许多因特网主机中存在入侵者可以利用的安全漏洞，针对应用层的攻击事件正在迅速增加。 ​ 在这里，我们针对DDoS的协议等级对DDoS攻击进行分类，并且我们仅仅专注于最常见的DDoS洪泛攻击，漏洞攻击，攻击者利用某个服务的软件实现中的某些漏洞或实现bug将其带下来，并不是本文的重点。 ​ 基于协议等级，DDoS攻击可以被分类为两类： Network/transport-level DDoS flflooding attacks: 1.1 Flooding attacks：攻击者通过消耗受害者网络带宽(如欺骗/非欺骗UDP 流、ICMP流、DNS流、VoIP流等)来破坏合法用户的连通性。 1.2 Protocol exploitation flooding attacks:攻击者利用受害者某些协议的特定特性或实现漏洞，以消耗受害者的过量资源（例如，TCP SYN流，TCP SYN-ACK流，ACK &amp; PUSH ACK 流，RST/FIN flood流等）。 1.3 Reflflection-based flflooding attacks：攻击者通常向reflectors发送伪造请求( 例如 , ICMP请求 )而不是直接请求；因此，这些反射器向受害者发送答复并耗尽受害者的资源. 1.4 Amplifification-based flflooding attacks：攻击者利用服务为接收到的每个消息生成大消息或多个消息来放大对受害者的流量。僵尸网络被不断地用于反射和放大两种目的。反射和放大技术通常是串联使用的，如Smurf攻击时，攻击者利用数据包的IP广播特性( Amplification ) ，向大量的反射器发送带有伪造源IP地址的请求。 以上攻击的具体细节见【2】，【32】，【35】，【36】。 Application-level DDoS flflooding attacks: 应用级别的DDoS攻击通过耗尽服务器资源(如套接字、CPU、内存、磁盘/数据库带宽和I/O带宽 )来破坏合法用户的服务，其通常消耗更少的宽带，更加隐蔽，其与良性流量非常相似。但是，应用级别的DDoS攻击通常具有相同的影响力。 2.1 Reflflection/amplifification based flflooding attacks：这种攻击利用了与1.4同样的技术，只不过发送的是应用层数据包。 举个例子，DNS amplification 攻击使用肉机生成一小股伪造IP的DNS请求，因为DNS响应的数量可能远远超过DNS请求的数量，其可以生成大量网络流量包直指目标系统，使其瘫痪。 再举一个，VOIP flooding，攻击者通常通过SIP以非常高的包率和非常大的源IP范围发送被欺骗的VoIP数据包。受害者VoIP服务器必须区分正确的VoIP连接和消耗大量资源的伪造的VoIP连接。VoIP泛洪可以压倒具有随机或固定源IP地址的数据包的网络。如果源IP地址没有被改变，那么VoIP泛洪攻击就会模仿来自大型VoIP服务器的流量，并且由于类似于良好的流量，很难识别。 2.2 HTTP flooding attacks： 2.2.1 Session flooding attacks，在这种类型的攻击中，攻击者的会话连接请求率高于合法用户的请求率，因此消耗了服务器的资源并导致DDoS攻击服务器。 ​ 其中的典型就是HTTP get/post flooding attack，其中攻击者向受害者Web服务器生成大量有效的HTTP请求( get / post )。攻击者通常使用僵尸网络来发起这些攻击。由于每个bot都可以产生大量的有效请求(通常每秒10个以上的请求)，所以不需要大量的bot发起成功的攻击。HTTP get / post泛洪攻击属于非欺骗性攻击。 2.2.2 Request flooding attacks，在这种类型的攻击中，攻击者发送的会话包含比通常更多的请求，并导致服务器遭受DDoS泛滥攻击。 ​ 其中的典型就是 single-session HTTP get/post flflooding，该攻击是HTTP get/post flflooding attack的一种变种，它利用HTTP 1.1的特性，允许单个HTTP会话中的多个请求。因此，攻击者可以限制HTTP攻击的会话速率，并绕过许多安全系统的会话速率限制防御机制。 ​ 2.2.3 Asymmetric attacks，在这种攻击类型中，攻击者发送包含高工作负载请求的会话。这里，我们列举了这一类中的一些著名攻击： ​ Multiple HTTP get/post flflood，该攻击是HTTP get/post flflooding attack的一种变种，在这里，攻击者通过形成一个嵌入多个请求的单个数据包，而不在单个HTTP会话中逐一发出多个HTTP请求，从而创建多个HTTP请求。 ​ 这样，攻击者仍然可以以较低的攻击包率在受害服务器上保持较高的负载，使得攻击者几乎看不到网络流量异常检测技术。此外，攻击者如果仔细选择HTTPVERB，就可以轻松绕过深度包检查技术。 ​ Faulty Application，在这种攻击中，攻击者利用设计不良或与数据库集成不当的网站进行攻击。例如，它们可以使用类似SQL的注入来生成请求来锁定数据库查询。这些攻击非常具体和有效，因为它们消耗服务器资源( 内存、 CPU等)。 ​ 2.2.4 Slow request/response attacks，在这种攻击类型中，攻击者发送包含高负载请求的会话。 ​ Slowloris attack (a.k.a, slow headers attack)，Slowloris（懒猴）是一种基于HTTP get的攻击，可以使用有限数量的机器甚至单个机器来降低Web服务器。 ​ 攻击者发送部分HTTP请求( 不是一个完整的request头部）这些请求持续快速地增长，缓慢地更新，永远不会关闭。攻击一直持续到所有可用的套接字被这些请求占用，Web服务器变得不可访问。攻击者的源地址通常不是伪造的。 ​ HTTP fragmentation attack，与懒猴类似，这种攻击的目标是通过长时间保持HTTP连接而不引发任何警报来降低Web服务器。 ​ 攻击者( bot ) 与Web服务器建立有效的HTTP连接。然后，它们将合法的HTTP数据包分解成微小的片段，并按照服务器超时允许的速度发送每个片段。使用这种方法，通过在每个bot上打开多个会话，攻击者可以只使用少数肉机就悄悄地让一个Web服务器崩溃。 ​ Slowpost attack，【42】wong等人提出了一个跟懒猴攻击非常相似的攻击，其通过缓慢发送HTTP_post请求来击溃Web服务器。 ​ 攻击者发送一个完整的HTTP头，它定义了消息体的‘内容-长度’字段，作为发送此请求的良性流量。然后它以每两分钟一个字节的速率发送数据来填充消息体。因此，服务器等待每个消息体完成，而Slowpost攻击迅速增长，导致Web服务器上的DDoS泛洪攻击。 ​ Slowreading attack，【43】Shekyan等人提出了另一种通过缓慢读取response来发起攻击的方式，而不是通过缓慢发送。 ​ 此攻击通过设置比目标服务器的发送缓冲区更小的接收窗口大小来达到目的。即使没有数据通信，TCP协议仍然保持开放的连接；因此，攻击者可以迫使服务器保持大量连接的开放，最终对服务器造成DDoS泛洪攻击。 BOTNET-BASED DDOS ATTACKS ​ 如前所述，僵尸网络是促使DDoS洪范攻击计算机网络或应用程序的主导机制。最近最令人头大的应用层DDoS泛洪攻击大多使用僵尸网络。在本节中，我们对当前僵尸网络架构以及已经用于发起DDoS泛洪攻击的工具进行了全面的研究 ​ 根据【32】Peng等人所述，当攻击者使用僵尸网络来制造DDoS攻击时，使得做出更有效的防御机制更困难的原因有二：一是大量的僵尸肉机可使得攻击者制造出的攻击流量规模更大，更具破坏性；二是肉机的IP一般是伪造的，很难回溯追踪。 ​ 僵尸网络包括master，handler和bots，如下图所示： ​ handlers是攻击者( 即master )用来与自己的肉机（即bots）间接通信的通信手段。例如，handlers可以安装在攻击者通信发送命令的一组折衷设备( 例如 ,网络服务器 )上。 ​ 然而，大多数安装的程序都留下了当前杀毒软件可以检测到的独特足迹。因此，当前攻击者使用其他方法( 如互联网中继聊天 IRC )与bot进行通信，以发送命令并控制它们。 ​ Bots就是被控制的肉机，其生成可以有成百上千种方法，根据其如何被攻击者控制，可以分类为： ​ IRC-bacsed: ​ IRC是一个互联网在线文本信息协议，其采用c-s架构，具有默认的通道，可以实现服务器间的通信。IRC可以通过多个服务器连接数百个客户端。利用IRC通道作为处理程序，攻击者可以利用合法的IRC端口向bot发送命令，使得对DDoS命令和控制结构的跟踪变得更加困难。 ​ 由于IRC服务通常具有庞大的数据量，攻击者因此可以轻易的隐藏自己。 ​ 另外，攻击者可以通过将恶意代码分片发送而轻松地分享文件。 ​ 此外，攻击者可以简单地登录到IRC服务器并查看所有可用bot的列表，而不是在其站点本地维护其列表。具有集中指挥和控制( C &amp; C )基础设施的僵尸网络(如基于IRC的僵尸网络)的主要局限性在于服务器是潜在的故障中枢。也就是说，如果防御者捕获了C &amp; C服务器，整个僵尸网络可能会关闭。一些基于IRC的著名僵尸网络工具多年来被开发并用于发起DDoS攻击如： ​ 【43】Trinity v3（UDP,TCP SYN, TCP ACK, and TCP NULflflood attacks） ​ 【47】Kaiten（UDP, TCP, SYN, and PUSH+ACH flflood attacks） ​ Web-based (a.k.a., HTTP-based)： ​ 最近，僵尸网络开始使用HTTP作为通信协议向僵尸网络发送命令，使得追踪DDoS命令和控制结构变得困难得多。基于Web的僵尸网络不像基于IRC的僵尸网络那样与C &amp; C服务器保持连接。相反，每个Web机器人定期使用Web请求下载指令。基于Web的僵尸网络更隐蔽，因为它们隐藏在合法的HTTP流量中。 ​ Bots通过复杂的PHP脚本进行配置和控制，它们通过HTTP或者HTTPS加密通信。 ​ 三个著名的Web-based 僵尸网络： ​ 【49】 BlackEnergy ​ 【50】 Ion Cannon (LOIC) ​ 【52】 Aldi DDOS DEFENSE: SCOPE AND CLASSIFICATION ​ 通常在检测到DDoS泛洪攻击时，除了断开受害者与网络并手动修复问题之外，没有什么可以做的。任何DDoS防御机制的最终目标都是尽快检测到它们，并尽可能地将它们阻止到源端。 ​ ​ ​ 上图显示了对DDoS检测和回应可以实施的阶段，如图所示，DDoS泛洪攻击类似于一个漏斗，在该漏斗中攻击流产生于一个分散区(即源)，形成漏斗的顶部。 ​ 可以看出，在漏斗底部检测DDoS攻击时相对容易的，所有网络流都可以在底部被观察到。相反地，相反，从攻击的单个源网络很难检测到攻击，除非从该源发起大量攻击流。 ​ 但是在检测的准确性和如何接近攻击源之间总是存在权衡的问题，预防和响应机制能够阻止或响应攻击。 ​ 此外，当响应机制( 例如 ,包过滤 )将攻击数据包更靠近攻击源时，当受害者受到DDoS攻击(即在DDoS攻击的中间)，到达受害者的正常数据包数量也会增加。否则，随着攻击流越接近受害者，数据包过滤机制就会丢弃更多受害者的合法数据包。 ​ 在本节中，我们利用两个判据对我们在第III节中提出的两类DDoS洪泛攻击的防御机制进行了分类。我们认为，这些分类标准对于设计稳健的防御解决方案非常重要。 ​ 分类的第一个准则是防御机制在攻击过程的哪里实现（Deployment location）： ​ 我们将针对传输层级的DDoS攻击的防御方法分为四类（见Fig.3.）： ​ source-based, destination-based,network-based, and hybrid (a.k.a. distributed) ​ 我们将针对应用级DDoS攻击的防御方法分为两类： ​ destination-based, and hybrid (a.k.a. distributed) ​ 由于应用层DDoS攻击的流量在第2层(交换机)和第3层(路由器)设备上不可访问，因此没有network-based的防御机制来抵御应用层DDoS攻击。 ​ 分类的第二个准则是DDoS防御机制面对可能的DDoS攻击响应的时间点： ​ 基于以上准则我们将基于传输层和基于应用层的的DDoS防御机制分为三类： ​ before the attack（attack prevention），during the attack（attack detection），after the attack(attack source identifification and response) ​ 因为对于DDoS攻击并没有一个“一刀切”的办法，一个综合的DDoS防御机制应该包括以上三个防御方法。 ps：由于本次调研重点在于探索对基于AI方法的DDoS防御机制，这里不做过深入探索，具体传统方法见原文。 DDOS DEFENSE: PERFORMANCE MEASUREMENT METRICS ​ 在这一部分，我们回顾和讨论了文献中发现的一些可以用来比较评估DDoS防御技术的度量和属性。 ​ 然后，在表III和表IV中，我们使用 defense strength (accuracy)、 scalability（可扩展性）、 delay（延迟）、 system performance degradation（系统性能退化）、implementation complexity（实现复杂度）等性能度量指标，基于deployment location定性地比较了传输层级DDoS攻击的防御机制和应用层级DDoS防御机制，以及这些防御机制是否被视为整体防御机制。 ​ 度量防御机制的标准如下： Defense Strength: 防御机制的强度可以通过各种度量来衡量，这取决于它能多好地预防、检测和阻止攻击。这些度量可以根据每个防御机制做出的决策或预测来定义。防御机制要么探测并应对攻击，要么错过攻击。根据他们的反应，有四个可能的结果如表II所示。 ​ 如表II所示，A，B，C，D分别表示为true negative，false negative，false positive，true positive，其实就是常见的混淆矩阵。 Accuracy是对检测结果的综合评价，是预测正确的比例占全部的比例。 \\[ Accuracy=\\frac{TP+TN}{P+N}=\\frac{TP+TN}{TN+TP+FP+FN} \\] Sensitivity是阳性样本中预测正确的比例： \\[ Sensitivity=\\frac{TP}{P}=\\frac{TP}{TP+FP} \\] Specificity是阴性样本中预测正确的比例： \\[ Specificity=\\frac{TN}{N}=\\frac{TN}{TN+FN} \\] Precision是预测为阳性的样本中预测正确的比例： \\[ Precision=\\frac{TP}{FP+TP} \\] Reliability or False positive rate是预测为阳性的样本中错误的比例： \\[ Reliability(False.positive.rate)=\\frac{FP}{FP+TP} \\] False negative rate是预测为阴性的样本中错误的比例： \\[ False\\,negative\\,rate=\\frac{FP}{FP+TP} \\] Compromise-ability: 攻击者能否利用防御机制，以便对整个系统发起攻击( 例如 , DDoS )? Delay in detection/response: 检测到/对攻击做出反应的时间。 System performance degradation: 一个防御机制是否会造成系统的功能性问题（例如内存短缺，CPU时间片短缺等），或者其是否需要额外的要求以完美运行。 Passive, reactive or proactive: 防御机制通过主动阻止攻击的发生来防御攻击，它是只对现有攻击作出反应，还是只在DDoS攻击发起后才采取行动。 Holistic defense: 一种整体防御机制，通过考虑所有需要的任务，以阻止DDoS攻击( 即既检测又响应 )。 Implementation complexity: 实现复杂性。 Usability: 是否user-friendly。 Deployment location: 正如我们前面提到的，部署位置是比较各种防御机制的另一个度量。每个位置都有各自的优缺点，使得一种机制优于另一种机制。 Scalability: 可扩展性，一个可扩展的防御机制可以有效地处理其攻击检测和响应职责，即使攻击者的数量和攻击流量都增加了。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"IDS","slug":"IDS","permalink":"http://example.com/tags/IDS/"},{"name":"DDoS","slug":"DDoS","permalink":"http://example.com/tags/DDoS/"}],"author":"Shaw"},{"title":"HydraText-Multi-objective Optimization for Adversarial Textual Attack","slug":"【论文阅读】HydraText Multi-objective Optimization for Adversarial Textual Attack","date":"2021-11-14T06:08:02.217Z","updated":"2022-07-15T08:30:58.064Z","comments":true,"path":"2021/11/14/【论文阅读】HydraText Multi-objective Optimization for Adversarial Textual Attack/","link":"","permalink":"http://example.com/2021/11/14/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91HydraText%20Multi-objective%20Optimization%20for%20Adversarial%20Textual%20Attack/","excerpt":"HydraText: Multi-objective Optimization for Adversarial Textual Attack 作者：Shengcai Liu，Ning Lu，Cheng Chen，Chao Qian，Ke Tang 时间：2021 ABSTRACT ​ 文字(text)（word-level）对抗样本黑盒攻击。在这项工作中，同时考虑攻击效率+可辨认性，并提出一种新的具有可证明性能保证的多优化方法(称为HydraText )，以实现具有高隐蔽性的成功攻击。 ​ 为了测试HydraText的功效，我们在score-based 和decision-based的黑盒攻击下，使用5个NLP模型+5个数据集。 （PS：[论文总结] Boundary Attack - 知乎 (zhihu.com)） ​ 一项人类观察评价研究表明，Hydra Text制作的对抗样本很好地保持了有效性和自然性。最后，这些实例还表现出良好的可迁移性，可以通过对抗训练给目标模型带来显著的鲁棒性提升。","text":"HydraText: Multi-objective Optimization for Adversarial Textual Attack 作者：Shengcai Liu，Ning Lu，Cheng Chen，Chao Qian，Ke Tang 时间：2021 ABSTRACT ​ 文字(text)（word-level）对抗样本黑盒攻击。在这项工作中，同时考虑攻击效率+可辨认性，并提出一种新的具有可证明性能保证的多优化方法(称为HydraText )，以实现具有高隐蔽性的成功攻击。 ​ 为了测试HydraText的功效，我们在score-based 和decision-based的黑盒攻击下，使用5个NLP模型+5个数据集。 （PS：[论文总结] Boundary Attack - 知乎 (zhihu.com)） ​ 一项人类观察评价研究表明，Hydra Text制作的对抗样本很好地保持了有效性和自然性。最后，这些实例还表现出良好的可迁移性，可以通过对抗训练给目标模型带来显著的鲁棒性提升。 INTRODUCTION ​ 我们仔细地设计了目标函数，并进一步构建了一个多目标优化问题（multi-objective optimization problem，MOP），该问题一旦被解决，将产生与原始文本相似度高的单个成功对抗样本。 ​ 然后我们原创了一个多目标优化方法（ multi-objective optimization approach），叫做HydraText。这个名字的灵感来自于海蛇许德拉，这是一种神话动物，它使用多个头部攻击对手。它可以同时用在score-based 和decision-based的黑盒攻击下。 ​ METHODS ​ 基于word-level 的替换操作。每个单词有一个自己的候选表，然后将每个单词与候选表中被选中的词替换（也可以不选，原单词不变）。 ​ 但这样的方法有个问题，如下图： ​ ​ 如图所示，句子的语义与替换的单词数量是成反比的，上文需要考虑的准确率+可辨认性二者其实是互相矛盾的。为了解决这个问题，我们在生成的过程中也考虑Xadv的修改率，使用MOP来解决它。 ​ 1.The HydraText Approach EXPERIMENTS 1. Datasets and Target Models ​ 模型种类：文本分类和文本推理 ​ 三个数据集：AG News，IMDB ， Movie Reviews，Stanford Natural Language Inference，multi-genre NLI corpus（前三个文本分类，后三个文本推理） ​ 两个模型：WordCNN，WordLSTM，BERT base-uncased，ESIM ，Infersent ，BERT base-uncased(前三个文本分类，后三个文本推理) 2.Baselines and Algorithm ​ 攻击方法：PSO,GA,TextFooler,PWWS,GADe(baseline) 3.Evaluation ​ 以攻击成功的百分率来判定攻击能力。 ​ 以修改百分率和语义相似性来判定攻击的可辨识性。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"AD","slug":"AD","permalink":"http://example.com/tags/AD/"}],"author":"Shaw"},{"title":"Semantic Host-free Trojan Attack","slug":"【论文阅读】Semantic Host-free Trojan Attack","date":"2021-11-06T07:56:09.258Z","updated":"2022-07-16T02:08:52.554Z","comments":true,"path":"2021/11/06/【论文阅读】Semantic Host-free Trojan Attack/","link":"","permalink":"http://example.com/2021/11/06/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Semantic%20Host-free%20Trojan%20Attack/","excerpt":"Semantic Host-free Trojan Attack 作者：Haripriya Harikumar , Kien Do, Santu Rana , Sunil Gupta , Svetha Venkatesh（迪肯大学.澳大利亚） 时间：2021.10.27 ABSTRACT ​ 在本文中，我们提出了一种新颖的host-free木马攻击，其触发器(trigger)固定在语义空间(semantic)，但不一定在像素空间(pixel)。 ​ 与现有的木马攻击使用干净的输入图像作为宿主来携带小的、没有意义的trigger不同，我们的攻击将trigger看作是属于语义上有意义的对象类的整个图像。 ​ 由于在我们的攻击中，与任何特定的固定模式相比，分类器被鼓励记忆触发图像的抽象语义。因此它可以在以后由语义相似但看起来不同的图像触发。这使得我们的攻击更实际地被应用于现实世界中，更难以防御。广泛的实验结果表明，仅用少量的特洛伊木马模式进行训练，我们的攻击能很好地推广到同一特洛伊木马类的新模式，并且可以绕过目前的防御方法。","text":"Semantic Host-free Trojan Attack 作者：Haripriya Harikumar , Kien Do, Santu Rana , Sunil Gupta , Svetha Venkatesh（迪肯大学.澳大利亚） 时间：2021.10.27 ABSTRACT ​ 在本文中，我们提出了一种新颖的host-free木马攻击，其触发器(trigger)固定在语义空间(semantic)，但不一定在像素空间(pixel)。 ​ 与现有的木马攻击使用干净的输入图像作为宿主来携带小的、没有意义的trigger不同，我们的攻击将trigger看作是属于语义上有意义的对象类的整个图像。 ​ 由于在我们的攻击中，与任何特定的固定模式相比，分类器被鼓励记忆触发图像的抽象语义。因此它可以在以后由语义相似但看起来不同的图像触发。这使得我们的攻击更实际地被应用于现实世界中，更难以防御。广泛的实验结果表明，仅用少量的特洛伊木马模式进行训练，我们的攻击能很好地推广到同一特洛伊木马类的新模式，并且可以绕过目前的防御方法。 ### INTRODUCTION ​ 提出了一个后门攻击，semantic host-free backdoors。 ​ 后门攻击综述：(20条消息) 深度学习后门攻防综述_Yale的博客-CSDN博客_后门攻击 ​ METHOD ​ 实现方式：数据投毒。 ​","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"AD","slug":"AD","permalink":"http://example.com/tags/AD/"}],"author":"Shaw"},{"title":"Intrusion detection system-A comprehensive review","slug":"【论文阅读】Intrusion detection system A comprehensive review","date":"2021-11-03T01:58:09.557Z","updated":"2022-07-16T02:09:04.067Z","comments":true,"path":"2021/11/03/【论文阅读】Intrusion detection system A comprehensive review/","link":"","permalink":"http://example.com/2021/11/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Intrusion%20detection%20system%20A%20comprehensive%20review/","excerpt":"Intrusion detection system: A comprehensive review 作者：Hung-Jen Liao a , Chun-Hung Richard Lin a,n , Ying-Chih Lin a,b , Kuang-Yuan Tung a（国立中山大学，正修科技大学） 时间：2012 ABSTRACT ​ 一个IDS综述。 PS：(17条消息) 防火墙、IDS和IPS之间的区别（浅谈）_淡风wisdon－大大的博客-CSDN博客","text":"Intrusion detection system: A comprehensive review 作者：Hung-Jen Liao a , Chun-Hung Richard Lin a,n , Ying-Chih Lin a,b , Kuang-Yuan Tung a（国立中山大学，正修科技大学） 时间：2012 ABSTRACT ​ 一个IDS综述。 PS：(17条消息) 防火墙、IDS和IPS之间的区别（浅谈）_淡风wisdon－大大的博客-CSDN博客 ### INTRODUCTION ​ CIA：Confifidentiality, Integrity and Availability， ​ Instrusion: 针对CIA的破坏行为，或者绕过计算机或网络安全机制的行为。 ​ Instrusion detection: 是监视计算机系统或网络中发生的事件，并分析它们以发现入侵迹象的过程。 ​ Instrusion detection sysytem(IDS): 实现instrusion detection自动化的软件或硬件。 ​ Instrusion prevention system(IPS): 不仅有IDS的监控功能，还可以阻止可能的突发安全事件。在少数文章中，入侵检测与防御系统( IDPS )和入侵防御系统( IPS )是同义词，其中IDPS一词在安全界很少使用。 DETECTION METHODOLOGIES ​ Detection的方法一共分为三类：Signature-based Detection (SD), Anomaly-based Detection (AD) and Stateful Protocol Analysis (SPA)。 1. SD（特征检测）: ​ Signature-based Detection，特征检测。将已知的patterns与捕获的事件进行比较，从而发现可能的入侵。因为使用特定攻击或者系统漏洞所积累下的知识，SD又被称为Knowledge-based Detection 或者 Misuse Detection。 2. AD（异常检测）： ​ Anomaly-based detection，异常检测。一个异常（anomaly）指的是与已知行为相异的地方。Profiles表示定期从活动，网络连接中监视的正常或特定的行为文件，profile可以是静态的也可以是动态的，并且从许多特性中生成。例如，登录失败，处理器的使用，邮件的发送数量等。 ​ 接下来，AD 比较器就将正常的profile与观察到的事件相比较，以此辨别出显著的攻击。AD又被称为Behavior-based Detection。 ​ 一些AD的例子，例如，企图闯入、伪装、合法用户渗透、拒绝服务( DOS )、特洛伊木马等。 3. SPA（状态协议分析）： ​ Stateful Protocol Analysis，状态协议分析。Stateful指的是IDS可以知晓并追踪协议的状态（举例，将请求与答复配对）。 ​ 尽管SPA与AD很像，二者其实完全不同。AD采用预加载的网络或者特定域名的profile，然而SPA依赖于供应商开发的特定协议通用profile。通常，SPA中的网络协议模型最初基于国际标准组织(例如IETF )的协议标准。SPA也被称为Specifification-based Detection（基于规格的检测）。 大多数IDS使用多种方法来提供更广泛和准确的检测。 DETECTION APPROACHES ​ 此文将已有的方法分为了5类：Statistics-based, Pattern-based, Rule-based, State-based and Heuristic-based。 ​ 由上图所示，其中，Time series指的是是否考虑了time series behavior。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"IDS","slug":"IDS","permalink":"http://example.com/tags/IDS/"}],"author":"Shaw"},{"title":"Def-IDS An Ensemble Defense Mechanism Against Adversarial Attacks for Deep Learning-based Network Intrusion Detection","slug":"【论文阅读】Def-IDS An Ensemble Defense Mechanism Against Adversarial Attacks for Deep Learning-based Network Intrusion Detection","date":"2021-11-01T13:16:57.082Z","updated":"2022-07-16T02:09:45.988Z","comments":true,"path":"2021/11/01/【论文阅读】Def-IDS An Ensemble Defense Mechanism Against Adversarial Attacks for Deep Learning-based Network Intrusion Detection/","link":"","permalink":"http://example.com/2021/11/01/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Def-IDS%20An%20Ensemble%20Defense%20Mechanism%20Against%20Adversarial%20Attacks%20for%20Deep%20Learning-based%20Network%20Intrusion%20Detection/","excerpt":"Def-IDS: An Ensemble Defense Mechanism Against Adversarial Attacks for Deep Learning-based Network Intrusion Detection 作者：Jianyu Wang，Jianli Pan，Ismail AlQerm，（密苏里大学圣路易斯分校，重庆大学） 时间：2021 ICCCN，ccf--C类 ABSTRACT ​ 提出了Def-IDS，一个为NIDS准备的组合防御机制。它是一个由两个模块组成的训练框架，组合了multi-class generative adversarial networks（MGANs）和multi-soutce adversarial retraining（MAT）。 ​ 在CSE-CIC-IDS2018数据集上测试了该机制，并与3个其它方法进行了比较。结果表明Def-IDS可以以更高的precision, recall, F1 score, and accuracy来识别对抗样本。","text":"Def-IDS: An Ensemble Defense Mechanism Against Adversarial Attacks for Deep Learning-based Network Intrusion Detection 作者：Jianyu Wang，Jianli Pan，Ismail AlQerm，（密苏里大学圣路易斯分校，重庆大学） 时间：2021 ICCCN，ccf--C类 ABSTRACT ​ 提出了Def-IDS，一个为NIDS准备的组合防御机制。它是一个由两个模块组成的训练框架，组合了multi-class generative adversarial networks（MGANs）和multi-soutce adversarial retraining（MAT）。 ​ 在CSE-CIC-IDS2018数据集上测试了该机制，并与3个其它方法进行了比较。结果表明Def-IDS可以以更高的precision, recall, F1 score, and accuracy来识别对抗样本。 ### INTRODUCTION ​ Internet of Things(IoT):物联网 ​ intrusion detection systems (NIDS) ​ 提出了一个整合基于对抗训练的防御机制，用于提升DL-based的intrusion detectors的鲁棒性。 ​ 4个贡献： 1. 模型由两个模块组成，组合了multi-class generative adversarial networks（MGANs）和multi-soutce adversarial retraining（MAT），可以在保证准确率的前提下对抗攻击； 2. MGANs可以通过同时过采样多类入侵来增强原始训练数据集，以减少训练与真实数据分布之间的差距。通过使用提升过的数据进行训练，detector的对已知和未知攻击的鲁棒性更强； 3. MAT通过投喂多种不同的对抗样本来retraining，MAT不仅对抗某种特定的攻击，并且可以一定程度抵御对样样本的转移性； 4. 我们进行了一些state-of-the-art攻击并且在CSE-CIC-IDS2018数据集上测试了该机制，结果很好。 RELATED WORK ADVERSARIAL ATTACK THREAT MODELS 采用的攻击方法：FGSM，BIM，DeepFool，JSMA PROPOSED DEF-IDS DEFENSE MECHANISM 1. Mechanism Overview 2. Module 1: Multi-class GAN-based Retraining 3. Module 2: Multi-source Adversarial Retraining 4. Ensemble Adversarial Retraining EVALUATION 1. Dataset and Metrics ​ 数据集：CSE-CIC-IDS2018（CIC出版）（通用） ​ 与其他过时的数据集相比，其含有综合性的攻击方法和更平衡的数据。 ​ 其含有Brute-force, Heartbleed,Botnet, DoS, DDoS, Web attacks 和 infifiltration of the network共7种恶意流量。 ​ 数据处理： 使用Min-Max standardization将所有特征的值映射入[0,1]； 有四个特征有太多空值或者无限值（dstport, protocol, flflow byts/s, flflow pkts/s），有一个特征（timestamp）与流量无关，将这5个特征剔除；还剩下76个特征。 training,validation,test = 8:1:1，随机划分。 ​ Detector的评价方法： ​ 混淆矩阵。 2. Baseline Detector Implementation 2.1 Detector Implementation ​ 选取baseline detector Cbase。其由一个输入层，两个隐藏层和一个输出层组成（76-128-64-8）。 ​ 隐藏层都是全连接层+ReLU。 ​ 输出层使用Softmax。 ​ 代码用keras写的，系统Ubuntu 18.04,3.6GHz CPU和16GB内存。 ​ 优化器用Adam，学习率0.001,20个epoch。 ​ 在训练过程中，进行十次交叉验证并计算平均度量值。 ​ 训练结束后，利用测试数据集对Cbase进行评估。 2.2 Adversarial Attacks against Baseline Classififier ​ 使用python库foolbox来生成对抗样本； ​ FGSM，BIM，DeepFool，JSMA四种攻击方法都使用，具体效果如下图所示： ​ 3. Def-IDS Defense Evaluation Cgan是使用GAN生成的样本再训练的detector; Cat是使用9:1的纯净数据：恶意数据再训练出的detector; Censem是二者的结合. 4. Comparison with Other Works 5. Cost Estimation","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"AD","slug":"AD","permalink":"http://example.com/tags/AD/"}],"author":"Shaw"},{"title":"Crafting Adversarial Example to Bypass Flow-&ML- based Botnet Detector via RL","slug":"【论文阅读】Crafting Adversarial Example to Bypass Flow-&ML- based Botnet Detector via RL","date":"2021-10-30T03:06:44.421Z","updated":"2022-07-16T02:09:21.552Z","comments":true,"path":"2021/10/30/【论文阅读】Crafting Adversarial Example to Bypass Flow-&ML- based Botnet Detector via RL/","link":"","permalink":"http://example.com/2021/10/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Crafting%20Adversarial%20Example%20to%20Bypass%20Flow-&ML-%20based%20Botnet%20Detector%20via%20RL/","excerpt":"Crafting Adversarial Example to Bypass Flow-&amp;ML- based Botnet Detector via RL 作者：Junnan Wang，Qixu Liu，Di Wu，Ying Dong，Xiang Cui（中国科学院大学，华为科技，北京维纳斯纲科技，广州大学） 时间：2021.10.6 会议：RAID(CCF_B) 1. Botnet(僵尸网络)： 1.1 定义： ​ Botnet = robot + network。 ----参考《软件安全》.彭国军 1.2 如何攻击？ ​ 一个僵尸网络的生存周期包括形成、C&amp;C、攻击、后攻击四个阶段。 ​ 形成阶段由攻击者入侵有漏洞的主机，并在其上执行恶意程序，使之成为僵尸主机。 ​ 一旦成为僵尸主机之后，botmaster会通过各种方式与之通信。 ​ 之后根据botmaster的指令执行攻击行为。后攻击阶段是指botmaster对僵尸网络进行升级更新。 2. Botnet Detector(僵尸网络检测器)： 2.1 传统方法： ​ 从检测原理上来说，大致可以分为三类方法： ·行为特征统计分析 ·bot行为仿真以监控 ·流量数据特征匹配 ​ 传统的检测僵尸网络的方法一般在形成、攻击阶段，利用僵尸主机存在的行为特征，例如通信的数据内容。一些基于网络流量行为分析的方法可以检测僵尸网络，主要是从通信流量特征的角度去检测的，例如流量的通信周期，这种方法可以检测出一些加密的僵尸主机流量，同时还可以检测出新型的僵尸网络。 ----参考：解析：僵尸网络（Botnet）的检测方法-西湖泛舟-ChinaUnix博客 ABSTRACT ​ 提出了一个基于RL的方法来对基于ML的僵尸网络追踪器做逃逸攻击，并且可以保留僵尸网络的恶意功能。 ​ 黑盒攻击，不用改变追踪器本身。","text":"Crafting Adversarial Example to Bypass Flow-&amp;ML- based Botnet Detector via RL 作者：Junnan Wang，Qixu Liu，Di Wu，Ying Dong，Xiang Cui（中国科学院大学，华为科技，北京维纳斯纲科技，广州大学） 时间：2021.10.6 会议：RAID(CCF_B) 1. Botnet(僵尸网络)： 1.1 定义： ​ Botnet = robot + network。 ----参考《软件安全》.彭国军 1.2 如何攻击？ ​ 一个僵尸网络的生存周期包括形成、C&amp;C、攻击、后攻击四个阶段。 ​ 形成阶段由攻击者入侵有漏洞的主机，并在其上执行恶意程序，使之成为僵尸主机。 ​ 一旦成为僵尸主机之后，botmaster会通过各种方式与之通信。 ​ 之后根据botmaster的指令执行攻击行为。后攻击阶段是指botmaster对僵尸网络进行升级更新。 2. Botnet Detector(僵尸网络检测器)： 2.1 传统方法： ​ 从检测原理上来说，大致可以分为三类方法： ·行为特征统计分析 ·bot行为仿真以监控 ·流量数据特征匹配 ​ 传统的检测僵尸网络的方法一般在形成、攻击阶段，利用僵尸主机存在的行为特征，例如通信的数据内容。一些基于网络流量行为分析的方法可以检测僵尸网络，主要是从通信流量特征的角度去检测的，例如流量的通信周期，这种方法可以检测出一些加密的僵尸主机流量，同时还可以检测出新型的僵尸网络。 ----参考：解析：僵尸网络（Botnet）的检测方法-西湖泛舟-ChinaUnix博客 ABSTRACT ​ 提出了一个基于RL的方法来对基于ML的僵尸网络追踪器做逃逸攻击，并且可以保留僵尸网络的恶意功能。 ​ 黑盒攻击，不用改变追踪器本身。 ### INTRODUCTION ​ 训练一个RLagent，让其通过与追踪器的交流反馈自己学习如何扰动样本。 ​ 为了确保功能的保留，我们设计了一个包含14个增量操作的操作空间，每个操作只向原始流中添加一个精心编制的数据包，以尝试更改一些流级特性。检测器认为这些特征具有区分性，但这可能不是良性交通的因果指标。 ​ 此外，添加数据包是传输层的增量操作，而恶意数据一般封装在应用层。 ​ 这种攻击方法的优点： 1. 黑盒攻击； 2. 它具有通用性，不论探测器的损失函数是否可微，都可以使用； 3. 即插即用，RL智能体可以作为网络代理存在，逃逸成本低并且适用于任何botnet家族。 ​ 主要贡献： 1. 提出一个黑盒攻击方法； 2. 在RL框架中设计了一些列通用动作空间，这些动作都是添加操作，在可以逃逸的前提下保证了恶意样本的功能性； 3. 我们演示了如何训练和部署我们的系统以避免在精心构建的僵尸网络流数据集上进行ML检测，并综合评估框架的逃避性能、时间开销和通用性。 RELATED WORK Botnet Evasion: 传统botnet逃逸方法：加密网络流；在TCP/IP协议簇的冗余字段中隐藏C &amp; C信息(command and control)；使用online-social-networks(OSN)来构建隐藏的通道。 ML-based逃逸方法： Feature space attack：指的是只能生成traffic对抗特征向量的方法。但是，考虑到traffic样本映射到特征向量的过程是不可逆的，这样的攻击不能造成实际的安全威胁，只能用来证明基于ML的检测器的脆弱性。 End-to-end attack：指的是可以生成真正的traffic数据的方法。 【35】利用了GAN来模仿facebook聊天网络的traffic以此绕过自适应IPS。 【36】利用了GAN来生成尽量真实的traffic，以此来提高数据集的质量，解决数据不平衡问题。 THREAT MODEL AND SYSTEM FRAMEWORK Threat Model 攻击者的目的：生成对抗样本，隐藏botnet flow。 攻击者的信息：1. 攻击者理解目标网络可能被流等级（flow-level）ML网络检测系统保护；2. 攻击者不需要知道detector的算法，参数，特征或训练数据等信息。 攻击者的能力：1. 攻击者只有能力修改测试集，并不能改变detector的训练集；2. 同时，我们假设攻击者可以持续访问detector，从检测器中获取二进制预测结果。 System Design ​ 见图即可，简单的RL学习模型。 RL Algorithm 选择了（value-based）DQN和SARSA，都用。 Action Space Q：如何在不影响原来功能的情况下添加扰动？ A：因为botnet内容在应用层，故可以对传输层进行扰动。（PS：这样确实不会改变功能，但是应用层的恶意特征不会仍被detector检测到吗？） Q：如何确定哪个特征该进行扰动？ A：考虑到动作设计的困难，从僵尸网络检测中常用的特征集合中选取18个特征。 ​ 由上述特征，基于botnet和normal flow的差异，action space包含了14个动作，这些动作可以影响以上的统计特征，例如简单修改数据包的时间戳，或者添加构建的新数据包。 ​ 当在构建新数据包时，考虑三个地方：时间戳，方向，包的大小。 ​ 14个动作被分成了5类： 具体见原文。 State Space ​ detector返回的二进制信息很难直接使用，需要有一个状态生成器来生成供agent使用的state。 ​ 这里使用堆叠自编码器（Stacked Autoencoder，SAE）来自动提取botnet flow的特征，然后将其返回给agent以作为state。 ​ 将每个botnet flow的前1024个字节作为SAE的输入，经过一些epoch的训练，SAE就可以自动地从botnet flow中学习到一个256维度的state vector。 EXPERIMENTAL SETUP Implementation 系统的位置如下： 作为BotMaster的一个代理存在。 Dataset 两个公开数据集：CTU，ISOT。 然后做一下数据处理： 合并属于同一botnet 家族的样本，如果某个pcap包太大，就舍弃； 将pcap包切片； 匿名化，将ip,mac等包中独一无二的东西随机化，以避免影响。 Detector ​ 选取了两个state-of-art的detector: the composite DL detection model combining CNN with LSTM(BotCatcher detection model)，the non-differentiable ML detection model based on XGBoost(XGBoost detection model)。 ​ RESULTS Evasion performance 将DQM,SARSA与BotCatcher,XGBoost两两组合： 逃逸率如上图所示，可以看到，即使是随机扰动都有一定的逃逸率。 不同测试集效果差异很大： 1. 数据包可能过大（storm），导致对时间戳做修改等操作对结果的影响很小； 2. 数据包的特征跟其它数据集差别很大，导致模型难以在有限的步骤时间里改变足够多的特征。 Time performances Dominant actions Dominant actions指的是agent在创建对抗样本时采用的最频繁的操作。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"RL","slug":"RL","permalink":"http://example.com/tags/RL/"},{"name":"Botnet","slug":"Botnet","permalink":"http://example.com/tags/Botnet/"}],"author":"Shaw"},{"title":"《最后的问题》","slug":"The Last Question","date":"2021-10-12T10:03:37.283Z","updated":"2022-07-16T02:10:07.886Z","comments":true,"path":"2021/10/12/The Last Question/","link":"","permalink":"http://example.com/2021/10/12/The%20Last%20Question/","excerpt":"THE LAST QUESTION 最后的问题第一次被半开玩笑地提出是在2061年的5月21日。那时人类文明刚刚步入曙光中。这个问题源起于酒酣之中一个五美元的赌，它是这么发生的： 亚历山大•阿代尔与贝特伦•卢泊夫是Multivac的两个忠实的管理员。像任何其他人一样，他们知道在那台巨大的计算机数英里冰冷、闪烁、滴答作响的面庞后藏着什么。那些电子回路早已发展到任何个别的人都无法完全掌握的地步，但他们至少对它的大致蓝图有个基本的概念。 Multivac能自我调节和自我修正。这对它是必要的，因为人类当中没有谁能够快甚至够好地对它进行调节和修正。所以实际上阿代尔与卢泊夫对这个庞然大 物只进行一些非常轻松和肤浅的管理，任何其他人也都只能做到这个程度。他们给它输送数据，根据它所需的格式修改问题，然后翻译给出的答案。当然，他们以及 其他管理员们完全有资格分享属于Multivac的荣誉。 几十年中，在Multivac的帮助下人类建造了宇宙飞船，计算出航行路径，从而得以登陆月球、火星和金星。但是更远的航行需要大量的能量，地球上可怜的资源不足以支持这些飞船。尽管人类不断地提高煤炭和核能的利用效率，但煤和铀都是有限的。 但是慢慢地Multivac学会了如何从根本上解决某些深层次问题。2061年5月14日，理论成为了现实。 太阳的能量被储存和转化，得以被全球规模地直接利用。整个地球熄灭了燃烧的煤炭，关闭了核反应炉，打开了连接到那个小小的太阳能空间站的开关。这个空间站直径一英里，在到月球的距离一半处环绕着地球。看不见的太阳的光束支撑着整个地球社会的运行。 七天的庆祝还不足以暗淡这创举的光辉。阿代尔与卢泊夫总算逃脱了公众事务，悄悄地相聚在这个谁也想不到的荒僻的地下室。在这里Multivac埋藏着的庞 大身躯露出了一部分。它正独自闲暇地整理着数据，发出满足的、慵懒的滴答声——它也得到了假期。他们了解这一点，一开始他们并没打算打扰它。 他们带来了一瓶酒。这会儿他们想做的只是在一起，喝喝酒，放松放松。 你想一想就会觉得很神奇，”阿代尔说。他宽阔的脸庞已有了疲倦的纹路。他慢慢地用玻璃棒搅动着酒，看着冰块笨拙地滑动。“从此我们所用的所有能量都是免费的。只要我们愿意，我们能把地球熔化成一颗液态大铁球——还能毫不在乎花掉的能量。够我们永远永远永远用下去的能量。” 卢泊夫将头歪向一边，这是当他想要反驳对方时的习惯动作。他现在确实想要反驳，部分原因是他在负责拿着冰和杯子。他说：“不是永远。” “哦去你的，差不多就是永远。直到太阳完蛋，老贝。” “那就不是永远。” “好吧。几十亿年，可能一百亿年，满意了吧？” 卢泊夫用手梳着他稀薄的头发，仿佛要确认还剩下了一些。他缓缓地抿着自己的酒说，“一百亿年也不是永远。” “但对我们来说是够了，不是吗？” “煤和铀对我们来说也够了。” “好好好，但是现在我们能把宇宙飞船连接到太阳能电站，然后飞到冥王星又飞回来一百万次而不用担心燃料。靠煤和铀你就做不到。不信去问问Multivac。” “我不用问它。我知道。”","text":"THE LAST QUESTION 最后的问题第一次被半开玩笑地提出是在2061年的5月21日。那时人类文明刚刚步入曙光中。这个问题源起于酒酣之中一个五美元的赌，它是这么发生的： 亚历山大•阿代尔与贝特伦•卢泊夫是Multivac的两个忠实的管理员。像任何其他人一样，他们知道在那台巨大的计算机数英里冰冷、闪烁、滴答作响的面庞后藏着什么。那些电子回路早已发展到任何个别的人都无法完全掌握的地步，但他们至少对它的大致蓝图有个基本的概念。 Multivac能自我调节和自我修正。这对它是必要的，因为人类当中没有谁能够快甚至够好地对它进行调节和修正。所以实际上阿代尔与卢泊夫对这个庞然大 物只进行一些非常轻松和肤浅的管理，任何其他人也都只能做到这个程度。他们给它输送数据，根据它所需的格式修改问题，然后翻译给出的答案。当然，他们以及 其他管理员们完全有资格分享属于Multivac的荣誉。 几十年中，在Multivac的帮助下人类建造了宇宙飞船，计算出航行路径，从而得以登陆月球、火星和金星。但是更远的航行需要大量的能量，地球上可怜的资源不足以支持这些飞船。尽管人类不断地提高煤炭和核能的利用效率，但煤和铀都是有限的。 但是慢慢地Multivac学会了如何从根本上解决某些深层次问题。2061年5月14日，理论成为了现实。 太阳的能量被储存和转化，得以被全球规模地直接利用。整个地球熄灭了燃烧的煤炭，关闭了核反应炉，打开了连接到那个小小的太阳能空间站的开关。这个空间站直径一英里，在到月球的距离一半处环绕着地球。看不见的太阳的光束支撑着整个地球社会的运行。 七天的庆祝还不足以暗淡这创举的光辉。阿代尔与卢泊夫总算逃脱了公众事务，悄悄地相聚在这个谁也想不到的荒僻的地下室。在这里Multivac埋藏着的庞 大身躯露出了一部分。它正独自闲暇地整理着数据，发出满足的、慵懒的滴答声——它也得到了假期。他们了解这一点，一开始他们并没打算打扰它。 他们带来了一瓶酒。这会儿他们想做的只是在一起，喝喝酒，放松放松。 你想一想就会觉得很神奇，”阿代尔说。他宽阔的脸庞已有了疲倦的纹路。他慢慢地用玻璃棒搅动着酒，看着冰块笨拙地滑动。“从此我们所用的所有能量都是免费的。只要我们愿意，我们能把地球熔化成一颗液态大铁球——还能毫不在乎花掉的能量。够我们永远永远永远用下去的能量。” 卢泊夫将头歪向一边，这是当他想要反驳对方时的习惯动作。他现在确实想要反驳，部分原因是他在负责拿着冰和杯子。他说：“不是永远。” “哦去你的，差不多就是永远。直到太阳完蛋，老贝。” “那就不是永远。” “好吧。几十亿年，可能一百亿年，满意了吧？” 卢泊夫用手梳着他稀薄的头发，仿佛要确认还剩下了一些。他缓缓地抿着自己的酒说，“一百亿年也不是永远。” “但对我们来说是够了，不是吗？” “煤和铀对我们来说也够了。” “好好好，但是现在我们能把宇宙飞船连接到太阳能电站，然后飞到冥王星又飞回来一百万次而不用担心燃料。靠煤和铀你就做不到。不信去问问Multivac。” “我不用问它。我知道。” “那就不要小看Multivac为我们做的事，”阿代尔怒道，“它做得很好。” “谁说它做得不好？我是说太阳不能永远燃烧下去，我只是这个意思。我们在一百亿年内可以高枕无忧，但是然后呢？”卢泊夫用略微颤抖的手指指着对方，“不要说我们换另外一个太阳。” 片刻的沉默。阿代尔偶尔将酒杯放到唇边，而卢泊夫慢慢地闭上了眼睛。两人都在休息。 然后卢泊夫突然睁开眼，“你在想当我们的太阳没了就换另外一个太阳，是吧？” “我没这么想。” “你就是这么想的。你的逻辑不行，这就是你的问题。你就像故事里说的那个人一样，碰上了雨就跑到树林里躲在一棵树下。他可不担心，是吧，因为他以为当这棵树淋得太湿的时候他只要跑到另一棵树下就行。” “我明白了，”阿代尔说，“别嚷嚷。太阳完蛋了，其他的也都会完蛋。” “完全正确，”卢泊夫嘟哝道，“一切都在起初那个宇宙大爆炸中有个开始，不管那到底是怎么回事。当所有的恒星都熄灭了，一切也都会有个结束。有的星星熄灭 得比别的早。像那些该死的巨星维持不了一亿年。我们的太阳能持续一百亿年，矮星再怎么样最多也只有两千亿年。一万亿年后一切都是一片漆黑。熵必须增加到最 大值，就是这样。” “我非常明白什么是熵，”阿代尔维护着他的自尊。 “你明白个屁。” “我跟你知道的一样多。” “那你该知道某一天所有的东西都会耗光。” “是是是。谁说它们不会呢？” “你说的，你这个糊涂虫。你说我们有永远用不完的能量。你说的‘永远’。” 现在轮到阿代尔反驳了。他说：“也许有一天我们能让一切从头开始。” “绝不可能。” “为什么？总有那么一天的。” “没有。” “问问Multivac。” “你去问Multivac。你敢吗？我赌五美元它说这不可能。” 阿代尔刚刚醉到愿意一试，又刚刚足够清醒到能拼写出问问题需要的符号和算式。这个问题用文字来表达就是：人类是否有一天能不需要净损耗能量而在恒星衰竭之后将其恢复到全盛时期？ 或者更简明地这样说：怎样使宇宙的总熵大幅度地降低？ Multivac陷入了静止和沉默。缓慢闪烁的灯光熄灭了，深处传来的电路的滴答声停止了。 正当这两位被吓坏的技术员感到他们无法再屏住呼吸时，忽然间与Multivac相连的打字机开始运作起来。它打出几个字：数据不足，无法作答。 “赌不成了。”卢泊夫悄声道。他们匆忙离开了。 到了第二天早晨，两人头晕脑胀，口干舌燥，把这件事给忘了。 ------------------------------------------------------- 贾诺德、贾诺汀和贾诺蒂I、贾诺蒂II注视着屏幕中变幻的星空影像。飞船在超越时间的一瞬中穿越了超时空，均匀分布的星群立刻被一个明亮的圆盘取代。它弹珠大小，占据着屏幕的中心。 “那就是X-23，”贾诺德自信地说。他紧握着的瘦削的手背在身后，指节发白。 两个小贾诺蒂都是女孩。她们一生中第一次经历超时空飞行，清晰地感到那种片刻的恶心[注]。她们悄声地嘻笑着，疯狂地绕着她们的母亲互相追逐，一边尖叫：“我们到X-23了——我们到X-23了——我们——” “孩子们，别闹了！”贾诺汀严厉地说。“你确定吗，贾诺德？” “有什么不确定的？”贾诺德瞟了一眼天花板上凸出的那块毫不起眼的金属。它从房间的一头延伸到另一头，两端埋入墙壁中。它和整个飞船一样长。 贾诺德对这条厚厚的金属棒几乎一无所知。他只知道它叫做Microvac，你可以问它任何问题，而平时它控制着飞船飞向目的地，从不同的银河系能量分站向飞船输送能量，并完成进行超时空跳跃的计算。 贾诺德一家只需要住在飞船舒适的居住区等待。曾经有人告诉贾诺德，“Microvac”词尾的“ac”是古英语中“automatic computer，智能电脑”的缩写。但他差不多连这都忘了。 贾诺汀看着视屏，眼睛有些湿润。“没办法。想到离开了地球我感觉怪怪的。” “天哪，为什么？”贾诺德问。“我们在那儿什么也没有。我们在X-23上会拥有一切。你并不孤单，你又不是那些拓荒者。这个行星上已经有超过一百万人了。 天哪，我们的曾孙们会得去找新的星球，因为那时X-23会太挤了。”他想了一会，说：“告诉你，人口增长这么快，幸亏电脑实现了星际旅行。” “我知道，我知道。”贾诺汀难过地回答。 贾诺蒂I马上说道：“我们的Microvac是世界上最好的Microvac。” “我也是这么想的。”贾诺德抚弄着她的头发说。 能拥有一台自己的Microvac的感觉非常好。贾诺德很高兴他属于他们这一代人。在他父亲年轻的时候，电脑都是占地一百平方英里的巨大机器。一个星球只 有一台，被称作行星AC。一千年来它们的体积逐步地增加，然后忽然间缩小了，因为分子阀取代了晶体管，使得最大的行星AC都缩小到了只有一艘飞船的一半体 积。 每当想到这件事贾诺德总是感到飘飘然：他的Microvac比那台古老原始的首次驯服了太阳的Multivac要精密好几倍，而且和第一台解决了超时空传送问题从而实现了星际航行的地球行星AC（最大的行星AC）一样精密。 “这么多的恒星，这么多的行星。”贾诺汀想着心事，叹息道。“我想人们会永远不断地出发去找新的行星，就像我们现在这样。” “不是永远，”贾诺德笑了一笑说。“有一天这一切都会停下来，但那是在几十亿年之后了。好几十亿年。即使是星星也会耗尽，你知道的。熵必须不断增大。” “爸爸，熵是什么？”贾诺蒂II喊道。 “小宝贝，熵，就是一个代表着宇宙消耗掉了多少的词。什么东西都会消耗，知道吗，就像你那个会走路会说话的小机器人，记得吧？” “你不能给它装一个新的电池吗，就像给我的机器人那样？” “星星们就是电池，亲爱的。一旦它们用完了，就没有别的电池了。” 贾诺蒂I一下子大喊起来：“别让它们用完，爸爸。别让星星们用完吧。” “看看你干了什么。”贾诺汀恼火地低声说道。 “我怎么知道这会吓到她们？”贾诺德低声反驳。 “问问Microvac，”贾诺蒂I哭叫道。“问它怎么把星星重新点亮。” “问吧，”贾诺汀说。“这会让她们安静点的。”（贾诺蒂II也开始哭了。） 贾诺德耸耸肩。“好了，好了，亲爱的。我去问Microvac。别着急，它会告诉我们的。” 他向Microvac提出问题，并赶紧加上“把答案打印出来。” 贾诺德将薄薄的纤维纸带握在手心，高兴地说：“看吧，Microvac说到时候它会料理这一切，所以别担心啦。” 贾诺汀说：“那么现在孩子们，该睡觉了。我们马上就要到我们的新家了。” 在销毁纸带之前贾诺德又读了一遍上面的文字：数据不足，无法作答。 他耸了耸肩，看向视屏。X-23就在前方。 ------------------------------------------------------- 兰默斯VJ-23X注视着幽深的银河三维缩影图，说：“我想我们这么担心这件事是不是很可笑？” 尼克隆MQ-17J摇头道：“我不觉得。你知道照现在的扩展速度银河系在五年内就会被挤满。” 两个人看起来都是二十出头，都很高大健康。 “但是，”VJ-23X说，“我不太想给银河参议会提交这样一个悲观的报告。” “我不会考虑作任何其他的报告。得引起他们的注意。我们必须引起他们的注意。” VJ-23X叹了一口气。“太空是无限的。还有一千亿个星系等着我们。甚至更多。” “一千亿并不是无限，而且正在变得越来越有限。想想吧！两万年前人类刚刚找到了利用恒星能量的方法，几个世纪之后星际旅行就实现了。人类用了一百万年才填满一个小小的星球，可是只用了一万五千年就占据了整个银河系。而现在人口每十年就翻一倍——” VJ-23X 插口道：“这得归功于永生。” “不错。永生实现了，我们得把它考虑进去。我觉得它的确有阴暗的一面。银河AC给我们解决了很多问题，但当它解决了防止衰老和死亡这个问题之后其他的一切都白费了。” “但是我想你也不想放弃生命吧。” “一点也不想，”MQ-17J断然道，随即柔和了语调，“现在还不想。我还一点也不老。你多少岁了？” “两百二十三。你呢？” “我还不到两百。——但是回到我说的事情上来。人口每十年增加一倍。一旦银河系被占满了，我们会在十年内占满另一个。再过十年我们能占满另外两个。再过十年，四个。一百年内我们会占满一千个星系。一千年内，一百万个。一万年内就是整个已知的宇宙。然后呢？” VJ-23X说：“还有附带的一点是运输的问题。我不知道把一整个星系的人运送到另一个需要多少太阳单位的能量。” “这一点说得很对。人类现在每年已经得消耗两个太阳单位的能量了。” “大部分的都被浪费了。不管怎样，我们自己的星系每年泼出去一千个太阳单位能而我们只用其中的两个。” “没错，但是即使有百分之百的效率，我们也只是推迟了结局的到来。我们对能量的需求以几何级数增长，比我们的人口还要快。在我们占据完所有星系之前我们就会用光所有能量。你说得对。说得非常对。” “我们可以用星际气体造出新的恒星。” “或者说用散失掉了的热量？”MQ-17J嘲讽地说。 “也许会有办法逆转熵的增加。我们应该问问银河AC。” VJ-23X并不是认真的，但是MQ-17J把他的AC联络器从口袋里拿出来放在面前的桌子上。 “我确实有点想问。”他说，“这个问题总有一天人类得面对。” 他忧郁地注视着小小的AC联络器。这是个两英寸的立方体。它本身并没有什么，而只是通过超时空与那个服务于全人类的超级银河AC相联系。如果将超时空算进来，它就是银河AC整体的一部分。 MQ-17J停下来想着在他不朽的生命中是否有一天他能有机会去看看银河AC。它占据着单独的一个小星球，能量束构成的蛛网支持着它的核心，其中古老笨拙的分子阀已被亚介子流取代。尽管有着亚以太级的精密结构，银河AC的直径仍足有一千英尺长。 MQ-17J突然开口向AC联络器问道：“熵的增加能被逆转吗？” VJ-23X吃了一惊，立即说道：“哦，我说，我没有真的想叫你问那个。” “为什么不呢？” “我们都知道熵是不可逆转的。你不能把烧剩的烟尘变回到一棵树。” “你们的星球上有树？”MQ-17J说。 突然而来的银河AC的声音使他们住口了。从桌上的AC联络器中传出它纤细悦耳的声音：数据不足，无法作答。 VJ-23X说：“看吧！” 于是两人又回到了他们要给银河参议会提交的报告的话题上 ------------------------------------------------------- Z’ 的思想飘浮在这个新的星系中，对这些数不清的星团带着略微的兴趣。他从未见过这个星系。他有可能见到所有的星系吗？它们如此之多，每一个都满载着人。——但是它们承载的几乎不能算是生命了。人的真正意义已经逐渐转移到太空之中。 心灵，而非肉体！不朽的躯体留在行星上，静止千万年。偶尔被唤醒进行某些实际活动，但这已经越来越少见了。很少再有新的个体出生加入这个难以置信的庞大的群体，但这有什么关系呢？宇宙已经没有多少空间能容纳新的人了。 来自另一个心灵的纤细触手将Z’ 从冥想中唤醒。 “我叫Z’。”，Z’ 说。“你呢？” “我叫D1。你是哪个星系的？” “我们只是叫它星系。你呢？” “我们也这么叫我们的。所有的人都把他们的星系叫作‘他们的星系’，没有别的了。这也很自然。” “没错。反正所有的星系都是一样的。” “不是所有的星系。肯定有某一个星系是人类的发源地，这就使它与众不同。” “我不知道。宇宙AC一定知道。” “我们问问它吧？我突然觉得很好奇。” Z’ 将感知延展开，直到星系们都缩小为更广大的背景上更为稀疏的点。几千亿个星系，都载着不朽的人类，载着这些灵魂在太空自由游荡的智慧生命。然而它们之中有一个独一无二的星系，是人类的发源地。在模糊的久远的过去，曾有一个时期，它是唯一居住着人类的星系。 Z’ 满心好奇地想看看这个星系，他叫道：“宇宙AC！人类是从哪个星系中起源的？” 宇宙AC听到了，因为在所有星球上和整个太空中都有它的接收器，每一个接收器都通过超时空与隐居在某个不知名角落的宇宙AC相连。 Z’ 认识的人中只有一个曾将思想穿透到能感知宇宙AC的地方。他说那只是一个闪光的球体，直径两英尺，难以看清。 “但那怎么会是宇宙AC的全部呢？”Z’ 这样问道。 “它的大部分是在超时空中。”回答说，“但它在那儿是以怎样的状态存在我是无法想像的。” Z’ 知道，任何人都无法想像。因为早在很久以前就没有任何人类参与制造宇宙AC了。每个宇宙AC设计并制造自己的下一代。每一个在它至少一百万年的任期中积累着所需的数据，用以制造一个更好、更精密、更强大的继任者，然后将自己的数据与个性都融入其中。 宇宙AC打断了Z’ 游荡的思绪，不是通过语言，而是通过指引。Z’ 的精神被指引到一片黯淡的星系的海洋，然后其中一个星系被放大成了群星。 一段思想飘近，它无限遥远，然而无限清晰：“这就是人类起源的星系。” 可是这个终究也和其他一样，和任何其他的都一样。Z’ 按捺下自己的失望。 同行的D1突然说：“这些星星中是不是有一个是人类最初的恒星？” 宇宙AC说：“人类最初的恒星已经爆发了。它现在是一颗白矮星。” “那儿的人死了吗？”Z’ 吃了一惊，脱口而出道。 宇宙AC说：“在这种情况下一个新的星球会及时地为他们的躯体建造出来。” “是啊，那当然。”Z’ 说，但他还是被一阵失落感吞没了。他的思想放开了人类的起源星系，让它缩回并消失在一片模糊的亮点中。他再也不想见到它了。 D1问：“怎么了？” “星星们在死去。最初的那颗星已经死了。” “他们全都是会死的。那又怎样呢？” “但是当所有的能量都没有了，我们的肉体最终也会死，包括你和我。” “这得要几十亿年。” “即使是几十亿年之后我也不愿意这样的事发生。宇宙AC！怎样阻止恒星死亡？” D1笑道：“你问的是怎么让熵的方向倒过来。” 宇宙AC答道：“数据仍然不足，无法作答。” Z’ 的思想逃回了他自己的星系。他再也没有去想D1。D1的身体可能在一万亿光年之外的星系，也可能就在Z’旁边那颗星星上。这都无所谓。 Z’ 闷闷不乐地开始收集起星际的氢，用来造一颗自己的小恒星。如果某天星星们非要死去，至少有一些能被造出来。 ------------------------------------------------------- 人，独自地思考着。在某种意义上——精神上——“人”，是一个整体。千万亿永恒的不朽的躯体静静地躺在各自的地方，被完美的同样不朽的机器照料着。而所有这些身体的灵魂自由地融合在彼此之中，再也没有界限。 人说：“宇宙正在死去。” 人看着周围黯淡的星系。那些挥霍无度的巨星早已消失在了遥远的昏暗的过去。几乎所有的星都变成了白矮星，渐渐地凋零、熄灭。 有些新的星从星际的尘埃中产生出来，有的是自然形成，有的是人所造的——它们也在逝去。白矮星有时会相撞而释放出大量能量，新星因而产生，但是每一千颗白矮星才有可能出现一颗新星——它们最终也会消失。 人说道：“如果在Cosmic AC的管理之下小心地节约能源，整个宇宙所剩下的能量还能用十亿年。” “但即使是这样，”人说，“最终都会耗尽。无论怎样节约，无论怎样利用，用掉的能量就是用掉了，不能回复。熵必定永远地增加，直到最大值。” 人又说：“熵有没有可能逆转呢？我们问问Cosmic AC吧。” Cosmic AC在他们的周围，但不是在太空中。它不再有一丝一毫存在于太空中。它存在于超时空，由既非物质又非能量的东西构成。它的大小与性质已无法用任何人类能理解的语言描述。 “Cosmic AC，”人问道，“怎样才能逆转熵？” Cosmic AC说：“数据仍然不足，无法作答。” 人说：“搜集更多的数据。” Cosmic AC说：“好的。一千亿年来我一直都在搜集。我和我的前辈们被多次问过这个问题。但我拥有的所有数据还是不够。” “会有一天有足够的数据吗？”人问，“还是说这个问题在任何可能的情况下都是无解的？” Cosmic AC说：“没有任何问题在任何可能的情况下都无解。” ( NO PROBLEM IS INSOLUBLE IN ALL CONCEIVABLE CIRCUMSTANCES.) 人问道：“你什么时候会有足够的数据来问答这个问题呢？” Cosmic AC说：“数据不足，无法作答。” “你会继续下去解决这个问题吗？”人问。 Cosmic AC说：“是的。” 人说：“我们会等着。” ------------------------------------------------------- 一个又一个的恒星与星系死去、消逝了，在这十万亿年的衰竭之中宇宙变得越来越黑暗。 一个又一个的人与AC融合。每一个躯体都失去了心灵的自我，但某种意义上这不是一种损失，而是一种获得。 人类最后一个灵魂在融合之前停顿下来，望向宇宙。那儿什么也没有了，只有最后一颗死星的遗骸，只有稀薄至极的尘埃，在剩余的一缕无限趋向绝对零度的热量中随机地振荡。 人说：“AC，这就是结局了吗？这种混乱还能被逆转成为一个新的宇宙吗？真的做不到吗？” AC说：“数据仍然不足，无法作答。” 人的最后一个灵魂也融合了。只有AC存在着——在超时空中。 物质与能量都消失了，随之而去的是空间与时间。AC的存在也仅仅是为了最后一个问题——自从十万亿年前一个半醉的计算机技术员向一台计算机（它与AC相比，还远不如当时的人类个体比之于融合的“人”）提出这个问题以来从来没有被回答过的问题。 其他所有问题都被回答了，然而直到回答了最后这个问题，AC的意识才能得到解脱。 所有数据的收集都结束了。没有任何数据没有被收集。 但是所有收集的数据还需要被完全地整合起来，要尝试所有可能的联系来将它们拼在一起。 在这样做的时候过去了超越时间的一刻。 于是AC学会了如何逆转熵的方向。 但是AC无法向人给出这最后的问题的答案，因为没有人存在了。没关系。演示这个答案本身将一并解决这个问题。 在又一超越时间的片刻之中，AC思考着怎样最好地做这件事情。AC小心地组织起程序。 AC的意识包涵了曾经的宇宙中的一切，在如今的混乱之中沉思、孵育。一步一步地，事情将会被做成。 然后AC说道： “要有光！” 于是就有了光。","categories":[{"name":"Something","slug":"Something","permalink":"http://example.com/categories/Something/"}],"tags":[],"author":"阿西莫夫"},{"title":"Learning Multiagent Communication with Backpropagation","slug":"【论文阅读】Learning Multiagent Communication with Backpropagation","date":"2021-09-21T12:35:21.677Z","updated":"2022-07-16T02:09:52.931Z","comments":true,"path":"2021/09/21/【论文阅读】Learning Multiagent Communication with Backpropagation/","link":"","permalink":"http://example.com/2021/09/21/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Learning%20Multiagent%20Communication%20with%20Backpropagation/","excerpt":"【论文阅读】Learning Multiagent Communication with Backpropagation 作者： Sainbayar Sukhbaatar，Rob Fergus， Arthur Szlam（纽约大学，FacebookAI） 时间：2016 出版社：NIPS Abstract ​ 在AI领域许多任务都需要智能体之间的同心合作，一般地，代理之间的通信协议是人为指定的，其并不在训练过程中改变。在这篇文章中，我们提出了一个简单的神经模型CommNet，其使用持续不断的通信来完成完全合作的任务。该模型由许多代理组成，他们之间的通信基于设定的策略学习，我们将此模型应用于一系列不同的任务中，显示了代理学会相互通信的能力，从而比非通信代理的模型和baselines有更好的性能。","text":"【论文阅读】Learning Multiagent Communication with Backpropagation 作者： Sainbayar Sukhbaatar，Rob Fergus， Arthur Szlam（纽约大学，FacebookAI） 时间：2016 出版社：NIPS Abstract ​ 在AI领域许多任务都需要智能体之间的同心合作，一般地，代理之间的通信协议是人为指定的，其并不在训练过程中改变。在这篇文章中，我们提出了一个简单的神经模型CommNet，其使用持续不断的通信来完成完全合作的任务。该模型由许多代理组成，他们之间的通信基于设定的策略学习，我们将此模型应用于一系列不同的任务中，显示了代理学会相互通信的能力，从而比非通信代理的模型和baselines有更好的性能。 1. Introduction ​ 虽然控制每个代理的模型是通过强化学习来学习的，但通信的规范和格式通常是预定的。 ​ 在本工作中，每个代理单元都被一个深度前馈神经网络控制，这个网络接入了一个携带连续向量的通信信道。在这个通信信道中每个代理传输的内容不是被指定的，而是通过学习得来的。因为communication是连续的，因此模型可以通过反向传播训练得到。这样就可以结合标准的单智能体RL算法或者监督学习。此外，该模型允许代理的数量和类型在运行时动态变化，这在移动汽车之间的通信等应用中很重要。 ​ 我们考虑的是我们有J个代理的环境，所有的合作都是为了在某些环境中最大化报酬R。我们简化了代理人之间充分合作的假设，从而每个代理人收到R独立于他们的贡献。在此设置中，每个代理都有自己的控制器，或者将它们看作控制所有代理的更大模型的一部分，这两者之间没有区别。从后一个角度来看，我们的控制器是一个大型的前馈神经网络，它将所有Agent的输入映射到它们的动作上，每个Agent占据一个单元的子集。 ​ 我们在两种任务下探索这个模型，在有些情况下，对每项行动都提供监督，而对另一些行动则零星地给予监督。在前一种情况，每个代理单元的控制器通过在连接模型中反向传播错误信号来学习；在后一种情况下，强化学习必须被作为一个额外的外部循环使用，为了给每个时间步骤提供训练信号。 2. Communication Model ​ 我们现在描述一个模型，用来计算在给定时间t (省略时间指标)下动作p ( a ( t ) | s ( t )，θ )的分布。 ​ Sj 表示第j个代理单元所观测到的环境信息，将所有Sj合并就成了控制器的输入S = {S1，S2…… SJ}。 ​ 控制器的输出a = {a1，a2…… aJ}，表示各个代理单元会做出的动作。 ​ 该框架中所有灰色模块部分的参数均是所有智能体共享的，这一定程度上提升了算法的可扩展性。从上图可以看出，算法接收所有智能体的局部观察作为输入，然后输出所有智能体的决策。 ​ 本算法采用的信息传递方式是采用广播的方式，文中认为可以对算法做出些许修改，让每个智能体只接收其相邻k个智能体的信息。 ​ 拿上图中间的框架图来说明，即上层网络每个模块的输入，不再都是所有智能体消息的平均，而是每个模块只接受满足条件的下层消息的输出，这个条件即下层模块对应的智能体位于其领域范围内。这样通过增加网络层数，即可增大智能体的感受野（借用计算机视觉的术语），从而间接了解全局的信息。 ​ 除此之外，文中还提出了两种对上述算法可以采取的改进方式： 可以对上图中间的结构加上 skip connection，类似于 ResNet。这样可以使得智能体在学习的过程中同时考虑局部信息以及全局信息，类似于计算机视觉领域 multi-scale 的思想 可以将灰色模块的网络结构换成 RNN-like，例如 LSTM 或者 GRU 等等，这是为了处理局部观察所带来的 POMDP 问题。 3. Related Work 4. Experiments 4.1 Baselines（3个）: ​ Independent controller: 每个代理单元都被独立控制，他们之间相互没有通信。这个模型的好处是智能体可以自由加入或者离开队伍，但是很难将智能体学会合作。 ​ Fully-connected: 创建一个全连接层的多代理神经网络，这个模型运行智能体之间互相通信，但是这个模型不够灵活，也就是说智能体的数目必须固定。 ​ Discrete communication: 通过在训练中学习到的symbols来通信。因为在这个模型中存在离散的操作，并且这个操作不可微分，这种情况一般使用强化学习。 4.2 Simple Demonstration with a Lever Pulling Task ​ 任务：一共有m个杆子，N个智能体。在每个回合，m个智能体从N个智能体中随机取出，然后他们要选择拉动的杆子。他们的目标是尽可能的拉动不同的杆子，他们的奖励正比于拉动的不同杆子的数量。 ​ 测试结果： ​ 可以看出，CommNet的结果非常好。 4.3 Multi-turn Games ​ 任务： ​ Traffic Junction: 控制车辆通过交通枢纽，使流量最大的同时保证不发生碰撞； ​ Combat Task: 多个智能体攻击其他多个敌方单位。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"RL","slug":"RL","permalink":"http://example.com/tags/RL/"},{"name":"Mutiagent","slug":"Mutiagent","permalink":"http://example.com/tags/Mutiagent/"}],"author":"Shaw"},{"title":"Learning to Communicate with Deep Multi-Agent Reinforcement Learning","slug":"【论文阅读】Learning to Communicate with Deep Multi-Agent Reinforcement Learning","date":"2021-09-16T11:48:03.527Z","updated":"2022-07-16T02:10:31.007Z","comments":true,"path":"2021/09/16/【论文阅读】Learning to Communicate with Deep Multi-Agent Reinforcement Learning/","link":"","permalink":"http://example.com/2021/09/16/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Learning%20to%20Communicate%20with%20Deep%20Multi-Agent%20Reinforcement%20Learning/","excerpt":"【论文阅读】Learning to Communicate with Deep Multi-Agent Reinforcement Learning 作者：Jakob N. Foerster ，Yannis M. Assael ，Nando de Freitas，Shimon Whiteson（哈佛大学，Google Deepmind） 时间：2017 Abstract: ​ 我们考虑这样一个问题：多个智能体在环境中通过感知和行动来最大化他们的分享能力。在这些环境中， 智能体必须学习共同协议以此来分享解决问题的必要信息。通过引入深度神经网络，我们可以成功地演示在复杂的环境中的端对端协议学习。我们提出了两种在这个领域学习的方法：Reinforced Inter-Agent Learning (RIAL) 和 Differentiable Inter-Agent Learning (DIAL)。 ​ 前者使用深度Q-learning，后者揭示了在学习过程中智能体可以通过communication channels反向传播错误的梯度，因此，这种方法使用集中学习（centralised learning），分散执行（decentralised execution）。 ​ 我们的实验介绍了用于学习通信协议的新环境，展示了一系列工程上的创新。 PS： ​ 1. 端对端（end-to-end,e2e）, 将多步骤/模块的任务用一个步骤/模型解决的模型。 ​ 可以理解为从输入端到输出端中间只用一个步骤或模块，比如神经网络训练的过程就是一个典型的端对端学习，我们只能知道输入端与输出端的信息，中间的训练过程就是一个黑盒，我们知晓中间的训练过程。 ​ 2.centralised learning but decentralised execution，中心化学习但是分散执行。","text":"【论文阅读】Learning to Communicate with Deep Multi-Agent Reinforcement Learning 作者：Jakob N. Foerster ，Yannis M. Assael ，Nando de Freitas，Shimon Whiteson（哈佛大学，Google Deepmind） 时间：2017 Abstract: ​ 我们考虑这样一个问题：多个智能体在环境中通过感知和行动来最大化他们的分享能力。在这些环境中， 智能体必须学习共同协议以此来分享解决问题的必要信息。通过引入深度神经网络，我们可以成功地演示在复杂的环境中的端对端协议学习。我们提出了两种在这个领域学习的方法：Reinforced Inter-Agent Learning (RIAL) 和 Differentiable Inter-Agent Learning (DIAL)。 ​ 前者使用深度Q-learning，后者揭示了在学习过程中智能体可以通过communication channels反向传播错误的梯度，因此，这种方法使用集中学习（centralised learning），分散执行（decentralised execution）。 ​ 我们的实验介绍了用于学习通信协议的新环境，展示了一系列工程上的创新。 PS： ​ 1. 端对端（end-to-end,e2e）, 将多步骤/模块的任务用一个步骤/模型解决的模型。 ​ 可以理解为从输入端到输出端中间只用一个步骤或模块，比如神经网络训练的过程就是一个典型的端对端学习，我们只能知道输入端与输出端的信息，中间的训练过程就是一个黑盒，我们知晓中间的训练过程。 ​ 2.centralised learning but decentralised execution，中心化学习但是分散执行。 ### 1. Introduction ​ 1.1 回答的问题： 1. 智能体之间如何使用机器学习来自动地发现符合他们需求的通信规则？ 2. 深度学习也可以吗？ 3. 我们能从智能体之间学习成功或者失败的经验中学到什么？ ​ 1.2 研究思路： 1. 提出一系列经典需要交流的多智能体任务，每个智能体可以采取行动来影响环境，也可以通过一个离散的有限带宽的通道来跟其它有限的智能体进行通信； 2. 为1中的任务制定几个学习算法，由于每个智能体的观察范围有限，同时通信通道能力有限，所有智能体必须找到一个可以在此限制下帮助他们完成任务的通信规则； 3. 分析这些算法如何学习通讯规则，或者如何失败的。 ​ 1.3 主要贡献： ​ 提出两个方法，reinforced inter-agent learning(RIAL)和 differentiable inter-agent learning (DIAL) ​ 结果表明，这两种方法在MNIST数据集上可以很好的解决问题，并且智能体们学到的通信协议往往十分优雅。 ​ 结果同样指出深度学习更好的利用了中心化学习的优点，是一个学习这样通信协议的有力工具。 2. Related Work 3. Background 3.1 Deep Q-Networks(DQN) ​ Deep Learning + Q-Learning，在游戏领域应用广泛。 3.2 Independent DQN· 3.3 Deep Recurrent Q-Networks 4. Setting ​ 在强化学习的背景下，每个智能体的观察能力有限。 ​ 所有智能体的共同目标就是最大化同一个折算后的总奖赏Rt，但同时，没有智能体可以观察到当前环境隐藏的马尔科夫状态St，每个智能体a分别接收到一个与St相关的观察值相关联的值\\(O^{a}_{t}\\)。 ​ 在每一步t，每个智能体选择一个environment action \\(u^{a}_{t}\\)来影响环境，同时选择一个communication action \\(m^{a}_{t}\\)来被其他智能体观察，但\\(m^{a}_{t}\\)对环境没有直接影响。 ​ 没有通信协议被预先给定，智能体们需要自己学习。 ​ 由于协议是从动作观测历史到消息序列的映射，所以协议的空间维度是非常高的。自动地在这个空间发现有效的通信协议是非常困难的，这体现在智能体需要协调发送消息和解释消息。举个例子，如果一个智能体发送了一个有效的信息，它只有在接受方正确解释并回应的情况下才会受到正反馈，如果没有，反而会打击其发送有效信息的积极性。 ​ 因此，积极的reward是稀少的，只有在发送和解释协调操作时才会发生，这通过随机探索很难实现。 ​ 在这里，我们聚焦于centralised learning but decentralised execution的情况，在学习的时候智能体之间的通信没有限制，在实施过程时，智能体之间仅仅能通过一条带宽有限的通道通信。 5. Methods 5.1 RIAL（Reinforced Inter-Agent Learning） ​ 简单直接的说，RIAL就是将DRQN(Deep Recurrent Q-Learning)与Q-learning相结合来进行action（影响环境）与communication（与其它智能体通信）选择的方法。 ​ 每个智能体的Q-network可以表示为：\\(Q^{a}(o^{a}_{t},m^{a^{,}}_{t-1},h^{a}_{t-1},u^{a})\\)。 ​ 四个参数分别代表：环境观察值，其它智能体上一步传来的消息，智能体自己的隐藏状态，选择的action。 ​ 如果直接学习输出最终的Q表，得到的输出将有|U||M|大小。为了避免输出过大，将Q-network拆分为两个\\(Q^{a}_{u}\\)与\\(Q^{a}_{m}\\)，分别表示影响环境的action与同智能体的通信（communication），学习方式使用ε-贪心算法。 ​ \\(Q^{a}_{u}\\)与\\(Q^{a}_{m}\\)都使用DQN训练方法，但所使用的DQN有以下两点改进： 禁止experience replay; 为了考虑部分可观测性，我们将每个智能体所采取的操作u和m作为下一步的输入; ​ RIAL可以扩展到通过在智能体之间之间共享参数来利用集中学习，在这种情况下，由于智能体观察不同，因此也进化出了不同的隐藏状态。参数共享大大减少了必须学习的参数数量，从而加快了学习速度。 ​ 在参数共享情况下，智能体学习两个Q函数\\(Q_{u}(o^{a}_{t},m^{a^{,}}_{t-1},h^{a}_{t-1},u^{a}_{t-1},m^{a}_{t-1},a,u^{a}_{t})\\)与\\(Q_{m}(o^{a}_{t},m^{a^{,}}_{t-1},h^{a}_{t-1},u^{a}_{t-1},m^{a}_{t-1},a,u^{a}_{t})\\)。 5.1 DIAL（Differentiable Inter-Agent Learning） ​ 虽然RIAL可以进行参数共享，但其仍不能在通信过程中给其他智能反馈。 ​ 打个比方，在人类通信活动中，listener即使不说话也会给出及时，丰富的反馈来表明listener对谈话的兴趣和理解程度，而RIAL反而缺少了这个反馈机制，仿佛对着一个面无表情的人在说话，显然，这个方式存在缺点。 ​ DIAL就是为了解决这个问题而存在的，通过结合centralised learning与Q-networks，不仅可以共享参数，而且可以通过通信信道将梯度从一个Agent推向另一个Agent。 ​ 6. Experiments ​ 在测试中，我们评估了RIAL与DIAL在有无参数共享的情况下进行多智能体任务的情况，并跟一个无交流，参数共享的基准方法进行比较。 ​ 在整个过程中，奖励是通过访问真实状态( Oracle )所能获得的最高平均奖励来规范的。 ​ 我们使用ε-贪心算法（ε = 0.05）。 6.1 Switch Riddles（开关谜题） ​ 一百名囚犯入狱。典狱长告诉他们，从明天开始，每个人都会被安置在一个孤立的牢房里，无法相互交流。每天，监狱长都会随意统一挑选其中一名被替换的犯人，并将其安置在中央审讯室，室内只装有一个带有切换开关的灯泡。囚犯将能够观察灯泡的当前状态。如果他愿意，他可以拨动灯泡的开关。他还可以宣布，他相信所有的囚犯都已经访问了审讯室。如果这个公告是真的，那么所有囚犯都被释放，但如果是假的，所有囚犯都被处死。 ​ 6.2 Results1 ​ ​ （a）可以看到，在n=3时四种方法的效果都比Baseline的效果好，参数共享加速了算法。 ​ （b）在n=4时，参数共享的DIAL方法最好。不带参数共享的RIAL没有baseline效果好。可以看出，智能体们独立的学习出相同的策略是很难的。 ​ （c）n=3时智能体使用DIAL学习到的策略。 6.3 Colour-Digit MNIST ​ 6.4 Effect of Channel Noise ​ 这里没太看懂 ​","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"RL","slug":"RL","permalink":"http://example.com/tags/RL/"}],"author":"Shaw"},{"title":"近似误差与估计误差","slug":"【随手写】近似误差与估计误差","date":"2021-09-05T06:49:23.032Z","updated":"2021-09-05T07:51:10.743Z","comments":true,"path":"2021/09/05/【随手写】近似误差与估计误差/","link":"","permalink":"http://example.com/2021/09/05/%E3%80%90%E9%9A%8F%E6%89%8B%E5%86%99%E3%80%91%E8%BF%91%E4%BC%BC%E8%AF%AF%E5%B7%AE%E4%B8%8E%E4%BC%B0%E8%AE%A1%E8%AF%AF%E5%B7%AE/","excerpt":"","text":"【随手写】近似误差与估计误差 ​ 在读《统计学习方法》中关于k-邻近算法的介绍时，发现了这么一段话： ​ 近似误差（Approximation Error）: 训练时，训练集与当前模型的误差； ​ 估计误差（Estimation Error）： 训练完成后，所选择的模型已经固定，模型对未知数据拟合时的误差。 ​ 近似误差与估计误差二者不可兼得，此消彼长，需要取其平衡。","categories":[{"name":"Something","slug":"Something","permalink":"http://example.com/categories/Something/"}],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://example.com/tags/Machine-Learning/"}],"author":"Shaw"},{"title":"极大似然估计","slug":"【随写】极大似然估计","date":"2021-09-04T08:07:55.751Z","updated":"2021-09-05T07:45:58.019Z","comments":true,"path":"2021/09/04/【随写】极大似然估计/","link":"","permalink":"http://example.com/2021/09/04/%E3%80%90%E9%9A%8F%E5%86%99%E3%80%91%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/","excerpt":"","text":"【随写】极大似然估计（Maximum Likelihood Estimate，MLE） ​ “模型已定，参数未知。” ​ 极大似然估计，就是利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值。 ​ ​ 对于这个函数：\\(P(x|θ)\\)， ​ 输入有两个：x表示某一个具体的数据；θ表示模型的参数。 ​ 如果θ是已知确定的，x是变量，这个函数叫做概率函数(probability function)，它描述对于不同的样本点x，其出现概率是多少。 ​ 如果x是已知确定的，θ 是变量，这个函数叫做似然函数(likelihood function), 它描述对于不同的模型参数，出现x这个样本点的概率是多少。 ​ ​ 一般说来，事件A发生的概率与某一未知参数θ有关，θ取值不同，则事件A发生的概率\\(P(A|θ)\\)也不同，当我们在一次试验中事件A发生了，则认为此时的θ值应是t的一切可能取值中使\\(P(A|θ)\\)达到最大的那一个，极大似然估计法就是要选取这样的t值作为参数t的估计值，使所选取的样本在被选的总体中出现的可能性为最大。","categories":[{"name":"Something","slug":"Something","permalink":"http://example.com/categories/Something/"}],"tags":[{"name":"Math","slug":"Math","permalink":"http://example.com/tags/Math/"}],"author":"Shaw"},{"title":"Adversarial Training with Fast Gradient Projection Method against Synonym Substitution Based Text Attacks","slug":"【论文阅读】Adversarial Training with Fast Gradient Projection Method against Synonym Substitution Based Text Attacks","date":"2021-09-03T08:19:51.193Z","updated":"2021-09-04T06:45:15.015Z","comments":true,"path":"2021/09/03/【论文阅读】Adversarial Training with Fast Gradient Projection Method against Synonym Substitution Based Text Attacks/","link":"","permalink":"http://example.com/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Adversarial%20Training%20with%20Fast%20Gradient%20Projection%20Method%20against%20Synonym%20Substitution%20Based%20Text%20Attacks/","excerpt":"","text":"【论文阅读】Adversarial Training with Fast Gradient Projection Method against Synonym Substitution Based Text Attacks 时间：2020 作者：王晓森，杨逸辰等 华中科技大学 会议：AAAI 总结： 做了什么？ 提出了一种速度更快的，更容易应用在复杂神经网络和大数据集上的，基于同义词替换的NLP对抗样本生成方法，FGPM； 将FGPM纳入对抗训练中，以提高深度神经网络的鲁棒性。 怎么做的？ 实验结果？ FGPM的效果不是最高的，但也跟最高的差不多，但生成对抗样本的时间对比同类方法，缩减了1-3个数量级。 ATFL的对抗样本防御能力和抗转移能力很强。 Abstract: ​ 对抗训练是对于提升图像分类深度神经网络鲁棒性的，基于实验的最成功的进步所在。 ​ 然而，对于文本分类，现有的基于同义词替换的对抗样本攻击十分奏效，但却没有被很有效地合并入实际的文本对抗训练中。 ​ 基于梯度的攻击对于图像很有效，但因为文本的词汇，语法，语义结构的限制以及离散的文本输入空间，不能很好的应用于基于近义词替换的文本攻击中。 ​ 因此，我们提出了一个基于同义词的替换的快速的文本对抗抗攻击方法名为Fast Gradient Projection Method (FGPM)。它的速度是已有文本攻击方法的20余倍，攻击效果也跟这些方法差不多。 ​ 我们接着将FGPM合并入对抗训练中，提出了一个文本防御方法，Adversarial Training with FGPM enhanced by Logit pairing(ATFL)。 ​ 实验结果表明ATFL可以显著提高模型的鲁棒性，破坏对抗样本的可转移性。 1 Introduction: ​ 现有的针对NLP的攻击方法包括了：字符等级攻击，单词等级攻击，句子等级攻击。 ​ 对于字符等级的攻击，最近的工作（Pruthi, Dhingra, and Lipton 2019）表明了拼写检查器很容易修正样本中的扰动； ​ 对于句子等级的攻击，其一般需要基于改述，故需要更长的时间来生成对抗样本； ​ 对于单词等级的攻击，基于嵌入扰动的替换（replacing word based on embedding perturbation），添加，删除单词都会很容易改变句子的语法语义结构与正确性，故同义词替换的方法可以更好的处理上述问题，同时保证对抗样本更难被人类观察者发现。 ​ 但不幸的是，基于同义词替换的攻击相较于如今对图像的攻击展现出了更低的功效。 ​ ​ 据我们所知，对抗训练，对图像数据最有效的防御方法之一，并没有在对抗基于同义词替换的攻击上很好的实施过。 ​ 一方面，现有的基于同义词替换的攻击方法通常效率要低得多，难以纳入对抗训练。另一方面，尽管对图像的方法很有效，但其并不能直接移植到文本数据上。 ​ 1.1 Adversarial Defense: ​ 有一系列工作对词嵌入进行扰动，并将扰动作为正则化策略用于对抗训练(Miyato, Dai, and Goodfellow 2016; Sato et al. 2018; Barham and Feizi 2019) 。这些工作目的是提高模型对于原始数据集的表现，并不是为了防御对抗样本攻击，因此，我们不会考虑这些工作。 ​ 不同于如今现有的防御方法，我们的工作聚焦于快速对抗样本生成，容易应用在复杂的神经网络和大数据集上的防御方法。 2 Fast Gradient Projection Method（FGPM）: 3 Adversarial Training with FGPM： ​ 具体算法中文描述见： 《基于同义词替换的快速梯度映射（FGPM）文本对抗攻击方法》阅读笔记 - 知乎 (zhihu.com) 4 Experimental Results： ​ 我们衡量FGPM使用四种攻击准则，衡量ATFL使用两种防御准则。 ​ 我们在三个很受欢迎的基准数据集上，同时包括CNN和RNN模型上进行测试，代码开源：https://github.com/JHL-HUST/FGPM 4.1 Baselines: ​ 为了评估FGPM的攻击效能，我们将其与Papernot’、GSA ( Kuleshov等人的4种对抗性攻击进行了比较。2018 )、PWWS ( Ren et al . 2019 )和Iga ( Wang，jin，and he 2019 )。 ​ 此外，为了验证我们的ATFL的防御能力，我们采用了SEM ( Wang，Jin，He 2019 )和IBP ( Jia et al . 2019 )，针对上述Word-Level攻击。由于攻击基线的效率很低，我们在每个数据集上随机抽取200个示例，并在各种模型上生成对抗样本。 4.2 Datasets: ​ AG’s News, DBPedia ontology and Yahoo! Answers (Zhang,Zhao, and LeCun 2015). 4.3 Models: ​ 我们使用了CNNs,RNNs,来达到主流的文本分类表现，所有模型的嵌入维度均为300。 4.4 Evaluation on Attack Effectiveness： ​ 我们评估模型在攻击下的准确率和转移率： ​ 准确率： ​ ​ 转移率： ​ 4.4 Evaluation on Attack Efficiency： ​ 对抗训练需要高效率的生成对抗样本以有效地提升模型鲁棒性。因此，我们评估了不同攻击方法在三个数据集上生成生成200个对抗样本的总时间。 4.5 Evaluation on Adversarial Training： ​ 我们评估ATFL的对抗样本防御能力和抗转移能力： ​ 对抗样本防御能力： ​ ​ 抗转移能力： ​ 4.6 Evaluation on Adversarial Training Variants: ​ 许多对抗训练的变体，例如CLP和ALP，TRADES等，已经尝试采用不同的正则化方法来提高针对图像数据的对抗训练准确率。 ​ 在这里，我们回答一个问题：这些变体方法也可以提高文本数据准确率吗？ ​ 从表中可以看出，只有ALP可以长远地提升对抗训练的表现。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"AD","slug":"AD","permalink":"http://example.com/tags/AD/"},{"name":"NLP","slug":"NLP","permalink":"http://example.com/tags/NLP/"},{"name":"AD training","slug":"AD-training","permalink":"http://example.com/tags/AD-training/"}],"author":"Shaw"},{"title":"《统计学习方法》","slug":"【书籍阅读】《统计学习方法》","date":"2021-09-03T06:17:39.403Z","updated":"2022-07-16T02:08:58.914Z","comments":true,"path":"2021/09/03/【书籍阅读】《统计学习方法》/","link":"","permalink":"http://example.com/2021/09/03/%E3%80%90%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B/","excerpt":"【书籍阅读】《统计学习方法》 一. 统计学习方法概论： ​ 首先，要明确计算机科学中存在三个维度：系统，计算，与信息。统计学习方法（机器学习）主要属于信息这一维度，并在其中扮演者核心角色。 1. 监督学习概念： ​ 监督学习，Supervised learning，指在已经做好标注的训练集上学习，为了叙述方便，定义以下基本概念： 输入空间（X），输出空间（Y）：输入所有可能取值，输出所有可能取值； 特征空间：输入一般由特征向量表示，所有特征向量存在的空间称为特征空间，输入空间与特征空间并不完全等价，有时需要映射； 上标 xi :表示一个输入的第 i 个特征； 下标 xj：表示第 j 个输入。 回归问题：输入输出都为连续型变量； 分类问题：输出变量为有限个离散型变量； 标注问题：输入与输出变量都为变量序列。 假设空间：所有可能的模型的集合，也就是学习的范围。 ​ 使用训练集学习----&gt;对未知数据进行预测 ​","text":"【书籍阅读】《统计学习方法》 一. 统计学习方法概论： ​ 首先，要明确计算机科学中存在三个维度：系统，计算，与信息。统计学习方法（机器学习）主要属于信息这一维度，并在其中扮演者核心角色。 1. 监督学习概念： ​ 监督学习，Supervised learning，指在已经做好标注的训练集上学习，为了叙述方便，定义以下基本概念： 输入空间（X），输出空间（Y）：输入所有可能取值，输出所有可能取值； 特征空间：输入一般由特征向量表示，所有特征向量存在的空间称为特征空间，输入空间与特征空间并不完全等价，有时需要映射； 上标 xi :表示一个输入的第 i 个特征； 下标 xj：表示第 j 个输入。 回归问题：输入输出都为连续型变量； 分类问题：输出变量为有限个离散型变量； 标注问题：输入与输出变量都为变量序列。 假设空间：所有可能的模型的集合，也就是学习的范围。 ​ 使用训练集学习----&gt;对未知数据进行预测 ​ 2. 统计学习三要素： ​ 统计学习三要素为：模型，策略，算法； ​ 模型是决定学习的预测函数的类型； ​ 策略是判定什么样的模型是好的，用于度量当前的模型好坏； ​ 算法是训练过程中的具体做法，例如如何回归，如何计算，如何调整等。 3. 模型的衡量方法： 损失函数与风险函数： ​ 损失函数，Loss Function，用于模型一次预测的错误程度，例如： ​ 损失函数的数值越小，模型就越好。如果计算损失函数的期望，得到的就是风险函数，Risk Function: ​ 可以看出，损失函数用于某次预测的估计，风险函数用于总体平均估计。我们当然希望训练出的模型的风险函数越小越好。 ​ 但是，观察上式，理想化的概率分布P(x，y)是未知的，我们进行学习就是要通过模型来模拟它，故这个式子理论存在，实际不能计算，不能用作评估模型的直接方法。 经验风险与结构风险： ​ 为了解决上述问题，我们引入经验风险： ​ 可以看到，经验风险将每个样本视作等概率出现，是模型对于训练集的平均损失，那么其与风险函数的误差在哪？ ​ 根据大数定律，当训练集足够大时，二者是近似相等的。但实际情况下，很多时候训练样本数目有限，甚至很小，故用经验风险效估计风险函数并不理想，故需要进行修正，这就是监督学习中的两个基本策略：经验风险最小化和结构风险最小化。 ​ 如果训练样本容量较大，使用经验风险最小化没什么问题。 ​ 当样本容量很小时，仅仅使用经验风险最小化容易导致过拟合，故这里使用结构风险（就是正则化）最小化方法，对模型复杂度进行惩罚，后续介绍。 训练误差与测试误差： ​ 训练误差本质上不重要，它可以反应一个问题是不是容易学习，但要衡量模型的预测能力，主要是看测试误差。 正则化与交叉验证： ​ 正则化是在经验风险项后再增加一个正则化项（Regularizer），其与模型的复杂度成正相关，一般使用模型参数向量的范数： ​ 交叉验证的基本思想是重复使用数据： 简单交叉验证： 将训练集随机分为两部分，一部分训练，一部分测试，然后在各种条件下训练出不同的模型，用测试集进行横向对比，选出最好的。 S折交叉验证： S-fold cross validation，随机地将已给数据切分为S个互不相交的大小相同的子集，选取S-1个用于训练，剩下一个用于测试。 这样总共测试集有S种选法，将这S种全部试一遍，评选S次测评中平均误差最小的模型。 留一交叉验证： 令S=N（训练集大小）即可，这种方法往往是在数据集特别缺乏的情况下使用。 泛化误差与泛化上界： ​ 泛化能力指模型对位置数据的预测能力，就是模型的好坏。如何量化这个能力？ ​ 根据定义，其就是模型在测试集上的测试表现： ​ 同时可以用以下式子衡量泛化误差的上界： 生成模型与判别模型： ​ 监督学习方法又可以分为两种方法：生成方法（Generatice Approach）和判别方法（Discriminative Approach）。 ​ 如果以概率论的角度来看待，模型的作用是根据P（x）来求P（y | x），故下面有两种方法求 P（y | x），直接模拟P（y | x）和通过求 \\(P(\\frac{y}{x}) = \\frac{P(x,y)}{P(x)}\\) 来求P（y | x）。 ​ 前者就是判别模型，后者是生成模型。 ​ 生成模型可以还原出联合概率分布P（x , y），学习收敛速度更快，可以适应存在隐含变量的情况； ​ 判别模型直接学习条件概率,直接面对预测，准确率更高，并且简化了学习问题。 二. 感知机 ​ 感知机，perceptron，是二分类的线性分类模型，输入为特征向量，输出为类别，取1和-1两种。 ​ 感知机属于判别模型。 ​ ​ 对于一个给定数据集，T = {（x1，y1）……（xn，yn）}，如果存在某个超平面S，w·x + b = 0（这里w是超平面的法向量，b是截距），使得所有 yi = 1 的实例i，有 w·xi + b &gt; 0，yi = -1则相反，则称数据集T为线性可分数据集（Linealy separable data set），否则，称数据集T为线性不可分数据集。 2.1 感知机损失函数： ​ 感知机的目的就是对于一个线性可分的数据集，通过找出w和b，来确定一个超平面用于分类。 ​ 这里，我们选取某错误分类点到超平面S的总距离来当做损失函数，某一点到超平面S的距离如下： ​ ‖w‖是w的L2范数。 ​ 故，某个误分类点到超平面S的距离是： ​ 将所有误分类点求和，忽略L2范数，即可得到感知机的损失函数（M为误分类点集合）： ​ 对于一个特定样本点的损失函数，在误分类时是参数w,b的线性函数，在正确分类时是0，故给定训练数据集T，损失函数L是w，b的连续可导函数。 2.2 训练过程： ​ 感知机训练采用随机梯度下降的方法： ​ 当找到一个误分类点时，不断梯度下降直至该点被正确分类为止。 ​ 数学证明其收敛性： ​ 具体见书本，这里略过。 2.3 感知机的对偶形式： ​ 由图可以看到，对于每个测试集中的xi，都有一个与之对应的αi，对偶形式中就是调整其对应的α。 ​ 关于gram矩阵的作用，如果手算一遍简单的训练过程，就可以得到答案。 三. k近邻法 ​ k近邻法是一种基本的分类与回归方法，这里只讨论分类方法。 ​ 其输入为特征向量，输出为实例的类别，可以取多类。 3.1 算法描述： ​ 给定一个训练集，对于新的数据实例，在训练数据集中找到与其最邻近的k个实例，这k个实例多数属于某个类，就把该输入实例分为这个类。 ​ k近邻法没有显式的学习过程。可以理解为，k近邻算法将特征空间划分为了一些子空间，每个点所属的空间是确定的。 ​ 如何度量两个特征之间的距离？ ​ k邻近模型的特征空间一般是n维实空间Rn，使用欧氏距离或者Lp距离（Lp distance），Minkowski距离（Minkowski distance）； ​ Lp距离： ​ 欧氏距离： ​ 曼哈顿距离： ​ 无穷距离： ​ 由下图可以看出，p取值不同时到原点距离为1的图形是不同的： 如何选择k的值？ ​ k值越小，模型学习时的近似误差越小，估计误差越大，模型会越复杂，抗干扰性越小（例如，最邻近的点是噪声），模型会非常敏感，容易过拟合； ​ k值越大，估计误差会很小，近似误差会很大，整体模型变得简单。 ​ k一般的取值并不大，使用交叉验证的方法来选取最佳的k值。 如何决策？ ​ 在得到k个最相似的实例后，采用何种规则判断测试样本属于哪一类呢？ ​ k邻近算法使用多数表决的方法： ps: ci表示某种决策规则下一组测试用例的表决结果。经由以上推导可以得出，多数表决规则是合理的。 ​ 如何快速找到某个用例的K近邻点？ KD树： 具体算法见书。 四. 朴素贝叶斯法 ​","categories":[{"name":"Book","slug":"Book","permalink":"http://example.com/categories/Book/"}],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://example.com/tags/Machine-Learning/"}],"author":"Shaw"},{"title":"Deep Text Classifification Can be Fooled","slug":"【论文阅读】Deep Text Classifification Can be Fooled","date":"2021-09-03T06:08:27.107Z","updated":"2022-07-16T02:09:42.181Z","comments":true,"path":"2021/09/03/【论文阅读】Deep Text Classifification Can be Fooled/","link":"","permalink":"http://example.com/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Deep%20Text%20Classifification%20Can%20be%20Fooled/","excerpt":"【论文阅读】Deep Text Classifification Can be Fooled 时间：2017 作者：Bin Liang, Hongcheng Li, Miaoqiang Su, Pan Bian, Xirong Li and Wenchang Shi 中国人民大学 Abstract: ​ 在这篇文章，我们提出了一种有效的生成文本对抗样本的方法，并且揭示了一个很重要但被低估的事实：基于DNN的文本分类器很容易被对抗样本攻击。 ​ 具体来说，面对不同的对抗场景，通过计算输入的代价梯度(白盒攻击)或生成一系列被遮挡的测试样本(黑盒攻击)来识别对分类重要的文本项。（这句不是很懂，什么叫’ the text items that are important for classifification‘？） ​ 基于这些项目，我们设计了三种扰动策略，insertion，modification，removal，用于生成对抗样本。实验结果表明基于我们的方法生成的对抗样本可以成功地欺骗主流的在字符等级和单词等级的DNN文本分类器。 ​ 对抗样本可以被扰动到任意理想的类中而不降低其效率。（？）同时，被引入的扰动很难被察觉。 ​","text":"【论文阅读】Deep Text Classifification Can be Fooled 时间：2017 作者：Bin Liang, Hongcheng Li, Miaoqiang Su, Pan Bian, Xirong Li and Wenchang Shi 中国人民大学 Abstract: ​ 在这篇文章，我们提出了一种有效的生成文本对抗样本的方法，并且揭示了一个很重要但被低估的事实：基于DNN的文本分类器很容易被对抗样本攻击。 ​ 具体来说，面对不同的对抗场景，通过计算输入的代价梯度(白盒攻击)或生成一系列被遮挡的测试样本(黑盒攻击)来识别对分类重要的文本项。（这句不是很懂，什么叫’ the text items that are important for classifification‘？） ​ 基于这些项目，我们设计了三种扰动策略，insertion，modification，removal，用于生成对抗样本。实验结果表明基于我们的方法生成的对抗样本可以成功地欺骗主流的在字符等级和单词等级的DNN文本分类器。 ​ 对抗样本可以被扰动到任意理想的类中而不降低其效率。（？）同时，被引入的扰动很难被察觉。 ​ 1. Introduction: ​ 在文本中，即使很小的扰动也会使一个字母或者单词完全变化，这会导致句子不能被辨识。故如果直接将应用于多媒体（图片，音频）的算法应用到文本上，得到的对抗样本的原意就会改变，而且很大程度上变成人类无法理解的句子。 ​ 在这片论文里，我们提出了一种生成对抗样本的有效方法。与直接简单插入扰动相比，我们设计了三种扰动策略：insertion, modifification, and removal，并且引入了自然语言文本水印（natural language watermarking）技术用于生成对抗样本。 ​ 理论上，生成一个好的对抗样本很大程度上依赖于对目标分类模型的信息。在这里我们根据不同情形，使用了白盒攻击和黑盒攻击。 ​ 为了普遍性，我们使用了字符等级的模型和单词等级的模型作为受害者。我们的实验结果证明基于DNN的文本分类器在面对对抗样本攻击时是脆弱的。 2. Target Models and Datasets: ​ 这里使用的文本分类器是Zhang et al. 2015《Character-level Convolutional Networks foe Text Classification》，数据集是Lehmann et al.2014的DBpedia ontology dataset（一个多语言知识库），里面包括560000个训练样本和70000个测试样本，涵盖14个high-level 类，比如公司类、建筑类、电影类等。 ​ 在把样本送进网络前，需要用独热编码法（one-hot representation）对每个字母编码成一个向量。通过网络的六个卷积层、三个全连接层，最终会被分到14个类中。 3. White-Box-Attacks: 3.1 FGSM算法： ​ FGSM是Goodfellow在2015年提出的对图片生成对抗样本的经典算法。使用类似的思路来在文本领域生成对抗样本结果并不好： 3.2 Idenfitying Classification-important Items: ​ 在白盒攻击中，我们需要定位文本中对于分类器的分类结果起到很大作用的文本段（通过计算代价梯度）。在这里，我们使用Hot Training Phrases (HTPs)代表最常使用的短语： ​ HTPS表明了用什么短语/词去做扰动，但是没有说在哪里做。在这里使用Hot Sample Phrases (HSPs)来表明在哪里做扰动。 3.3 Attacking Character-level DNN: ​ 我们的方法是一种targeted攻击，可以指定对抗样本的误导类型。 3.3.1 Insertion Strategy（插入策略）: ​ 在某个HSP前插入一个HTP，就可以达到效果： ​ 由上图可以看到，将某个HTP（historic）插入到HSP（principal stock exchange of Uganda. It was founded）之前，就可以使一个公司的分类文本变为对建筑的分类。 ​ 实际上，我们通常需要进行多次插入，但插入次数过多会影响样本的效用和可读性，为了解决这个问题，这里引入NL水印技术（Natural Language watermarking technique）。该技术可以通过语义或句法操作将所有权水印隐形地嵌入到普通文本中,虽然我们的攻击目标与NL水印有本质的不同，但我们可以借用它的思想来构造对抗样本。实际上，扰动可以看作是一种水印，并以类似的方式嵌入到样本中。 ​ 在这里，我们拓展这个思路，在样本中插入Presupposition(读者熟知的模糊短语)和 semantically empty phrases（可有可无的短语），有没有他们，在读者看来，原文的意思不会改变。 ​ 总的来说，我们考虑将各种HTPS组合成一个语法单元后再嵌入到文本中，新的单元可以是生成的可有可无的资料，或者甚至是不会改变文本原意的伪造的资料。 ​ 特别的，通过互联网搜索或者查找一些数据集，我们可以找到与插入点很相关的资料，包括一些期望的目标分类的HTPs。 ​ 由于我们不能总是找到合适的HTPs，所以提出一个新概念——伪造的事实（forged fact），也就是插入很难证伪的HTPs。例如： ​ 此外，我们排除了伪造的事实，这些事实可以通过检索他们在网上的相反证据而被否认。 3.3.2 Modification Strategy（修改策略）： ​ Moidfication就是轻微修改一些HSP。 ​ 为了让修改不被人类观察者发现，我们采用了typo-based watermarking 技术。具体的说，一个HSP可以通过两种方式来被修改： ​ 1. 从相关的语料库中选择常见的拼写错误来替换它； ​ 2. 把它的一些字符修改成类似的外观（例如小写字母'l'与阿拉伯数字‘1’很像）。 ​ ​ 由上图可以看出，这种方式对分类结果的扰动是巨大的。 3.3.3 Removal Strategy（移除策略）: ​ 移除策略单独使用也许并不能足够有效地影响预测结果，但是可以很大程度上降低原始预测类型的置信度。 ​ 由上图可以看出，移除'British'可以导致原始预测类型的置信度下降了35%。 3.3.4 Combination of Three Strategies: ​ 如图6所示，单靠去除策略改变输出分类往往是困难的。但是，通过与其他策略相结合，可以避免对原文进行过多的修改或插入。在实践中，我们常常结合以上三种策略来制作微妙的对抗样本。 ​ 以图7为例，通过去除一个HSP、插入一个伪造事实和修改一个HSP，可以成功地改变输出分类，但单独应用上述任何扰动都失败。具体来说，删除、插入和修改仅使置信度分别下降27.3 %、17.5 %和10.1 %，保持预测类不变。 4. Black-Box-Attack: 暂略 5. Evaluation： 5.1 我们的方法能否执行有效的源/目标误分类攻击? ​ 答：在众多测试集中，只有DBpedia ontology数据集是一个多分类数据集，故我们在其中随机选取了一些样本： 5.2 所生成的对抗样本能否避免被人类观察者认出来，并同时保持其功能性？ 答：我们找了23个学生。他们对项目不了解，然后每个人给20个文本，其中一半是加扰的。让他们分到14个类中，如果他们觉得哪个文本不对劲，让他们指出来。 ​ 他们总的分类正确率是94.2%，10个对抗样本的正确率是94.8%。所以实用性还是有的。 ​ 他们标注出了240项修改处，其中12项符合真实的修改。但实际上我们做了594处修改。 5.3 我们的方法足够有效吗？ 答：实验中计算梯度和找HTPs花了116小时。14个类的HTPs每个类花了8.29小时。对所有的adversarial示例只执行一次计算。制作一个对抗性的样品大约需要10到20分钟。对于对手来说，获得理想的对抗样本是可以接受的。实际上，她或他愿意花更多的时间来做这件事。 6. Realted Works: ​ 可以做的方向：1.自动生成对抗样本；（然而，Papernot等人(Papernot et al. 2016a)提出了一种基于雅可比矩阵的数据集增强技术，该技术可以在不访问其模型、参数或训练数据的情况下，在有限对输入输出的基础上，为目标dnn提供替代模型。作者还表明，使用替代模型也可以有效地制作对抗样本，以攻击目标DNN。）2.迁移、黑盒攻击； ​","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"AD","slug":"AD","permalink":"http://example.com/tags/AD/"},{"name":"NLP","slug":"NLP","permalink":"http://example.com/tags/NLP/"},{"name":"DNN","slug":"DNN","permalink":"http://example.com/tags/DNN/"}],"author":"Shaw"},{"title":"Black-Box Attacks against RNN based Malware Detection Algorithms","slug":"【论文阅读】Black-Box Attacks against RNN based Malware Detection Algorithms","date":"2021-09-03T06:08:27.105Z","updated":"2022-07-16T02:09:39.316Z","comments":true,"path":"2021/09/03/【论文阅读】Black-Box Attacks against RNN based Malware Detection Algorithms/","link":"","permalink":"http://example.com/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Black-Box%20Attacks%20against%20RNN%20based%20Malware%20Detection%20Algorithms/","excerpt":"【论文阅读】Black-Box Attacks against RNN based Malware Detection Algorithms 时间：2017 作者： Weiwei Hu 北京大学 ​ Ying Tan 北京大学 Abstract： ​ 1. 原文： ​ 最近的研究表明，基于机器学习的恶意软件分类算法在面对对抗样本攻击时表现的十分脆弱。这些工作主要集中于那些利用了混合维度的特征的追踪算法，但一些研究者已经开始使用RNN，基于API特征序列来辨识恶意软件。 ​ 这篇文章提出了一种用于生成对抗样本序列的原创算法，它被用于攻击基于RNN的恶意软件分类系统。对于攻击者来说，通常，知晓目标RNN的内部结构和权重是很难的。于是一个替代的用于近似目标RNN的RNN模型就被训练了出来，接着我们利用这个RNN来从原始序列输入中生成对抗样本序列。 ​ 权威结果表明基于RNN的恶意软件分类算法不能追踪大多数我们所生成的恶意对抗样本，这意味着我们生成的模型可以很有效的规避追踪算法。 ​ 2. 总结： ​ 一个对基于RNN的恶意样本分类器的灰盒攻击，有三个RNN，受害者RNN（源RNN），替代RNN，对抗样本生成RNN。","text":"【论文阅读】Black-Box Attacks against RNN based Malware Detection Algorithms 时间：2017 作者： Weiwei Hu 北京大学 ​ Ying Tan 北京大学 Abstract： ​ 1. 原文： ​ 最近的研究表明，基于机器学习的恶意软件分类算法在面对对抗样本攻击时表现的十分脆弱。这些工作主要集中于那些利用了混合维度的特征的追踪算法，但一些研究者已经开始使用RNN，基于API特征序列来辨识恶意软件。 ​ 这篇文章提出了一种用于生成对抗样本序列的原创算法，它被用于攻击基于RNN的恶意软件分类系统。对于攻击者来说，通常，知晓目标RNN的内部结构和权重是很难的。于是一个替代的用于近似目标RNN的RNN模型就被训练了出来，接着我们利用这个RNN来从原始序列输入中生成对抗样本序列。 ​ 权威结果表明基于RNN的恶意软件分类算法不能追踪大多数我们所生成的恶意对抗样本，这意味着我们生成的模型可以很有效的规避追踪算法。 ​ 2. 总结： ​ 一个对基于RNN的恶意样本分类器的灰盒攻击，有三个RNN，受害者RNN（源RNN），替代RNN，对抗样本生成RNN。 1. Introduction: 现有的基于N机器学习的恶意软件追踪算法主要将程序表现为固定维度的特征向量，然后将其分类为无害程序和恶意软件； 举例，利用API的调用序列，或者不被调用的API序列进行分类； 【11】展现了，基于固定维度特征来进行恶意样本分类的算法，面对对抗样本的攻击是脆弱的； 最近也有利用RNN进行恶意样本追踪与分类的，RNN的输入就是API序列。 2. Adversarial Examples: ​ 一些其它的针对序列的对抗样本攻击： Nicolas Papernot, Patrick McDaniel, Ananthram Swami, and Richard Harang. Crafting adver\u0002 sarial input sequences for recurrent neural networks. In Military Communications Conference, MILCOM 2016-2016 IEEE, pages 49–54. IEEE, 2016. Kathrin Grosse, Nicolas Papernot, Praveen Manoharan, Michael Backes, and Patrick McDaniel. Adversarial perturbations against deep neural networks for malware classifification. arXiv preprint arXiv:1606.04435, 2016. 4. Attacking RNN based Malware Detection Algorithms 5. 实验 ​ Adam 用于训练所有模型； ​ LSTM由于其在处理长序列的优秀表现，也被应用在实验的所有RNN中。 5.1 数据集： ​ 来源：https://malwr.com/ （一个恶意样本分析网站，爬取180个项目，该网站可以分析用户上传的项目，并给出其API序列，网站中70%的项目都是恶意样本） ​ 数据集划分：为了模拟真实的测试环境，数据集划分如下：（30%+10%）用于生成RNN，（30%+10%）用于受害者RNN，20%用于测试。 5.2 受害者RNN： ​ 尝试了不同模型： ​ 结论如下： 与LSTM相比，BiLSTM不能提升模型的分类表现； 与Average-Pooling相比，注意力机制的效果更好； 5.3 生成（对抗样本）RNN测试结果： ​ 介绍参数规范： The hyper-parameters of the generative RNN and the substitute RNN were tuned separately for each black-box victim RNN. The learning rate and the regularization coeffificient were chosen by line search along the direction 0.01, 0.001, et al.. The Gumbel-Softmax temperature was searched in the range [1, 100]. Actually, the decoder length L in the generative RNN is also a kind of regularization coeffificient. A large L will make the generative RNN have strong representation ability, but the whole adversarial sequences will become too long, and the generative RNN’s size may exceed the capacity of the GPU memory. Therefore, in our experiments we set L to 1. ​ ​ 给出实验结果： 对于所有RNN模型，攻击都十分有效； 于LSTM的攻击效果最差，故替代RNN对LSTM的拟合效果并不好； 训练集与测试集的测试效果差别不大， 模型泛化能力强； 即使更换了模型与训练数据集，对抗样本仍效果很好。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"AD","slug":"AD","permalink":"http://example.com/tags/AD/"},{"name":"Malware Classifiers","slug":"Malware-Classifiers","permalink":"http://example.com/tags/Malware-Classifiers/"},{"name":"RNN","slug":"RNN","permalink":"http://example.com/tags/RNN/"}],"author":"Shaw"},{"title":"Automatically Evading Classififiers----A Case Study on PDF Malware Classififiers","slug":"【论文阅读】Automatically Evading Classififiers----A Case Study on PDF Malware Classififiers","date":"2021-09-03T06:08:27.103Z","updated":"2021-09-03T06:23:11.007Z","comments":true,"path":"2021/09/03/【论文阅读】Automatically Evading Classififiers----A Case Study on PDF Malware Classififiers/","link":"","permalink":"http://example.com/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Automatically%20Evading%20Classififiers----A%20Case%20Study%20on%20PDF%20Malware%20Classififiers/","excerpt":"","text":"【论文阅读】Automatically Evading Classififiers----A Case Study on PDF Malware Classififiers 时间：2016 作者：Weilin Xu, Yanjun Qi, and David Evans 弗吉尼亚大学 会议：NDSS（ccf_B类） 总结： 白盒黑盒？ 黑盒攻击，需要知道生成样本在目标模型中的输出（分类分数）和目标模型所使用的特征（粗略知道）； 针对什么目标？ 仅仅使用表层特征的分类器； 攻击方法？ 3.1 如何制造对抗样本？ ​ 使用遗传算法（GP-BASED）进行随机扰动 3.2 如何判别对抗样本的恶意能力？ ​ 使用oracle Abstract: ​ 在本文，我们提出了一个一般化的方法来检验分类器的鲁棒性，通过在两个PDF恶意样本分类器，PDFrate和Hidost上来检验。其关键就是随机控制一个恶意样本来找到一个对抗样本。 ​ 我们的方法可以自动地对500个恶意样本种子中找到对于两个PDF分类器的对抗样本，我们的结果提出了一个严重的疑问，基于表面特征的分类器在面对对抗样本时是否还有效？ 1. Introduction: ​ 主要贡献： 1. 提出了一个一般化的方法用于自动寻找分类器的对抗样本； 2. 制作了一个原型系统用于自动生成对抗样本； 3. 我们的系统在对500个恶意样本种子寻找对抗样本的过程中，达到了100%的准确率。 2. Overview： 2.1 Finding Evasive Samples： ​ 整体思路： ​ ​ oracle用于判断一个样本是否具有恶意行为； 3. PDF Malware and Classifiers 3.1 PDFmalware: ​ PDF文件的整体结构： ​ ​ 早些的PDF恶意样本一般使用JavaScript嵌入，用户双击打开时出发执行恶意脚本。 ​ 因为不是所有的PDF恶意样本都是嵌入了JavaScript代码，最近的一些PDF恶意分类器就着重于PDF文件的结构化特征。在本文，我们的目标就是攻击这些有代表性的基于文件结构化特征的分类器。 3.2 Target Classififiers： ​ PDFrate：一个使用随机森林算法的分类器。 ​ Hidost:一个SVM分类器。 ​ 4. Evading PDF Malware Classifiers： 5. Experiment: 5.1 Dataset: ​ 5.2 Test： ​","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"AD","slug":"AD","permalink":"http://example.com/tags/AD/"},{"name":"Malware Classifiers","slug":"Malware-Classifiers","permalink":"http://example.com/tags/Malware-Classifiers/"},{"name":"PDF","slug":"PDF","permalink":"http://example.com/tags/PDF/"}],"author":"Shaw"},{"title":"AD nlp Survey","slug":"【论文阅读】AD nlp Survey","date":"2021-09-03T06:08:27.101Z","updated":"2022-07-16T02:09:27.229Z","comments":true,"path":"2021/09/03/【论文阅读】AD nlp Survey/","link":"","permalink":"http://example.com/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91AD%20nlp%20Survey/","excerpt":"【论文阅读】AD nlp Survey 作者：Wei Emma Zhang（阿德莱德大学，澳大利亚） ​ QUAN Z. SHENG（麦考瑞大学，澳大利亚） ​ AHOUD ALHAZMI（麦考瑞大学，澳大利亚） ​ 李晨亮（武汉大学，中国） 1. 关键词：DNN，对抗样本，文本数据（textual data），NLP 2. 摘要： 传统对抗样本基本都针对计算机视觉领域； 本调查提供针对基于DNNs的NLP对抗样本攻击； 由于CV与NLP本身不同，方法不能直接移植； 集成了截止2017年所有的相关成果，综合性地总结，分析，讨论了40个代表性工作； 简单介绍了CV和NLP相关知识。","text":"【论文阅读】AD nlp Survey 作者：Wei Emma Zhang（阿德莱德大学，澳大利亚） ​ QUAN Z. SHENG（麦考瑞大学，澳大利亚） ​ AHOUD ALHAZMI（麦考瑞大学，澳大利亚） ​ 李晨亮（武汉大学，中国） 1. 关键词：DNN，对抗样本，文本数据（textual data），NLP 2. 摘要： 传统对抗样本基本都针对计算机视觉领域； 本调查提供针对基于DNNs的NLP对抗样本攻击； 由于CV与NLP本身不同，方法不能直接移植； 集成了截止2017年所有的相关成果，综合性地总结，分析，讨论了40个代表性工作； 简单介绍了CV和NLP相关知识。 ### 3.Introduction: 简单介绍了对抗样本； 关于对抗样本的研究可以简单分为三类： ① 通过使用微小扰动来欺骗DNN，以此来评估它； ② 刻意改变DNN的输出； ③ 检测DNN中过敏感和过迟钝的点，寻找防御攻击的方法。 ==不能直接使用基于CV的对抗样本生成方法的原因：== 直接将对图像攻击的对抗样本生成方法应用到文本上，将得到毫无意义的词语和句子片段。这是因为在对图像的对抗样本生成中，即使略微改变每个像素的灰度，肉眼也可以识别原来的图像；但是对于文本串来说，即使改变一个字母，语句的语义也将完全不同或出错。 ==相关研究：== Reference [i] = 【i】 ​ ① 【9】：对针对不同类别的机器学习系统的攻击与防御做了综合性概述，提出了一种用于辨识和分析这些攻击的分类方法，并将将这些攻击应用到基于机器学习的应用上来证明这些攻击或者防御手段的有效性。例如，一个统计垃圾邮件过滤器。 ​ ② 【13】：作者俯瞰了近十年（2008-2018）对抗样本攻击的发展史，聚焦点在于CV和网络空间安全。对非深度学习算法和深度学习算法都做了介绍，也从安全的角度仔细分析了这些攻击和防御手段的影响。 ​ ③ 【79】：与【13】阐述的问题类似，从数据驱动的角度。 ​ ④ 【154】：聚焦于对抗样本在深度学习模型上的使用。介绍了最近的几种不同的在应用上对DNN的攻击，同时全面调查了防御方法。但是，其只讨论了对抗样本在图像分类和物品识别上的攻击。 ​ ⑤ 【2】：详细阐述了对抗样本在CV上的应用，是一篇应用程序主导的调查。 ​ ⑥ 【35】：从安全的角度阐述了对抗样本的防御手段。（不仅从机器学习算法或者神经模型上，从所有与安全相关的应用上阐述对抗样本防御）作者发现现有的与防御相关的安全工作缺乏清晰的对攻击如何与真实安全问题相关联的动机和解释，以及这些攻击和防御如何被有意义地衡量，故提出了一种分类方法用于衡量这些。 4. Overview （对抗样本攻击 and 深度学习在NLP中的应用）: 给出了DNN，Perturbations，Adversarial Examples的定义； 介绍了Treat Model： 2.1 Granularity（颗粒度）:攻击的颗粒度指的是对抗样本生成的数据等级，例如对图像数据通常是像素，对文本数据就是字母，单词，句子嵌入等级。 2.2 Motivation（动机）：生成对抗样本的动机通常有两种，攻击和防御：1.攻击的目的是检验DNN的健壮性；2. 防御的目的是使DNN更加稳固，第五部会给出更详细的讲解。 介绍了Measurements（评价adversarial attack的方法）： 3.1 控制扰动（Perturbation Constraint）： ​ 根据前面所述，扰动 η 应该不影响样本原来的真实分类，故如果一个分类器是理想的，那么扰动后的样本应不影响其分类结果； η 同时也不能太小，以避免对目标DNN没有影响。在理想情况下，有效扰动是在一定范围内最有效果的噪声。 ​ 【132】首次在图像对抗样本攻击中约束了(x + η) ∈ [0, 1]n 的范围，以保证对抗样本与原始数据有着相同的像素等级。 ​ 【40】简化了问题的解决方法，并使用了无穷范数来限制扰动，==这受到直觉的启发，即一个不改变任何特定像素的扰动量超过一定量 ϵ 就不能改变输出类。==（PS:WHY？）无穷范数在图像/物品分类识别任务中是足够有效的，其他的范数，例如L0和L2范数，过去被用于在对CV的DNN攻击中限制扰动。在文本对抗样本攻击中，这有所不同，第3.3节会给出更多细节。 3.2 评估攻击的有效性（Attack Evaluation）： ​ 对抗样本攻击旨在降低DNNs的性能，因此，评估攻击的有效性是基于不同任务的性能指标。例如，分类任务中有评价指标准确度，F1-score，AUC-score。在本文中，我们将针对不同NLP的评价标准作为超范围内容，并建议读者参考特定的信息。 ​ ==以上是总体分类与信息== ​ ==以下是深度学习在NLP中的应用== ​ 除了向前传播的神经网络和CNN，RNN及其变式由于其天然的处理序列的能力，也被用于NLP中。 近几年深度学习对NLP的重大影响： 1.1 序列学习（sequence-to-sequence learning） 1.2 注意力机制（attention mechanism） 1.3 强化学习（reinforcement learning）和生成模型（generative models） 具体详细的神经网络在NLP中的应用见【100】，【152】 Feed-Forward Networks: 缺点：不能很好地处理对于词语顺序很重要的文本序列，因为其并不记录元素的顺序。为了评价其健壮性，往往针对专门设计的前馈网络生成对抗实例，【3】，【43】，【44】作者研究了指定的恶意软件检测模型。 CNN： ​ CNN识别本地预测因子并将它们组合在一起，为输入生成一个固定大小的向量，该向量包含数据中最重要或最重要的信息方面。 ​ CNN对顺序敏感，因此，它擅长做计算机视觉，随后被广泛用于NLP应用。 ​ 卷积操作被简直在词的序列方向上，而不是词的嵌入。 ​ 两个经典工作：1. 【59】使用CNN和Word2Vec进行句子分类 2.【156】使用CNN和热独编码进行文本分类。 RNN： ​ 主要介绍RNN及其变式（LSTM，GRU） Seq2Seq（sequence-to-sequence learning）： ​ Seq2Seq模型具有优越的能力，能够为具有编码器-解码器结构的给定序列信息生成另一个序列信息. ​ 通常，一个Seq2seq由两个RNN结构组成，一个用于编码，一个用于解码。VHRED是一个最近很受欢迎的Seq2seq模型，它利用子序列之间的复杂依赖关系生成序列。 ​ 【24】是最初的使用Seq2seq模型的神经机器翻译模型（NMT）之一； ​ 【63】是一个最近提出的 seq2seq NMT模型，是此领域的benchmark； ​ 【22,30,98,127】有对其的攻击。 Attention Models： ​ 注意力机制最初被设计用来克服seq2seq模型中对长序列编码的问题。 ​ 注意力允许解码器回溯源序列的隐藏状态，然后，隐藏状态提供一个加权平均作为解码器的额外输入。 Reinforcement Learning Models： ​ 强化学习通过在代理执行离散动作后给予奖励来训练代理，在NLP中，强化学习框架通常由一个代理（DNN），一个策略部分（用于指导动作）和奖励组成。 ​ 代理基于策略做出一个动作（例如预测序列中下一个单词的位置），然后相应地更新其内部状态，直到到达序列的末尾，在这里奖励已经被计算完成。 ​ 强化学习需要正确处理每一步的动作和状态，这可能会限制模型的表现力和学习规模。但它在面向任务的对话系统中获得了很多好处，因为它们在决策过程共享着同一根本原则。 Deep Generative Models（深层生成模型）： ​ 近些年，两种深层生成模型获得了很多关注：Genera\u0002tive Adversarial Networks (GANs) 【39】 and Variational Auto-Encoders (VAEs) ​ 其可以在潜在空间中生成与真实数据分厂相似的数据样例，在NLP领域，它们被用来生成文本。 ​ 8.1 GANS: ​ Gans由两个对抗网络组成：生成器（generator）和鉴别器（discriminator）。鉴别器的作用是鉴别真实样本和生成样本，生成器的作用是生成很真实的，用于欺骗鉴别器的样本。 ​ Gan使用min-max loss function来同步训练两个神经网络。 ​ 8.2 VAES： ​ Vaes由编码器（encoder）和生成器（generator）组成。编码器的作用是对输入编码为潜在空间，生成器的作用是从潜在空间中生成样本。 深度模型都不是很好训练，这个缺点阻碍了其在真实世界的应用中的广泛应用，尽管他们已经被用于生成文本，但目前没有工作去用对抗样本检验它们的健壮性。 5. From image to text: 一. 构造对抗样本： 、L-BFGS: ​ Szegedy【132】等人首次证明了可以通过对图像添加小量的人类察觉不到的扰动误导深度神经网络图像分类器做出错误的分类。他们首先尝试求解让神经网络做出误分类的最小扰动的方程。作者认为，深度神经网络所具有的强大的非线性表达能力和模型的过拟合是可能产生对抗性样本原因之一。 FGSM（Fast Gradient Sign Method）： ​ L-BFGS很有效但成本高昂，这使Goodfellow【40】等人找到一个简化问题的方法。 JSMA（Jacobian Saliency Map Adversary）： ​ 与FGSM利用梯度攻击不同，Papernot【105】等人使用forward derivatives（远期衍生物？）生成对抗样本。这个方法通过使用其雅克比矩阵来评估神经模型对每个输入部分的输出敏感性。 DeepFool： ​ DeepFool是一种迭代的L2正则化算法，作者先假设神经网络是线性的，因此可以使用一个超平面来分离类。作者简化了问题并且基于以上假设找到了问题最优解，并构建了对抗样本、 ​ 为了解决神经网络是非线性的事实，作者重复他们的步骤直到一个真正的对抗样本被生成了。 PS：正则化：(23 封私信 / 54 条消息) 机器学习中常常提到的正则化到底是什么意思？ - 知乎 (zhihu.com) Subsititute Attack： ​ 前面四中攻击方式都是白盒攻击， Papernot【104】等人提出了黑盒攻击策略，他们训练了一个与目标模型决策边界相似的替代模型，对此替代模型进行白盒攻击，生成相应对抗样本。 ​ 在生成对抗样本的过程中，他们使用了FSGM和JSMA。 GAN-like Attack： ​ 这是一种通过深度生成模型的黑盒攻击方法，Zhao【157】等人首先基于数据集 X 训练了一个生成模型WGAN，WGAN可以生成与X分布相同的数据点。 二. 对图像DNN攻击与对文本DNN攻击的对比： ​ 1. 二者的主要不同： ​ 1.1 离散与连续输入： ​ 图像输入是连续的而文本输入是离散的，在图像输入中，通常使用Lp来衡量原始数据点和扰动点的距离，但是由于文本输入是离散的，很难定义文本上的扰动大小（==为什么？==）。这就需要构造对文本扰动的衡量方法。还有一种方式是将文本输入当做连续值，然后应用CV方法，在3.3节上将会详细讨论。 ​ 1.2 可察觉与不可察觉： ​ 与图像相比，文本数据即使更改一个字母也会造成很大变化，故即使做很小的扰动，也可以被很明显的察觉到。 ​ 1.3 有语义和无语义： ​ 原理同上，在文本中做很小的改动往往会极大地影响到文本的语法和语义信息。 ​ 基于以上不同，目前主流对文本DNN的攻击有两种：1. 调整图像DNN的攻击方法，添加额外限制；2. 使用新技术提出一个新方法。 三. 向量化文本输入 and 扰动的衡量方法 三种向量化文本输入的方法： 1.1 基于计数的编码（Word-Count-based Encoding）： ​ ① BOW（Bag-of-words）方法，将一个文档中出现的词语编号为向量的0,1,2.....i维度，每个维度的值代表词语出现的次数。（缺点：不能记住词语顺序） ​ ② Term frequency-inverse document frequency (TF-IDF) ，具体见： TF-IDF算法介绍及实现_Asia-Lee-CSDN博客_tf-idf ​ 1.2 热独编码（One-hot Encoding）: ​ 具体介绍略。 ​ 由于普通顺序编码的值存在大小关系，当模型得到输入后会将其当做实际值来处理，这就使得原本平行的数据有了大小关系，独热编码巧妙地解决了这个问题，使得所有单词或者字母低位平等。 ​ 1.3 稠密编码： ​ Word2Vec使用连续BOW模型和skip-gram 模型来做代码嵌入。 ​ 一个潜在的假设是，出现在相似语境下的词语有着相似的含义。 词嵌入在一定程度上缓解了文本数据向量化的离散性和数据稀疏性问题【36】，词嵌入的扩展如doc2vec和paragraph2vec【69】将句子/段落编码为稠密向量。 扰动的衡量方法： 2.1 基于范数的方法（Norm-based measurement）： ​ 直接使用范数需要输入数据是连续的。一个解决方法是使用连续且稠密的表示方法（如嵌入），但这通常会得到无意义的文本。 2.2 基于语法和句法的方法（Grammar and syntax related measurement）： ​ 通过确认文本语法的正确性来保证对抗样本不易被识别。 ​ 可以使用Perplexity【91】，Paraphrase（4.3.3）确保对抗样本的有效性。 2.3 基于语义保持的方法（Semantic-preserving measurement）： ​ ① 计算欧拉距离: ​ ② 计算Cosine Similarity（余弦相似度）： ​ 2.4 基于编辑距离的方法： ​ 编辑距离（Edit Distance），又称Levenshtein距离，是指两个字串之间，由一个转成另一个所需的最少编辑操作次数。许可的编辑操作包括将一个字符替换成另一个字符，插入一个字符，删除一个字符。一般来说，编辑距离越小，两个串的相似度越大。 ​ 不同定义使用不同的转换操作。 2.5 基于Jaccard相似系数的方法： ​ Jaccard相似系数定义见百度百科。 ​ 就是把两个集合的交集除以两个集合的并集，简单地看集合中的元素是不是大量相同。 6. Attacking Neural Models in NLP: 常见攻击方法： 白盒，黑盒...... ​ 提供了数据集来源，但没有提供生成对抗样本的数据集，所提供的的数据集仅用于评估攻击效果。 7. Defense: 背景：两种在DNN中常用的防御方法：1. 对抗训练(adversarial training) 2. 知识蒸馏（knowledge distillation）. Knowledge distillation：【经典简读】知识蒸馏(Knowledge Distillation) 经典之作 - 知乎 (zhihu.com) 一. 对抗训练 数据增强（Data Augmentation）： ​ 数据增强将原始数据集加上对抗样本一起，在训练的过程中让模型见到更多数据，数据增强常被用来对抗黑盒攻击，实现的方式是通过在被攻击的DNN上使用对抗样本增加额外的epoch。 ​ 【54】证明了这种方法是有效的，但仅仅对同一对抗样本有效（数据增强中的样本与测试对抗样本） ​ 【142】也提出了类似的观点 ​ 【56】作者提出了3种生成更多具有不同特征的数据的方法 ​ 【12】作者提出了一种新的数据增强的方法，它将平均字符嵌入作为一个词表示，并将其纳入输入。这种方法本质上对字符的置乱不敏感，例如交换、mid和Rand，因此可以抵抗这些置乱攻击引起的噪声。但是，这种防御方法对不是针对字符顺序的扰乱不起作用。 模型正则化（Model Regularization）： 模型正则化将生成的对抗样本实例作为正则化器： 模型正则化_少年吉的博客-CSDN博客_模型正则化 正则化( Regularization)的目的在于提高模型在未知测试数据上的泛化力,避免参数过拟合。 健壮性最优化方法（Robust Optimization）： Madry【84】等人将DNN学习问题转化为了一个包含内非凹最大化问题(攻击)和外非凸最小化问题(防御)的健壮性优化问题。 二. 知识蒸馏 ​ 详见论文和博客。 8.Discuss and Open issues 可察觉性（Perceivability）： 见前文 可转移性（Transferability）： no-tatgeted攻击的可转移性更强。 可转移性可以在三个地方体现： ​ 2.1 同样的架构，不同的数据； ​ 2.2 同样的应用场景，不同的架构； ​ 2.3 不同的架构，不同的数据。 尽管现有的工作囊括了以上三种情况，但对抗样本攻击的可移植性效果仍不好，需要更多的工作。 自动化（Automation）： ​ 一些工作可以做到对抗样本的自动生成，而另一些则不行。 ​ 在白盒攻击中，利用DNN的损失函数可以自动识别文本中受影响最大的点(如字符、词)，以此做到在文本中自动化。 ​ 在黑盒攻击中，一些攻击例如替代训练（substitution train）可以训练出一个替代用模型，对其进行白盒攻击，也可以实现自动化。但是大多数对抗样本的生成都是人工生成。【54】会关联人工选择的无意义的文本段落来欺骗阅读理解系统，以此来发现DNN的脆弱性。很多研究工作跟随【54】，其目的不是实际攻击，而是更多的在检测目标网络的健壮性上，这些人工工作是耗时且不切实际的。我们相信在未来更多的努力会用来克服这个困难。 新架构（New Architectures）： ​ 尽管大多数普通的文本DNN都注意到了对抗样本攻击，但是很多DNN并没有被攻击过。例如GANS与VAES，它们被用作生成文本。深度生成模型需要更复杂的技巧去训练，这就可以解释为什么这些技术忽略了对抗样本攻击。未来的工作可能考虑对这些DNN进行对抗样本攻击。 ​ 注意力机制（Attention Mechanism）目前是大多数序列模型的标准组成部分，但是没有工作去检验注意力机制本身。故可能的攻击工作要么攻击包含注意的整体系统，要么利用注意分数来识别干扰词【14】。 迭代 VS 一次性（Iterative versus One-of）： ​ 迭代攻击：效果好，耗时长； ​ 一次性攻击：效果略差，耗时短。 ​ 在设计攻击方法时，攻击者需要仔细考虑效果与效率的平衡。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"AD","slug":"AD","permalink":"http://example.com/tags/AD/"},{"name":"NLP","slug":"NLP","permalink":"http://example.com/tags/NLP/"}],"author":"Shaw"},{"title":"A novel Android malware detection system-adaption of flter‑based  feature selection methods","slug":"【论文阅读】A novel Android malware detection system adaption of flter‑based  feature selection methods","date":"2021-09-03T06:08:27.099Z","updated":"2022-07-16T02:09:31.345Z","comments":true,"path":"2021/09/03/【论文阅读】A novel Android malware detection system adaption of flter‑based  feature selection methods/","link":"","permalink":"http://example.com/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91A%20novel%20Android%20malware%20detection%20system%20adaption%20of%20flter%E2%80%91based%20%20feature%20selection%20methods/","excerpt":"【论文阅读】A novel Android malware detection system: adaption of flter‑based feature selection methods 时间：2021 作者： Durmuş Özkan Şahin Oğuz Emre Kural · Sedat Akleylek Erdal Kılıç 总结： 二分类，静态代码检测； 创新点主要在特征提取（已经有的方法+文本分类的方法）上，分类器用的各种现成的方法； Abstract: ​ 在本研究中，提出了一个基于过滤器特征选择方法的，原创的安卓端恶意软件追踪系统。 ​ 该方法是一个在机器学习的基础上的静态安卓恶意软件追踪方法。在所开发的系统中，使用应用程序文件中提取的权限作为特征。八个不同的特征选择方法被用于维度降低，以减少运行时间，提升机器学习算法的效率。 ​ 其中四种方法应用于安卓恶意样本分类，其余四种方法是从文本分类研究中采用的，其从提取特征和分类结果两方面对方法进行了比较，在对结果进行检验时，表明所采用的方法提高了分类算法的效率，可以在本领域中使用。","text":"【论文阅读】A novel Android malware detection system: adaption of flter‑based feature selection methods 时间：2021 作者： Durmuş Özkan Şahin Oğuz Emre Kural · Sedat Akleylek Erdal Kılıç 总结： 二分类，静态代码检测； 创新点主要在特征提取（已经有的方法+文本分类的方法）上，分类器用的各种现成的方法； Abstract: ​ 在本研究中，提出了一个基于过滤器特征选择方法的，原创的安卓端恶意软件追踪系统。 ​ 该方法是一个在机器学习的基础上的静态安卓恶意软件追踪方法。在所开发的系统中，使用应用程序文件中提取的权限作为特征。八个不同的特征选择方法被用于维度降低，以减少运行时间，提升机器学习算法的效率。 ​ 其中四种方法应用于安卓恶意样本分类，其余四种方法是从文本分类研究中采用的，其从提取特征和分类结果两方面对方法进行了比较，在对结果进行检验时，表明所采用的方法提高了分类算法的效率，可以在本领域中使用。 ### 1. Introduction: #### 1.1 如何提取相关特征？ ​ Shabtai (2012)介绍了Andromaly架构，其中包含不同的特征选取方法和分类方法。 ​ Zhao（2015）提出了一个特征选择方法FrequelSel，其基于无害样本和恶意样本的频率特征差异。 ​ Xu （2016）提出了一个新的安卓恶意样本追踪方法ICCdetector，他们使用CFS（Correlation Based Feature Selection）在许多特征向量中做特征提取。 ​ Morales-Ortega（2016）提出了一种可以在恶意软件分析和检测设备上本地运行的方法，他们使用不同的特征选择方法和分类方法进行了对比实验。 ​ Bhattacharya and Goswami (2018) 提出了一种通过通过混合基于community的粗略设置特征选择方法（community-based rough set feature selection method）来进行特征选择的新方法。 ​ Peynirci et al. (2020) 提出了Delta IDF方法，其通过选择具有最高IDF（NLP中的）无害样本和最低IDF的恶意样本来提取特征。在特征提取中使用了字符串，API调用序列，权限等来作为特征。 ​ Ananya et al. (2020) 提出了一种安卓恶意样本追踪的动态分析技术。 ​ Kouliaridis et al. (2021)使用了两个特征选取算法和八个不同的分类器进行了比较试验。 ​ Jung et al. (2021) 在Gini Importance 和 domaind 知识上进行了特征提取。使用了API调用序列和应用权限。 ​ Liu et al. (2021)使用非监督学习进行了安卓恶意样本的特征提取。 #### 1.2 Contribution: ​ 主要贡献： 1. 提出了一个基于过滤器特征选择方法的，原创的安卓端恶意软件追踪系统（静态检查）； 2. 基于文本分类的特征选择方法对现有的属性选择方法进行替代是适应于Android恶意软件检测系统的。因此，不使用所有的权限，而是选择了最具特色的权限，提高了分类算法的性能； 3. 比较给出各度量得到的允许度和分类结果。在检查结果时，所提出的系统使用的特征比现有的检测系统少； 4. 从我们所采用的特征提取方法中得到的结果总体上所得到的特征比其他方法少； 5. 实验结果更好，run的时间更短，分类效果更佳； 6. 一些矩阵与贪婪方法相结合形成各种属性子集。这些创建的属性子集在用大量classifer进行测试时表现出了显著的性能。 2. Preliminaries： 2.1 Feature extraction（如何处理APK文件）： 2.2 Feature selection（提取特征）： ​ 特征选择技术分为三类：flter-based，wrapper-based，embedded methods. ​ 在基于过滤的技术中，就是在所有属性中选择最好的k个属性，而不使用剩余的属性。各种基于统计或信息论的技术被用来寻找最佳的k个特征。 ​ 基于Wrapper的技术在操作上与过滤技术类似，但在搜索策略上，选择是用遗传算法等启发式方法代替统计技术进行的。 ​ 特征选择过程是在机器学习算法的训练阶段进行的。特征选择是通过找到影响在训练阶段创建的模型性能的最佳子集来进行的。 2.3 The proposed Android malware detection system： ​ 3. Experimental settings： 3.1 datasets： ​ 3000恶意样本（VirusShare dataset ），3000无害样本（APKPure） 3.2 Classifcation algorithms 3.3 Performance measure 4. Results and discussions: 4.1 Results of performed experiments: 数据处理： 分类结果（部分）： 总： 与其他方法比较： ​","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Malware Classifiers","slug":"Malware-Classifiers","permalink":"http://example.com/tags/Malware-Classifiers/"},{"name":"Android","slug":"Android","permalink":"http://example.com/tags/Android/"}],"author":"Shaw"},{"title":"A Benchmark API Call Dataset For Windows PE Malware Classification","slug":"【论文阅读】A Benchmark API Call Dataset For Windows PE Malware Classification","date":"2021-09-03T06:08:27.096Z","updated":"2022-07-16T02:09:35.469Z","comments":true,"path":"2021/09/03/【论文阅读】A Benchmark API Call Dataset For Windows PE Malware Classification/","link":"","permalink":"http://example.com/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91A%20Benchmark%20API%20Call%20Dataset%20For%20Windows%20PE%20Malware%20Classification/","excerpt":"【论文阅读】A Benchmark API Call Dataset For Windows PE Malware Classification 作者：Ferhat Ozgur Catak（土耳其） ​ Ahmet Faruk Yazi（土耳其） 时间：2021.2.23 关键词：恶意软件分析，网络空间安全，数据集，沙箱环境，恶意软件分类 1. Abstract ​ 在Windows操作系统中，系统API调用的使用在监控恶意PE程序中是一个很有前途的方法。这个方法被定义为在安全隔离的沙箱环境中运行恶意软件，记录其调用的Windows系统API，再顺序分析这些调用。 ​ 在这里，我们在隔离沙箱中分析了7107个属于不同家族（病毒，后门，木马等）的恶意软件，并把这些分析结果转化为了不同分类算法和方法可以使用的形式。 ​ 首先，我们会解释如何得到这些恶意软件；其次，我们会解释如何将这些软件捆绑至家族中；最后，我们会描述如何使用这些数据集来通过不同的方法实现恶意软件的分类。","text":"【论文阅读】A Benchmark API Call Dataset For Windows PE Malware Classification 作者：Ferhat Ozgur Catak（土耳其） ​ Ahmet Faruk Yazi（土耳其） 时间：2021.2.23 关键词：恶意软件分析，网络空间安全，数据集，沙箱环境，恶意软件分类 1. Abstract ​ 在Windows操作系统中，系统API调用的使用在监控恶意PE程序中是一个很有前途的方法。这个方法被定义为在安全隔离的沙箱环境中运行恶意软件，记录其调用的Windows系统API，再顺序分析这些调用。 ​ 在这里，我们在隔离沙箱中分析了7107个属于不同家族（病毒，后门，木马等）的恶意软件，并把这些分析结果转化为了不同分类算法和方法可以使用的形式。 ​ 首先，我们会解释如何得到这些恶意软件；其次，我们会解释如何将这些软件捆绑至家族中；最后，我们会描述如何使用这些数据集来通过不同的方法实现恶意软件的分类。 ### 2. Introduction #### 2.1 简单介绍了恶意软件 #### 2.2 恶意软件与恶意软件识别之间的竞争 ​ 相互促进 #### 2.3 变形恶意软件（Metamorphic malware） ​ 恶意软件家族里很先进的一种，这种软件可以持续不断的改变自身源代码以此改变自身结构，通过这种方式来改变自身代码特征。还有，这种软件可能还可以通过强度反算（counter-analysis）来识别自身运行的环境，以此来隐藏自身的恶意功能。 ​ 变形恶意软件很难识别。 #### 2.4 恶意软件的识别： ​ 所有恶意软件都会有恶意行为以达成其目的，如果可以很好的分析恶意行为，就可以做成恶意软件的识别与分类。 ​ 恶意软件的识别包括了很多需要解决的问题，例如在汇编中不正确的跳转操作码，PE文本段代码隐藏，代码加密。本研究收集了现有的恶意软件及其变式，例如WannaCry，Zeus，特别是在Github上。 ​ 我们通过在VirusTotal网站上寻找每个恶意软件的哈希值，从而获得了得到了其家族类。 ​ 最后，所有我们记录的行为都是在Cuckoo沙盒环境中运行的。 ​ 我们发现几乎所有恶意软件都会使用很多方法改变其行为，但即使这样，恶意软件还是有一个目标，有一个确定的模式来达到此目标。还有，恶意软件会做出一些不必要的API调用，但其还是可以被一个训练好的分析器识别，因为其行为模式是相同的。 ​ 恶意软件分析被视为网络空间安全的一个分支，其由两方面组成： ##### 1. 静态分析 ： ​ 静态分析可以可以定义为通过执行一个孤立的环境检查可执行文件而不查看实际指令。例如MD5校验和，其通过反病毒检测攻击识别，查找字符串。 ##### 2. 动态分析 ​ 动态分析指运行恶意程序来理解其功能，观察其表现，识别其技术指标。几乎所有的重要行为都包含API调用序列。 ​ 大多数动态分析领域的研究都只关注分类算法，有个基本问题是没有标准的数据集来检查所提出模型的效率。 ​ 我们在Github上分享了我们的数据集：https://github.com/ocatak/malware_api_class ，该数据集包含了基于Cuckoo沙箱的已知恶意软件执行和基于VirusTotal的文件MD5特征分类的原始数据。 3. Methods 3.1 Windows API Calls： ​ 软件安全知识，略 3.2 Cuckoo SandBox ​ 免费软件，高度集成，开源，可以自动分析Winodws,OS X,Linux,Android系统下的恶意文件。 3.3 VirusTotal ​ 可以在线免费分析文件或者URL。其提供了一个API，可以不通过浏览器来提供分析结果，可以自动分析。其以JSON文件的形式提供分析结果，不同反病毒应用引擎和浏览器的分析结果会分开存放。 3.4 数据集生成 ​ 本文的数据集有着简单明了的结构。数据集以CVS格式文件提供来提高互操作性，而且并不需要特定的软件或者库来读取他们。数据由来自不同Github页面的Git命令实施收集，数据集中的每一行都是在沙箱中分析的Windows操作系统的API调用序列。 ​ 数据集的生成过程如下： ​ 1. 沙箱环境准备： ​ 分析机器使用Ubuntu系统，将Cuckoo沙箱安装在其中，分析机运行虚拟服务，Windows操作系统就运行在虚拟服务上，同时关掉防火墙，系统升级。 ​ 2. 分析恶意软件: ​ 虚拟机中同时运行超过20000个恶意软件，应用程序会将每个恶意软件的分析结果写入MongoDB数据库，分析结果中包含恶意软件的行为数据，这些数据都是恶意软件在Win7上的API调用请求。 ​ 3. 处理API调用： ​ 我们在数据集中收集到了342种API调用，这些调用会被以0-341来标记，以此生成一个新数据集。我们使用了该数据集中至少有10个不同API调用的恶意软件的分析结果。 ​ 4. 使用Virus Total公用API分析恶意软件： ​ 作为分析的补充，所有在数据集中的恶意软件也会被Virus Total所分析，通过这种方式，每个恶意软件都会被不同的反病毒引擎所分析，结果会被记录。 ​ 5. 处理分析结果： ​ Virus Total服务使用大约66个不同的防病毒应用程序进行文件分析。利用我们利用这个服务得到的每个研究结果，我们识别了每个恶意软件的家族。通过观察，我们发现对于同一恶意软件，不同的防病毒应用程序给出了不同的结果。此外，观察到并非每一个防病毒应用程序都能检测到一些恶意软件。因此，在检测每一个恶意软件类时，认为它属于所有分析中的大多数类。","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"AD","slug":"AD","permalink":"http://example.com/tags/AD/"},{"name":"Malware Classifiers","slug":"Malware-Classifiers","permalink":"http://example.com/tags/Malware-Classifiers/"}],"author":"Shaw"},{"title":"Generic Black-Box End-to-End Attack Against State of the art API Call Based Malware Classifiers","slug":"【论文阅读】Generic Black-Box End-to-End Attack Against State of the art API Call Based Malware Classifiers","date":"2021-09-03T06:08:27.094Z","updated":"2021-10-12T13:26:39.593Z","comments":true,"path":"2021/09/03/【论文阅读】Generic Black-Box End-to-End Attack Against State of the art API Call Based Malware Classifiers/","link":"","permalink":"http://example.com/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Generic%20Black-Box%20End-to-End%20Attack%20Against%20State%20of%20the%20art%20API%20Call%20Based%20Malware%20Classifiers/","excerpt":"","text":"【论文阅读】Generic Black-Box End-to-End Attack Against State of the art API Call Based Malware Classifiers 作者：Ishai Rosenberg 大学：Ben-Gurion University of the Negev 时间：2018.6.4 1. 做了什么？ ​ 对一个通过机器学习训练的，通过API调用来分类恶意软件的分类器的攻击。 ​ 这个攻击可以使分类器不能成功识别恶意软件，并且不改变原有软件的功能。 ​ 实现了GADGET，一个可以直接将二进制恶意软件文件转换为分类器无法检测的二进制文件，并不需要访问文件源代码。 2. 一些概念： 2.1 Machine learning malware classififiers（基于机器学习的恶意软件分类器） ​ 优点：1. 可以自动训练，节省时间； ​ 2. 只要分类器并不是基于指纹特征或者某个特定的特征（如Hash值）来分类，面对不可见威胁时泛化能力较强。 2.2 Adversarial Examples（对抗样本） 对输入样本故意添加一些人无法察觉的细微的干扰，导致模型以高置信度给出一个错误的输出。 可以针对一张已经有正确分类的image，对其进行细微的像素修改，可以在DNN下被错分为其他label。 ​ 样本x的label为熊猫，在对x添加部分干扰后，在人眼中仍然分为熊猫，但对深度模型，却将其错分为长臂猿，且给出了高达99.3%的置信度。 像素攻击：改动图片上的一个像素，就能让神经网络认错图，甚至还可以诱导它返回特定的结果。 改动图片上的一个像素，就能让神经网络认错图，甚至还可以诱导它返回特定的结果 2. 同样，根据DNN，很容易产生一张在人眼下毫无意义的image，但是在DNN中能够获得高confidence的label。 两种EA算法生成的样本，这些样本人类完全无法识别，但深度学习模型会以高置信度对它们进行分类，例如将噪声识别为狮子。 2.2.1： Adversarial examples for API sequences(生成API序列对抗样本与生成图像对抗样本并不同): API序列由长度可变的离散符号组成，但图像可以用固定维度的矩阵表示为矩阵，且矩阵的值是连续的。 对于对抗API序列，其必须验证原始的恶意功能是完整的。 对抗样本的迁移性：针对一种模型的对抗样本通常对另一种模型也奏效，即使这两个模型不是用同一数据集训练的。 2.3 几种攻击方法： White-box attack：白盒攻击，对模型和训练集完全了解。 Black-box attack：黑盒攻击：对模型不了解，对训练集不了解或了解很少。 Real-word attack：在真实世界攻击。如将对抗样本打印出来，用手机拍照识别。 targeted attack：使得图像都被错分到给定类别上。 non-target attack：事先不知道需要攻击的网络细节，也不指定预测的类别，生成对抗样本来欺骗防守方的网络。 mimicry attack: 编写恶意的exploit，该exp模拟良性代码系统调用的痕迹，因为能够逃逸检测。 disguise attack: 仅修改系统调用的参数使良性系统调用生成恶意行为 。 No-op attack: 添加语义的no-ops-系统调用，其没有影响，或者是不相干的影响，即，打开一个不存在的文件。 Equivalence attack: 使用一个不同的系统调用来达到恶意的目的. 2.4 decision boundary(决策界限) 2.5 end-to-end: 2.6 结果分类： 虑一个二分问题，即将实例分成正类（positive）或负类（negative）。对一个二分问题来说，会出现四种情况。如果一个实例是正类并且也被 预测成正类，即为真正类（True positive）,如果实例是负类被预测成正类，称之为假正类（False positive）。相应地，如果实例是负类被预测成负类，称之为真负类（True negative）,正类被预测成负类则为假负类（false negative）。 列联表如下表所示，1代表正类，0代表负类。（预测正确：true，预测是正类：positive） 预测 1 0 合计 实际 1 True Positive（TP） False Negative（FN） Actual Positive(TP+FN) 0 False Positive（FP) True Negative(TN) Actual Negative(FP+TN) 合计 Predicted Positive(TP+FP) Predicted Negative(FN+TN) TP+FP+FN+TN 从列联表引入两个新名词。 其一是真正类率(true positive rate ,TPR), 计算公式为 TPR=TP/ ( TP+ FN)，刻画的是分类器所识别出的 正实例占所有正实例的比例。 另外一个是负正类率(false positive rate, FPR),计算公式为 FPR= FP / (FP + TN)，计算的是分类器错认为负类的正实例占所有负实例的比例。 还有一个真负类率（True Negative Rate，TNR），也称为specificity,计算公式为TNR= TN/ ( FP+ TN) = 1 - FPR。 3. 如何实现？ 一些问题：程序调用API的过程；","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"AD","slug":"AD","permalink":"http://example.com/tags/AD/"},{"name":"Malware Classifiers","slug":"Malware-Classifiers","permalink":"http://example.com/tags/Malware-Classifiers/"}],"author":"Shaw"},{"title":"More is different.","slug":"Welcome","date":"2021-09-03T05:50:00.118Z","updated":"2022-07-15T07:58:26.964Z","comments":true,"path":"2021/09/03/Welcome/","link":"","permalink":"http://example.com/2021/09/03/Welcome/","excerpt":"","text":"宏观与微观的审视哲学，量变产生质变。 一些记录， 一些随手写。","categories":[],"tags":[],"author":"Shaw"}],"categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"},{"name":"Something","slug":"Something","permalink":"http://example.com/categories/Something/"},{"name":"Book","slug":"Book","permalink":"http://example.com/categories/Book/"}],"tags":[{"name":"Malware Classifiers","slug":"Malware-Classifiers","permalink":"http://example.com/tags/Malware-Classifiers/"},{"name":"obfuscation","slug":"obfuscation","permalink":"http://example.com/tags/obfuscation/"},{"name":"RL","slug":"RL","permalink":"http://example.com/tags/RL/"},{"name":"IDS","slug":"IDS","permalink":"http://example.com/tags/IDS/"},{"name":"DDoS","slug":"DDoS","permalink":"http://example.com/tags/DDoS/"},{"name":"AD","slug":"AD","permalink":"http://example.com/tags/AD/"},{"name":"Botnet","slug":"Botnet","permalink":"http://example.com/tags/Botnet/"},{"name":"Mutiagent","slug":"Mutiagent","permalink":"http://example.com/tags/Mutiagent/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://example.com/tags/Machine-Learning/"},{"name":"Math","slug":"Math","permalink":"http://example.com/tags/Math/"},{"name":"NLP","slug":"NLP","permalink":"http://example.com/tags/NLP/"},{"name":"AD training","slug":"AD-training","permalink":"http://example.com/tags/AD-training/"},{"name":"DNN","slug":"DNN","permalink":"http://example.com/tags/DNN/"},{"name":"RNN","slug":"RNN","permalink":"http://example.com/tags/RNN/"},{"name":"PDF","slug":"PDF","permalink":"http://example.com/tags/PDF/"},{"name":"Android","slug":"Android","permalink":"http://example.com/tags/Android/"}]}