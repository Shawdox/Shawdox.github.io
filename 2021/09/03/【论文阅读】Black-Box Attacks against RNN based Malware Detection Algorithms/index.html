<!DOCTYPE html>
<html>

<head>
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" >
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
  <title>Black-Box Attacks against RNN based Malware Detection Algorithms | Shaw</title>
  <meta name="description" content="@hust" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="MobileOptimized" content="320" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <link rel="stylesheet" type="text/css" href="/css/screen.css" />
  <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Noto+Serif:400,700,400italic|Open+Sans:700,400" />

  <meta name="generator" content="Shaw">

  
  
  

  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>


<body class="post-template">

  <header class="site-head"  style="background-image: url(//blog.ghost.org/content/images/2013/Nov/cover.png)" >
    <div class="vertical">
        <div class="site-head-content inner">
             <a class="blog-logo" href="/"><img src="//blog.ghost.org/content/images/2013/Nov/bloglogo_1-1.png" alt="Blog Logo"/></a> 
            <h1 class="blog-title">Shaw</h1>
            <h2 class="blog-description">@hust</h2>
        </div>
    </div>
</header>
  

<main class="content" role="main">
  <article class="post">
    <span class="post-meta">
      <time datetime="2021-09-03T06:08:27.105Z" itemprop="datePublished">
          2021-09-03
      </time>
    
    
    | 
    <a href='/tags/Malware-Classifiers/'>Malware Classifiers</a>,
    
    <a href='/tags/AD/'>AD</a>,
    
    <a href='/tags/RNN/'>RNN</a>
    
    
</span>
    <h1 class="post-title">Black-Box Attacks against RNN based Malware Detection Algorithms</h1>
    <section class="post-content">
      <h1 id="【论文阅读】Black-Box-Attacks-against-RNN-based-Malware-Detection-Algorithms"><a href="#【论文阅读】Black-Box-Attacks-against-RNN-based-Malware-Detection-Algorithms" class="headerlink" title="【论文阅读】Black-Box Attacks against RNN based Malware Detection Algorithms"></a>【论文阅读】Black-Box Attacks against RNN based Malware Detection Algorithms</h1><blockquote>
<p><strong>时间</strong>：2017</p>
<p><strong>作者：</strong> Weiwei Hu 北京大学</p>
<p>​                 Ying Tan    北京大学</p>
</blockquote>
<ul>
<li><h4 id="Abstract："><a href="#Abstract：" class="headerlink" title="Abstract："></a>Abstract：</h4><p>​    1. <strong>原文：</strong></p>
<p>​    最近的研究表明，基于机器学习的恶意软件分类算法在面对对抗样本攻击时表现的十分脆弱。这些工作主要集中于那些利用了混合维度的特征的追踪算法，但一些研究者已经开始使用RNN，基于API特征序列来辨识恶意软件。</p>
<p>​    这篇文章提出了一种用于生成对抗样本序列的原创算法，它被用于攻击基于RNN的恶意软件分类系统。对于攻击者来说，通常，知晓目标RNN的内部结构和权重是很难的。于是一个替代的用于近似目标RNN的RNN模型就被训练了出来，接着我们利用这个RNN来从原始序列输入中生成对抗样本序列。</p>
<p>​    <strong>权威结果表明基于RNN的恶意软件分类算法不能追踪大多数我们所生成的恶意对抗样本，这意味着我们生成的模型可以很有效的规避追踪算法。</strong></p>
<p>​    2. <strong>总结：</strong></p>
<p>​    一个对基于RNN的恶意样本分类器的灰盒攻击，有三个RNN，受害者RNN（源RNN），替代RNN，对抗样本生成RNN。</p>
</li>
</ul>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction:"></a>1. Introduction:</h3><ol>
<li>现有的基于N机器学习的恶意软件追踪算法主要将程序表现为固定维度的特征向量，然后将其分类为无害程序和恶意软件；</li>
<li>举例，利用API的调用序列，或者不被调用的API序列进行分类；</li>
<li>【11】展现了，基于固定维度特征来进行恶意样本分类的算法，面对对抗样本的攻击是脆弱的；</li>
<li>最近也有利用RNN进行恶意样本追踪与分类的，RNN的输入就是API序列。</li>
</ol>
<h3 id="2-Adversarial-Examples"><a href="#2-Adversarial-Examples" class="headerlink" title="2. Adversarial Examples:"></a>2. Adversarial Examples:</h3><p>​    一些其它的针对序列的对抗样本攻击：</p>
<blockquote>
<p>Nicolas Papernot, Patrick McDaniel, Ananthram Swami, and Richard Harang. Crafting adver</p>
<p>sarial input sequences for recurrent neural networks. In <em>Military Communications Conference,</em></p>
<p><em>MILCOM 2016-2016 IEEE</em>, pages 49–54. IEEE, 2016.</p>
<p>Kathrin Grosse, Nicolas Papernot, Praveen Manoharan, Michael Backes, and Patrick McDaniel.</p>
<p>Adversarial perturbations against deep neural networks for malware classifification. <em>arXiv preprint</em></p>
<p><em>arXiv:1606.04435</em>, 2016.</p>
</blockquote>
<h3 id="4-Attacking-RNN-based-Malware-Detection-Algorithms"><a href="#4-Attacking-RNN-based-Malware-Detection-Algorithms" class="headerlink" title="4. Attacking RNN based Malware Detection Algorithms"></a>4. Attacking RNN based Malware Detection Algorithms</h3><p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210830150941.png" alt=""></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210830151007.png" alt=""></p>
<h3 id="5-实验"><a href="#5-实验" class="headerlink" title="5. 实验"></a>5. 实验</h3><p>​    Adam 用于训练所有模型；</p>
<p>​    LSTM由于其在处理长序列的优秀表现，也被应用在实验的所有RNN中。</p>
<h4 id="5-1-数据集："><a href="#5-1-数据集：" class="headerlink" title="5.1    数据集："></a>5.1    数据集：</h4><p>​    <strong>来源：</strong><a target="_blank" rel="noopener" href="https://malwr.com/">https://malwr.com/</a>    （一个恶意样本分析网站，爬取180个项目，该网站可以分析用户上传的项目，并给出其API序列，网站中70%的项目都是恶意样本）</p>
<p>​    <strong>数据集划分：</strong>为了模拟真实的测试环境，数据集划分如下：（30%+10%）用于生成RNN，（30%+10%）用于受害者RNN，20%用于测试。</p>
<h4 id="5-2-受害者RNN："><a href="#5-2-受害者RNN：" class="headerlink" title="5.2 受害者RNN："></a>5.2 受害者RNN：</h4><p>​    尝试了不同模型：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210830110738.png" alt=""></p>
<p>​    <strong>结论如下：</strong></p>
<ol>
<li>与LSTM相比，BiLSTM不能提升模型的分类表现；</li>
<li>与Average-Pooling相比，注意力机制的效果更好；</li>
</ol>
<h4 id="5-3-生成（对抗样本）RNN测试结果："><a href="#5-3-生成（对抗样本）RNN测试结果：" class="headerlink" title="5.3 生成（对抗样本）RNN测试结果："></a>5.3 生成（对抗样本）RNN测试结果：</h4><p>​    介绍参数规范：</p>
<blockquote>
<p>The hyper-parameters of the generative RNN and the substitute RNN were tuned separately for each</p>
<p>black-box victim RNN. The learning rate and the regularization coeffificient were chosen by line</p>
<p>search along the direction 0.01, 0.001, et al.. The Gumbel-Softmax temperature was searched in the</p>
<p>range [1<em>,</em> 100]. Actually, the decoder length <em>L</em> in the generative RNN is also a kind of regularization</p>
<p>coeffificient. A large <em>L</em> will make the generative RNN have strong representation ability, but the whole</p>
<p>adversarial sequences will become too long, and the generative RNN’s size may exceed the capacity</p>
<p>of the GPU memory. Therefore, in our experiments we set <em>L</em> to 1.</p>
</blockquote>
<p>​    </p>
<p>​    给出实验结果：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210830140545.png" alt=""></p>
<ol>
<li>对于所有RNN模型，攻击都十分有效；</li>
<li>于LSTM的攻击效果最差，故替代RNN对LSTM的拟合效果并不好；</li>
<li>训练集与测试集的测试效果差别不大， 模型泛化能力强；</li>
<li>即使更换了模型与训练数据集，对抗样本仍效果很好。</li>
</ol>

    </section>
    <footer class="post-footer">
      <section class="author">
    <h4>Shaw</h4>
    <p>A designer, developer and entrepreneur. Spends his time travelling the world with a bag of kites. Likes journalism and publishing platforms.</p>
</section>
      <section class="share">
    <h4>Share this post</h4>
    <a class="icon-twitter" target="_blank" rel="noopener" href="http://twitter.com/share?url=http://example.com/2021/09/03/【论文阅读】Black-Box Attacks against RNN based Malware Detection Algorithms/"
       onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
        <span class="hidden">Twitter</span>
    </a>
    <a class="icon-facebook" target="_blank" rel="noopener" href="https://www.facebook.com/sharer/sharer.php?u=http://example.com/2021/09/03/【论文阅读】Black-Box Attacks against RNN based Malware Detection Algorithms/"
       onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
        <span class="hidden">Facebook</span>
    </a>
    <a class="icon-google-plus" target="_blank" rel="noopener" href="https://plus.google.com/share?url=http://example.com/2021/09/03/【论文阅读】Black-Box Attacks against RNN based Malware Detection Algorithms/"
       onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
        <span class="hidden">Google+</span>
    </a>
</section>
    </footer>
  </article>
  <nav class="pagination" role="pagination">
    
    <a class="newer-posts" href="/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Deep%20Text%20Classifification%20Can%20be%20Fooled/">
        ← Deep Text Classifification Can be Fooled
    </a>
    
    <span class="page-number">•</span>
    
    <a class="older-posts" href="/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Automatically%20Evading%20Classififiers----A%20Case%20Study%20on%20PDF%20Malware%20Classififiers/">
        Automatically Evading Classififiers----A Case Study on PDF Malware Classififiers →
    </a>
    
</nav>
  <div id="comment" class="comments-area">
    <h1 class="title"><a href="#disqus_comments" name="disqus_comments">Comments</a></h1>

    
</div>
</main>


  
<footer class="site-footer">
  
  <div class="inner">
     <section class="copyright">All content copyright <a href="/">Shaw</a> &copy; 2014 &bull; All rights reserved.</section>
     <section class="poweredby">Proudly published with <a class="icon-ghost" target="_blank" rel="noopener" href="http://zespia.tw/hexo/">Hexo</a></section>
  </div>
</footer>

  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script type="text/javascript" src="/js/jquery.fitvids.js"></script>
<script type="text/javascript" src="/js/index.js"></script>






<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>
