<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>《统计学习方法》 | Shaw</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  <meta name="keywords" content="Machine Learning" />
  
  
  
    <meta name="baidu-site-verification" content="63656ec0c686f8aaeeaad1b7243ba233" />
  
  
  <meta name="description" content="【书籍阅读】《统计学习方法》一. 统计学习方法概论：​    首先，要明确计算机科学中存在三个维度：系统，计算，与信息。统计学习方法（机器学习）主要属于信息这一维度，并在其中扮演者核心角色。 1. 监督学习概念：​    监督学习，Supervised learning，指在已经做好标注的训练集上学习，为了叙述方便，定义以下基本概念：   输入空间（X），输出空间（Y）：输入所有可能取值，输出所有">
<meta property="og:type" content="article">
<meta property="og:title" content="《统计学习方法》">
<meta property="og:url" content="http://example.com/2021/09/03/%E3%80%90%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B/index.html">
<meta property="og:site_name" content="Shaw">
<meta property="og:description" content="【书籍阅读】《统计学习方法》一. 统计学习方法概论：​    首先，要明确计算机科学中存在三个维度：系统，计算，与信息。统计学习方法（机器学习）主要属于信息这一维度，并在其中扮演者核心角色。 1. 监督学习概念：​    监督学习，Supervised learning，指在已经做好标注的训练集上学习，为了叙述方便，定义以下基本概念：   输入空间（X），输出空间（Y）：输入所有可能取值，输出所有">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902154618.png">
<meta property="og:image" content="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902154745.png">
<meta property="og:image" content="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902155212.png">
<meta property="og:image" content="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902161201.png">
<meta property="og:image" content="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902162814.png">
<meta property="og:image" content="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902162851.png">
<meta property="og:image" content="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904182025.png">
<meta property="og:image" content="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904182154.png">
<meta property="og:image" content="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904182339.png">
<meta property="og:image" content="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904183233.png">
<meta property="og:image" content="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905112734.png">
<meta property="og:image" content="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905112750.png">
<meta property="og:image" content="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905113440.png">
<meta property="og:image" content="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905143250.png">
<meta property="og:image" content="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905143332.png">
<meta property="og:image" content="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905143356.png">
<meta property="og:image" content="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905143648.png">
<meta property="og:image" content="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905143741.png">
<meta property="og:image" content="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905154943.png">
<meta property="article:published_time" content="2021-09-03T06:17:39.000Z">
<meta property="article:modified_time" content="2023-09-04T07:12:46.000Z">
<meta property="article:author" content="Shaw">
<meta property="article:tag" content="Machine Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902154618.png">
  
    <link rel="alternate" href="/atom.xml" title="Shaw" type="application/atom+xml">
  
  <link rel="icon" href="/css/images/ytre.jpg">
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Montserrat:700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Roboto:400,300,300italic,400italic" rel="stylesheet" type="text/css">
  <link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <style type="text/css">
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/9749f0/00000000000000000001008f/27/l?subset_id=2&fvd=n5) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/90cf9f/000000000000000000010091/27/l?subset_id=2&fvd=n7) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/8a5494/000000000000000000013365/27/l?subset_id=2&fvd=n4) format("woff2");font-weight:lighter;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/d337d8/000000000000000000010095/27/l?subset_id=2&fvd=i4) format("woff2");font-weight:400;font-style:italic;}</style>
    
  <link rel="stylesheet" id="athemes-headings-fonts-css" href="//fonts.googleapis.com/css?family=Yanone+Kaffeesatz%3A200%2C300%2C400%2C700&amp;ver=4.6.1" type="text/css" media="all">

  <link rel="stylesheet" id="athemes-headings-fonts-css" href="//fonts.googleapis.com/css?family=Oswald%3A300%2C400%2C700&amp;ver=4.6.1" type="text/css" media="all">
  
<link rel="stylesheet" href="/css/style.css">


  
<script src="/js/jquery-3.1.1.min.js"></script>


  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="/css/bootstrap.css" >
  <link rel="stylesheet" href="/css/fashion.css" >
  <link rel="stylesheet" href="/css/glyphs.css" >

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head>



  <body data-spy="scroll" data-target="#toc" data-offset="50">


  


<header id="allheader" class="site-header" role="banner" 
   >
  <div class="clearfix container">
      <div class="site-branding">

          <h1 class="site-title">
            
              <a href="/" rel="home" >
                <img style="margin-bottom: 10px;"  width="124px" height="124px" alt="Hike News" src=" /css/images/ytre.jpg">
              </a>
            
          </h1>
          
          
            <div class="site-description">积沙成塔</div>
          
            
          <nav id="main-navigation" class="main-navigation" role="navigation">
            <a class="nav-open">Menu</a>
            <a class="nav-close">Close</a>

            <div class="clearfix sf-menu">
              <ul id="main-nav" class="menu sf-js-enabled sf-arrows"  style="touch-action: pan-y;">
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663" linktext="/"> <a class="" href="/">首页</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663" linktext="archives"> <a class="" href="/archives">归档</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663" linktext="categories"> <a class="" href="/categories">分类</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663" linktext="tags"> <a class="" href="/tags">标签</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663" linktext="about"> <a class="" href="/about">关于</a> </li>
                    
              </ul>
            </div>
          </nav>

      </div>
  </div>
</header>


  <div id="container">
    <div id="wrap">
            
      <div id="content" class="outer">
        
          <section id="main" style="float:none;"><article id="post-【书籍阅读】《统计学习方法》" style="width: 66%; float:left;" class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="clearfix post-1016 post type-post status-publish format-standard has-post-thumbnail hentry category-template-2 category-uncategorized tag-codex tag-edge-case tag-featured-image tag-image tag-template">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" class="article-title" itemprop="name">
      《统计学习方法》
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2021/09/03/%E3%80%90%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B/" class="article-date">
	  <time datetime="2021-09-03T06:17:39.000Z" itemprop="datePublished">九月 3, 2021</time>
	</a>

      
	<span class="ico-folder"></span>
    <a class="article-category-link" href="/categories/Book/">Book</a>
 
      
	<span id="busuanzi_container_page_pv">
	  本文总阅读量<span id="busuanzi_value_page_pv"></span>次
	</span>

    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="【书籍阅读】《统计学习方法》"><a href="#【书籍阅读】《统计学习方法》" class="headerlink" title="【书籍阅读】《统计学习方法》"></a>【书籍阅读】《统计学习方法》</h1><h3 id="一-统计学习方法概论："><a href="#一-统计学习方法概论：" class="headerlink" title="一. 统计学习方法概论："></a>一. 统计学习方法概论：</h3><p>​    首先，要明确计算机科学中存在三个维度：系统，计算，与信息。统计学习方法（机器学习）主要属于信息这一维度，并在其中扮演者核心角色。</p>
<h4 id="1-监督学习概念："><a href="#1-监督学习概念：" class="headerlink" title="1. 监督学习概念："></a>1. 监督学习概念：</h4><p>​    监督学习，Supervised learning，指在已经做好标注的训练集上学习，为了叙述方便，定义以下基本概念：</p>
<blockquote>
<ol>
<li><strong>输入空间（X），输出空间（Y）：</strong>输入所有可能取值，输出所有可能取值；</li>
<li><strong>特征空间：</strong>输入一般由特征向量表示，所有特征向量存在的空间称为特征空间，输入空间与特征空间并不完全等价，有时需要映射；</li>
<li><strong>上标  x^i^</strong> :表示一个输入的第  i 个特征；</li>
<li><strong>下标  x~j~：</strong>表示第 j 个输入。</li>
<li><strong>回归问题：</strong>输入输出都为连续型变量；</li>
<li><strong>分类问题：</strong>输出变量为有限个离散型变量；</li>
<li><strong>标注问题：</strong>输入与输出变量都为变量序列。</li>
<li><strong>假设空间：</strong>所有可能的模型的集合，也就是学习的范围。</li>
</ol>
</blockquote>
<p>​    使用训练集学习——&gt;对未知数据进行预测</p>
<p>​    <span id="more"></span></p>
<h4 id="2-统计学习三要素："><a href="#2-统计学习三要素：" class="headerlink" title="2. 统计学习三要素："></a>2. 统计学习三要素：</h4><p>​    统计学习三要素为：<strong>模型，策略，算法</strong>；</p>
<p>​    模型是决定学习的预测函数的类型；</p>
<p>​    策略是判定什么样的模型是好的，用于度量当前的模型好坏；</p>
<p>​    算法是训练过程中的具体做法，例如如何回归，如何计算，如何调整等。</p>
<h4 id="3-模型的衡量方法："><a href="#3-模型的衡量方法：" class="headerlink" title="3. 模型的衡量方法："></a>3. 模型的衡量方法：</h4><ul>
<li><p><strong>损失函数与风险函数：</strong></p>
<p>​    损失函数，Loss Function，用于模型一次预测的错误程度，例如：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902154618.png" alt=""></p>
<p>​    损失函数的数值越小，模型就越好。如果计算损失函数的期望，得到的就是风险函数，Risk Function:</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902154745.png" alt=""></p>
<p>​    可以看出，损失函数用于某次预测的估计，风险函数用于总体平均估计。我们当然希望训练出的模型的风险函数越小越好。</p>
<p>​    <strong>但是，观察上式，理想化的概率分布P(x，y)是未知的，我们进行学习就是要通过模型来模拟它，故这个式子理论存在，实际不能计算，不能用作评估模型的直接方法。</strong></p>
</li>
</ul>
<ul>
<li><p><strong>经验风险与结构风险：</strong></p>
<p>​    为了解决上述问题，我们引入经验风险：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902155212.png" alt=""></p>
<p>​    可以看到，经验风险将每个样本视作等概率出现，是模型对于训练集的平均损失，那么其与风险函数的误差在哪？</p>
<p>​    根据大数定律，当训练集足够大时，二者是近似相等的。但实际情况下，很多时候训练样本数目有限，甚至很小，故用经验风险效估计风险函数并不理想，故需要进行修正，这就是监督学习中的<strong>两个基本策略：</strong>经验风险最小化和结构风险最小化。</p>
<p>​    如果训练样本容量较大，使用经验风险最小化没什么问题。</p>
<p>​    当样本容量很小时，仅仅使用经验风险最小化容易导致过拟合，故这里使用<strong>结构风险（就是正则化）</strong>最小化方法，对模型复杂度进行惩罚，后续介绍。</p>
</li>
</ul>
<ul>
<li><p><strong>训练误差与测试误差：</strong></p>
<p>​    训练误差本质上不重要，它可以反应一个问题是不是容易学习，但要衡量模型的预测能力，主要是看测试误差。</p>
</li>
</ul>
<ul>
<li><p><strong>正则化与交叉验证：</strong></p>
<p>​    正则化是在经验风险项后再增加一个正则化项（Regularizer），其与模型的复杂度成正相关，一般使用模型参数向量的范数：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902161201.png" alt=""></p>
<p>​    交叉验证的基本思想是重复使用数据：</p>
<ol>
<li><p><strong>简单交叉验证：</strong></p>
<p>将训练集随机分为两部分，一部分训练，一部分测试，然后在各种条件下训练出不同的模型，用测试集进行横向对比，选出最好的。</p>
<ol>
<li><strong>S折交叉验证：</strong></li>
</ol>
<p>S-fold cross validation，随机地将已给数据切分为S个互不相交的大小相同的子集，选取S-1个用于训练，剩下一个用于测试。</p>
<p>这样总共测试集有S种选法，将这S种全部试一遍，评选S次测评中平均误差最小的模型。</p>
<ol>
<li><strong>留一交叉验证：</strong></li>
</ol>
<p>令S=N（训练集大小）即可，这种方法往往是在数据集特别缺乏的情况下使用。</p>
</li>
</ol>
</li>
<li><p><strong>泛化误差与泛化上界：</strong></p>
<p>​    泛化能力指模型对位置数据的预测能力，就是模型的好坏。如何量化这个能力？</p>
<p>​    根据定义，其就是模型在测试集上的测试表现：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902162814.png" alt=""></p>
<p>​    同时可以用以下式子衡量泛化误差的上界：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902162851.png" alt=""></p>
</li>
<li><p><strong>生成模型与判别模型：</strong></p>
<p>​    监督学习方法又可以分为两种方法：生成方法（Generatice Approach）和判别方法（Discriminative Approach）。</p>
<p>​    如果以概率论的角度来看待，模型的作用是根据P（x）来求P（y | x），故下面有两种方法求</p>
<p>P（y | x），直接模拟P（y | x）和通过求  $P(\frac{y}{x}) = \frac{P(x,y)}{P(x)}$  来求P（y | x）。</p>
<p>​    前者就是判别模型，后者是生成模型。</p>
<p>​    生成模型可以还原出联合概率分布P（x , y），学习收敛速度更快，可以适应存在隐含变量的情况；</p>
<p>​    判别模型直接学习条件概率,直接面对预测，准确率更高，并且简化了学习问题。</p>
</li>
</ul>
<hr>
<h3 id="二-感知机"><a href="#二-感知机" class="headerlink" title="二. 感知机"></a>二. 感知机</h3><p>​    感知机，perceptron，是二分类的线性分类模型，输入为特征向量，输出为类别，取1和-1两种。</p>
<p>​    感知机属于判别模型。</p>
<p>​    </p>
<p>​    对于一个给定数据集，T = {（x~1~，y~1~）……（x~n~，y~n~）}，如果存在某个超平面S，w·x + b = 0（这里w是超平面的法向量，b是截距），使得所有 y~i~ = 1 的实例i，有 w·x~i~ + b &gt; 0，y~i~ = -1则相反，则称数据集T为<strong>线性可分数据集（<em>Linealy separable data set</em>）</strong>，否则，称数据集T为线性不可分数据集。</p>
<h4 id="2-1-感知机损失函数："><a href="#2-1-感知机损失函数：" class="headerlink" title="2.1 感知机损失函数："></a>2.1 感知机损失函数：</h4><p>​    感知机的目的就是对于一个线性可分的数据集，通过找出w和b，来确定一个超平面用于分类。</p>
<p>​    这里，我们选取某错误分类点到超平面S的<strong>总距离</strong>来当做损失函数，某一点到超平面S的距离如下：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904182025.png" alt=""></p>
<p>​    ‖w‖是w的L~2~范数。</p>
<p>​    故，某个误分类点到超平面S的距离是：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904182154.png" alt=""></p>
<p>​    将所有误分类点求和，忽略L~2~范数，即可得到<strong>感知机的损失函数</strong>（M为误分类点集合）：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904182339.png" alt=""></p>
<p>​    对于一个特定样本点的损失函数，在误分类时是参数w,b的线性函数，在正确分类时是0，故给定训练数据集T，损失函数L是w，b的连续可导函数。</p>
<h4 id="2-2-训练过程："><a href="#2-2-训练过程：" class="headerlink" title="2.2 训练过程："></a>2.2 训练过程：</h4><p>​    感知机训练采用随机梯度下降的方法：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904183233.png" alt=""></p>
<p>​    当找到一个误分类点时，不断梯度下降直至该点被正确分类为止。</p>
<p>​    <strong>数学证明其收敛性：</strong></p>
<p>​        具体见书本，这里略过。</p>
<h4 id="2-3-感知机的对偶形式："><a href="#2-3-感知机的对偶形式：" class="headerlink" title="2.3 感知机的对偶形式："></a>2.3 感知机的对偶形式：</h4><p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905112734.png" alt=""></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905112750.png" alt=""></p>
<p>​    由图可以看到，对于每个测试集中的x~i~，都有一个与之对应的α~i~，对偶形式中就是调整其对应的α。</p>
<p>​    关于gram矩阵的作用，如果手算一遍简单的训练过程，就可以得到答案。</p>
<hr>
<h3 id="三-k近邻法"><a href="#三-k近邻法" class="headerlink" title="三. k近邻法"></a>三. k近邻法</h3><p>​    k近邻法是一种基本的分类与回归方法，这里只讨论分类方法。</p>
<p>​    其输入为特征向量，输出为实例的类别，可以取<strong>多类</strong>。</p>
<h4 id="3-1-算法描述："><a href="#3-1-算法描述：" class="headerlink" title="3.1 算法描述："></a>3.1 算法描述：</h4><p>​    给定一个训练集，对于新的数据实例，在训练数据集中找到与其最邻近的k个实例，这k个实例多数属于某个类，就把该输入实例分为这个类。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905113440.png" alt=""></p>
<p>​        <u>k近邻法没有显式的学习过程。</u>可以理解为，k近邻算法将特征空间划分为了一些子空间，每个点所属的空间是确定的。</p>
<p>​        </p>
<ul>
<li><strong>如何度量两个特征之间的距离？</strong></li>
</ul>
<p>​        k邻近模型的特征空间一般是n维实空间R^n^，使用欧氏距离或者L~p~距离（<em>L~p~ distance</em>），Minkowski距离（<em>Minkowski distance</em>）；</p>
<p>​        <strong>L~p~距离：</strong></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905143250.png" alt=""></p>
<p>​        <strong>欧氏距离：</strong></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905143332.png" alt=""></p>
<p>​        <strong>曼哈顿距离：</strong></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905143356.png" alt=""></p>
<p>​        <strong>无穷距离：</strong></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905143648.png" alt=""></p>
<p>​    由下图可以看出，p取值不同时到原点距离为1的图形是不同的：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905143741.png" alt=""></p>
<ul>
<li><p><strong>如何选择k的值？</strong></p>
<p>​    k值越小，模型学习时的近似误差越小，估计误差越大，模型会越复杂，抗干扰性越小（例如，最邻近的点是噪声），模型会非常敏感，容易过拟合；</p>
<p>​    k值越大，估计误差会很小，近似误差会很大，整体模型变得简单。</p>
<p>​    k一般的取值并不大，使用交叉验证的方法来选取最佳的k值。</p>
</li>
<li><p><strong>如何决策？</strong></p>
<p>​    在得到k个最相似的实例后，采用何种规则判断测试样本属于哪一类呢？</p>
<p>​    k邻近算法使用多数表决的方法：</p>
</li>
</ul>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905154943.png" alt=""></p>
<blockquote>
<p>ps: ci表示某种决策规则下一组测试用例的表决结果。经由以上推导可以得出，多数表决规则是合理的。</p>
</blockquote>
<p>​        </p>
<ul>
<li><p><strong>如何快速找到某个用例的K近邻点？</strong></p>
<p><strong>KD树：</strong> 具体算法见书。</p>
</li>
</ul>
<hr>
<h3 id="四-朴素贝叶斯法"><a href="#四-朴素贝叶斯法" class="headerlink" title="四. 朴素贝叶斯法"></a>四. 朴素贝叶斯法</h3><p>  ​    </p>

      
    </div>
    <footer class="entry-meta entry-footer">
      
	<span class="ico-folder"></span>
    <a class="article-category-link" href="/categories/Book/">Book</a>

      
  <span class="ico-tags"></span>
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a></li></ul>

      
    </footer>
    <hr class="entry-footer-hr">
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Adversarial%20Training%20with%20Fast%20Gradient%20Projection%20Method%20against%20Synonym%20Substitution%20Based%20Text%20Attacks/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">上一篇</strong>
      <div class="article-nav-title">
        
          Adversarial Training with Fast Gradient Projection Method against Synonym Substitution Based Text Attacks
        
      </div>
    </a>
  
  
    <a href="/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Automatically%20Evading%20Classififiers----A%20Case%20Study%20on%20PDF%20Malware%20Classififiers/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">下一篇</strong>
      <div class="article-nav-title">Automatically Evading Classififiers----A Case Study on PDF Malware Classififiers</div>
    </a>
  
</nav>

  
</article>

<!-- Table of Contents -->

  <aside id="sidebar">
    <div id="toc" class="toc-article">
    <strong class="toc-title">文章目录</strong>
    
      <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E3%80%90%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B"><span class="nav-number">1.</span> <span class="nav-text">【书籍阅读】《统计学习方法》</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%AE%BA%EF%BC%9A"><span class="nav-number">1.0.1.</span> <span class="nav-text">一. 统计学习方法概论：</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5%EF%BC%9A"><span class="nav-number">1.0.1.1.</span> <span class="nav-text">1. 监督学习概念：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E4%B8%89%E8%A6%81%E7%B4%A0%EF%BC%9A"><span class="nav-number">1.0.1.2.</span> <span class="nav-text">2. 统计学习三要素：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A1%A1%E9%87%8F%E6%96%B9%E6%B3%95%EF%BC%9A"><span class="nav-number">1.0.1.3.</span> <span class="nav-text">3. 模型的衡量方法：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C-%E6%84%9F%E7%9F%A5%E6%9C%BA"><span class="nav-number">1.0.2.</span> <span class="nav-text">二. 感知机</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-%E6%84%9F%E7%9F%A5%E6%9C%BA%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%EF%BC%9A"><span class="nav-number">1.0.2.1.</span> <span class="nav-text">2.1 感知机损失函数：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B%EF%BC%9A"><span class="nav-number">1.0.2.2.</span> <span class="nav-text">2.2 训练过程：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3-%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%9A%84%E5%AF%B9%E5%81%B6%E5%BD%A2%E5%BC%8F%EF%BC%9A"><span class="nav-number">1.0.2.3.</span> <span class="nav-text">2.3 感知机的对偶形式：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89-k%E8%BF%91%E9%82%BB%E6%B3%95"><span class="nav-number">1.0.3.</span> <span class="nav-text">三. k近邻法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-%E7%AE%97%E6%B3%95%E6%8F%8F%E8%BF%B0%EF%BC%9A"><span class="nav-number">1.0.3.1.</span> <span class="nav-text">3.1 算法描述：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%9B-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95"><span class="nav-number">1.0.4.</span> <span class="nav-text">四. 朴素贝叶斯法</span></a></li></ol></li></ol></li></ol>
    
    </div>
  </aside>
</section>
        
      </div>

    </div>
    <!-- <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav> -->
    
<footer id="footer" class="site-footer">
  

  <div class="clearfix container">
      <div class="site-info">
	      &copy; 2024 Shaw All Rights Reserved.
        
          <span id="busuanzi_container_site_pv">
            本站总访问量<span id="busuanzi_value_site_pv"></span>次
          </span>
          <span class="post-meta-divider">|</span>
          <span id="busuanzi_container_site_uv" style='display:none'>
            本站访客数<span id="busuanzi_value_site_uv"></span>人
          </span>
          <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
          
      </div>
      <div class="site-credit">
        Theme by <a href="https://github.com/iTimeTraveler/hexo-theme-hipaper" target="_blank">hipaper</a>
      </div>
  </div>
</footer>


<!-- min height -->

<script>
    var wrapdiv = document.getElementById("wrap");
    var contentdiv = document.getElementById("content");

    wrapdiv.style.minHeight = document.body.offsetHeight - document.getElementById("allheader").offsetHeight - document.getElementById("footer").offsetHeight + "px";
    contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("allheader").offsetHeight - document.getElementById("footer").offsetHeight + "px";


    <!-- headerblur min height -->
    
    
</script>

  
    
<div style="display: none;">
  <script src="https://s11.cnzz.com/z_stat.php?id=1260716016&web_id=1260716016" language="JavaScript"></script>
</div>

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>


<script src="/js/bootstrap.js"></script>


<script src="/js/main.js"></script>



<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'true', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->



<!-- Gaug.es Analytics -->
<script type="text/javascript">
  var _gauges = _gauges || [];
  (function() {
    var t   = document.createElement('script');
    t.type  = 'text/javascript';
    t.async = true;
    t.id    = 'gauges-tracker';
    t.setAttribute('data-site-id', 'true');
    t.setAttribute('data-track-path', 'https://track.gaug.es/track.gif');
    t.src = 'https://d36ee2fcip1434.cloudfront.net/track.js';
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(t, s);
  })();
</script>
<!-- End Gaug.es Analytics -->




  <div style="display: none;">
    <script src="https://s95.cnzz.com/z_stat.php?id=1260716016&web_id=1260716016" language="JavaScript"></script>
  </div>



	<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
	</script>



	<script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?2439014eb270056ee1808a49956fe114";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
</script>




<!-- Tencent Analytics -->
	<script type="text/javascript">
    (function() {
      var hm = document.createElement("script");
      hm.src = "//tajs.qq.com/stats?sId={{ theme.tencent_analytics }}";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>
<!-- End Tencent Analytics -->


  </div>

  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js" async=""></script>
</body>
</html>
