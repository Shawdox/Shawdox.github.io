<!DOCTYPE html>
<html lang="zh-CN">

<!-- Head tag -->
<head>

    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>

    <!--Description-->

    

    
        <meta name="description" content="随想随录"/>
    

    <!--Author-->
    
        <meta name="author" content="Shaw"/>
    

    <!--Open Graph Title-->
    
        <meta property="og:title" content="《统计学习方法》"/>
    

    <!--Open Graph Description-->
    
        <meta property="og:description" content="随想随录"/>
    

    <!--Open Graph Site Name-->
        <meta property="og:site_name" content="Shaw"/>

    <!--Type page-->
    
        <meta property="og:type" content="article"/>
    

    <!--Page Cover-->
    
    
        <meta property="og:image" content="http://example.comimg/home-bg.jpg"/>
    

        <meta name="twitter:card" content="summary_large_image"/>

    

    
        <meta name="twitter:image" content="http://example.comimg/home-bg.jpg"/>
    

    <!-- Title -->
    
    <title>《统计学习方法》 - Shaw</title>

    <!-- Bootstrap Core CSS -->
    <link href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" rel="stylesheet"/>

    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/css/style.css">


    <!-- Custom Fonts -->
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/>
    <link href="//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css"/>
    <link href="//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css"/>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    <script src="//oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="//oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Gallery -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.css" type="text/css" rel="stylesheet"/>

    <!-- Google Analytics -->
    


    <!-- favicon -->
    
    <link rel="icon" href="img/putaoyou.png"/>
    

<meta name="generator" content="Hexo 5.4.1"></head>


<body>

    <!-- Menu -->
    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Here</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                
                    <li>
                        <a href="/">
                            
                                Home
                            
                        </a>
                    </li>
                
                    <li>
                        <a href="/tags">
                            
                                Tags
                            
                        </a>
                    </li>
                
                    <li>
                        <a href="/categories">
                            
                                Categories
                            
                        </a>
                    </li>
                
                    <li>
                        <a target="_blank" rel="noopener" href="https://github.com/Shawdox">
                            
                                <i class="fa fa-github fa-stack-2x"></i>
                            
                        </a>
                    </li>
                
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>

    <!-- Main Content -->
    <!-- Page Header -->
<!-- Set your background image for this header in your post front-matter: cover -->

<header class="intro-header" style="background-image: url('/img/home-bg.jpg')">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <h1>《统计学习方法》</h1>
                    
                    <span class="meta">
                        <!-- Date and Author -->
                        
                            Posted by Shaw on
                        
                        
                            2021-09-03
                        
                    </span>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

            <!-- Tags and categories -->
           
                <div class="col-lg-4 col-lg-offset-2 col-md-5 col-md-offset-1 post-tags">
                    
                        


<a href="/tags/Machine-Learning/">#Machine Learning</a>


                    
                </div>
                <div class="col-lg-4 col-md-5 post-categories">
                    
                        

<a href="/categories/Book/">Book</a>

                    
                </div>
            

            <!-- Gallery -->
            

            <!-- Post Main Content -->
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <h1 id="【书籍阅读】《统计学习方法》"><a href="#【书籍阅读】《统计学习方法》" class="headerlink" title="【书籍阅读】《统计学习方法》"></a>【书籍阅读】《统计学习方法》</h1><h3 id="一-统计学习方法概论："><a href="#一-统计学习方法概论：" class="headerlink" title="一. 统计学习方法概论："></a>一. 统计学习方法概论：</h3><p>​    首先，要明确计算机科学中存在三个维度：系统，计算，与信息。统计学习方法（机器学习）主要属于信息这一维度，并在其中扮演者核心角色。</p>
<h4 id="1-监督学习概念："><a href="#1-监督学习概念：" class="headerlink" title="1. 监督学习概念："></a>1. 监督学习概念：</h4><p>​    监督学习，Supervised learning，指在已经做好标注的训练集上学习，为了叙述方便，定义以下基本概念：</p>
<blockquote>
<ol>
<li><strong>输入空间（X），输出空间（Y）：</strong>输入所有可能取值，输出所有可能取值；</li>
<li><strong>特征空间：</strong>输入一般由特征向量表示，所有特征向量存在的空间称为特征空间，输入空间与特征空间并不完全等价，有时需要映射；</li>
<li><strong>上标  x^i^</strong> :表示一个输入的第  i 个特征；</li>
<li><strong>下标  x~j~：</strong>表示第 j 个输入。</li>
<li><strong>回归问题：</strong>输入输出都为连续型变量；</li>
<li><strong>分类问题：</strong>输出变量为有限个离散型变量；</li>
<li><strong>标注问题：</strong>输入与输出变量都为变量序列。</li>
<li><strong>假设空间：</strong>所有可能的模型的集合，也就是学习的范围。</li>
</ol>
</blockquote>
<p>​    使用训练集学习——&gt;对未知数据进行预测</p>
<p>​    </p>
<h4 id="2-统计学习三要素："><a href="#2-统计学习三要素：" class="headerlink" title="2. 统计学习三要素："></a>2. 统计学习三要素：</h4><p>​    统计学习三要素为：<strong>模型，策略，算法</strong>；</p>
<p>​    模型是决定学习的预测函数的类型；</p>
<p>​    策略是判定什么样的模型是好的，用于度量当前的模型好坏；</p>
<p>​    算法是训练过程中的具体做法，例如如何回归，如何计算，如何调整等。</p>
<h4 id="3-模型的衡量方法："><a href="#3-模型的衡量方法：" class="headerlink" title="3. 模型的衡量方法："></a>3. 模型的衡量方法：</h4><ul>
<li><p><strong>损失函数与风险函数：</strong></p>
<p>​    损失函数，Loss Function，用于模型一次预测的错误程度，例如：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902154618.png" alt=""></p>
<p>​    损失函数的数值越小，模型就越好。如果计算损失函数的期望，得到的就是风险函数，Risk Function:</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902154745.png" alt=""></p>
<p>​    可以看出，损失函数用于某次预测的估计，风险函数用于总体平均估计。我们当然希望训练出的模型的风险函数越小越好。</p>
<p>​    <strong>但是，观察上式，理想化的概率分布P(x，y)是未知的，我们进行学习就是要通过模型来模拟它，故这个式子理论存在，实际不能计算，不能用作评估模型的直接方法。</strong></p>
</li>
</ul>
<ul>
<li><p><strong>经验风险与结构风险：</strong></p>
<p>​    为了解决上述问题，我们引入经验风险：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902155212.png" alt=""></p>
<p>​    可以看到，经验风险将每个样本视作等概率出现，是模型对于训练集的平均损失，那么其与风险函数的误差在哪？</p>
<p>​    根据大数定律，当训练集足够大时，二者是近似相等的。但实际情况下，很多时候训练样本数目有限，甚至很小，故用经验风险效估计风险函数并不理想，故需要进行修正，这就是监督学习中的<strong>两个基本策略：</strong>经验风险最小化和结构风险最小化。</p>
<p>​    如果训练样本容量较大，使用经验风险最小化没什么问题。</p>
<p>​    当样本容量很小时，仅仅使用经验风险最小化容易导致过拟合，故这里使用<strong>结构风险（就是正则化）</strong>最小化方法，对模型复杂度进行惩罚，后续介绍。</p>
</li>
</ul>
<ul>
<li><p><strong>训练误差与测试误差：</strong></p>
<p>​    训练误差本质上不重要，它可以反应一个问题是不是容易学习，但要衡量模型的预测能力，主要是看测试误差。</p>
</li>
</ul>
<ul>
<li><p><strong>正则化与交叉验证：</strong></p>
<p>​    正则化是在经验风险项后再增加一个正则化项（Regularizer），其与模型的复杂度成正相关，一般使用模型参数向量的范数：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902161201.png" alt=""></p>
<p>​    交叉验证的基本思想是重复使用数据：</p>
<ol>
<li><p><strong>简单交叉验证：</strong></p>
<p>将训练集随机分为两部分，一部分训练，一部分测试，然后在各种条件下训练出不同的模型，用测试集进行横向对比，选出最好的。</p>
<ol>
<li><strong>S折交叉验证：</strong></li>
</ol>
<p>S-fold cross validation，随机地将已给数据切分为S个互不相交的大小相同的子集，选取S-1个用于训练，剩下一个用于测试。</p>
<p>这样总共测试集有S种选法，将这S种全部试一遍，评选S次测评中平均误差最小的模型。</p>
<ol>
<li><strong>留一交叉验证：</strong></li>
</ol>
<p>令S=N（训练集大小）即可，这种方法往往是在数据集特别缺乏的情况下使用。</p>
</li>
</ol>
</li>
<li><p><strong>泛化误差与泛化上界：</strong></p>
<p>​    泛化能力指模型对位置数据的预测能力，就是模型的好坏。如何量化这个能力？</p>
<p>​    根据定义，其就是模型在测试集上的测试表现：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902162814.png" alt=""></p>
<p>​    同时可以用以下式子衡量泛化误差的上界：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902162851.png" alt=""></p>
</li>
<li><p><strong>生成模型与判别模型：</strong></p>
<p>​    监督学习方法又可以分为两种方法：生成方法（Generatice Approach）和判别方法（Discriminative Approach）。</p>
<p>​    如果以概率论的角度来看待，模型的作用是根据P（x）来求P（y | x），故下面有两种方法求</p>
<p>P（y | x），直接模拟P（y | x）和通过求  $P(\frac{y}{x}) = \frac{P(x,y)}{P(x)}$  来求P（y | x）。</p>
<p>​    前者就是判别模型，后者是生成模型。</p>
<p>​    生成模型可以还原出联合概率分布P（x , y），学习收敛速度更快，可以适应存在隐含变量的情况；</p>
<p>​    判别模型直接学习条件概率,直接面对预测，准确率更高，并且简化了学习问题。</p>
</li>
</ul>
<hr>
<h3 id="二-感知机"><a href="#二-感知机" class="headerlink" title="二. 感知机"></a>二. 感知机</h3><p>​    感知机，perceptron，是二分类的线性分类模型，输入为特征向量，输出为类别，取1和-1两种。</p>
<p>​    感知机属于判别模型。</p>
<p>​    </p>
<p>​    对于一个给定数据集，T = {（x~1~，y~1~）……（x~n~，y~n~）}，如果存在某个超平面S，w·x + b = 0（这里w是超平面的法向量，b是截距），使得所有 y~i~ = 1 的实例i，有 w·x~i~ + b &gt; 0，y~i~ = -1则相反，则称数据集T为<strong>线性可分数据集（<em>Linealy separable data set</em>）</strong>，否则，称数据集T为线性不可分数据集。</p>
<h4 id="2-1-感知机损失函数："><a href="#2-1-感知机损失函数：" class="headerlink" title="2.1 感知机损失函数："></a>2.1 感知机损失函数：</h4><p>​    感知机的目的就是对于一个线性可分的数据集，通过找出w和b，来确定一个超平面用于分类。</p>
<p>​    这里，我们选取某错误分类点到超平面S的<strong>总距离</strong>来当做损失函数，某一点到超平面S的距离如下：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904182025.png" alt=""></p>
<p>​    ‖w‖是w的L~2~范数。</p>
<p>​    故，某个误分类点到超平面S的距离是：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904182154.png" alt=""></p>
<p>​    将所有误分类点求和，忽略L~2~范数，即可得到<strong>感知机的损失函数</strong>（M为误分类点集合）：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904182339.png" alt=""></p>
<p>​    对于一个特定样本点的损失函数，在误分类时是参数w,b的线性函数，在正确分类时是0，故给定训练数据集T，损失函数L是w，b的连续可导函数。</p>
<h4 id="2-2-训练过程："><a href="#2-2-训练过程：" class="headerlink" title="2.2 训练过程："></a>2.2 训练过程：</h4><p>​    感知机训练采用随机梯度下降的方法：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904183233.png" alt=""></p>
<p>​    当找到一个误分类点时，不断梯度下降直至该点被正确分类为止。</p>
<p>​    <strong>数学证明其收敛性：</strong></p>
<p>​        具体见书本，这里略过。</p>
<h4 id="2-3-感知机的对偶形式："><a href="#2-3-感知机的对偶形式：" class="headerlink" title="2.3 感知机的对偶形式："></a>2.3 感知机的对偶形式：</h4><p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905112734.png" alt=""></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905112750.png" alt=""></p>
<p>​    由图可以看到，对于每个测试集中的x~i~，都有一个与之对应的α~i~，对偶形式中就是调整其对应的α。</p>
<p>​    关于gram矩阵的作用，如果手算一遍简单的训练过程，就可以得到答案。</p>
<hr>
<h3 id="三-k近邻法"><a href="#三-k近邻法" class="headerlink" title="三. k近邻法"></a>三. k近邻法</h3><p>​    k近邻法是一种基本的分类与回归方法，这里只讨论分类方法。</p>
<p>​    其输入为特征向量，输出为实例的类别，可以取<strong>多类</strong>。</p>
<h4 id="3-1-算法描述："><a href="#3-1-算法描述：" class="headerlink" title="3.1 算法描述："></a>3.1 算法描述：</h4><p>​    给定一个训练集，对于新的数据实例，在训练数据集中找到与其最邻近的k个实例，这k个实例多数属于某个类，就把该输入实例分为这个类。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905113440.png" alt=""></p>
<p>​        <u>k近邻法没有显式的学习过程。</u>可以理解为，k近邻算法将特征空间划分为了一些子空间，每个点所属的空间是确定的。</p>
<p>​        </p>
<ul>
<li><strong>如何度量两个特征之间的距离？</strong></li>
</ul>
<p>​        k邻近模型的特征空间一般是n维实空间R^n^，使用欧氏距离或者L~p~距离（<em>L~p~ distance</em>），Minkowski距离（<em>Minkowski distance</em>）；</p>
<p>​        <strong>L~p~距离：</strong></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905143250.png" alt=""></p>
<p>​        <strong>欧氏距离：</strong></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905143332.png" alt=""></p>
<p>​        <strong>曼哈顿距离：</strong></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905143356.png" alt=""></p>
<p>​        <strong>无穷距离：</strong></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905143648.png" alt=""></p>
<p>​    由下图可以看出，p取值不同时到原点距离为1的图形是不同的：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905143741.png" alt=""></p>
<ul>
<li><p><strong>如何选择k的值？</strong></p>
<p>​    k值越小，模型学习时的近似误差越小，估计误差越大，模型会越复杂，抗干扰性越小（例如，最邻近的点是噪声），模型会非常敏感，容易过拟合；</p>
<p>​    k值越大，估计误差会很小，近似误差会很大，整体模型变得简单。</p>
<p>​    k一般的取值并不大，使用交叉验证的方法来选取最佳的k值。</p>
</li>
<li><p><strong>如何决策？</strong></p>
<p>​    在得到k个最相似的实例后，采用何种规则判断测试样本属于哪一类呢？</p>
<p>​    k邻近算法使用多数表决的方法：</p>
</li>
</ul>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905154943.png" alt=""></p>
<blockquote>
<p>ps: ci表示某种决策规则下一组测试用例的表决结果。经由以上推导可以得出，多数表决规则是合理的。</p>
</blockquote>
<p>​        </p>
<ul>
<li><p><strong>如何快速找到某个用例的K近邻点？</strong></p>
<p><strong>KD树：</strong> 具体算法见书。</p>
</li>
</ul>
<hr>
<h3 id="四-朴素贝叶斯法"><a href="#四-朴素贝叶斯法" class="headerlink" title="四. 朴素贝叶斯法"></a>四. 朴素贝叶斯法</h3><p>  ​    </p>


                
            </div>

            <!-- Comments -->
            
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    


                </div>
            
        </div>
    </div>
</article>

    <!-- Footer -->
    <hr />

<!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    

                    

                    
                        <li>
                            <a href="https://github.com/Shawdox" target="_blank">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                    

                    

                    

                    
                </ul>
                <p class="copyright text-muted">&copy; 2022 Shaw<br></p>
                <p class="copyright text-muted">Original Theme <a target="_blank" href="http://startbootstrap.com/template-overviews/clean-blog/">Clean Blog</a> from <a href="http://startbootstrap.com/" target="_blank">Start Bootstrap</a></p>
                <p class="copyright text-muted">Adapted for <a target="_blank" href="https://hexo.io/">Hexo</a> by <a href="http://www.codeblocq.com/" target="_blank">Jonathan Klughertz</a></p>
            </div>
        </div>
    </div>
</footer>


    <!-- After footer scripts -->
    
<!-- jQuery -->
<script src="//code.jquery.com/jquery-2.1.4.min.js"></script>

<!-- Bootstrap -->
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>

<!-- Gallery -->
<script src="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.js" type="text/javascript" charset="utf-8"></script>

<!-- Disqus Comments -->



</body>

</html>