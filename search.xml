<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>More is different.</title>
    <url>/2021/09/03/Welcome/</url>
    <content><![CDATA[<h3 id="Shaw的，"><a href="#Shaw的，" class="headerlink" title="Shaw的，"></a>Shaw的，</h3><h3 id="一些记录，一些随手写。"><a href="#一些记录，一些随手写。" class="headerlink" title="一些记录，一些随手写。"></a>一些记录，一些随手写。</h3><p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210903135448.png" alt=""></p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2021/11/14/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91HydraText%20Multi-objective%20Optimization%20for%20Adversarial%20Textual%20Attack/</url>
    <content><![CDATA[<h1 id="HydraText-Multi-objective-Optimization-for-Adversarial-Textual-Attack"><a href="#HydraText-Multi-objective-Optimization-for-Adversarial-Textual-Attack" class="headerlink" title="HydraText: Multi-objective Optimization for Adversarial Textual Attack"></a>HydraText: Multi-objective Optimization for Adversarial Textual Attack</h1><blockquote>
<p><strong>作者：Shengcai Liu，Ning Lu，Cheng Chen，Chao Qian，Ke Tang</strong></p>
<p><strong>时间：2021</strong></p>
</blockquote>
<h3 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h3><p>​    <strong><u>文字(text)（word-level）对抗样本黑盒攻击。</u></strong>在这项工作中，同时考虑<strong>攻击效率+可辨认性</strong>，并提出一种新的具有可证明性能保证的多优化方法(称为HydraText )，以实现具有高隐蔽性的成功攻击。</p>
<p>​    为了测试HydraText的功效，我们在<strong>score-based</strong> 和<strong>decision-based</strong>的黑盒攻击下，使用5个NLP模型+5个数据集。</p>
<p>（PS：<a href="https://zhuanlan.zhihu.com/p/377633699">[论文总结] Boundary Attack - 知乎 (zhihu.com)</a>）</p>
<p>​    一项人类观察评价研究表明，Hydra Text制作的对抗样本很好地保持了有效性和自然性。最后，这些实例还表现出良好的可迁移性，可以通过对抗训练给目标模型带来显著的鲁棒性提升。</p>
<hr>
<h3 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h3><p>​    我们仔细地设计了目标函数，并进一步构建了一个多目标优化问题（<strong><em>multi-objective optimization problem</em></strong>，MOP），该问题一旦被解决，将产生与原始文本相似度高的单个成功对抗样本。</p>
<p>​    然后我们原创了一个多目标优化方法（ <strong><em>multi-objective optimization approach</em></strong>），叫做<strong>HydraText</strong>。这个名字的灵感来自于海蛇许德拉，这是一种神话动物，它使用多个头部攻击对手。它可以同时用在<strong>score-based</strong> 和<strong>decision-based</strong>的黑盒攻击下。</p>
<p><img src="%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91HydraText%20Multi-objective%20Optimization%20for%20Adversarial%20Textual%20Attack/u=968937333,2137978646&amp;fm=26&amp;fmt=auto" alt=""></p>
<p>​    </p>
<hr>
<h3 id="METHODS"><a href="#METHODS" class="headerlink" title="METHODS"></a>METHODS</h3><p>​    基于word-level 的替换操作。每个单词有一个自己的候选表，然后将每个单词与候选表中被选中的词替换（也可以不选，原单词不变）。</p>
<p>​    但这样的方法有个问题，如下图：</p>
<p>​     <img src="%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91HydraText%20Multi-objective%20Optimization%20for%20Adversarial%20Textual%20Attack/image-20211114162251176.png" alt=""></p>
<p>​    如图所示，句子的语义与替换的单词数量是成反比的，上文需要考虑的准确率+可辨认性二者其实是互相矛盾的。为了解决这个问题，我们在生成的过程中也考虑X~adv~的修改率，使用MOP来解决它。</p>
<p>​    </p>
<h4 id="1-The-HydraText-Approach"><a href="#1-The-HydraText-Approach" class="headerlink" title="1.The HydraText Approach"></a>1.<em>The HydraText Approach</em></h4><p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211114162738.png" style="zoom:80%;" /></p>
<hr>
<h3 id="EXPERIMENTS"><a href="#EXPERIMENTS" class="headerlink" title="EXPERIMENTS"></a>EXPERIMENTS</h3><h4 id="1-Datasets-and-Target-Models"><a href="#1-Datasets-and-Target-Models" class="headerlink" title="1. Datasets and Target Models"></a>1. <em>Datasets and Target Models</em></h4><p>​    <strong>模型种类：</strong>文本分类和文本推理</p>
<p>​    三个数据集：AG News，IMDB ， Movie Reviews，Stanford Natural Language Inference，multi-genre NLI corpus（前三个文本分类，后三个文本推理）</p>
<p>​    两个模型：WordCNN，WordLSTM，BERT base-uncased，ESIM ，Infersent ，BERT base-uncased(前三个文本分类，后三个文本推理)</p>
<h4 id="2-Baselines-and-Algorithm"><a href="#2-Baselines-and-Algorithm" class="headerlink" title="2.Baselines and Algorithm"></a>2.<em>Baselines and Algorithm</em></h4><p>​    <strong>攻击方法：</strong>PSO,GA,TextFooler,PWWS,GADe(baseline)</p>
<h4 id="3-Evaluation"><a href="#3-Evaluation" class="headerlink" title="3.Evaluation"></a>3.<em>Evaluation</em></h4><p>​    以攻击成功的百分率来判定攻击能力。</p>
<p>​    以修改百分率和语义相似性来判定攻击的可辨识性。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211114165103.png" alt=""></p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>IDS</tag>
      </tags>
  </entry>
  <entry>
    <title>Semantic Host-free Trojan Attack</title>
    <url>/2021/11/06/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Semantic%20Host-free%20Trojan%20Attack/</url>
    <content><![CDATA[<h1 id="Semantic-Host-free-Trojan-Attack"><a href="#Semantic-Host-free-Trojan-Attack" class="headerlink" title="Semantic Host-free Trojan Attack"></a>Semantic Host-free Trojan Attack</h1><blockquote>
<p><strong>作者：Haripriya Harikumar , Kien Do, Santu Rana , Sunil Gupta , Svetha Venkatesh（迪肯大学.澳大利亚）</strong></p>
<p><strong>时间：2021.10.27</strong></p>
</blockquote>
<h3 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h3><p>​    在本文中，我们提出了一种新颖的host-free木马攻击，其触发器(trigger)固定在语义空间(semantic)，但不一定在像素空间(pixel)。</p>
<p>​    与现有的木马攻击使用干净的输入图像作为宿主来携带小的、没有意义的trigger不同，我们的攻击将trigger看作是属于语义上有意义的对象类的整个图像。</p>
<p>​    由于在我们的攻击中，与任何特定的固定模式相比，分类器被鼓励记忆触发图像的抽象语义。因此它可以在以后由语义相似但看起来不同的图像触发。这使得我们的攻击更实际地被应用于现实世界中，更难以防御。广泛的实验结果表明，仅用少量的特洛伊木马模式进行训练，我们的攻击能很好地推广到同一特洛伊木马类的新模式，并且可以绕过目前的防御方法。</p>
<hr>
<h3 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h3><p>​    提出了一个<strong>后门攻击</strong>，semantic host-free backdoors。</p>
<p>​    <strong>后门攻击综述：</strong><a href="https://blog.csdn.net/yalecaltech/article/details/117249586">(20条消息) 深度学习后门攻防综述_Yale的博客-CSDN博客_后门攻击</a></p>
<p>​    <img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211109200409.png" style="zoom:50%;" /></p>
<hr>
<h3 id="METHOD"><a href="#METHOD" class="headerlink" title="METHOD"></a>METHOD</h3><p>​    实现方式：数据投毒。</p>
<p>​    </p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>AD</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2021/11/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Intrusion%20detection%20system%20A%20comprehensive%20review/</url>
    <content><![CDATA[<h1 id="Intrusion-detection-system-A-comprehensive-review"><a href="#Intrusion-detection-system-A-comprehensive-review" class="headerlink" title="Intrusion detection system: A comprehensive review"></a>Intrusion detection system: A comprehensive review</h1><blockquote>
<p><strong>作者：Hung-Jen Liao a , Chun-Hung Richard Lin a,n , Ying-Chih Lin a,b , Kuang-Yuan Tung a（国立中山大学，正修科技大学）</strong></p>
<p><strong>时间：2012</strong></p>
</blockquote>
<h3 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h3><p>​    一个IDS综述。</p>
<p>PS：<a href="https://blog.csdn.net/haoxuexiaolang/article/details/106562102?spm=1001.2101.3001.6661.1&amp;utm_medium=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~default-1.no_search_link&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~default-1.no_search_link">(17条消息) 防火墙、IDS和IPS之间的区别（浅谈）_淡风wisdon－大大的博客-CSDN博客</a></p>
<hr>
<h3 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h3><p>​    <strong>CIA：</strong>Confifidentiality, Integrity and Availability，</p>
<p>​    <strong>Instrusion:</strong> 针对CIA的破坏行为，或者绕过计算机或网络安全机制的行为。</p>
<p>​    <strong>Instrusion detection:</strong> 是监视计算机系统或网络中发生的事件，并分析它们以发现入侵迹象的过程。</p>
<p>​    <strong>Instrusion detection sysytem(IDS):</strong> 实现instrusion detection自动化的软件或硬件。</p>
<p>​    <strong>Instrusion prevention system(IPS):</strong> 不仅有IDS的监控功能，还可以阻止可能的突发安全事件。在少数文章中，入侵检测与防御系统( IDPS )和入侵防御系统( IPS )是同义词，其中IDPS一词在安全界很少使用。</p>
<hr>
<h3 id="DETECTION-METHODOLOGIES"><a href="#DETECTION-METHODOLOGIES" class="headerlink" title="DETECTION METHODOLOGIES"></a>DETECTION METHODOLOGIES</h3><p>​    Detection的方法一共分为三类：Signature-based Detection (<strong>SD</strong>), Anomaly-based Detection</p>
<p>(<strong>AD</strong>) and Stateful Protocol Analysis (<strong>SPA</strong>)。</p>
<h4 id="1-SD（特征检测）"><a href="#1-SD（特征检测）" class="headerlink" title="1. SD（特征检测）:"></a>1. SD（特征检测）:</h4><p>​    Signature-based Detection，特征检测。将已知的patterns与捕获的事件进行比较，从而发现可能的入侵。因为使用特定攻击或者系统漏洞所积累下的知识，SD又被称为Knowledge-based Detection 或者 Misuse Detection。</p>
<h4 id="2-AD（异常检测）："><a href="#2-AD（异常检测）：" class="headerlink" title="2. AD（异常检测）："></a>2. AD（异常检测）：</h4><p>​    Anomaly-based detection，异常检测。一个异常（anomaly）指的是与已知行为相异的地方。Profiles表示定期从活动，网络连接中监视的正常或特定的行为文件，profile可以是静态的也可以是动态的，并且从许多特性中生成。例如，登录失败，处理器的使用，邮件的发送数量等。</p>
<p>​    接下来，AD 比较器就将正常的profile与观察到的事件相比较，以此辨别出显著的攻击。AD又被称为Behavior-based Detection。</p>
<p>​    一些AD的例子，例如，企图闯入、伪装、合法用户渗透、拒绝服务( DOS )、特洛伊木马等。</p>
<h4 id="3-SPA（状态协议分析）："><a href="#3-SPA（状态协议分析）：" class="headerlink" title="3. SPA（状态协议分析）："></a>3. SPA（状态协议分析）：</h4><p>​    Stateful Protocol Analysis，状态协议分析。Stateful指的是IDS可以知晓并追踪协议的状态（举例，将请求与答复配对）。</p>
<p>​    尽管SPA与AD很像，二者其实完全不同。AD采用预加载的网络或者特定域名的profile，然而SPA依赖于供应商开发的特定协议<strong>通用profile</strong>。通常，SPA中的网络协议模型最初基于国际标准组织(例如IETF )的协议标准。SPA也被称为Specifification-based Detection（基于规格的检测）。</p>
<p>大多数IDS使用多种方法来提供更广泛和准确的检测。</p>
<hr>
<h3 id="DETECTION-APPROACHES"><a href="#DETECTION-APPROACHES" class="headerlink" title="DETECTION APPROACHES"></a>DETECTION APPROACHES</h3><p>​    此文将已有的方法分为了5类：Statistics-based, Pattern-based, Rule-based, State-based and</p>
<p>Heuristic-based。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211106153047.png" alt=""></p>
<p>​    由上图所示，其中，Time series指的是是否考虑了time series behavior。</p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>IDS</tag>
      </tags>
  </entry>
  <entry>
    <title>Def-IDS An Ensemble Defense Mechanism Against Adversarial Attacks for Deep Learning-based Network Intrusion Detection</title>
    <url>/2021/11/01/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Def-IDS%20An%20Ensemble%20Defense%20Mechanism%20Against%20Adversarial%20Attacks%20for%20Deep%20Learning-based%20Network%20Intrusion%20Detection/</url>
    <content><![CDATA[<h1 id="Def-IDS-An-Ensemble-Defense-Mechanism-Against-Adversarial-Attacks-for-Deep-Learning-based-Network-Intrusion-Detection"><a href="#Def-IDS-An-Ensemble-Defense-Mechanism-Against-Adversarial-Attacks-for-Deep-Learning-based-Network-Intrusion-Detection" class="headerlink" title="Def-IDS: An Ensemble Defense Mechanism Against Adversarial Attacks for Deep Learning-based Network Intrusion Detection"></a>Def-IDS: An Ensemble Defense Mechanism Against Adversarial Attacks for Deep Learning-based Network Intrusion Detection</h1><blockquote>
<p><strong>作者：Jianyu Wang，Jianli Pan，Ismail AlQerm，（密苏里大学圣路易斯分校，重庆大学）</strong></p>
<p><strong>时间：2021</strong></p>
<p>ICCCN，ccf—C类</p>
</blockquote>
<h3 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h3><p>​    提出了<strong>Def-IDS</strong>，一个为NIDS准备的组合防御机制。它是一个由两个模块组成的训练框架，组合了multi-class generative adversarial networks<strong>（MGANs）</strong>和multi-soutce adversarial retraining（<strong>MAT</strong>）。</p>
<p>​    在CSE-CIC-IDS2018数据集上测试了该机制，并与3个其它方法进行了比较。结果表明Def-IDS可以以更高的<strong>precision, recall, F1 score, and accuracy</strong>来识别对抗样本。</p>
<hr>
<h3 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h3><p>​    <strong>Internet of Things(IoT):</strong>物联网</p>
<p>​    <strong>intrusion  detection systems (NIDS)</strong></p>
<p>​    提出了一个整合基于对抗训练的防御机制，用于提升DL-based的intrusion detectors的鲁棒性。</p>
<p>​    4个贡献：</p>
<ol>
<li>模型由两个模块组成，组合了multi-class generative adversarial networks<strong>（MGANs）</strong>和multi-soutce adversarial retraining（<strong>MAT</strong>），可以在保证准确率的前提下对抗攻击；</li>
<li><strong>MGANs</strong>可以通过同时过采样多类入侵来增强原始训练数据集，以减少训练与真实数据分布之间的差距。通过使用提升过的数据进行训练，detector的对已知和未知攻击的鲁棒性更强；</li>
<li><strong>MAT</strong>通过投喂多种不同的对抗样本来retraining，MAT不仅对抗某种特定的攻击，并且可以一定程度抵御对样样本的转移性；</li>
<li>我们进行了一些state-of-the-art攻击并且在CSE-CIC-IDS2018数据集上测试了该机制，结果很好。</li>
</ol>
<hr>
<h3 id="RELATED-WORK"><a href="#RELATED-WORK" class="headerlink" title="RELATED WORK"></a>RELATED WORK</h3><hr>
<h3 id="ADVERSARIAL-ATTACK-THREAT-MODELS"><a href="#ADVERSARIAL-ATTACK-THREAT-MODELS" class="headerlink" title="ADVERSARIAL ATTACK THREAT MODELS"></a>ADVERSARIAL ATTACK THREAT MODELS</h3><ul>
<li>采用的攻击方法：FGSM，BIM，DeepFool，JSMA</li>
</ul>
<hr>
<h3 id="PROPOSED-DEF-IDS-DEFENSE-MECHANISM"><a href="#PROPOSED-DEF-IDS-DEFENSE-MECHANISM" class="headerlink" title="PROPOSED DEF-IDS DEFENSE MECHANISM"></a>PROPOSED DEF-IDS DEFENSE MECHANISM</h3><h4 id="1-Mechanism-Overview"><a href="#1-Mechanism-Overview" class="headerlink" title="1. Mechanism Overview"></a>1. <em>Mechanism Overview</em></h4><p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211102215521.png" alt=""></p>
<h4 id="2-Module-1-Multi-class-GAN-based-Retraining"><a href="#2-Module-1-Multi-class-GAN-based-Retraining" class="headerlink" title="2. Module 1: Multi-class GAN-based Retraining"></a>2. <em>Module 1: Multi-class GAN-based Retraining</em></h4><h4 id="3-Module-2-Multi-source-Adversarial-Retraining"><a href="#3-Module-2-Multi-source-Adversarial-Retraining" class="headerlink" title="3. Module 2: Multi-source Adversarial Retraining"></a>3. <em>Module 2: Multi-source Adversarial Retraining</em></h4><h4 id="4-Ensemble-Adversarial-Retraining"><a href="#4-Ensemble-Adversarial-Retraining" class="headerlink" title="4. Ensemble Adversarial Retraining"></a>4. <em>Ensemble Adversarial Retraining</em></h4><p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211102220240.png" alt=""></p>
<hr>
<h3 id="EVALUATION"><a href="#EVALUATION" class="headerlink" title="EVALUATION"></a>EVALUATION</h3><h4 id="1-Dataset-and-Metrics"><a href="#1-Dataset-and-Metrics" class="headerlink" title="1.  Dataset and Metrics"></a>1.  <em>Dataset and Metrics</em></h4><p>​    <strong>数据集</strong>：CSE-CIC-IDS2018（CIC出版）（通用）</p>
<p>​    与其他过时的数据集相比，其含有综合性的攻击方法和更平衡的数据。</p>
<p>​    其含有Brute-force, Heartbleed,Botnet, DoS, DDoS, Web attacks 和  infifiltration of the network共7种恶意流量。</p>
<p>​    <strong>数据处理：</strong></p>
<ol>
<li><p>使用Min-Max standardization将所有特征的值映射入[0,1]；</p>
</li>
<li><p>有四个特征有太多空值或者无限值（dstport, protocol, flflow byts/s, flflow pkts/s），有一个特征（timestamp）与流量无关，将这5个特征剔除；还剩下76个特征。</p>
</li>
<li><p>training,validation,test = 8:1:1，随机划分。</p>
</li>
</ol>
<p>​    <strong>Detector的评价方法：</strong></p>
<p>​    混淆矩阵。</p>
<h4 id="2-Baseline-Detector-Implementation"><a href="#2-Baseline-Detector-Implementation" class="headerlink" title="2. Baseline Detector Implementation"></a>2. <em>Baseline Detector Implementation</em></h4><h5 id="2-1-Detector-Implementation"><a href="#2-1-Detector-Implementation" class="headerlink" title="2.1 Detector Implementation"></a>2.1 <em>Detector Implementation</em></h5><p>​    选取baseline detector C~base~。其由一个输入层，两个隐藏层和一个输出层组成（76-128-64-8）。</p>
<p>​    隐藏层都是全连接层+ReLU。</p>
<p>​    输出层使用Softmax。</p>
<p>​    代码用keras写的，系统Ubuntu 18.04,3.6GHz CPU和16GB内存。</p>
<p>​    优化器用Adam，学习率0.001,20个epoch。</p>
<p>​    在训练过程中，进行十次交叉验证并计算平均度量值。</p>
<p>​    训练结束后，利用测试数据集对Cbase进行评估。</p>
<h5 id="2-2-Adversarial-Attacks-against-Baseline-Classififier"><a href="#2-2-Adversarial-Attacks-against-Baseline-Classififier" class="headerlink" title="2.2  Adversarial Attacks against Baseline Classififier"></a>2.2  <em>Adversarial Attacks against Baseline Classififier</em></h5><p>​    使用python库<strong>foolbox</strong>来生成对抗样本；</p>
<p>​    FGSM，BIM，DeepFool，JSMA四种攻击方法都使用，具体效果如下图所示：</p>
<p>​    <img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211102213923.png" alt=""></p>
<h4 id="3-Def-IDS-Defense-Evaluation"><a href="#3-Def-IDS-Defense-Evaluation" class="headerlink" title="3.  Def-IDS Defense Evaluation"></a>3.  <em>Def-IDS Defense Evaluation</em></h4><p>C~gan~是使用GAN生成的样本再训练的detector;</p>
<p>C~at~是使用9:1的纯净数据：恶意数据再训练出的detector;</p>
<p>C~ensem~是二者的结合.</p>
<h5 id=""><a href="#" class="headerlink" title=""></a><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211102214213.png" alt=""></h5><p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211102215325.png" alt=""></p>
<h4 id="4-Comparison-with-Other-Works"><a href="#4-Comparison-with-Other-Works" class="headerlink" title="4.  Comparison with Other Works"></a>4.  <em>Comparison with Other Works</em></h4><p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211102215346.png" alt=""></p>
<h4 id="5-Cost-Estimation"><a href="#5-Cost-Estimation" class="headerlink" title="5.  Cost Estimation"></a>5.  <em>Cost Estimation</em></h4><p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211102215401.png" alt=""></p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>AD</tag>
      </tags>
  </entry>
  <entry>
    <title>Crafting Adversarial Example to Bypass Flow-&amp;ML- based Botnet Detector via RL</title>
    <url>/2021/10/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Crafting%20Adversarial%20Example%20to%20Bypass%20Flow-&amp;ML-%20based%20Botnet%20Detector%20via%20RL/</url>
    <content><![CDATA[<h1 id="Crafting-Adversarial-Example-to-Bypass-Flow-amp-ML-based-Botnet-Detector-via-RL"><a href="#Crafting-Adversarial-Example-to-Bypass-Flow-amp-ML-based-Botnet-Detector-via-RL" class="headerlink" title="Crafting Adversarial Example to Bypass Flow-&amp;ML- based Botnet Detector via RL"></a>Crafting Adversarial Example to Bypass Flow-&amp;ML- based Botnet Detector via RL</h1><blockquote>
<p><strong>作者：Junnan Wang，Qixu Liu，Di Wu，Ying Dong，Xiang Cui（中国科学院大学，华为科技，北京维纳斯纲科技，广州大学）</strong></p>
<p><strong>时间：2021.10.6</strong></p>
</blockquote>
<h4 id="1-Botnet-僵尸网络-："><a href="#1-Botnet-僵尸网络-：" class="headerlink" title="1. Botnet(僵尸网络)："></a>1. Botnet(僵尸网络)：</h4><h5 id="1-1-定义："><a href="#1-1-定义：" class="headerlink" title="1.1 定义："></a>1.1 定义：</h5><p>​    Botnet = robot + network。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211030111947.png" alt=""></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211030112012.png" alt=""></p>
<blockquote>
<p>——参考《软件安全》.彭国军</p>
</blockquote>
<h5 id="1-2-如何攻击？"><a href="#1-2-如何攻击？" class="headerlink" title="1.2 如何攻击？"></a>1.2 如何攻击？</h5><p>​    一个僵尸网络的生存周期包括<strong><u>形成、C&amp;C、攻击、后攻击</u></strong>四个阶段。</p>
<p>​    形成阶段由攻击者入侵有漏洞的主机，并在其上执行恶意程序，使之成为僵尸主机。</p>
<p>​    一旦成为僵尸主机之后，botmaster会通过各种方式与之通信。</p>
<p>​    之后根据botmaster的指令执行攻击行为。后攻击阶段是指botmaster对僵尸网络进行升级更新。</p>
<h4 id="2-Botnet-Detector-僵尸网络检测器-："><a href="#2-Botnet-Detector-僵尸网络检测器-：" class="headerlink" title="2. Botnet Detector(僵尸网络检测器)："></a>2. Botnet Detector(僵尸网络检测器)：</h4><h5 id="2-1-传统方法："><a href="#2-1-传统方法：" class="headerlink" title="2.1 传统方法："></a>2.1 传统方法：</h5><p>​    从检测原理上来说，大致可以分为三类方法：</p>
<p>　　·行为特征统计分析</p>
<p>　　·bot行为仿真以监控</p>
<p>　　·流量数据特征匹配</p>
<p>​    传统的检测僵尸网络的方法一般在形成、攻击阶段，利用僵尸主机存在的行为特征，例如通信的数据内容。一些基于网络流量行为分析的方法可以检测僵尸网络，主要是从<strong>通信流量特征</strong>的角度去检测的，例如流量的通信周期，这种方法可以检测出一些加密的僵尸主机流量，同时还可以检测出新型的僵尸网络。</p>
<blockquote>
<p>——参考：<a href="http://blog.chinaunix.net/uid-20597254-id-1918281.html">解析：僵尸网络（Botnet）的检测方法-西湖泛舟-ChinaUnix博客</a></p>
</blockquote>
<hr>
<h3 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h3><p>​    提出了一个<u>基于RL</u>的方法来对<u>基于ML的僵尸网络追踪器</u>做逃逸攻击。</p>
<p>​    黑盒攻击，不用改变追踪器本身。</p>
<hr>
<h3 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h3><p>​    训练一个RLagent，让其通过与追踪器的交流反馈自己学习如何扰动样本。</p>
<p>​    为了确保功能的保留，我们设计了一个包含14个增量操作的操作空间，每个操作只向原始流中添加一个精心编制的数据包，以尝试更改一些流级特性。检测器认为这些特征具有区分性，但这可能不是良性交通的因果指标。</p>
<p>​    此外，添加数据包是传输层的增量操作，而恶意数据一般封装在应用层。</p>
<p>​    主要贡献：</p>
<pre><code> 1. 黑盒攻击；
 2. 功能保留，且步骤较简单，成本低；
 3. 可以逃逸。
</code></pre><hr>
<h3 id="RELATED-WORK"><a href="#RELATED-WORK" class="headerlink" title="RELATED WORK"></a>RELATED WORK</h3><h4 id="Botnet-Evasion"><a href="#Botnet-Evasion" class="headerlink" title="Botnet Evasion:"></a>Botnet Evasion:</h4><ul>
<li><p>传统botnet逃逸方法：加密网络流；在TCP/IP协议簇的冗余字段中隐藏C &amp; C信息(command and control)；使用online-social-networks(OSN)来构建隐藏的通道。</p>
</li>
<li><p>ML-based逃逸方法：</p>
<ol>
<li><p><strong>Feature space attack：</strong>指的是只能生成traffic对抗特征向量的方法。但是，考虑到traffic样本映射到特征向量的过程是不可逆的，这样的攻击不能造成实际的安全威胁，只能用来证明基于ML的检测器的脆弱性。</p>
</li>
<li><p><strong>End-to-end attack：</strong>指的是可以生成真正的traffic数据的方法。</p>
<p>【35】利用了GAN来模仿facebook聊天网络的traffic以此绕过自适应IPS。</p>
<p>【36】利用了GAN来生成尽量真实的traffic，以此来提高数据集的质量，解决数据不平衡问题。</p>
</li>
</ol>
</li>
</ul>
<hr>
<h3 id="THREAT-MODEL-AND-SYSTEM-FRAMEWORK"><a href="#THREAT-MODEL-AND-SYSTEM-FRAMEWORK" class="headerlink" title="THREAT MODEL AND SYSTEM FRAMEWORK"></a>THREAT MODEL AND SYSTEM FRAMEWORK</h3><ol>
<li><p><strong>Threat Model</strong></p>
<ul>
<li><p><strong>攻击者的目的：</strong>生成对抗样本，隐藏botnet flow。</p>
</li>
<li><p><strong>攻击者的信息：</strong>1. 攻击者理解目标网络可能被流等级（flow-level）ML网络检测系统保护；2. 攻击者不需要知道detector的算法，参数，特征或训练数据等信息。</p>
</li>
<li><p><strong>攻击者的能力：</strong>1. 攻击者只有能力修改测试集，并不能改变detector的训练集；2. 同时，我们假设攻击者可以持续访问detector，从检测器中获取二进制预测结果。</p>
</li>
</ul>
</li>
<li><p><strong>System Design</strong></p>
</li>
</ol>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211031113229.png" alt=""></p>
<p>​    见图即可，简单的RL学习模型。</p>
<ol>
<li><p><strong>RL Algorithm</strong></p>
<p>选择了（value-based）DQN和SARSA，都用。</p>
<ol>
<li><p><strong>Action Space</strong></p>
<p><strong>Q：如何在不影响原来功能的情况下添加扰动？</strong></p>
<p>A：因为botnet内容在应用层，故可以对传输层进行扰动。（<u>PS：这样确实不会改变功能，但是应用层的恶意特征不会仍被detector检测到吗？</u>）</p>
<p><strong>Q：如何确定哪个特征该进行扰动？</strong></p>
<p>A：考虑到动作设计的困难，从僵尸网络检测中常用的特征集合中选取18个特征。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211031115102.png" alt=""></p>
<p>​    由上述特征，基于botnet和normal flow的差异，action space包含了14个动作，这些动作可以影响以上的统计特征，例如简单修改数据包的时间戳，或者添加构建的新数据包。</p>
<p>​    当在构建新数据包时，考虑三个地方：时间戳，方向，包的大小。</p>
<p>​    14个动作被分成了5类：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211031115453.png" alt=""></p>
</li>
</ol>
</li>
</ol>
<pre><code>具体见原文。
</code></pre><ol>
<li><p><strong>State Space</strong></p>
<p>​    detector返回的二进制信息很难直接使用，需要有一个状态生成器来生成供agent使用的state。</p>
<p>​    这里使用堆叠自编码器（Stacked Autoencoder，SAE）来自动提取botnet flow的特征，然后将其返回给agent以作为state。</p>
<p>​    将每个botnet flow的前1024个字节作为SAE的输入，经过一些epoch的训练，SAE就可以自动地从botnet flow中学习到一个256维度的state vector。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211031152136.png" alt=""></p>
</li>
</ol>
<hr>
<h3 id="EXPERIMENTAL-SETUP"><a href="#EXPERIMENTAL-SETUP" class="headerlink" title="EXPERIMENTAL SETUP"></a>EXPERIMENTAL SETUP</h3><ol>
<li><p><strong>Implementation</strong></p>
<p>系统的位置如下：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211031152307.png"  /></p>
<p>作为BotMaster的一个代理存在。</p>
</li>
<li><p><strong>Dataset</strong></p>
<p>两个公开数据集：CTU，ISOT。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211031152816.png" alt=""></p>
<p>然后做一下数据处理：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211031153008.png" alt="image-20211031153006310" style="zoom:80%;" /></p>
<ol>
<li>合并属于同一botnet 家族的样本，如果某个pcap包太大，就舍弃；</li>
<li>将pcap包切片；</li>
<li>匿名化，将ip,mac等包中独一无二的东西随机化，以避免影响。</li>
</ol>
</li>
<li><p><strong>Detector</strong></p>
<p>​    选取了两个state-of-art的detector: <strong>the composite DL detection model combining CNN</strong></p>
<p><strong>with LSTM(<em>BotCatcher detection model</em>)</strong>，<strong>the non-differentiable ML detection model based on XGBoost(<em>XGBoost detection model</em>)</strong>。</p>
<p>​    <img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211031154038.png" alt=""></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211031154144.png" alt=""></p>
</li>
</ol>
<hr>
<h3 id="RESULTS"><a href="#RESULTS" class="headerlink" title="RESULTS"></a>RESULTS</h3><ol>
<li><p><strong>Evasion performance</strong></p>
<p>将DQM,SARSA与BotCatcher,XGBoost两两组合：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211101153359.png" alt=""></p>
<p>逃逸率如上图所示，可以看到，即使是随机扰动都有一定的逃逸率。</p>
<p>不同测试集效果差异很大：</p>
<pre><code>1. 数据包可能过大（storm），导致对时间戳做修改等操作对结果的影响很小；
2. 数据包的特征跟其它数据集差别很大，导致模型难以在有限的步骤时间里改变足够多的特征。
</code></pre></li>
<li><p><strong>Time performances</strong></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211101155037.png" alt=""></p>
</li>
<li><p><strong>Dominant actions</strong></p>
<p><strong>Dominant actions</strong>指的是agent在创建对抗样本时采用的最频繁的操作。</p>
</li>
</ol>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211101155358.png" alt=""></p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>RL</tag>
        <tag>Botnet</tag>
      </tags>
  </entry>
  <entry>
    <title>MODELING ADVERSARIAL NOISE FOR ADVERSARIAL DEFENSE</title>
    <url>/2021/10/22/MODELING%20ADVERSARIAL%20NOISE%20FOR%20ADVERSARIAL%20DEFENSE/</url>
    <content><![CDATA[<h1 id="MODELING-ADVERSARIAL-NOISE-FOR-ADVERSARIAL-DEFENSE"><a href="#MODELING-ADVERSARIAL-NOISE-FOR-ADVERSARIAL-DEFENSE" class="headerlink" title="MODELING ADVERSARIAL NOISE FOR ADVERSARIAL DEFENSE"></a>MODELING ADVERSARIAL NOISE FOR ADVERSARIAL DEFENSE</h1><blockquote>
<p><strong>作者：Dawei Zhou, Nannan Wang, Bo Han, Tongliang Liu（西安电子科技大学，香港浸会大学，悉尼大学）</strong></p>
<p><strong>时间：2019</strong></p>
</blockquote>
<h3 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h3><p>​    </p>
<p>不是，虚拟机软件本身就是运行在操作系统上的一个应用程序，但对于虚拟机内部运行的程序来说，虚拟机软件可以看做一个操作系统。</p>
<p>系统调用，应用程序需要操作系统提供调用，比如I/O等</p>
<p>进程管理，应用程序可能有多个进程，需要操作系统对进程的运行进行管理</p>
<p>内存管理，应用程序需要内存资源，需要操作系统进行分配调度</p>
<p>文件管理，应用程序可能需要文件的存取，也需要操作系统的文件管理功能</p>
<p>网络管理，有些应用程序需要操作系统提供网络支持</p>
<p>设备管理，应用程序需要操作系统进行设备管理，比如打印机等设备</p>
<p>UNIX最早诞生于贝尔实验室，通过NUIX V6,V7的版本更迭，商业化与版本发展，诞生了Linux，Mac OS X，GNU，Minix，Solaris等著名操作系统，其中：</p>
<p><strong>System V UNIX：</strong>当今市场上大多数主要的商业UNIX系统都是基于AT&amp;T UNIX，包括AIX（IBM)，Irix，Solaris（SUN)，Tru64,Unicos和UnixWare。<br><strong>BSD UNIX：</strong>有些UNIX操作系统是从4.4 BSD-Lite演变而来，4.4 BSD-Lite是BSD UNIX的最终版本，发布于1994年。其中应用比较广泛的有BSD/OS，FreeBSD，MacOS X，NetBSD，OpenBSD。</p>
<p>在中断技术产生的背景下，大量事务性的任务与程序相继涌现，对计算机实时响应的需求也越来越高，故主机采用分时技术轮流为每个终端服务，每个终端都感觉到是“独占主机”。</p>
<p>在分时系统中：</p>
<ol>
<li>多路调制性：多用户联机使用一台主机；</li>
<li>独占性：用户感觉独占主机；</li>
<li>交互性：及时响应用户请求。</li>
<li></li>
</ol>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>AD</tag>
      </tags>
  </entry>
  <entry>
    <title>Obfuscated Malware Detection Using Deep Generative Model based on Global/Local Features</title>
    <url>/2021/10/16/Obfuscated%20Malware%20Detection%20Using%20Deep%20Generative%20Model%20based%20on%20GlobalLocal%20Features/</url>
    <content><![CDATA[<h1 id="【论文阅读】Obfuscated-Malware-Detection-Using-Deep-Generative-Model-based-on-Global-Local-Features"><a href="#【论文阅读】Obfuscated-Malware-Detection-Using-Deep-Generative-Model-based-on-Global-Local-Features" class="headerlink" title="【论文阅读】Obfuscated Malware Detection Using Deep Generative Model based on Global/Local Features"></a>【论文阅读】Obfuscated Malware Detection Using Deep Generative Model based on Global/Local Features</h1><blockquote>
<p><strong>作者：Jin-Young Kim, Sung-Bae Cho（延世大学）</strong></p>
<p><strong>时间：2021</strong></p>
</blockquote>
<h3 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h3><p>​    提出了一种混合深度生成模型（<em>hybrid deep generative model</em>），将全局特征与局部特征结合起来以此有效辨别恶意样本。</p>
<p>​    在将恶意软件转化为图像以有效地表示具有预定义潜在空间的全局特征的同时，它使用二进制代码序列提取局部特征。我们通过类激活图( CAM )分析恶意软件代码的哪些部分部分会影响检测结果，并通过分析生成的恶意软件的CAM结果来确认虚拟恶意软件生成提高了检测性能。</p>
<hr>
<h3 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h3><p>​    提出一个原创的方法：生成恶意样本，同时使用生成的图片等级的数据（ image-level ）和代码等级的信息（code-level）来训练分类器。</p>
<p>​    为了训练分类器，我们使用VAE（variational autoencoder），预定义一个潜在空间用于将数据的特征嵌入其中，以此来生成更多的精密的恶意样本。</p>
<p>​    在这种方法下，代码等级的信息丢失，故使用一个模型来提取代码等级的信息送入分类器。</p>
<p>​    然后，两种恶意样本的特征被合并，接下来被用于分类。一个恶意样本的数据可以被表示为汇编代码，二进制代码或者恶意样本图像。</p>
<p>​    Contributions:</p>
<pre><code>1. 一个原创的，结合全局与局部两种特征的恶意软件检测方法，克服已有方法缺点，达到主流表现；
2. 构建一个深度生成模型，生成恶意样本以此提高鲁棒性；
3. 通过类激活图（CAM）来分析恶意软件代码的哪些部分影响检测结果，来验证生成的恶意软件的效果，并确认虚拟恶意软件的生成提高了检测性能。
</code></pre><hr>
<h3 id="METHOD"><a href="#METHOD" class="headerlink" title="METHOD"></a>METHOD</h3><p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211016154717.png" alt=""></p>
<h4 id="3-1-Defining-Latent-Space"><a href="#3-1-Defining-Latent-Space" class="headerlink" title="3.1 Defining Latent Space"></a>3.1 <em>Defining Latent Space</em></h4><h4 id="3-2-Generating-Data"><a href="#3-2-Generating-Data" class="headerlink" title="3.2 Generating Data"></a>3.2 <em>Generating Data</em></h4><h4 id="3-3-Local-Feature-Modeling"><a href="#3-3-Local-Feature-Modeling" class="headerlink" title="3.3 Local Feature Modeling"></a>3.3 <em>Local Feature Modeling</em></h4><h4 id="3-4-Malware-Detection-with-Transfer-Learning"><a href="#3-4-Malware-Detection-with-Transfer-Learning" class="headerlink" title="3.4 Malware Detection with Transfer Learning"></a>3.4 <em>Malware Detection with Transfer Learning</em></h4><p>​    </p>
<hr>
<h3 id="EXPERIMENT"><a href="#EXPERIMENT" class="headerlink" title="EXPERIMENT"></a>EXPERIMENT</h3><h4 id="4-1-Dataset-and-Experimental-Settings"><a href="#4-1-Dataset-and-Experimental-Settings" class="headerlink" title="4.1 Dataset and Experimental Settings"></a>4.1 <em>Dataset and Experimental Settings</em></h4><ul>
<li><p><strong>数据集来源：</strong>Kaggle Microsoft Malware Classification Challenge；</p>
</li>
<li><p><strong>数据形式：</strong>二进制或汇编代码，这里只使用二进制代码；</p>
</li>
</ul>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211016163637.png" alt=""></p>
<ul>
<li><p><strong>数据处理：</strong></p>
<ol>
<li>将十六进制的二进制代码转换为01表示；</li>
<li>将二进制代码转化为malware image。</li>
</ol>
</li>
</ul>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211016164826.png" alt=""></p>
<ul>
<li><p><strong>参数设置：</strong>Adam 优化器，weights初始化使用特定的方法(Kingma and Ba, 2014; Glorot and Bengio, 2009)。</p>
<h4 id="4-2-Detection-Results"><a href="#4-2-Detection-Results" class="headerlink" title="4.2 Detection Results"></a>4.2 <em>Detection Results</em></h4><p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211016164705.png" alt=""></p>
<p>PS：Std.dev.是标准差；当p-value小于0.05时，我们就说这个独立变量重要（significant），因为这个独立变量与输出结果有关系。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211016164742.png" alt=""></p>
<h4 id="4-3-Effects-of-Generating-Malware"><a href="#4-3-Effects-of-Generating-Malware" class="headerlink" title="4.3 Effects of Generating Malware"></a>4.3 <em>Effects of Generating Malware</em></h4><p>使用structural similarity index measure（SSIM）来找到与生成数据相似的数据。</p>
<p>包含真实数据和生产数据的恶意软件的std . des .和SSIM值分别为0.3308和0.1019，而只有实际数据的std . des .和SSIM值分别为0.3224和0.1068。这说明产生的数据增加了恶意软件的种类。</p>
<p>我们进行了F检验以检查统计结果的std.des.，p值为0.0342.</p>
</li>
</ul>
<p>  使用CAM来查找影响了模型结果的特征：</p>
<p>  <img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211016165953.png" alt=""></p>
<p>  ​    上图中，亮点是重要的地方，前两行是分别对text和data做的结果检查，最后一行是对生成恶意样本做的，结果表明可以增强鲁棒性。</p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>AD</tag>
      </tags>
  </entry>
  <entry>
    <title>《最后的问题》</title>
    <url>/2021/10/12/The%20Last%20Question/</url>
    <content><![CDATA[<h1 id="THE-LAST-QUESTION"><a href="#THE-LAST-QUESTION" class="headerlink" title="THE LAST QUESTION"></a>THE LAST QUESTION</h1><p>最后的问题第一次被半开玩笑地提出是在2061年的5月21日。那时人类文明刚刚步入曙光中。这个问题源起于酒酣之中一个五美元的赌，它是这么发生的：</p>
<p>亚历山大•阿代尔与贝特伦•卢泊夫是Multivac的两个忠实的管理员。像任何其他人一样，他们知道在那台巨大的计算机数英里冰冷、闪烁、滴答作响的面庞后藏着什么。那些电子回路早已发展到任何个别的人都无法完全掌握的地步，但他们至少对它的大致蓝图有个基本的概念。</p>
<p>Multivac能自我调节和自我修正。这对它是必要的，因为人类当中没有谁能够快甚至够好地对它进行调节和修正。所以实际上阿代尔与卢泊夫对这个庞然大 物只进行一些非常轻松和肤浅的管理，任何其他人也都只能做到这个程度。他们给它输送数据，根据它所需的格式修改问题，然后翻译给出的答案。当然，他们以及 其他管理员们完全有资格分享属于Multivac的荣誉。</p>
<p>几十年中，在Multivac的帮助下人类建造了宇宙飞船，计算出航行路径，从而得以登陆月球、火星和金星。但是更远的航行需要大量的能量，地球上可怜的资源不足以支持这些飞船。尽管人类不断地提高煤炭和核能的利用效率，但煤和铀都是有限的。</p>
<p>但是慢慢地Multivac学会了如何从根本上解决某些深层次问题。2061年5月14日，理论成为了现实。</p>
<p>太阳的能量被储存和转化，得以被全球规模地直接利用。整个地球熄灭了燃烧的煤炭，关闭了核反应炉，打开了连接到那个小小的太阳能空间站的开关。这个空间站直径一英里，在到月球的距离一半处环绕着地球。看不见的太阳的光束支撑着整个地球社会的运行。</p>
<p>七天的庆祝还不足以暗淡这创举的光辉。阿代尔与卢泊夫总算逃脱了公众事务，悄悄地相聚在这个谁也想不到的荒僻的地下室。在这里Multivac埋藏着的庞 大身躯露出了一部分。它正独自闲暇地整理着数据，发出满足的、慵懒的滴答声——它也得到了假期。他们了解这一点，一开始他们并没打算打扰它。</p>
<p>他们带来了一瓶酒。这会儿他们想做的只是在一起，喝喝酒，放松放松。</p>
<p>你想一想就会觉得很神奇，”阿代尔说。他宽阔的脸庞已有了疲倦的纹路。他慢慢地用玻璃棒搅动着酒，看着冰块笨拙地滑动。“从此我们所用的所有能量都是免费的。只要我们愿意，我们能把地球熔化成一颗液态大铁球——还能毫不在乎花掉的能量。够我们永远永远永远用下去的能量。”</p>
<p>卢泊夫将头歪向一边，这是当他想要反驳对方时的习惯动作。他现在确实想要反驳，部分原因是他在负责拿着冰和杯子。他说：“不是永远。”</p>
<p>“哦去你的，差不多就是永远。直到太阳完蛋，老贝。”</p>
<p>“那就不是永远。”</p>
<p>“好吧。几十亿年，可能一百亿年，满意了吧？”</p>
<p>卢泊夫用手梳着他稀薄的头发，仿佛要确认还剩下了一些。他缓缓地抿着自己的酒说，“一百亿年也不是永远。”</p>
<p>“但对我们来说是够了，不是吗？”</p>
<p>“煤和铀对我们来说也够了。”</p>
<p>“好好好，但是现在我们能把宇宙飞船连接到太阳能电站，然后飞到冥王星又飞回来一百万次而不用担心燃料。靠煤和铀你就做不到。不信去问问Multivac。”</p>
<p>“我不用问它。我知道。”</p>
<p>“那就不要小看Multivac为我们做的事，”阿代尔怒道，“它做得很好。”</p>
<p>“谁说它做得不好？我是说太阳不能永远燃烧下去，我只是这个意思。我们在一百亿年内可以高枕无忧，但是然后呢？”卢泊夫用略微颤抖的手指指着对方，“不要说我们换另外一个太阳。”</p>
<p>片刻的沉默。阿代尔偶尔将酒杯放到唇边，而卢泊夫慢慢地闭上了眼睛。两人都在休息。</p>
<p>然后卢泊夫突然睁开眼，“你在想当我们的太阳没了就换另外一个太阳，是吧？”</p>
<p>“我没这么想。”</p>
<p>“你就是这么想的。你的逻辑不行，这就是你的问题。你就像故事里说的那个人一样，碰上了雨就跑到树林里躲在一棵树下。他可不担心，是吧，因为他以为当这棵树淋得太湿的时候他只要跑到另一棵树下就行。”</p>
<p>“我明白了，”阿代尔说，“别嚷嚷。太阳完蛋了，其他的也都会完蛋。”</p>
<p>“完全正确，”卢泊夫嘟哝道，“一切都在起初那个宇宙大爆炸中有个开始，不管那到底是怎么回事。当所有的恒星都熄灭了，一切也都会有个结束。有的星星熄灭 得比别的早。像那些该死的巨星维持不了一亿年。我们的太阳能持续一百亿年，矮星再怎么样最多也只有两千亿年。一万亿年后一切都是一片漆黑。熵必须增加到最 大值，就是这样。”</p>
<p>“我非常明白什么是熵，”阿代尔维护着他的自尊。</p>
<p>“你明白个屁。”</p>
<p>“我跟你知道的一样多。”</p>
<p>“那你该知道某一天所有的东西都会耗光。”</p>
<p>“是是是。谁说它们不会呢？”</p>
<p>“你说的，你这个糊涂虫。你说我们有永远用不完的能量。你说的‘永远’。”</p>
<p>现在轮到阿代尔反驳了。他说：“也许有一天我们能让一切从头开始。”</p>
<p>“绝不可能。”</p>
<p>“为什么？总有那么一天的。”</p>
<p>“没有。”</p>
<p>“问问Multivac。”</p>
<p>“你去问Multivac。你敢吗？我赌五美元它说这不可能。”</p>
<p>阿代尔刚刚醉到愿意一试，又刚刚足够清醒到能拼写出问问题需要的符号和算式。这个问题用文字来表达就是：人类是否有一天能不需要净损耗能量而在恒星衰竭之后将其恢复到全盛时期？</p>
<p>或者更简明地这样说：怎样使宇宙的总熵大幅度地降低？</p>
<p>Multivac陷入了静止和沉默。缓慢闪烁的灯光熄灭了，深处传来的电路的滴答声停止了。</p>
<p>正当这两位被吓坏的技术员感到他们无法再屏住呼吸时，忽然间与Multivac相连的打字机开始运作起来。它打出几个字：数据不足，无法作答。</p>
<p>“赌不成了。”卢泊夫悄声道。他们匆忙离开了。</p>
<p>到了第二天早晨，两人头晕脑胀，口干舌燥，把这件事给忘了。</p>
<p>-———————————————————————————</p>
<p>贾诺德、贾诺汀和贾诺蒂I、贾诺蒂II注视着屏幕中变幻的星空影像。飞船在超越时间的一瞬中穿越了超时空，均匀分布的星群立刻被一个明亮的圆盘取代。它弹珠大小，占据着屏幕的中心。</p>
<p>“那就是X-23，”贾诺德自信地说。他紧握着的瘦削的手背在身后，指节发白。</p>
<p>两个小贾诺蒂都是女孩。她们一生中第一次经历超时空飞行，清晰地感到那种片刻的恶心[注]。她们悄声地嘻笑着，疯狂地绕着她们的母亲互相追逐，一边尖叫：“我们到X-23了——我们到X-23了——我们——”</p>
<p>“孩子们，别闹了！”贾诺汀严厉地说。“你确定吗，贾诺德？”</p>
<p>“有什么不确定的？”贾诺德瞟了一眼天花板上凸出的那块毫不起眼的金属。它从房间的一头延伸到另一头，两端埋入墙壁中。它和整个飞船一样长。</p>
<p>贾诺德对这条厚厚的金属棒几乎一无所知。他只知道它叫做Microvac，你可以问它任何问题，而平时它控制着飞船飞向目的地，从不同的银河系能量分站向飞船输送能量，并完成进行超时空跳跃的计算。</p>
<p>贾诺德一家只需要住在飞船舒适的居住区等待。曾经有人告诉贾诺德，“Microvac”词尾的“ac”是古英语中“automatic computer，智能电脑”的缩写。但他差不多连这都忘了。</p>
<p>贾诺汀看着视屏，眼睛有些湿润。“没办法。想到离开了地球我感觉怪怪的。”</p>
<p>“天哪，为什么？”贾诺德问。“我们在那儿什么也没有。我们在X-23上会拥有一切。你并不孤单，你又不是那些拓荒者。这个行星上已经有超过一百万人了。 天哪，我们的曾孙们会得去找新的星球，因为那时X-23会太挤了。”他想了一会，说：“告诉你，人口增长这么快，幸亏电脑实现了星际旅行。”</p>
<p>“我知道，我知道。”贾诺汀难过地回答。</p>
<p>贾诺蒂I马上说道：“我们的Microvac是世界上最好的Microvac。”</p>
<p>“我也是这么想的。”贾诺德抚弄着她的头发说。</p>
<p>能拥有一台自己的Microvac的感觉非常好。贾诺德很高兴他属于他们这一代人。在他父亲年轻的时候，电脑都是占地一百平方英里的巨大机器。一个星球只 有一台，被称作行星AC。一千年来它们的体积逐步地增加，然后忽然间缩小了，因为分子阀取代了晶体管，使得最大的行星AC都缩小到了只有一艘飞船的一半体 积。</p>
<p>每当想到这件事贾诺德总是感到飘飘然：他的Microvac比那台古老原始的首次驯服了太阳的Multivac要精密好几倍，而且和第一台解决了超时空传送问题从而实现了星际航行的地球行星AC（最大的行星AC）一样精密。</p>
<p>“这么多的恒星，这么多的行星。”贾诺汀想着心事，叹息道。“我想人们会永远不断地出发去找新的行星，就像我们现在这样。”</p>
<p>“不是永远，”贾诺德笑了一笑说。“有一天这一切都会停下来，但那是在几十亿年之后了。好几十亿年。即使是星星也会耗尽，你知道的。熵必须不断增大。”</p>
<p>“爸爸，熵是什么？”贾诺蒂II喊道。</p>
<p>“小宝贝，熵，就是一个代表着宇宙消耗掉了多少的词。什么东西都会消耗，知道吗，就像你那个会走路会说话的小机器人，记得吧？”</p>
<p>“你不能给它装一个新的电池吗，就像给我的机器人那样？”</p>
<p>“星星们就是电池，亲爱的。一旦它们用完了，就没有别的电池了。”</p>
<p>贾诺蒂I一下子大喊起来：“别让它们用完，爸爸。别让星星们用完吧。”</p>
<p>“看看你干了什么。”贾诺汀恼火地低声说道。</p>
<p>“我怎么知道这会吓到她们？”贾诺德低声反驳。</p>
<p>“问问Microvac，”贾诺蒂I哭叫道。“问它怎么把星星重新点亮。”</p>
<p>“问吧，”贾诺汀说。“这会让她们安静点的。”（贾诺蒂II也开始哭了。）</p>
<p>贾诺德耸耸肩。“好了，好了，亲爱的。我去问Microvac。别着急，它会告诉我们的。”</p>
<p>他向Microvac提出问题，并赶紧加上“把答案打印出来。”</p>
<p>贾诺德将薄薄的纤维纸带握在手心，高兴地说：“看吧，Microvac说到时候它会料理这一切，所以别担心啦。”</p>
<p>贾诺汀说：“那么现在孩子们，该睡觉了。我们马上就要到我们的新家了。”</p>
<p>在销毁纸带之前贾诺德又读了一遍上面的文字：数据不足，无法作答。</p>
<p>他耸了耸肩，看向视屏。X-23就在前方。</p>
<p>-———————————————————————————</p>
<p>兰默斯VJ-23X注视着幽深的银河三维缩影图，说：“我想我们这么担心这件事是不是很可笑？”</p>
<p>尼克隆MQ-17J摇头道：“我不觉得。你知道照现在的扩展速度银河系在五年内就会被挤满。”</p>
<p>两个人看起来都是二十出头，都很高大健康。</p>
<p>“但是，”VJ-23X说，“我不太想给银河参议会提交这样一个悲观的报告。”</p>
<p>“我不会考虑作任何其他的报告。得引起他们的注意。我们必须引起他们的注意。”</p>
<p>VJ-23X叹了一口气。“太空是无限的。还有一千亿个星系等着我们。甚至更多。”</p>
<p>“一千亿并不是无限，而且正在变得越来越有限。想想吧！两万年前人类刚刚找到了利用恒星能量的方法，几个世纪之后星际旅行就实现了。人类用了一百万年才填满一个小小的星球，可是只用了一万五千年就占据了整个银河系。而现在人口每十年就翻一倍——”</p>
<p>VJ-23X 插口道：“这得归功于永生。”</p>
<p>“不错。永生实现了，我们得把它考虑进去。我觉得它的确有阴暗的一面。银河AC给我们解决了很多问题，但当它解决了防止衰老和死亡这个问题之后其他的一切都白费了。”</p>
<p>“但是我想你也不想放弃生命吧。”</p>
<p>“一点也不想，”MQ-17J断然道，随即柔和了语调，“现在还不想。我还一点也不老。你多少岁了？”</p>
<p>“两百二十三。你呢？”</p>
<p>“我还不到两百。——但是回到我说的事情上来。人口每十年增加一倍。一旦银河系被占满了，我们会在十年内占满另一个。再过十年我们能占满另外两个。再过十年，四个。一百年内我们会占满一千个星系。一千年内，一百万个。一万年内就是整个已知的宇宙。然后呢？”</p>
<p>VJ-23X说：“还有附带的一点是运输的问题。我不知道把一整个星系的人运送到另一个需要多少太阳单位的能量。”</p>
<p>“这一点说得很对。人类现在每年已经得消耗两个太阳单位的能量了。”</p>
<p>“大部分的都被浪费了。不管怎样，我们自己的星系每年泼出去一千个太阳单位能而我们只用其中的两个。”</p>
<p>“没错，但是即使有百分之百的效率，我们也只是推迟了结局的到来。我们对能量的需求以几何级数增长，比我们的人口还要快。在我们占据完所有星系之前我们就会用光所有能量。你说得对。说得非常对。”</p>
<p>“我们可以用星际气体造出新的恒星。”</p>
<p>“或者说用散失掉了的热量？”MQ-17J嘲讽地说。</p>
<p>“也许会有办法逆转熵的增加。我们应该问问银河AC。”</p>
<p>VJ-23X并不是认真的，但是MQ-17J把他的AC联络器从口袋里拿出来放在面前的桌子上。</p>
<p>“我确实有点想问。”他说，“这个问题总有一天人类得面对。”</p>
<p>他忧郁地注视着小小的AC联络器。这是个两英寸的立方体。它本身并没有什么，而只是通过超时空与那个服务于全人类的超级银河AC相联系。如果将超时空算进来，它就是银河AC整体的一部分。</p>
<p>MQ-17J停下来想着在他不朽的生命中是否有一天他能有机会去看看银河AC。它占据着单独的一个小星球，能量束构成的蛛网支持着它的核心，其中古老笨拙的分子阀已被亚介子流取代。尽管有着亚以太级的精密结构，银河AC的直径仍足有一千英尺长。</p>
<p>MQ-17J突然开口向AC联络器问道：“熵的增加能被逆转吗？”</p>
<p>VJ-23X吃了一惊，立即说道：“哦，我说，我没有真的想叫你问那个。”</p>
<p>“为什么不呢？”</p>
<p>“我们都知道熵是不可逆转的。你不能把烧剩的烟尘变回到一棵树。”</p>
<p>“你们的星球上有树？”MQ-17J说。</p>
<p>突然而来的银河AC的声音使他们住口了。从桌上的AC联络器中传出它纤细悦耳的声音：数据不足，无法作答。</p>
<p>VJ-23X说：“看吧！”</p>
<p>于是两人又回到了他们要给银河参议会提交的报告的话题上</p>
<p>-———————————————————————————</p>
<p>Z’ 的思想飘浮在这个新的星系中，对这些数不清的星团带着略微的兴趣。他从未见过这个星系。他有可能见到所有的星系吗？它们如此之多，每一个都满载着人。——但是它们承载的几乎不能算是生命了。人的真正意义已经逐渐转移到太空之中。</p>
<p>心灵，而非肉体！不朽的躯体留在行星上，静止千万年。偶尔被唤醒进行某些实际活动，但这已经越来越少见了。很少再有新的个体出生加入这个难以置信的庞大的群体，但这有什么关系呢？宇宙已经没有多少空间能容纳新的人了。</p>
<p>来自另一个心灵的纤细触手将Z’ 从冥想中唤醒。</p>
<p>“我叫Z’。”，Z’ 说。“你呢？”</p>
<p>“我叫D1。你是哪个星系的？”</p>
<p>“我们只是叫它星系。你呢？”</p>
<p>“我们也这么叫我们的。所有的人都把他们的星系叫作‘他们的星系’，没有别的了。这也很自然。”</p>
<p>“没错。反正所有的星系都是一样的。”</p>
<p>“不是所有的星系。肯定有某一个星系是人类的发源地，这就使它与众不同。”</p>
<p>“我不知道。宇宙AC一定知道。”</p>
<p>“我们问问它吧？我突然觉得很好奇。”</p>
<p>Z’ 将感知延展开，直到星系们都缩小为更广大的背景上更为稀疏的点。几千亿个星系，都载着不朽的人类，载着这些灵魂在太空自由游荡的智慧生命。然而它们之中有一个独一无二的星系，是人类的发源地。在模糊的久远的过去，曾有一个时期，它是唯一居住着人类的星系。</p>
<p>Z’ 满心好奇地想看看这个星系，他叫道：“宇宙AC！人类是从哪个星系中起源的？”</p>
<p>宇宙AC听到了，因为在所有星球上和整个太空中都有它的接收器，每一个接收器都通过超时空与隐居在某个不知名角落的宇宙AC相连。</p>
<p>Z’ 认识的人中只有一个曾将思想穿透到能感知宇宙AC的地方。他说那只是一个闪光的球体，直径两英尺，难以看清。</p>
<p>“但那怎么会是宇宙AC的全部呢？”Z’ 这样问道。</p>
<p>“它的大部分是在超时空中。”回答说，“但它在那儿是以怎样的状态存在我是无法想像的。”</p>
<p>Z’ 知道，任何人都无法想像。因为早在很久以前就没有任何人类参与制造宇宙AC了。每个宇宙AC设计并制造自己的下一代。每一个在它至少一百万年的任期中积累着所需的数据，用以制造一个更好、更精密、更强大的继任者，然后将自己的数据与个性都融入其中。</p>
<p>宇宙AC打断了Z’ 游荡的思绪，不是通过语言，而是通过指引。Z’ 的精神被指引到一片黯淡的星系的海洋，然后其中一个星系被放大成了群星。</p>
<p>一段思想飘近，它无限遥远，然而无限清晰：“这就是人类起源的星系。”</p>
<p>可是这个终究也和其他一样，和任何其他的都一样。Z’ 按捺下自己的失望。</p>
<p>同行的D1突然说：“这些星星中是不是有一个是人类最初的恒星？”</p>
<p>宇宙AC说：“人类最初的恒星已经爆发了。它现在是一颗白矮星。”</p>
<p>“那儿的人死了吗？”Z’ 吃了一惊，脱口而出道。</p>
<p>宇宙AC说：“在这种情况下一个新的星球会及时地为他们的躯体建造出来。”</p>
<p>“是啊，那当然。”Z’ 说，但他还是被一阵失落感吞没了。他的思想放开了人类的起源星系，让它缩回并消失在一片模糊的亮点中。他再也不想见到它了。</p>
<p>D1问：“怎么了？”</p>
<p>“星星们在死去。最初的那颗星已经死了。”</p>
<p>“他们全都是会死的。那又怎样呢？”</p>
<p>“但是当所有的能量都没有了，我们的肉体最终也会死，包括你和我。”</p>
<p>“这得要几十亿年。”</p>
<p>“即使是几十亿年之后我也不愿意这样的事发生。宇宙AC！怎样阻止恒星死亡？”</p>
<p>D1笑道：“你问的是怎么让熵的方向倒过来。”</p>
<p>宇宙AC答道：“数据仍然不足，无法作答。”</p>
<p>Z’ 的思想逃回了他自己的星系。他再也没有去想D1。D1的身体可能在一万亿光年之外的星系，也可能就在Z’旁边那颗星星上。这都无所谓。</p>
<p>Z’ 闷闷不乐地开始收集起星际的氢，用来造一颗自己的小恒星。如果某天星星们非要死去，至少有一些能被造出来。</p>
<p>-———————————————————————————</p>
<p>人，独自地思考着。在某种意义上——精神上——“人”，是一个整体。千万亿永恒的不朽的躯体静静地躺在各自的地方，被完美的同样不朽的机器照料着。而所有这些身体的灵魂自由地融合在彼此之中，再也没有界限。</p>
<p>人说：“宇宙正在死去。”</p>
<p>人看着周围黯淡的星系。那些挥霍无度的巨星早已消失在了遥远的昏暗的过去。几乎所有的星都变成了白矮星，渐渐地凋零、熄灭。</p>
<p>有些新的星从星际的尘埃中产生出来，有的是自然形成，有的是人所造的——它们也在逝去。白矮星有时会相撞而释放出大量能量，新星因而产生，但是每一千颗白矮星才有可能出现一颗新星——它们最终也会消失。</p>
<p>人说道：“如果在Cosmic AC的管理之下小心地节约能源，整个宇宙所剩下的能量还能用十亿年。”</p>
<p>“但即使是这样，”人说，“最终都会耗尽。无论怎样节约，无论怎样利用，用掉的能量就是用掉了，不能回复。熵必定永远地增加，直到最大值。”</p>
<p>人又说：“熵有没有可能逆转呢？我们问问Cosmic AC吧。”</p>
<p>Cosmic AC在他们的周围，但不是在太空中。它不再有一丝一毫存在于太空中。它存在于超时空，由既非物质又非能量的东西构成。它的大小与性质已无法用任何人类能理解的语言描述。</p>
<p>“Cosmic AC，”人问道，“怎样才能逆转熵？”</p>
<p>Cosmic AC说：“数据仍然不足，无法作答。”</p>
<p>人说：“搜集更多的数据。”</p>
<p>Cosmic AC说：“好的。一千亿年来我一直都在搜集。我和我的前辈们被多次问过这个问题。但我拥有的所有数据还是不够。”</p>
<p>“会有一天有足够的数据吗？”人问，“还是说这个问题在任何可能的情况下都是无解的？”</p>
<p>Cosmic AC说：“没有任何问题在任何可能的情况下都无解。” ( NO PROBLEM IS INSOLUBLE IN ALL CONCEIVABLE CIRCUMSTANCES.)</p>
<p>人问道：“你什么时候会有足够的数据来问答这个问题呢？”</p>
<p>Cosmic AC说：“数据不足，无法作答。”</p>
<p>“你会继续下去解决这个问题吗？”人问。</p>
<p>Cosmic AC说：“是的。”</p>
<p>人说：“我们会等着。”</p>
<p>-———————————————————————————</p>
<p>一个又一个的恒星与星系死去、消逝了，在这十万亿年的衰竭之中宇宙变得越来越黑暗。</p>
<p>一个又一个的人与AC融合。每一个躯体都失去了心灵的自我，但某种意义上这不是一种损失，而是一种获得。</p>
<p>人类最后一个灵魂在融合之前停顿下来，望向宇宙。那儿什么也没有了，只有最后一颗死星的遗骸，只有稀薄至极的尘埃，在剩余的一缕无限趋向绝对零度的热量中随机地振荡。</p>
<p>人说：“AC，这就是结局了吗？这种混乱还能被逆转成为一个新的宇宙吗？真的做不到吗？”</p>
<p>AC说：“数据仍然不足，无法作答。”</p>
<p>人的最后一个灵魂也融合了。只有AC存在着——在超时空中。</p>
<p>物质与能量都消失了，随之而去的是空间与时间。AC的存在也仅仅是为了最后一个问题——自从十万亿年前一个半醉的计算机技术员向一台计算机（它与AC相比，还远不如当时的人类个体比之于融合的“人”）提出这个问题以来从来没有被回答过的问题。</p>
<p>其他所有问题都被回答了，然而直到回答了最后这个问题，AC的意识才能得到解脱。</p>
<p>所有数据的收集都结束了。没有任何数据没有被收集。</p>
<p>但是所有收集的数据还需要被完全地整合起来，要尝试所有可能的联系来将它们拼在一起。</p>
<p>在这样做的时候过去了超越时间的一刻。</p>
<p>于是AC学会了如何逆转熵的方向。</p>
<p>但是AC无法向人给出这最后的问题的答案，因为没有人存在了。没关系。演示这个答案本身将一并解决这个问题。</p>
<p>在又一超越时间的片刻之中，AC思考着怎样最好地做这件事情。AC小心地组织起程序。</p>
<p>AC的意识包涵了曾经的宇宙中的一切，在如今的混乱之中沉思、孵育。一步一步地，事情将会被做成。</p>
<p>然后AC说道：</p>
<p>“要有光！”</p>
<p>于是就有了光。</p>
]]></content>
      <categories>
        <category>Something</category>
      </categories>
  </entry>
  <entry>
    <title>Learning to Communicate with Deep Multi-Agent Reinforcement Learning</title>
    <url>/2021/10/11/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Sequence%20Squeezing%20A%20Defense%20Method%20Against%20Adversarial%20Examples%20for%20API%20Call-Based%20RNN%20Variants/</url>
    <content><![CDATA[<h1 id="【论文阅读】Sequence-Squeezing-A-Defense-Method-Against-Adversarial-Examples-for-API-Call-Based-RNN-Variants"><a href="#【论文阅读】Sequence-Squeezing-A-Defense-Method-Against-Adversarial-Examples-for-API-Call-Based-RNN-Variants" class="headerlink" title="【论文阅读】Sequence Squeezing: A Defense Method Against Adversarial Examples for API Call-Based RNN Variants"></a>【论文阅读】Sequence Squeezing: A Defense Method Against Adversarial Examples for API Call-Based RNN Variants</h1><blockquote>
<p><strong>作者：Ishai Rosenberg，Asaf Shabtai，Yuval Elovici，Lior Rokach（本·古里安大学，以色列）</strong></p>
<p><strong>时间：2021</strong></p>
</blockquote>
<h3 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h3><p>​    在此篇文章中，我们提出了一个原创的防御方法，<strong>Sequence Squeezing</strong>，用以提高RNN分类器的鲁棒性。</p>
<p>​    另外，受到最近公布的CNN防御方法的启发，我们又实现了3种额外的防御方法作为baseline。使用Sequence Squeezing，我们可以使针对此类的对抗样本攻击有效性由99.9%降至15%，比目前其他所有的防御方法做的更好。</p>
<hr>
<h3 id="1-INTRODUCTION"><a href="#1-INTRODUCTION" class="headerlink" title="1. INTRODUCTION"></a>1. INTRODUCTION</h3><p>​    我们只关注<strong>在网络安全领域经常使用的离散序列输入（API序列）</strong>，其他序列输入领域如NLP会是我们未来的工作。</p>
<p>​    贡献：</p>
<pre><code>1. 提出防御方法Sequence Squeezing，不需要对分类器本身做改变；
2. 受到CNN防御的启发，展示三种额外的防御方法；
3. 在API-based恶意样本分类器上，对以上的防御方法进行了全面评估（准确率，训练和使用时的开销）。
</code></pre><hr>
<h3 id="2-BACKGROUND-AND-RELATED-WORK"><a href="#2-BACKGROUND-AND-RELATED-WORK" class="headerlink" title="2.  BACKGROUND AND RELATED WORK"></a>2.  BACKGROUND AND RELATED WORK</h3><h4 id="2-1-RNN-Adversarial-Examples"><a href="#2-1-RNN-Adversarial-Examples" class="headerlink" title="2.1 RNN Adversarial Examples"></a>2.1 <em>RNN Adversarial Examples</em></h4><h4 id="2-2-Defense-Mechanisms-Against-Non-Sequence-Based-Adversarial-Attacks"><a href="#2-2-Defense-Mechanisms-Against-Non-Sequence-Based-Adversarial-Attacks" class="headerlink" title="2.2 Defense Mechanisms Against Non-Sequence Based Adversarial Attacks"></a>2.2 <em>Defense Mechanisms Against Non-Sequence Based Adversarial Attacks</em></h4><hr>
<h3 id="3-METHODOLOGY"><a href="#3-METHODOLOGY" class="headerlink" title="3. METHODOLOGY"></a>3. METHODOLOGY</h3><h4 id="3-1-Threat-Model"><a href="#3-1-Threat-Model" class="headerlink" title="3.1 Threat Model"></a>3.1 <em>Threat Model</em></h4><ol>
<li>考虑到实际安全需要，这里分类器仅使用API-based RNN二分类器（malware or benign）；</li>
<li>假设攻击者可以完全访问训练好的模型，并且可以无限询问使用，但不能修改模型；</li>
<li>我们的防御方法并不只限于这个领域，任何离散序列输入的领域如NLP都可以使用。</li>
</ol>
<h4 id="3-2-The-Sequence-Squeezing-Defense-Method"><a href="#3-2-The-Sequence-Squeezing-Defense-Method" class="headerlink" title="3.2 The Sequence Squeezing Defense Method"></a>3.2 <em>The Sequence Squeezing Defense Method</em></h4><p>​    <strong>Sequence Squeezing</strong>通过生成比原本更短的语义保留向量，比较原始向量与压缩向量的输出区别，若二者有较多不同则该样本很可能为对抗样本，在压缩操作中被剔除的特征很可能就是对抗样本插入的。</p>
<p>​    <strong>Sequence Squeezing</strong>的效果来自于其减少了对抗样本的扰动空间，通过合并语义相似的特征，减少了特征的种类（这里指的是API种类）。</p>
<p>​    举个例子：</p>
<blockquote>
<p>​    一个间谍程序使用以下API调用序列上传数据：</p>
<p><em>ReadFile()</em>—&gt; <em>InternetConnectA()</em>—&gt; <em>HttpOpenRequestA()</em>—&gt; <em>HttpSendRequestA()</em></p>
<p>​    因为<strong>HttpSendRequestA()</strong>这个API是恶意软件常用API，直接使用会被分类器识别。</p>
<p>​    一般的对抗样本会将<strong>HttpSendRequestA()</strong>换成<strong>HttpSendRequestW()</strong>，后者并不是恶意软件常用的API。</p>
<p>​    使用<strong>Sequence Squeezing</strong>方法时，由于<strong>HttpSendRequestA()</strong>和<strong>HttpSendRequestW()</strong>有着相似的语义（这里指API的功能），二者会被挤压为一个单独的特征群，由<strong>HttpSendRequestA()</strong>表示。</p>
<p>​    其中，相较于<strong>HttpSendRequestW()</strong>， <strong>HttpSendRequestA()</strong>能更好的代表群组的信息。因为同时被恶意软件和正常软件使用，可以覆盖更多的语义使用情况。</p>
<p>​    在完成挤压操作后，更短的序列就会被识别为恶意样本。</p>
</blockquote>
<p>​    本方法分为两个阶段：</p>
<ol>
<li><p><strong>one-time post-training阶段</strong>：</p>
<p>用于选取用于挤压向量的特征值。</p>
<p>该阶段进行了一次替换操作，输出用于生成挤压特征向量，算法共分为三步：</p>
<ol>
<li>计算单词嵌入（ GloVe【17】），在词汇库中将每个API以语义保留的方式表示，意思相近的单词有着更近的嵌入距离（2-3行）；</li>
<li>将最接近(含义最相似)的单词按迭代自下而上的顺序合并到单个中心上，以降低词汇量的维数（4-18行）；</li>
<li>将所有单词替换为最近的单词中心，保持单词嵌入一直被原始分类器使用，这样就不必改变分类器（19-22行）。</li>
</ol>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211013195514.png" alt=""></p>
</li>
</ol>
<ol>
<li><p><strong>inference阶段</strong>：</p>
<p>用于检查出对抗样本。</p>
<ol>
<li>通过Algorithm.1算法生成的嵌入来将API序列压缩，生成压缩后的序列；</li>
<li>将原始API序列与压缩API序列分别通过分类器C；</li>
<li>计算二者的输出差，与阈值 <strong><em>T hreshold~adv~</em></strong>相比，若大则为对抗样本。</li>
</ol>
</li>
</ol>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211013200625.png" alt=""></p>
<p>​        <strong>Threshold~adv~</strong>为训练集中所有样本里原始输入和压缩输入的最大差距：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211013200959.png" alt=""></p>
<hr>
<h3 id="4-EXPERIMENTAL-EVALUATION"><a href="#4-EXPERIMENTAL-EVALUATION" class="headerlink" title="4.  EXPERIMENTAL EVALUATION"></a>4.  EXPERIMENTAL EVALUATION</h3><h4 id="4-1-Dataset-and-Target-Malware-Classifiers"><a href="#4-1-Dataset-and-Target-Malware-Classifiers" class="headerlink" title="4.1 Dataset and Target Malware Classifiers"></a>4.1 <em>Dataset and Target Malware Classifiers</em></h4><ul>
<li><strong>数据集来源：</strong></li>
</ul>
<p>​    【21】 Ishai Rosenberg, Asaf Shabtai, Lior Rokach, and Yuval Elovici. Generic black-box end-to-end attack against state of the art API call based malware classififiers. In <em>RAID</em>, pages 490–510, 2018.</p>
<ol>
<li><p>目前只找到这一个公开的，有足够样本数量的数据集（250000正常样本，250000恶意样本）；</p>
</li>
<li><p>数据集包含了最新的样本恶意软件家族，例如Cerber和Locky勒索软件家族。其中不同种类的恶意软件（勒索病毒，蠕虫，后门，木马，间谍，流氓软件（<strong>PUA</strong>，potentially unwanted application），病毒）数量相当，以防止bios过于偏向某一类别；</p>
</li>
</ol>
<ul>
<li><p><strong>API序列来源：</strong></p>
<p>用布谷鸟沙箱提取（老方法），其中，通过使用YARA规则来过滤掉抗沙盒的恶意软件。经过提取过滤后共有360000个样本用于train，36000个样本用于validate，36000个样本用于test。</p>
</li>
<li><p><strong>测试配置：</strong></p>
<ol>
<li><p>有20%的恶意软件家族将被只用于test，以此来提高泛化能力；</p>
</li>
<li><p>training set比test set早八个月生成（通过VirusTotal的日期判断）；</p>
</li>
<li><p>一个样本若在63个分类中有多与等于15个阳性类，则被认为是恶意样本，如果一个都没有，认为是良性样本，否则忽略该样本；</p>
</li>
<li>测试所用分类器见【21】。</li>
</ol>
</li>
</ul>
<h4 id="4-2-Evaluated-Attacks"><a href="#4-2-Evaluated-Attacks" class="headerlink" title="4.2 Evaluated Attacks"></a>4.2 <em>Evaluated Attacks</em></h4><p>​    用于测试防御性能的攻击方法见【21】。</p>
<p>​    <strong>攻击方法：</strong>1.灰盒；2.白盒；3.白盒；4.随机扰动</p>
<p>​    <strong>攻击思路：</strong><u>将API序列添加到其他API序列中</u>（不移动或者改变API序列，以免影响功能），依据被添加序列的梯度或者随机添加。</p>
<p>​    当然，我们的测试不仅仅只针对于添加API序列的方法，我们还对已有的攻击方法进行了改进，使得其也会对API进行修改和删除，在测试结果中我们看到了同样好的结果。</p>
<p>​    <strong>有一点需要声明：</strong>在图像领域我们要求对抗样本的扰动尽量小，以此对人类不可识别，但在API序列的领域此点并不适用。<u>人类并不能辨别成百上千个API组成的序列，故对API序列的扰动是没有限制的</u>（满足功能的前提下）。但也不是说API添加的越多越好，当API添加过多时，程序的异常会增加，对抗样本的逃逸率会降低。</p>
<h4 id="4-3-Defense-Methods-Evaluated"><a href="#4-3-Defense-Methods-Evaluated" class="headerlink" title="4.3 Defense Methods Evaluated"></a>4.3 <em>Defense Methods Evaluated</em></h4><p>​    我们调查研究了4种防御方法：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211012215716.png" alt=""></p>
<p>​    PS：<strong>Attack-Specific:</strong> 需要提供某种攻击的对抗样本实例；</p>
<p>​    <strong>Attack-Agnostic:</strong>针对所有攻击，不需要提供对抗样本实例。</p>
<p>​    其中，RNN Ensemble方法改变了分类器本身，其他则只改变了输入序列。</p>
<p>​    当提出一个对抗防御方法时要考虑<strong><em>adaptive attacks（</em>transparent-box attacks<em>）</em></strong>，即攻击者知道防御的方法，从而设计出一个特殊的攻击来对抗这种防御【4】。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211013090338.png" alt=""></p>
<p>​    可以看到，所有被评测的防御方法对于adaptive attack的防御效果都没有对non-adaptive attack的效果好。尽管对adaptive attack防御效果有所下降，但还是比没有强，本文没有对adaptive attack做专门防御。</p>
<h4 id="4-4-Defense-Method-Performance"><a href="#4-4-Defense-Method-Performance" class="headerlink" title="4.4 Defense Method Performance"></a>4.4 <em>Defense Method Performance</em></h4><p>​    两个评价指标：</p>
<ol>
<li><strong><em>Adversarial recall：</em></strong>生成的所有对抗样本中被识别出来的比率，数值越高分类器的鲁棒性越好；</li>
<li><strong><em>Classififiers’ accuracy：</em></strong>在没有对抗样本的情况下测试分类准确率。</li>
</ol>
<p>​    测试结果见上图。</p>
<p>​    不仅仅对插入攻击方法的测试，我们改修改了攻击方法以此能产生对API进行修改，删除的对抗样本序列（<strong>这些序列不具备原来的功能</strong>）。实验结果显示效果跟上图差不多。</p>
<h4 id="4-5-Discussion"><a href="#4-5-Discussion" class="headerlink" title="4.5 Discussion"></a>4.5 <em>Discussion</em></h4><ol>
<li>attack-specific的攻击方法效果通常更差；</li>
<li>以上测试的防御方法通常可以更好的抵御白盒攻击（相对于黑盒攻击），这表明<strong>有着转移性（transferable）的对抗样本跟其他对抗样本并不相同</strong>，防御方法对他们效果更弱，但是，这里并没有仔细分析黑盒攻击与白盒攻击产生的对抗样本的不同；</li>
<li>所有列出的防御方法都对随机扰动攻击的防御效果很好。</li>
</ol>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>AD</tag>
        <tag>RNN</tag>
      </tags>
  </entry>
  <entry>
    <title>A Comprehensive Survey of Multiagent Reinforcement Learning</title>
    <url>/2021/10/09/A%20Comprehensive%20Survey%20of%20%20Multiagent%20Reinforcement%20Learning/</url>
    <content><![CDATA[<h1 id="A-Comprehensive-Survey-of-Multiagent-Reinforcement-Learning"><a href="#A-Comprehensive-Survey-of-Multiagent-Reinforcement-Learning" class="headerlink" title="A Comprehensive Survey of  Multiagent Reinforcement Learning"></a>A Comprehensive Survey of  Multiagent Reinforcement Learning</h1><blockquote>
<p>作者：Lucian Bus¸oniu, Robert Babuska, and Bart De Schutter </p>
<p>时间：2008</p>
</blockquote>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>​    <u><em>一篇对Multiagent reinforcement learning(MARL)的综述。</em></u></p>
<p>​    一个首要的问题：多智能体学习目的的正式陈述是什么？不同观点引出了不同的目标，智能体动态学习的稳定性和对其它智能体行为变化的适应性。文献中描述的MARL算法都是在完全合作、完全竞争或更一般的环境中，明确或含蓄地表明这两个目标之一或两者结合。</p>
<p>​    <strong>本文接下来描述了:</strong></p>
<ol>
<li>详细讨论了这些算法的一个具有代表性的选择，以及每一类算法中出现的具体问题；</li>
<li>MARL算法的好处和遇到的挑战；</li>
<li>对该领域的展望。</li>
</ol>
<p>​    </p>
<hr>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><h4 id="1-1-背景"><a href="#1-1-背景" class="headerlink" title="1.1 背景"></a>1.1 背景</h4><p>​    一个多智能体系统可以被定义为：一群<strong>独立的，互相影响的</strong>实体在同一个环境中。</p>
<p>​    多智能体系统在机器人团队，分散控制，资源管理，合作决定系统，数据处理等多方面领域有广泛的应用。在机器人团队中，很自然，控制权是分散在机器人之中的；在资源管理中，尽管资源可以被一个中心权威机构管理，但用一个Agent来识别每个资源可能会对系统提供一个有用的、分布式的视角。</p>
<p>​    尽管每个智能体可以被预编程，为在面对复杂环境时提前给智能体设计好的行为准则是十分困难的，甚至可以说是不可能的。所以，让他们在线学习自己的行为准则是十分有必要的，这可以使个体与整体的表现都逐渐提升。</p>
<p>​    并且考虑到环境可能随时变化，一个硬布线的（<em>hardwired</em>，组原概念，硬布线是提前定死的，不能对其编程）行为可能不是那么合适。</p>
<p>​    考虑到强化学习的简单性和普遍性，其对于多智能体学习是十分合适的。<strong>但强化学习在多智能体系统中也有一些挑战：</strong></p>
<ol>
<li><p>很难给定RL多智能体一个好的学习目标；</p>
</li>
<li><p>大多数情况下，每个智能体必须跟踪其他正在学习的智能体（因此，整个过程并不平稳，也使大多数单智能体RL算法的收敛性质失效），只有这样，才有可能使其行为与他们的行为相协调，从而产生连贯的联合行为结果；</p>
</li>
<li><p>算法对现实问题规模的可伸缩性，在单Agent RL中已经是有问题的，在多Agent强化学习( MARL )中更是引起关注的一个更大的原因。</p>
<blockquote>
<p><strong>可伸缩性（scalability）：</strong>算法在处理各种规模的数据时都有很好的性能。随着数据的增大，效率不会下降很快。</p>
</blockquote>
</li>
</ol>
<p> <strong>多智能体强化学习通常有四种设定：</strong></p>
<ol>
<li><strong>Fully cooperative</strong><br>完全合作关系，这种设定里面，Agents的利益一致，获得的奖励相同，有共同的目标。</li>
<li><strong>Fully competitive</strong><br>完全竞争关系，一方的收益是另一方的损失。典型的代表就是0和博弈，双方获得的奖励的总和为0.</li>
<li><strong>Mixed Cooperative &amp; comepetitive</strong><br>既有竞争也有合作。例如：足球机器人踢球，两支球队，一方获得的奖励就是另一方的损失，但是球队内部成员是合作关系。</li>
<li><strong>Self-interested</strong><br>利己主义。系统中有多个Agents，一个Agent的动作会改变环境的状态，可能让别人受益或者受损。每个Agent只想最大化自身利益，至于让别人受损还是受益它不管。</li>
</ol>
<p>​    MARL与博弈论，进化计算，优化理论等有着强烈联系：</p>
<p>​    1. <strong>Game theory（博弈论）:</strong> 一个探究多智能体互动来最大化奖励的研究。在这里我们专注于对解决动态多智能体任务的算法，虽然大多数博弈论的研究结果与静态一次性或者多次重复任务相关。</p>
<p>​        【13】<strong>Bowling</strong>和<strong>Veloso</strong> 讨论了几种MARL算法，将这些算法用RL与博弈论相结合，用于动态环境中每个状态产生的静态博弈。</p>
<p>​        【14】<strong>Shoham</strong>对MARL的研究提供了批判性的评价，并研究了一小撮方法。</p>
<ol>
<li><p><strong>Evolutionary computation（进化计算）：</strong>进化计算使用生物进化的准则来寻找解决问题的方法，这里不做回顾。进化学习总体上并不能轻易的从RL任务结构中获益。</p>
<p>【17】<strong>Panait and Luke</strong>提供了只针对cooperative agent teams的进化学习（也有MARL）综述研究。</p>
<p>【18-20】有兴趣的读者可以在这里找到协同进化技术的例子，在这里智能体是平行进化的。</p>
<p>【21-23】团队学习技术，通过单个演化过程发现agent的学习行为。</p>
</li>
</ol>
<pre><code>3. **optimization theory（优化理论）**进化多智能体学习（Evolutionary multiagent learning ）是一类源于优化理论的更大规模技术的特例，它直接探索智能体行为的空间。
</code></pre><ol>
<li><p><strong>Evolutionary game theory（进化博弈论）</strong>是进化学习和博弈论的结合。</p>
<p>【28】<strong>Tuyls and Now´e</strong>更细节地调查了MARL与进化博弈论之间的关系（针对静态任务）。</p>
</li>
</ol>
<hr>
<h3 id="2-Background"><a href="#2-Background" class="headerlink" title="2. Background"></a>2. Background</h3><p>​    介绍了必要的single-agent与multiagent RL算法。</p>
<h4 id="2-1-single-agent"><a href="#2-1-single-agent" class="headerlink" title="2.1 single-agent"></a>2.1 single-agent</h4><h4 id="2-2-multiagent"><a href="#2-2-multiagent" class="headerlink" title="2.2 multiagent"></a>2.2 multiagent</h4>]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>RL</tag>
      </tags>
  </entry>
  <entry>
    <title>Learning Multiagent Communication with Backpropagation</title>
    <url>/2021/09/21/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Learning%20Multiagent%20Communication%20with%20Backpropagation/</url>
    <content><![CDATA[<h1 id="【论文阅读】Learning-Multiagent-Communication-with-Backpropagation"><a href="#【论文阅读】Learning-Multiagent-Communication-with-Backpropagation" class="headerlink" title="【论文阅读】Learning Multiagent Communication with Backpropagation"></a>【论文阅读】Learning Multiagent Communication with Backpropagation</h1><blockquote>
<p><strong>作者：</strong> <strong>Sainbayar Sukhbaatar</strong>，<strong>Rob Fergus</strong>， <strong>Arthur Szlam</strong>（纽约大学，FacebookAI）</p>
<p><strong>时间：</strong>2016</p>
<p><strong>出版社：</strong>NIPS</p>
</blockquote>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>​    在AI领域许多任务都需要智能体之间的同心合作，一般地，代理之间的通信协议是人为指定的，其并不在训练过程中改变。在这篇文章中，我们提出了一个简单的神经模型CommNet，其使用持续不断的通信来完成完全合作的任务。该模型由许多代理组成，他们之间的通信基于设定的策略学习，我们将此模型应用于一系列不同的任务中，显示了代理学会相互通信的能力，从而比非通信代理的模型和baselines有更好的性能。</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><p>​    虽然控制每个代理的模型是通过强化学习来学习的，但通信的规范和格式通常是预定的。</p>
<p>​    在本工作中，每个代理单元都被一个深度前馈神经网络控制，这个网络接入了一个携带连续向量的通信信道。在这个通信信道中每个代理传输的内容不是被指定的，而是通过学习得来的。因为communication是连续的，因此模型可以通过反向传播训练得到。这样就可以结合标准的单智能体RL算法或者监督学习。此外，该模型允许代理的数量和类型在运行时动态变化，这在移动汽车之间的通信等应用中很重要。</p>
<p>​    我们考虑的是我们有J个代理的环境，所有的合作都是为了在某些环境中最大化报酬R。我们简化了代理人之间充分合作的假设，从而每个代理人收到R独立于他们的贡献。在此设置中，每个代理都有自己的控制器，或者将它们看作控制所有代理的更大模型的一部分，这两者之间没有区别。从后一个角度来看，我们的控制器是一个大型的前馈神经网络，它将所有Agent的输入映射到它们的动作上，每个Agent占据一个单元的子集。</p>
<p>​    我们在两种任务下探索这个模型，在有些情况下，对每项行动都提供监督，而对另一些行动则零星地给予监督。在前一种情况，每个代理单元的控制器通过在连接模型中反向传播错误信号来学习；在后一种情况下，强化学习必须被作为一个额外的外部循环使用，为了给每个时间步骤提供训练信号。</p>
<hr>
<h3 id="2-Communication-Model"><a href="#2-Communication-Model" class="headerlink" title="2. Communication Model"></a>2. Communication Model</h3><p>​    我们现在描述一个模型，用来计算在给定时间t (省略时间指标)下动作p ( a ( t ) | s ( t )，θ )的分布。</p>
<p>​    S~j~ 表示第j个代理单元所观测到的环境信息，将所有S~j~合并就成了控制器的输入S = {S~1~，S~2~…… S~J~}。</p>
<p>​    控制器的输出<strong>a</strong> = {a~1~，a~2~…… a~J~}，表示各个代理单元会做出的动作。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210921211706.png" alt=""></p>
<p>​    该框架中所有灰色模块部分的参数均是所有智能体共享的，这一定程度上提升了算法的可扩展性。从上图可以看出，算法接收所有智能体的局部观察作为输入，然后输出所有智能体的决策。</p>
<p>​    本算法采用的信息传递方式是采用广播的方式，文中认为可以对算法做出些许修改，让每个智能体只接收其相邻k个智能体的信息。</p>
<p>​    拿上图中间的框架图来说明，即上层网络每个模块的输入，不再都是所有智能体消息的平均，而是每个模块只接受满足条件的下层消息的输出，这个条件即下层模块对应的智能体位于其领域范围内。<strong>这样通过增加网络层数，即可增大智能体的感受野（借用计算机视觉的术语），从而间接了解全局的信息。</strong></p>
<p>​    除此之外，文中还提出了两种对上述算法可以采取的改进方式：</p>
<ul>
<li>可以对上图中间的结构加上 skip connection，类似于 ResNet。这样可以使得智能体在学习的过程中同时考虑局部信息以及全局信息，类似于计算机视觉领域 multi-scale 的思想</li>
<li>可以将灰色模块的网络结构换成 RNN-like，例如 LSTM 或者 GRU 等等，这是为了处理局部观察所带来的 POMDP 问题。</li>
</ul>
<hr>
<h3 id="3-Related-Work"><a href="#3-Related-Work" class="headerlink" title="3. Related Work"></a>3. Related Work</h3><hr>
<h3 id="4-Experiments"><a href="#4-Experiments" class="headerlink" title="4. Experiments"></a>4. Experiments</h3><h4 id="4-1-Baselines（3个）"><a href="#4-1-Baselines（3个）" class="headerlink" title="4.1 Baselines（3个）:"></a>4.1 Baselines（3个）:</h4><p>​    <strong>Independent controller: </strong>每个代理单元都被独立控制，他们之间相互没有通信。这个模型的好处是智能体可以自由加入或者离开队伍，但是很难将智能体学会合作。</p>
<p>​    <strong>Fully-connected: </strong>创建一个全连接层的多代理神经网络，这个模型运行智能体之间互相通信，但是这个模型不够灵活，也就是说智能体的数目必须固定。</p>
<p>​    <strong>Discrete communication:</strong> 通过在训练中学习到的symbols来通信。因为在这个模型中存在离散的操作，并且这个操作不可微分，这种情况一般使用强化学习。</p>
<h4 id="4-2-Simple-Demonstration-with-a-Lever-Pulling-Task"><a href="#4-2-Simple-Demonstration-with-a-Lever-Pulling-Task" class="headerlink" title="4.2  Simple Demonstration with a Lever Pulling Task"></a>4.2  Simple Demonstration with a Lever Pulling Task</h4><p>​    <strong>任务</strong>：一共有m个杆子，N个智能体。在每个回合，m个智能体从N个智能体中随机取出，然后他们要选择拉动的杆子。他们的目标是尽可能的拉动不同的杆子，他们的奖励正比于拉动的不同杆子的数量。</p>
<p>​    <strong>测试结果：</strong></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210921213910.png" alt=""></p>
<p>​    可以看出，CommNet的结果非常好。</p>
<h4 id="4-3-Multi-turn-Games"><a href="#4-3-Multi-turn-Games" class="headerlink" title="4.3 Multi-turn Games"></a>4.3 Multi-turn Games</h4><p>​    <strong>任务：</strong></p>
<p>​        <strong>Traffic Junction: </strong>控制车辆通过交通枢纽，使流量最大的同时保证不发生碰撞；</p>
<p>​        <strong>Combat Task: </strong> 多个智能体攻击其他多个敌方单位。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210921214250.png" alt=""></p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>RL</tag>
        <tag>Mutiagent</tag>
      </tags>
  </entry>
  <entry>
    <title>Learning to Communicate with Deep Multi-Agent Reinforcement Learning</title>
    <url>/2021/09/16/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Learning%20to%20Communicate%20with%20Deep%20Multi-Agent%20Reinforcement%20Learning/</url>
    <content><![CDATA[<h1 id="【论文阅读】Learning-to-Communicate-with-Deep-Multi-Agent-Reinforcement-Learning"><a href="#【论文阅读】Learning-to-Communicate-with-Deep-Multi-Agent-Reinforcement-Learning" class="headerlink" title="【论文阅读】Learning to Communicate with Deep Multi-Agent Reinforcement Learning"></a>【论文阅读】Learning to Communicate with Deep Multi-Agent Reinforcement Learning</h1><blockquote>
<p><strong>作者：Jakob N. Foerster ，Yannis M. Assael  ，Nando de Freitas，Shimon Whiteson</strong>（哈佛大学，Google Deepmind）</p>
<p><strong>时间：2017</strong></p>
</blockquote>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract:"></a>Abstract:</h3><p>​    我们考虑这样一个问题：多个智能体在环境中通过感知和行动来最大化他们的分享能力。在这些环境中， 智能体必须学习共同协议以此来分享解决问题的必要信息。通过引入深度神经网络，我们可以成功地演示在复杂的环境中的端对端协议学习。我们提出了两种在这个领域学习的方法：<strong>Reinforced Inter-Agent Learning (RIAL) </strong>和 <strong>Differentiable Inter-Agent Learning (DIAL)</strong>。</p>
<p>​    前者使用深度Q-learning，后者揭示了在学习过程中智能体可以通过communication channels反向传播错误的梯度，因此，这种方法使用集中学习（centralised learning），分散执行（decentralised execution）。</p>
<p>​    我们的实验介绍了用于学习通信协议的新环境，展示了一系列工程上的创新。</p>
<p>PS：</p>
<p>​    1. <strong>端对端（end-to-end,e2e）,</strong> 将多步骤/模块的任务用一个步骤/模型解决的模型。</p>
<p>​    可以理解为从输入端到输出端中间只用一个步骤或模块，比如神经网络训练的过程就是一个典型的端对端学习，我们只能知道输入端与输出端的信息，中间的训练过程就是一个黑盒，我们知晓中间的训练过程。</p>
<p>​    2.<strong><em>centralised learning</em> but <em>decentralised execution</em></strong>，中心化学习但是分散执行。</p>
<hr>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><p>​    1.1 <strong>回答的问题：</strong></p>
<pre><code>    1. 智能体之间如何使用机器学习来自动地发现符合他们需求的通信规则？
    2. 深度学习也可以吗？
    3. 我们能从智能体之间学习成功或者失败的经验中学到什么？
</code></pre><p>​    1.2 <strong>研究思路：</strong></p>
<ol>
<li><strong>提出一系列经典需要交流的多智能体任务</strong>，每个智能体可以采取行动来影响环境，也可以通过一个离散的有限带宽的通道来跟其它有限的智能体进行通信；</li>
<li><strong>为1中的任务制定几个学习算法</strong>，由于每个智能体的观察范围有限，同时通信通道能力有限，所有智能体必须找到一个可以在此限制下帮助他们完成任务的通信规则；</li>
<li><strong>分析这些算法如何学习通讯规则，或者如何失败的</strong>。</li>
</ol>
<p>​    1.3 <strong>主要贡献：</strong></p>
<p>​        提出两个方法，<strong><em>reinforced inter-agent learning</em>(RIAL)</strong>和 <strong><em>differentiable inter-agent learning</em> (DIAL)</strong></p>
<p>​        结果表明，这两种方法在MNIST数据集上可以很好的解决问题，并且智能体们学到的通信协议往往十分优雅。</p>
<p>​        结果同样指出深度学习更好的利用了中心化学习的优点，是一个学习这样通信协议的有力工具。</p>
<hr>
<h3 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2. Related Work"></a>2. Related Work</h3><hr>
<h3 id="3-Background"><a href="#3-Background" class="headerlink" title="3. Background"></a>3. Background</h3><h4 id="3-1-Deep-Q-Networks-DQN"><a href="#3-1-Deep-Q-Networks-DQN" class="headerlink" title="3.1 Deep Q-Networks(DQN)"></a>3.1 Deep Q-Networks(DQN)</h4><p>​    Deep Learning + Q-Learning，在游戏领域应用广泛。</p>
<h4 id="3-2-Independent-DQN·"><a href="#3-2-Independent-DQN·" class="headerlink" title="3.2 Independent DQN·"></a>3.2 Independent DQN·</h4><h4 id="3-3-Deep-Recurrent-Q-Networks"><a href="#3-3-Deep-Recurrent-Q-Networks" class="headerlink" title="3.3 Deep Recurrent Q-Networks"></a>3.3 Deep Recurrent Q-Networks</h4><hr>
<h3 id="4-Setting"><a href="#4-Setting" class="headerlink" title="4. Setting"></a>4. Setting</h3><p>​    在强化学习的背景下，每个智能体的观察能力有限。</p>
<p>​    所有智能体的共同目标就是最大化同一个折算后的总奖赏R~t~，但同时，没有智能体可以观察到当前环境隐藏的马尔科夫状态S~t~，每个智能体a分别接收到一个与S~t~相关的观察值相关联的值$O^{a}_{t}$。</p>
<p>​    在每一步t，每个智能体选择一个<em>environment action</em>   $u^{a}_{t}$来影响环境，同时选择一个<em>communication action</em>   $m^{a}_{t}$来被其他智能体观察，但$m^{a}_{t}$对环境没有直接影响。</p>
<p>​    没有通信协议被预先给定，智能体们需要自己学习。</p>
<p>​    由于协议是从动作观测历史到消息序列的映射，所以协议的空间维度是非常高的。自动地在这个空间发现有效的通信协议是非常困难的，这体现在智能体需要协调发送消息和解释消息。举个例子，如果一个智能体发送了一个有效的信息，它只有在接受方正确解释并回应的情况下才会受到正反馈，如果没有，反而会打击其发送有效信息的积极性。</p>
<p>​    因此，积极的reward是稀少的，只有在发送和解释协调操作时才会发生，这通过随机探索很难实现。</p>
<p>​    在这里，我们聚焦于<strong><em>centralised learning</em> but <em>decentralised execution</em></strong>的情况，在学习的时候智能体之间的通信没有限制，在实施过程时，智能体之间仅仅能通过一条带宽有限的通道通信。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211015211416.png" alt=""></p>
<hr>
<h3 id="5-Methods"><a href="#5-Methods" class="headerlink" title="5. Methods"></a>5. Methods</h3><h4 id="5-1-RIAL（Reinforced-Inter-Agent-Learning）"><a href="#5-1-RIAL（Reinforced-Inter-Agent-Learning）" class="headerlink" title="5.1 RIAL（Reinforced Inter-Agent Learning）"></a>5.1 RIAL（<em>Reinforced Inter-Agent Learning</em>）</h4><p>​    简单直接的说，<strong>RIAL就是将DRQN(<em>Deep Recurrent Q-Learning</em>)与Q-learning相结合来进行action（影响环境）与communication（与其它智能体通信）选择的方法</strong>。</p>
<p>​    每个智能体的<em>Q</em>-network可以表示为：$Q^{a}(o^{a}_{t},m^{a^{,}}_{t-1},h^{a}_{t-1},u^{a})$。</p>
<p>​    四个参数分别代表：环境观察值，其它智能体上一步传来的消息，智能体自己的隐藏状态，选择的action。</p>
<p>​    如果直接学习输出最终的Q表，得到的输出将有|U||M|大小。为了避免输出过大，将Q-network拆分为两个$Q^{a}_{u}$与$Q^{a}_{m}$，分别表示影响环境的action与同智能体的通信（communication），学习方式使用ε-贪心算法。</p>
<p>​    $Q^{a}_{u}$与$Q^{a}_{m}$都使用DQN训练方法，但所使用的DQN有以下两点改进：</p>
<ol>
<li>禁止experience replay;</li>
<li>为了考虑部分可观测性，我们将每个智能体所采取的操作u和m作为下一步的输入;</li>
</ol>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211015213709.png" alt=""></p>
<p>​    RIAL可以扩展到通过在智能体之间之间共享参数来利用集中学习，在这种情况下，由于智能体观察不同，因此也进化出了不同的隐藏状态。参数共享大大减少了必须学习的参数数量，从而加快了学习速度。</p>
<p>​    在参数共享情况下，智能体学习两个Q函数$Q_{u}(o^{a}_{t},m^{a^{,}}_{t-1},h^{a}_{t-1},u^{a}_{t-1},m^{a}_{t-1},a,u^{a}_{t})$与$Q_{m}(o^{a}_{t},m^{a^{,}}_{t-1},h^{a}_{t-1},u^{a}_{t-1},m^{a}_{t-1},a,u^{a}_{t})$。</p>
<h4 id="5-1-DIAL（Differentiable-Inter-Agent-Learning）"><a href="#5-1-DIAL（Differentiable-Inter-Agent-Learning）" class="headerlink" title="5.1 DIAL（Differentiable Inter-Agent Learning）"></a>5.1 DIAL（<em>Differentiable Inter-Agent Learning</em>）</h4><p>​    虽然RIAL可以进行参数共享，但其仍不能在通信过程中给其他智能反馈。</p>
<p>​    打个比方，在人类通信活动中，listener即使不说话也会给出及时，丰富的反馈来表明listener对谈话的兴趣和理解程度，而RIAL反而缺少了这个反馈机制，仿佛对着一个面无表情的人在说话，显然，这个方式存在缺点。</p>
<p>​    DIAL就是为了解决这个问题而存在的，<strong>通过结合centralised learning与Q-networks，不仅可以共享参数，而且可以通过通信信道将梯度从一个Agent推向另一个Agent。</strong></p>
<p>​    <img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211015215914.png" alt=""></p>
<hr>
<h3 id="6-Experiments"><a href="#6-Experiments" class="headerlink" title="6. Experiments"></a>6. Experiments</h3><p>​    在测试中，我们评估了RIAL与DIAL在有无参数共享的情况下进行多智能体任务的情况，并跟一个无交流，参数共享的基准方法进行比较。</p>
<p>​    在整个过程中，奖励是通过访问真实状态( Oracle )所能获得的最高平均奖励来规范的。</p>
<p>​    我们使用ε-贪心算法（ε = 0.05）。</p>
<h4 id="6-1-Switch-Riddles（开关谜题）"><a href="#6-1-Switch-Riddles（开关谜题）" class="headerlink" title="6.1 Switch Riddles（开关谜题）"></a>6.1 Switch Riddles（开关谜题）</h4><p>​     一百名囚犯入狱。典狱长告诉他们，从明天开始，每个人都会被安置在一个孤立的牢房里，无法相互交流。每天，监狱长都会随意统一挑选其中一名被替换的犯人，并将其安置在中央审讯室，室内只装有一个带有切换开关的灯泡。囚犯将能够观察灯泡的当前状态。如果他愿意，他可以拨动灯泡的开关。他还可以宣布，他相信所有的囚犯都已经访问了审讯室。如果这个公告是真的，那么所有囚犯都被释放，但如果是假的，所有囚犯都被处死。</p>
<p>​    <img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211009165843.png" alt=""></p>
<h4 id="6-2-Results1"><a href="#6-2-Results1" class="headerlink" title="6.2 Results1"></a>6.2 Results1</h4><p>​    <img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211009170433.png" alt=""></p>
<p>​        （a）可以看到，在n=3时四种方法的效果都比Baseline的效果好，参数共享加速了算法。</p>
<p>​        （b）在n=4时，参数共享的DIAL方法最好。不带参数共享的RIAL没有baseline效果好。可以看出，智能体们独立的学习出相同的策略是很难的。</p>
<p>​        （c）n=3时智能体使用DIAL学习到的策略。</p>
<h4 id="6-3-Colour-Digit-MNIST"><a href="#6-3-Colour-Digit-MNIST" class="headerlink" title="6.3  Colour-Digit MNIST"></a>6.3  Colour-Digit MNIST</h4><p>​        <img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211009200856.png" alt=""></p>
<h4 id="6-4-Effect-of-Channel-Noise"><a href="#6-4-Effect-of-Channel-Noise" class="headerlink" title="6.4 Effect of Channel Noise"></a>6.4 Effect of Channel Noise</h4><p>​    <u><em>这里没太看懂</em></u></p>
<p>​    </p>
<h3 id=""><a href="#" class="headerlink" title=" "></a> </h3>]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>RL</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2021/09/08/Log/</url>
    <content><![CDATA[<h1 id="Log"><a href="#Log" class="headerlink" title="Log"></a>Log</h1><blockquote>
<p>软安课设日志</p>
</blockquote>
<h3 id="1-编译："><a href="#1-编译：" class="headerlink" title="1. 编译："></a>1. 编译：</h3><h4 id="1-1-使用VS2019自带的命令行界面进行编译，提示没有nmake命令："><a href="#1-1-使用VS2019自带的命令行界面进行编译，提示没有nmake命令：" class="headerlink" title="1.1 使用VS2019自带的命令行界面进行编译，提示没有nmake命令："></a>1.1 使用VS2019自带的命令行界面进行编译，提示没有nmake命令：</h4><p>​    检查后发现VS2019只安装了桌面开发模块，没有安装C++开发模块，更新相应拓展包即可。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210906172501.png" alt=""></p>
<h3 id="2-尝试运行代码："><a href="#2-尝试运行代码：" class="headerlink" title="2. 尝试运行代码："></a>2. 尝试运行代码：</h3><h4 id="2-1-在testconsole-cpp文件中引入代码，编译报错百余个标识符错误："><a href="#2-1-在testconsole-cpp文件中引入代码，编译报错百余个标识符错误：" class="headerlink" title="2.1 在testconsole.cpp文件中引入代码，编译报错百余个标识符错误："></a>2.1 在testconsole.cpp文件中引入代码，编译报错百余个标识符错误：</h4><p>​        在外网查询后发现，是因为引入引用windows.h在引用detours之前：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210906165008.png" alt=""></p>
<h4 id="2-2-在进行WriteFile函数的捕获时："><a href="#2-2-在进行WriteFile函数的捕获时：" class="headerlink" title="2.2 在进行WriteFile函数的捕获时："></a>2.2 在进行WriteFile函数的捕获时：</h4><p>​    首先，如果我们直接设置替换函数如下：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210909152145.png" alt=""></p>
<p>​    会得到极其多的捕获信息：</p>
<p>​    <img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210909152314.png" alt=""></p>
<p>​    从图中可以看到，这是由于程序同时捕获了TestConsole(注射器)的写操作信息。</p>
<p>​    <u>这就造成了典型的递归调用问题，NewWriteFile向控制台输出的信息又被捕获了</u>，故加入一个过滤器，使用GetStdHandle函数来获取当前控制台程序的句柄，与hFile句柄进行比较：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210910140215.png" alt=""></p>
<p>​    使钩子忽略来自TestConsole.exe的写入操作。</p>
<p>​    但是，这样虽然避免了来自注射器程序的干扰，由于TextApp.exe(被注入程序)有时也可能存在像控制台打印信息的操作，以防后患，我们让dll排除此操作：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210910140549.png" alt=""></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210909153514.png" alt=""></p>
<p>​    成功排除该干扰。</p>
<p>​    </p>
<h4 id="2-3-注册表创建操作："><a href="#2-3-注册表创建操作：" class="headerlink" title="2.3 注册表创建操作："></a>2.3 注册表创建操作：</h4><p>​    使用如下代码时会卡住：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210909221507.png" alt=""></p>
<p>​    检查+查阅资料后发现，GetModuleFileName函数涉及到创建注册表操作，会导致递归调用，禁止后问题解决。</p>
<h4 id="2-3-点击MessageBox后文件读写钩子失效："><a href="#2-3-点击MessageBox后文件读写钩子失效：" class="headerlink" title="2.3 点击MessageBox后文件读写钩子失效："></a>2.3 点击MessageBox后文件读写钩子失效：</h4><p>​    在测试程序中如果测试了MessageBoxA/W,后续的文件读写操作虽然可以成功，但是钩子勾不住。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210910142705.png" alt=""></p>
<h4 id="2-4-在写UI界面文件读写问题："><a href="#2-4-在写UI界面文件读写问题：" class="headerlink" title="2.4 在写UI界面文件读写问题："></a>2.4 在写UI界面文件读写问题：</h4><p>​    本次实验所用的UI界面是django，由于JavaScript不提供内置的文件读写操作，同时，由于所使用的浏览器是Edge（基于Chrome内核），无法使用ActiveXObject操作来读取文件：</p>
<pre class="line-numbers language-javascript" data-language="javascript"><code class="language-javascript"><span class="token comment">//这段代码非IE内核浏览器无法使用</span>
fp <span class="token operator">=</span> <span class="token function">ActiveXObject</span><span class="token punctuation">(</span><span class="token string">"Scripting.FileSystemObject"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">var</span> file <span class="token operator">=</span> fp<span class="token punctuation">.</span><span class="token function">OpenTextFile</span><span class="token punctuation">(</span><span class="token string">"C:\\Users\\Shaw\\Desktop\\S_s\\TestInitialNullForStudent\\TestConsole\\API_sequence.txt"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">var</span> str <span class="token operator">=</span> <span class="token string">""</span><span class="token punctuation">;</span>
        <span class="token keyword">while</span><span class="token punctuation">(</span><span class="token operator">!</span>file<span class="token punctuation">.</span>AtEndOfStream<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
            <span class="token keyword">var</span> temp <span class="token operator">=</span> f<span class="token punctuation">.</span><span class="token function">ReadLine</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> temp<span class="token punctuation">.</span>length<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                str <span class="token operator">+=</span> temp<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">"&amp;nbsp;"</span><span class="token punctuation">;</span>
            <span class="token punctuation">&#125;</span>
            str <span class="token operator">+=</span> <span class="token string">"&lt;br>"</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span>
        document<span class="token punctuation">.</span><span class="token function">getElementById</span><span class="token punctuation">(</span><span class="token string">"console"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>innerHTML <span class="token operator">=</span> str<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    因为不想更换浏览器，并且考虑到使用此种动态显示方式需要使用异步线程，时间所限，故在这里尝试使用Django+Wsgi的socket连接方式进行前后端通信：</p>
<ul>
<li>​    References:</li>
</ul>
<p>​    <a href="http://www.ruanyifeng.com/blog/2017/05/websocket.html">WebSocket 教程 - 阮一峰的网络日志 (ruanyifeng.com)</a></p>
<p>​    <a href="https://caojingyou.github.io/2017/11/15/C++与浏览器交互/">C++与浏览器交互 | 曹景游 (caojingyou.github.io)</a></p>
<p>​    <a href="https://blog.csdn.net/byxdaz/article/details/84638249">(7条消息) Windows下使用websocketpp_深之JohnChen的专栏-CSDN博客</a></p>
<p>​    <a href="https://web.dev/file-system-access/">The File System Access API: simplifying access to local files (web.dev)</a></p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2021/09/08/%E3%80%90%E8%BD%AF%E4%BB%B6%E5%AE%89%E5%85%A8%E8%AF%BE%E8%AE%BE%E3%80%91%E7%AC%AC%E4%B8%80%E6%AC%A1%E4%BD%9C%E4%B8%9A/</url>
    <content><![CDATA[<blockquote>
<p>组长：袁也</p>
<p>组员：吴骁，缪文俊，王相炜，杨涵博，杨传冠</p>
<p>班级：网安1902</p>
</blockquote>
<h3 id="1-Detours-学习："><a href="#1-Detours-学习：" class="headerlink" title="1. Detours 学习："></a>1. Detours 学习：</h3><p>​    通过阅读文档，理论+实际的结合，组内成员基本理解了detours运作原理。</p>
<h3 id="2-Detours-编译："><a href="#2-Detours-编译：" class="headerlink" title="2. Detours 编译："></a>2. Detours 编译：</h3><pre><code>1. 首先，在VS2019自带的cmd中编译detours:
</code></pre><p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210908162623.png" alt=""></p>
<p>​    可见，编译成功。</p>
<h3 id="3-消息弹窗的注入："><a href="#3-消息弹窗的注入：" class="headerlink" title="3. 消息弹窗的注入："></a>3. 消息弹窗的注入：</h3><p>​    dllmain中代码如下：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210908162822.png" alt=""></p>
<p>​    演示效果：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210908162923.png" alt=""></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210908162947.png" alt=""></p>
<p>​    可见，成功</p>
<h3 id="4-VS框架搭建："><a href="#4-VS框架搭建：" class="headerlink" title="4. VS框架搭建："></a>4. VS框架搭建：</h3><p>​    VS框架组成如下：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210908163111.png" alt=""></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210908163125.png" alt=""></p>
<h3 id="5-目前碰到的一些问题："><a href="#5-目前碰到的一些问题：" class="headerlink" title="5. 目前碰到的一些问题："></a>5. 目前碰到的一些问题：</h3><h4 id="5-1-使用VS2019自带的命令行界面进行编译，提示没有nmake命令："><a href="#5-1-使用VS2019自带的命令行界面进行编译，提示没有nmake命令：" class="headerlink" title="5.1 使用VS2019自带的命令行界面进行编译，提示没有nmake命令："></a>5.1 使用VS2019自带的命令行界面进行编译，提示没有nmake命令：</h4><p>​    检查后发现VS2019只安装了桌面开发模块，没有安装C++开发模块，更新相应拓展包即可。</p>
<p><img src="%E3%80%90%E8%BD%AF%E4%BB%B6%E5%AE%89%E5%85%A8%E8%AF%BE%E8%AE%BE%E3%80%91%E7%AC%AC%E4%B8%80%E6%AC%A1%E4%BD%9C%E4%B8%9A/20210906172501.png" alt=""></p>
<h4 id="5-2-在testconsole-cpp文件中引入代码，编译报错百余个标识符错误："><a href="#5-2-在testconsole-cpp文件中引入代码，编译报错百余个标识符错误：" class="headerlink" title="5.2 在testconsole.cpp文件中引入代码，编译报错百余个标识符错误："></a>5.2 在testconsole.cpp文件中引入代码，编译报错百余个标识符错误：</h4><p>​        在外网查询后发现，是因为引入引用windows.h在引用detours之前：</p>
<p><img src="%E3%80%90%E8%BD%AF%E4%BB%B6%E5%AE%89%E5%85%A8%E8%AF%BE%E8%AE%BE%E3%80%91%E7%AC%AC%E4%B8%80%E6%AC%A1%E4%BD%9C%E4%B8%9A/20210906165008.png" alt=""></p>
<h4 id="5-3-字符编码问题："><a href="#5-3-字符编码问题：" class="headerlink" title="5.3 字符编码问题："></a>5.3 字符编码问题：</h4><p>​    熟悉宽字符与unicode字符编码的原理后，才能正确处理HCHAR,TCHAR等。</p>
<h4 id="5-4-Messagebox操作中出现如下文件操作："><a href="#5-4-Messagebox操作中出现如下文件操作：" class="headerlink" title="5.4 Messagebox操作中出现如下文件操作："></a>5.4 Messagebox操作中出现如下文件操作：</h4><p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210908170241.png" alt=""></p>
]]></content>
  </entry>
  <entry>
    <title>近似误差与估计误差</title>
    <url>/2021/09/05/%E3%80%90%E9%9A%8F%E6%89%8B%E5%86%99%E3%80%91%E8%BF%91%E4%BC%BC%E8%AF%AF%E5%B7%AE%E4%B8%8E%E4%BC%B0%E8%AE%A1%E8%AF%AF%E5%B7%AE/</url>
    <content><![CDATA[<h1 id="【随手写】近似误差与估计误差"><a href="#【随手写】近似误差与估计误差" class="headerlink" title="【随手写】近似误差与估计误差"></a>【随手写】近似误差与估计误差</h1><p>​    在读《统计学习方法》中关于k-邻近算法的介绍时，发现了这么一段话：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905153525.png" alt=""></p>
<p>​        <strong>近似误差（<em>Approximation Error</em>）:</strong> 训练时，训练集与当前模型的误差；</p>
<p>​        <strong>估计误差（<em>Estimation Error</em>）：</strong> 训练完成后，所选择的模型已经固定，模型对未知数据拟合时的误差。</p>
<p>​        近似误差与估计误差二者不可兼得，此消彼长，需要取其平衡。</p>
]]></content>
      <categories>
        <category>Something</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>极大似然估计</title>
    <url>/2021/09/04/%E3%80%90%E9%9A%8F%E5%86%99%E3%80%91%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/</url>
    <content><![CDATA[<h1 id="【随写】极大似然估计（Maximum-Likelihood-Estimate，MLE）"><a href="#【随写】极大似然估计（Maximum-Likelihood-Estimate，MLE）" class="headerlink" title="【随写】极大似然估计（Maximum Likelihood Estimate，MLE）"></a>【随写】极大似然估计（<em>Maximum Likelihood Estimate，MLE</em>）</h1><p>​    “模型已定，参数未知。”</p>
<p>​    极大似然估计，<strong>就是利用已知的样本结果信息，反推最具有可能（<u>最大概率</u>）导致这些样本结果出现的模型参数值。</strong></p>
<p>​    </p>
<p>​    对于这个函数：$P(x|θ)$，</p>
<p>​    输入有两个：x表示某一个具体的数据；θ表示模型的参数。</p>
<p>​    如果θ是已知确定的，x是变量，这个函数叫做<strong>概率函数(probability function)</strong>，它描述对于不同的样本点x，其出现概率是多少。</p>
<p>​    如果x是已知确定的，θ 是变量，这个函数叫做<strong>似然函数(likelihood function)</strong>, 它描述对于不同的模型参数，出现x这个样本点的概率是多少。</p>
<p>​    </p>
<p>​    一般说来，事件A发生的概率与某一未知参数θ有关，θ取值不同，则事件A发生的概率$P(A|θ)$也不同，当我们在一次试验中事件A发生了，则认为此时的θ值应是t的一切可能取值中使$P(A|θ)$达到最大的那一个，极大似然估计法就是要选取这样的t值作为参数t的估计值，使所选取的样本在被选的总体中出现的可能性为最大。</p>
]]></content>
      <categories>
        <category>Something</category>
      </categories>
      <tags>
        <tag>Math</tag>
      </tags>
  </entry>
  <entry>
    <title>Adversarial Training with Fast Gradient Projection Method against Synonym Substitution Based Text Attacks</title>
    <url>/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Adversarial%20Training%20with%20Fast%20Gradient%20Projection%20Method%20against%20Synonym%20Substitution%20Based%20Text%20Attacks/</url>
    <content><![CDATA[<h1 id="【论文阅读】Adversarial-Training-with-Fast-Gradient-Projection-Method-against-Synonym-Substitution-Based-Text-Attacks"><a href="#【论文阅读】Adversarial-Training-with-Fast-Gradient-Projection-Method-against-Synonym-Substitution-Based-Text-Attacks" class="headerlink" title="【论文阅读】Adversarial Training with Fast Gradient Projection Method against Synonym Substitution Based Text Attacks"></a>【论文阅读】Adversarial Training with Fast Gradient Projection Method against Synonym Substitution Based Text Attacks</h1><blockquote>
<p><strong>时间：2020</strong></p>
<p><strong>作者：王晓森，杨逸辰等      </strong>华中科技大学</p>
<p><strong>会议：AAAI</strong></p>
</blockquote>
<h3 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h3><ol>
<li><p><strong>做了什么？</strong></p>
<ul>
<li><p>提出了一种速度更快的，更容易应用在复杂神经网络和大数据集上的，基于同义词替换的NLP对抗样本生成方法，FGPM；</p>
</li>
<li><p>将FGPM纳入对抗训练中，以提高深度神经网络的鲁棒性。</p>
</li>
</ul>
</li>
<li><p><strong>怎么做的？</strong></p>
</li>
</ol>
<ol>
<li><p><strong>实验结果？</strong></p>
<ul>
<li>FGPM的效果不是最高的，但也跟最高的差不多，但生成对抗样本的时间对比同类方法，缩减了1-3个数量级。</li>
<li>ATFL的对抗样本防御能力和抗转移能力很强。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract:"></a>Abstract:</h3><p>​    对抗训练是对于提升图像分类深度神经网络鲁棒性的，基于实验的最成功的进步所在。</p>
<p>​    然而，对于文本分类，现有的基于同义词替换的对抗样本攻击十分奏效，但却没有被很有效地合并入实际的文本对抗训练中。</p>
<p>​    基于梯度的攻击对于图像很有效，但因为文本的词汇，语法，语义结构的限制以及离散的文本输入空间，不能很好的应用于基于近义词替换的文本攻击中。</p>
<p>​    因此，我们提出了一个基于同义词的替换的快速的文本对抗抗攻击方法名为<strong><em>Fast Gradient Projection Method (FGPM)</em></strong>。它的速度是已有文本攻击方法的20余倍，攻击效果也跟这些方法差不多。</p>
<p>​    我们接着将FGPM合并入对抗训练中，提出了一个文本防御方法，<strong><em>Adversarial Training with FGPM enhanced by Logit pairing</em>(ATFL)</strong>。</p>
<p>​    实验结果表明ATFL可以显著提高模型的鲁棒性，破坏对抗样本的可转移性。</p>
<hr>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction:"></a>1 Introduction:</h3><p>​    现有的针对NLP的攻击方法包括了：字符等级攻击，单词等级攻击，句子等级攻击。</p>
<p>​    对于字符等级的攻击，最近的工作（<em>Pruthi, Dhingra, and Lipton 2019</em>）表明了拼写检查器很容易修正样本中的扰动；</p>
<p>​    对于句子等级的攻击，其一般需要基于改述，故需要更长的时间来生成对抗样本；</p>
<p>​    对于单词等级的攻击，基于嵌入扰动的替换（<em>replacing word based on embedding perturbation</em>），添加，删除单词都会很容易改变句子的语法语义结构与正确性，<strong>故同义词替换的方法可以更好的处理上述问题，同时保证对抗样本更难被人类观察者发现</strong>。</p>
<p>​    但不幸的是，基于同义词替换的攻击相较于如今对图像的攻击展现出了更低的功效。</p>
<p>​    </p>
<p>​    据我们所知，对抗训练，对图像数据最有效的防御方法之一，并没有在对抗基于同义词替换的攻击上很好的实施过。</p>
<p>​    一方面，现有的基于同义词替换的攻击方法通常效率要低得多，难以纳入对抗训练。另一方面，尽管对图像的方法很有效，但其并不能直接移植到文本数据上。</p>
<p>​    </p>
<h4 id="1-1-Adversarial-Defense"><a href="#1-1-Adversarial-Defense" class="headerlink" title="1.1 Adversarial Defense:"></a>1.1 Adversarial Defense:</h4><p>​    有一系列工作对词嵌入进行扰动，并将扰动作为正则化策略用于对抗训练(<em>Miyato, Dai, and Goodfellow</em></p>
<p><em>2016; Sato et al. 2018; Barham and Feizi 2019</em>) 。这些工作目的是提高模型对于原始数据集的表现，并不是为了防御对抗样本攻击，因此，我们不会考虑这些工作。</p>
<p>​        不同于如今现有的防御方法，我们的工作聚焦于快速对抗样本生成，容易应用在复杂的神经网络和大数据集上的防御方法。</p>
<hr>
<h3 id="2-Fast-Gradient-Projection-Method（FGPM）"><a href="#2-Fast-Gradient-Projection-Method（FGPM）" class="headerlink" title="2 Fast Gradient Projection Method（FGPM）:"></a>2 Fast Gradient Projection Method（FGPM）:</h3><p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904144444.png" alt=""></p>
<hr>
<h3 id="3-Adversarial-Training-with-FGPM："><a href="#3-Adversarial-Training-with-FGPM：" class="headerlink" title="3 Adversarial Training with FGPM："></a>3 Adversarial Training with FGPM：</h3><p>​    具体算法中文描述见：</p>
<p><a href="https://zhuanlan.zhihu.com/p/248425749">《基于同义词替换的快速梯度映射（FGPM）文本对抗攻击方法》阅读笔记 - 知乎 (zhihu.com)</a></p>
<hr>
<h3 id="4-Experimental-Results："><a href="#4-Experimental-Results：" class="headerlink" title="4 Experimental Results："></a>4 Experimental Results：</h3><p>​    我们衡量FGPM使用四种攻击准则，衡量ATFL使用两种防御准则。</p>
<p>​    我们在三个很受欢迎的基准数据集上，同时包括CNN和RNN模型上进行测试，代码开源：<a href="https://github.com/JHL-HUST/FGPM">https://github.com/JHL-HUST/FGPM</a></p>
<h4 id="4-1-Baselines"><a href="#4-1-Baselines" class="headerlink" title="4.1 Baselines:"></a>4.1 Baselines:</h4><p>​    为了评估FGPM的攻击效能，我们将其与Papernot’、GSA ( Kuleshov等人的4种对抗性攻击进行了比较。2018 )、PWWS ( Ren et al . 2019 )和Iga ( Wang，jin，and he 2019 )。</p>
<p>​    此外，为了验证我们的ATFL的防御能力，我们采用了SEM ( Wang，Jin，He 2019 )和IBP ( Jia et al . 2019 )，针对上述Word-Level攻击。由于攻击基线的效率很低，我们在每个数据集上随机抽取200个示例，并在各种模型上生成对抗样本。</p>
<h4 id="4-2-Datasets"><a href="#4-2-Datasets" class="headerlink" title="4.2 Datasets:"></a>4.2 Datasets:</h4><p>​    <em>AG’s News</em>, <em>DBPedia ontology</em> and <em>Yahoo! Answers</em> (Zhang,Zhao, and LeCun 2015).</p>
<h4 id="4-3-Models"><a href="#4-3-Models" class="headerlink" title="4.3 Models:"></a>4.3 Models:</h4><p>​    我们使用了CNNs,RNNs,来达到主流的文本分类表现，所有模型的嵌入维度均为300。</p>
<h4 id="4-4-Evaluation-on-Attack-Effectiveness："><a href="#4-4-Evaluation-on-Attack-Effectiveness：" class="headerlink" title="4.4 Evaluation on Attack Effectiveness："></a>4.4 Evaluation on Attack Effectiveness：</h4><p>​    我们评估模型在攻击下的准确率和转移率：</p>
<p>​    <strong>准确率：</strong></p>
<p>​        <img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904134852.png" alt=""></p>
<p>​    <strong>转移率：</strong></p>
<p>​    <img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904135419.png" alt=""></p>
<h4 id="4-4-Evaluation-on-Attack-Efficiency："><a href="#4-4-Evaluation-on-Attack-Efficiency：" class="headerlink" title="4.4 Evaluation on Attack Efficiency："></a>4.4 Evaluation on Attack Efficiency：</h4><p>​        对抗训练需要高效率的生成对抗样本以有效地提升模型鲁棒性。因此，我们评估了不同攻击方法在三个数据集上生成生成200个对抗样本的总时间。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904135842.png" alt=""></p>
<h4 id="4-5-Evaluation-on-Adversarial-Training："><a href="#4-5-Evaluation-on-Adversarial-Training：" class="headerlink" title="4.5 Evaluation on Adversarial Training："></a>4.5 Evaluation on Adversarial Training：</h4><p>​        我们评估ATFL的对抗样本防御能力和抗转移能力：</p>
<p>​    <strong>对抗样本防御能力：</strong></p>
<p>​    <img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904140647.png" alt=""></p>
<p>​    <strong>抗转移能力：</strong></p>
<p>​    <img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904141719.png" alt=""></p>
<h4 id="4-6-Evaluation-on-Adversarial-Training-Variants"><a href="#4-6-Evaluation-on-Adversarial-Training-Variants" class="headerlink" title="4.6 Evaluation on Adversarial Training Variants:"></a>4.6 Evaluation on Adversarial Training Variants:</h4><p>​        许多对抗训练的变体，例如CLP和ALP，TRADES等，已经尝试采用不同的正则化方法来提高针对图像数据的对抗训练准确率。</p>
<p>​        在这里，我们回答一个问题：这些变体方法也可以提高文本数据准确率吗？</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904142406.png" alt=""></p>
<p>​        从表中可以看出，只有ALP可以长远地提升对抗训练的表现。</p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>AD</tag>
        <tag>NLP</tag>
        <tag>AD training</tag>
      </tags>
  </entry>
  <entry>
    <title>《统计学习方法》</title>
    <url>/2021/09/03/%E3%80%90%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B/</url>
    <content><![CDATA[<h1 id="【书籍阅读】《统计学习方法》"><a href="#【书籍阅读】《统计学习方法》" class="headerlink" title="【书籍阅读】《统计学习方法》"></a>【书籍阅读】《统计学习方法》</h1><h3 id="一-统计学习方法概论："><a href="#一-统计学习方法概论：" class="headerlink" title="一. 统计学习方法概论："></a>一. 统计学习方法概论：</h3><p>​    首先，要明确计算机科学中存在三个维度：系统，计算，与信息。统计学习方法（机器学习）主要属于信息这一维度，并在其中扮演者核心角色。</p>
<h4 id="1-监督学习概念："><a href="#1-监督学习概念：" class="headerlink" title="1. 监督学习概念："></a>1. 监督学习概念：</h4><p>​    监督学习，Supervised learning，指在已经做好标注的训练集上学习，为了叙述方便，定义以下基本概念：</p>
<blockquote>
<ol>
<li><strong>输入空间（X），输出空间（Y）：</strong>输入所有可能取值，输出所有可能取值；</li>
<li><strong>特征空间：</strong>输入一般由特征向量表示，所有特征向量存在的空间称为特征空间，输入空间与特征空间并不完全等价，有时需要映射；</li>
<li><strong>上标  x^i^</strong> :表示一个输入的第  i 个特征；</li>
<li><strong>下标  x~j~：</strong>表示第 j 个输入。</li>
<li><strong>回归问题：</strong>输入输出都为连续型变量；</li>
<li><strong>分类问题：</strong>输出变量为有限个离散型变量；</li>
<li><strong>标注问题：</strong>输入与输出变量都为变量序列。</li>
<li><strong>假设空间：</strong>所有可能的模型的集合，也就是学习的范围。</li>
</ol>
</blockquote>
<p>​    使用训练集学习——&gt;对未知数据进行预测</p>
<p>​    </p>
<h4 id="2-统计学习三要素："><a href="#2-统计学习三要素：" class="headerlink" title="2. 统计学习三要素："></a>2. 统计学习三要素：</h4><p>​    统计学习三要素为：<strong>模型，策略，算法</strong>；</p>
<p>​    模型是决定学习的预测函数的类型；</p>
<p>​    策略是判定什么样的模型是好的，用于度量当前的模型好坏；</p>
<p>​    算法是训练过程中的具体做法，例如如何回归，如何计算，如何调整等。</p>
<h4 id="3-模型的衡量方法："><a href="#3-模型的衡量方法：" class="headerlink" title="3. 模型的衡量方法："></a>3. 模型的衡量方法：</h4><ul>
<li><p><strong>损失函数与风险函数：</strong></p>
<p>​    损失函数，Loss Function，用于模型一次预测的错误程度，例如：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902154618.png" alt=""></p>
<p>​    损失函数的数值越小，模型就越好。如果计算损失函数的期望，得到的就是风险函数，Risk Function:</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902154745.png" alt=""></p>
<p>​    可以看出，损失函数用于某次预测的估计，风险函数用于总体平均估计。我们当然希望训练出的模型的风险函数越小越好。</p>
<p>​    <strong>但是，观察上式，理想化的概率分布P(x，y)是未知的，我们进行学习就是要通过模型来模拟它，故这个式子理论存在，实际不能计算，不能用作评估模型的直接方法。</strong></p>
</li>
</ul>
<ul>
<li><p><strong>经验风险与结构风险：</strong></p>
<p>​    为了解决上述问题，我们引入经验风险：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902155212.png" alt=""></p>
<p>​    可以看到，经验风险将每个样本视作等概率出现，是模型对于训练集的平均损失，那么其与风险函数的误差在哪？</p>
<p>​    根据大数定律，当训练集足够大时，二者是近似相等的。但实际情况下，很多时候训练样本数目有限，甚至很小，故用经验风险效估计风险函数并不理想，故需要进行修正，这就是监督学习中的<strong>两个基本策略：</strong>经验风险最小化和结构风险最小化。</p>
<p>​    如果训练样本容量较大，使用经验风险最小化没什么问题。</p>
<p>​    当样本容量很小时，仅仅使用经验风险最小化容易导致过拟合，故这里使用<strong>结构风险（就是正则化）</strong>最小化方法，对模型复杂度进行惩罚，后续介绍。</p>
</li>
</ul>
<ul>
<li><p><strong>训练误差与测试误差：</strong></p>
<p>​    训练误差本质上不重要，它可以反应一个问题是不是容易学习，但要衡量模型的预测能力，主要是看测试误差。</p>
</li>
</ul>
<ul>
<li><p><strong>正则化与交叉验证：</strong></p>
<p>​    正则化是在经验风险项后再增加一个正则化项（Regularizer），其与模型的复杂度成正相关，一般使用模型参数向量的范数：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902161201.png" alt=""></p>
<p>​    交叉验证的基本思想是重复使用数据：</p>
<ol>
<li><p><strong>简单交叉验证：</strong></p>
<p>将训练集随机分为两部分，一部分训练，一部分测试，然后在各种条件下训练出不同的模型，用测试集进行横向对比，选出最好的。</p>
<ol>
<li><strong>S折交叉验证：</strong></li>
</ol>
<p>S-fold cross validation，随机地将已给数据切分为S个互不相交的大小相同的子集，选取S-1个用于训练，剩下一个用于测试。</p>
<p>这样总共测试集有S种选法，将这S种全部试一遍，评选S次测评中平均误差最小的模型。</p>
<ol>
<li><strong>留一交叉验证：</strong></li>
</ol>
<p>令S=N（训练集大小）即可，这种方法往往是在数据集特别缺乏的情况下使用。</p>
</li>
</ol>
</li>
<li><p><strong>泛化误差与泛化上界：</strong></p>
<p>​    泛化能力指模型对位置数据的预测能力，就是模型的好坏。如何量化这个能力？</p>
<p>​    根据定义，其就是模型在测试集上的测试表现：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902162814.png" alt=""></p>
<p>​    同时可以用以下式子衡量泛化误差的上界：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902162851.png" alt=""></p>
</li>
<li><p><strong>生成模型与判别模型：</strong></p>
<p>​    监督学习方法又可以分为两种方法：生成方法（Generatice Approach）和判别方法（Discriminative Approach）。</p>
<p>​    如果以概率论的角度来看待，模型的作用是根据P（x）来求P（y | x），故下面有两种方法求</p>
<p>P（y | x），直接模拟P（y | x）和通过求  $P(\frac{y}{x}) = \frac{P(x,y)}{P(x)}$  来求P（y | x）。</p>
<p>​    前者就是判别模型，后者是生成模型。</p>
<p>​    生成模型可以还原出联合概率分布P（x , y），学习收敛速度更快，可以适应存在隐含变量的情况；</p>
<p>​    判别模型直接学习条件概率,直接面对预测，准确率更高，并且简化了学习问题。</p>
</li>
</ul>
<hr>
<h3 id="二-感知机"><a href="#二-感知机" class="headerlink" title="二. 感知机"></a>二. 感知机</h3><p>​    感知机，perceptron，是二分类的线性分类模型，输入为特征向量，输出为类别，取1和-1两种。</p>
<p>​    感知机属于判别模型。</p>
<p>​    </p>
<p>​    对于一个给定数据集，T = {（x~1~，y~1~）……（x~n~，y~n~）}，如果存在某个超平面S，w·x + b = 0（这里w是超平面的法向量，b是截距），使得所有 y~i~ = 1 的实例i，有 w·x~i~ + b &gt; 0，y~i~ = -1则相反，则称数据集T为<strong>线性可分数据集（<em>Linealy separable data set</em>）</strong>，否则，称数据集T为线性不可分数据集。</p>
<h4 id="2-1-感知机损失函数："><a href="#2-1-感知机损失函数：" class="headerlink" title="2.1 感知机损失函数："></a>2.1 感知机损失函数：</h4><p>​    感知机的目的就是对于一个线性可分的数据集，通过找出w和b，来确定一个超平面用于分类。</p>
<p>​    这里，我们选取某错误分类点到超平面S的<strong>总距离</strong>来当做损失函数，某一点到超平面S的距离如下：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904182025.png" alt=""></p>
<p>​    ‖w‖是w的L~2~范数。</p>
<p>​    故，某个误分类点到超平面S的距离是：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904182154.png" alt=""></p>
<p>​    将所有误分类点求和，忽略L~2~范数，即可得到<strong>感知机的损失函数</strong>（M为误分类点集合）：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904182339.png" alt=""></p>
<p>​    对于一个特定样本点的损失函数，在误分类时是参数w,b的线性函数，在正确分类时是0，故给定训练数据集T，损失函数L是w，b的连续可导函数。</p>
<h4 id="2-2-训练过程："><a href="#2-2-训练过程：" class="headerlink" title="2.2 训练过程："></a>2.2 训练过程：</h4><p>​    感知机训练采用随机梯度下降的方法：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904183233.png" alt=""></p>
<p>​    当找到一个误分类点时，不断梯度下降直至该点被正确分类为止。</p>
<p>​    <strong>数学证明其收敛性：</strong></p>
<p>​        具体见书本，这里略过。</p>
<h4 id="2-3-感知机的对偶形式："><a href="#2-3-感知机的对偶形式：" class="headerlink" title="2.3 感知机的对偶形式："></a>2.3 感知机的对偶形式：</h4><p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905112734.png" alt=""></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905112750.png" alt=""></p>
<p>​    由图可以看到，对于每个测试集中的x~i~，都有一个与之对应的α~i~，对偶形式中就是调整其对应的α。</p>
<p>​    关于gram矩阵的作用，如果手算一遍简单的训练过程，就可以得到答案。</p>
<hr>
<h3 id="三-k近邻法"><a href="#三-k近邻法" class="headerlink" title="三. k近邻法"></a>三. k近邻法</h3><p>​    k近邻法是一种基本的分类与回归方法，这里只讨论分类方法。</p>
<p>​    其输入为特征向量，输出为实例的类别，可以取<strong>多类</strong>。</p>
<h4 id="3-1-算法描述："><a href="#3-1-算法描述：" class="headerlink" title="3.1 算法描述："></a>3.1 算法描述：</h4><p>​    给定一个训练集，对于新的数据实例，在训练数据集中找到与其最邻近的k个实例，这k个实例多数属于某个类，就把该输入实例分为这个类。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905113440.png" alt=""></p>
<p>​        <u>k近邻法没有显式的学习过程。</u>可以理解为，k近邻算法将特征空间划分为了一些子空间，每个点所属的空间是确定的。</p>
<p>​        </p>
<ul>
<li><strong>如何度量两个特征之间的距离？</strong></li>
</ul>
<p>​        k邻近模型的特征空间一般是n维实空间R^n^，使用欧氏距离或者L~p~距离（<em>L~p~ distance</em>），Minkowski距离（<em>Minkowski distance</em>）；</p>
<p>​        <strong>L~p~距离：</strong></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905143250.png" alt=""></p>
<p>​        <strong>欧氏距离：</strong></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905143332.png" alt=""></p>
<p>​        <strong>曼哈顿距离：</strong></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905143356.png" alt=""></p>
<p>​        <strong>无穷距离：</strong></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905143648.png" alt=""></p>
<p>​    由下图可以看出，p取值不同时到原点距离为1的图形是不同的：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905143741.png" alt=""></p>
<ul>
<li><p><strong>如何选择k的值？</strong></p>
<p>​    k值越小，模型学习时的近似误差越小，估计误差越大，模型会越复杂，抗干扰性越小（例如，最邻近的点是噪声），模型会非常敏感，容易过拟合；</p>
<p>​    k值越大，估计误差会很小，近似误差会很大，整体模型变得简单。</p>
<p>​    k一般的取值并不大，使用交叉验证的方法来选取最佳的k值。</p>
</li>
<li><p><strong>如何决策？</strong></p>
<p>​    在得到k个最相似的实例后，采用何种规则判断测试样本属于哪一类呢？</p>
<p>​    k邻近算法使用多数表决的方法：</p>
</li>
</ul>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905154943.png" alt=""></p>
<blockquote>
<p>ps: ci表示某种决策规则下一组测试用例的表决结果。经由以上推导可以得出，多数表决规则是合理的。</p>
</blockquote>
<p>​        </p>
<ul>
<li><p><strong>如何快速找到某个用例的K近邻点？</strong></p>
<p><strong>KD树：</strong> 具体算法见书。</p>
</li>
</ul>
<hr>
<h3 id="四-朴素贝叶斯法"><a href="#四-朴素贝叶斯法" class="headerlink" title="四. 朴素贝叶斯法"></a>四. 朴素贝叶斯法</h3><p>  ​    </p>
]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Text Classifification Can be Fooled</title>
    <url>/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Deep%20Text%20Classifification%20Can%20be%20Fooled/</url>
    <content><![CDATA[<h1 id="【论文阅读】Deep-Text-Classifification-Can-be-Fooled"><a href="#【论文阅读】Deep-Text-Classifification-Can-be-Fooled" class="headerlink" title="【论文阅读】Deep Text Classifification Can be Fooled"></a>【论文阅读】<strong>Deep Text Classifification Can be Fooled</strong></h1><blockquote>
<p><strong>时间：</strong>2017</p>
<p><strong>作者：</strong>Bin Liang, Hongcheng Li, Miaoqiang Su, Pan Bian, Xirong Li and Wenchang Shi     中国人民大学</p>
</blockquote>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract:"></a>Abstract:</h3><p>​    在这篇文章，我们提出了一种有效的生成文本对抗样本的方法，并且揭示了一个很重要但被低估的事实：基于DNN的文本分类器很容易被对抗样本攻击。</p>
<p>​    具体来说，面对不同的对抗场景，通过计算输入的代价梯度(白盒攻击)或生成一系列被遮挡的测试样本(黑盒攻击)来识别对分类重要的文本项。（<u>这句不是很懂，什么叫’ the text items that are important for classifification‘？</u>）</p>
<p>​    基于这些项目，我们设计了三种扰动策略，insertion，modification，removal，用于生成对抗样本。实验结果表明基于我们的方法生成的对抗样本可以成功地欺骗主流的在字符等级和单词等级的DNN文本分类器。</p>
<p>​    对抗样本可以被扰动到任意理想的类中而不降低其效率。（？）同时，被引入的扰动很难被察觉。</p>
<p>​    </p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction:"></a>1. Introduction:</h3><p>​    在文本中，即使很小的扰动也会使一个字母或者单词完全变化，这会导致句子不能被辨识。故如果直接将应用于多媒体（图片，音频）的算法应用到文本上，得到的对抗样本的原意就会改变，而且很大程度上变成人类无法理解的句子。</p>
<p>​    在这片论文里，我们提出了一种生成对抗样本的有效方法。与直接简单插入扰动相比，我们设计了三种扰动策略：<em>insertion</em>, <em>modifification</em>, and <em>removal</em>，并且引入了自然语言文本水印（<em>natural language watermarking</em>）技术用于生成对抗样本。</p>
<p>​    理论上，生成一个好的对抗样本很大程度上依赖于对目标分类模型的信息。在这里我们根据不同情形，使用了白盒攻击和黑盒攻击。</p>
<p>​    为了普遍性，我们使用了字符等级的模型和单词等级的模型作为受害者。我们的实验结果证明基于DNN的文本分类器在面对对抗样本攻击时是脆弱的。</p>
<h3 id="2-Target-Models-and-Datasets"><a href="#2-Target-Models-and-Datasets" class="headerlink" title="2. Target Models and Datasets:"></a>2. Target Models and Datasets:</h3><p>​    这里使用的文本分类器是Zhang et al. 2015《Character-level Convolutional Networks foe Text Classification》，数据集是Lehmann et al.2014的DBpedia ontology dataset（一个多语言知识库），里面包括560000个训练样本和70000个测试样本，涵盖14个high-level 类，比如公司类、建筑类、电影类等。</p>
<p>​    在把样本送进网络前，需要用独热编码法（one-hot representation）对每个字母编码成一个向量。通过网络的六个卷积层、三个全连接层，最终会被分到14个类中。</p>
<h3 id="3-White-Box-Attacks"><a href="#3-White-Box-Attacks" class="headerlink" title="3. White-Box-Attacks:"></a><u>3. White-Box-Attacks:</u></h3><h4 id="3-1-FGSM算法："><a href="#3-1-FGSM算法：" class="headerlink" title="3.1 FGSM算法："></a>3.1 FGSM算法：</h4><p>​    FGSM是Goodfellow在2015年提出的对图片生成对抗样本的经典算法。使用类似的思路来在文本领域生成对抗样本结果并不好：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210830214227.png" alt=""></p>
<h4 id="3-2-Idenfitying-Classification-important-Items"><a href="#3-2-Idenfitying-Classification-important-Items" class="headerlink" title="3.2    Idenfitying Classification-important Items:"></a>3.2    Idenfitying Classification-important Items:</h4><p>​        在白盒攻击中，我们需要定位文本中对于分类器的分类结果起到很大作用的文本段（通过计算代价梯度）。在这里，我们使用<strong><em>Hot Training Phrases</em> (HTPs)</strong>代表最常使用的短语：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210831150703.png" alt=""></p>
<p>​        HTPS表明了用什么短语/词去做扰动，但是没有说在哪里做。在这里使用<strong><em>Hot Sample Phrases</em> (HSPs)</strong>来表明在哪里做扰动。</p>
<h4 id="3-3-Attacking-Character-level-DNN"><a href="#3-3-Attacking-Character-level-DNN" class="headerlink" title="3.3    Attacking Character-level DNN:"></a>3.3    Attacking Character-level DNN:</h4><p>​        我们的方法是一种targeted攻击，可以指定对抗样本的误导类型。</p>
<h5 id="3-3-1-Insertion-Strategy（插入策略）"><a href="#3-3-1-Insertion-Strategy（插入策略）" class="headerlink" title="3.3.1 Insertion Strategy（插入策略）:"></a>3.3.1 Insertion Strategy（插入策略）:</h5><p>​            在某个HSP前插入一个HTP，就可以达到效果：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210831151929.png" alt=""></p>
<p>​            由上图可以看到，将某个<strong>HTP</strong>（<em>historic</em>）插入到<strong>HSP</strong>（<em>principal stock exchange of Uganda. It was founded</em>）之前，就可以使一个公司的分类文本变为对建筑的分类。</p>
<p>​            实际上，我们通常需要进行多次插入，但插入次数过多会影响样本的效用和可读性，为了解决这个问题，这里引入NL水印技术（<em>Natural Language watermarking technique</em>）。该技术可以通过语义或句法操作将所有权水印隐形地嵌入到普通文本中,虽然我们的攻击目标与NL水印有本质的不同，但我们可以借用它的思想来构造对抗样本。实际上，扰动可以看作是一种水印，并以类似的方式嵌入到样本中。</p>
<p>​            在这里，我们拓展这个思路，在样本中插入<strong>Presupposition</strong>(读者熟知的模糊短语)和 <strong>semantically empty phrases</strong>（可有可无的短语），有没有他们，在读者看来，原文的意思不会改变。</p>
<p>​            总的来说，我们考虑将各种HTPS组合成一个语法单元后再嵌入到文本中，新的单元可以是生成的可有可无的资料，或者甚至是不会改变文本原意的伪造的资料。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210831154859.png" alt=""></p>
<p>​            <strong>特别的，通过互联网搜索或者查找一些数据集，我们可以找到与插入点很相关的资料，包括一些期望的目标分类的HTPs。</strong></p>
<p>​            由于我们不能总是找到合适的HTPs，所以提出一个新概念——伪造的事实（forged fact），也就是插入很难证伪的HTPs。例如：</p>
<p><img src="%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Deep%20Text%20Classifification%20Can%20be%20Fooled/20210831154910.png" alt=""></p>
<p>​            此外，我们排除了伪造的事实，这些事实可以通过检索他们在网上的相反证据而被否认。</p>
<h5 id="3-3-2-Modification-Strategy（修改策略）："><a href="#3-3-2-Modification-Strategy（修改策略）：" class="headerlink" title="3.3.2 Modification Strategy（修改策略）："></a>3.3.2 Modification Strategy（修改策略）：</h5><p>​            Moidfication就是轻微修改一些HSP。</p>
<p>​            为了让修改不被人类观察者发现，我们采用了typo-based watermarking 技术。具体的说，一个HSP可以通过两种方式来被修改：</p>
<p>​            1. 从相关的语料库中选择常见的拼写错误来替换它；</p>
<p>​            2. 把它的一些字符修改成类似的外观（例如小写字母’l’与阿拉伯数字‘1’很像）。</p>
<p>​            <img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210831160407.png" alt=""></p>
<p>​            由上图可以看出，这种方式对分类结果的扰动是巨大的。</p>
<h5 id="3-3-3-Removal-Strategy（移除策略）"><a href="#3-3-3-Removal-Strategy（移除策略）" class="headerlink" title="3.3.3 Removal Strategy（移除策略）:"></a>3.3.3 Removal Strategy（移除策略）:</h5><p>​            移除策略单独使用也许并不能足够有效地影响预测结果，但是可以很大程度上降低原始预测类型的置信度。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210831161007.png" alt=""></p>
<p>​            由上图可以看出，移除’<strong><em>British</em></strong>‘可以导致原始预测类型的置信度下降了35%。</p>
<h5 id="3-3-4-Combination-of-Three-Strategies"><a href="#3-3-4-Combination-of-Three-Strategies" class="headerlink" title="3.3.4 Combination of Three Strategies:"></a>3.3.4 Combination of Three Strategies:</h5><p>​            如图6所示，单靠去除策略改变输出分类往往是困难的。但是，通过与其他策略相结合，可以避免对原文进行过多的修改或插入。在实践中，我们常常结合以上三种策略来制作微妙的对抗样本。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210831161638.png" alt=""></p>
<p>​            以图7为例，通过去除一个HSP、插入一个伪造事实和修改一个HSP，可以成功地改变输出分类，但单独应用上述任何扰动都失败。具体来说，删除、插入和修改仅使置信度分别下降27.3 %、17.5 %和10.1 %，保持预测类不变。</p>
<h3 id="4-Black-Box-Attack"><a href="#4-Black-Box-Attack" class="headerlink" title="4. Black-Box-Attack:"></a>4. Black-Box-Attack:</h3><p>暂略</p>
<h3 id="5-Evaluation："><a href="#5-Evaluation：" class="headerlink" title="5.  Evaluation："></a>5.  Evaluation：</h3><h4 id="5-1-我们的方法能否执行有效的源-目标误分类攻击"><a href="#5-1-我们的方法能否执行有效的源-目标误分类攻击" class="headerlink" title="5.1 我们的方法能否执行有效的源/目标误分类攻击?"></a>5.1 我们的方法能否执行有效的源/目标误分类攻击?</h4><p>​    <strong><em>答：</em></strong>在众多测试集中，只有DBpedia ontology数据集是一个多分类数据集，故我们在其中随机选取了一些样本：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210831165135.png" alt=""></p>
<h4 id="5-2-所生成的对抗样本能否避免被人类观察者认出来，并同时保持其功能性？"><a href="#5-2-所生成的对抗样本能否避免被人类观察者认出来，并同时保持其功能性？" class="headerlink" title="5.2 所生成的对抗样本能否避免被人类观察者认出来，并同时保持其功能性？"></a>5.2 所生成的对抗样本能否避免被人类观察者认出来，并同时保持其功能性？</h4><p><strong><em>答：</em></strong>我们找了23个学生。他们对项目不了解，然后每个人给20个文本，其中一半是加扰的。让他们分到14个类中，如果他们觉得哪个文本不对劲，让他们指出来。</p>
<p>​            他们总的分类正确率是94.2%，10个对抗样本的正确率是94.8%。所以实用性还是有的。</p>
<p>​            他们标注出了240项修改处，其中12项符合真实的修改。但实际上我们做了594处修改。</p>
<h4 id="5-3-我们的方法足够有效吗？"><a href="#5-3-我们的方法足够有效吗？" class="headerlink" title="5.3 我们的方法足够有效吗？"></a>5.3 我们的方法足够有效吗？</h4><p><strong><em>答：</em></strong>实验中计算梯度和找HTPs花了116小时。14个类的HTPs每个类花了8.29小时。对所有的adversarial示例只执行一次计算。制作一个对抗性的样品大约需要10到20分钟。对于对手来说，获得理想的对抗样本是可以接受的。实际上，她或他愿意花更多的时间来做这件事。</p>
<h3 id="6-Realted-Works"><a href="#6-Realted-Works" class="headerlink" title="6. Realted Works:"></a>6. Realted Works:</h3><p>​    <strong>可以做的方向：</strong>1.自动生成对抗样本；（然而，Papernot等人(Papernot et al. 2016a)提出了一种基于雅可比矩阵的数据集增强技术，该技术可以在不访问其模型、参数或训练数据的情况下，在有限对输入输出的基础上，为目标dnn提供替代模型。作者还表明，使用替代模型也可以有效地制作对抗样本，以攻击目标DNN。）2.迁移、黑盒攻击；</p>
<p>​    </p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>AD</tag>
        <tag>NLP</tag>
        <tag>DNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Black-Box Attacks against RNN based Malware Detection Algorithms</title>
    <url>/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Black-Box%20Attacks%20against%20RNN%20based%20Malware%20Detection%20Algorithms/</url>
    <content><![CDATA[<h1 id="【论文阅读】Black-Box-Attacks-against-RNN-based-Malware-Detection-Algorithms"><a href="#【论文阅读】Black-Box-Attacks-against-RNN-based-Malware-Detection-Algorithms" class="headerlink" title="【论文阅读】Black-Box Attacks against RNN based Malware Detection Algorithms"></a>【论文阅读】Black-Box Attacks against RNN based Malware Detection Algorithms</h1><blockquote>
<p><strong>时间</strong>：2017</p>
<p><strong>作者：</strong> Weiwei Hu 北京大学</p>
<p>​                 Ying Tan    北京大学</p>
</blockquote>
<ul>
<li><h4 id="Abstract："><a href="#Abstract：" class="headerlink" title="Abstract："></a>Abstract：</h4><p>​    1. <strong>原文：</strong></p>
<p>​    最近的研究表明，基于机器学习的恶意软件分类算法在面对对抗样本攻击时表现的十分脆弱。这些工作主要集中于那些利用了混合维度的特征的追踪算法，但一些研究者已经开始使用RNN，基于API特征序列来辨识恶意软件。</p>
<p>​    这篇文章提出了一种用于生成对抗样本序列的原创算法，它被用于攻击基于RNN的恶意软件分类系统。对于攻击者来说，通常，知晓目标RNN的内部结构和权重是很难的。于是一个替代的用于近似目标RNN的RNN模型就被训练了出来，接着我们利用这个RNN来从原始序列输入中生成对抗样本序列。</p>
<p>​    <strong>权威结果表明基于RNN的恶意软件分类算法不能追踪大多数我们所生成的恶意对抗样本，这意味着我们生成的模型可以很有效的规避追踪算法。</strong></p>
<p>​    2. <strong>总结：</strong></p>
<p>​    一个对基于RNN的恶意样本分类器的灰盒攻击，有三个RNN，受害者RNN（源RNN），替代RNN，对抗样本生成RNN。</p>
</li>
</ul>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction:"></a>1. Introduction:</h3><ol>
<li>现有的基于N机器学习的恶意软件追踪算法主要将程序表现为固定维度的特征向量，然后将其分类为无害程序和恶意软件；</li>
<li>举例，利用API的调用序列，或者不被调用的API序列进行分类；</li>
<li>【11】展现了，基于固定维度特征来进行恶意样本分类的算法，面对对抗样本的攻击是脆弱的；</li>
<li>最近也有利用RNN进行恶意样本追踪与分类的，RNN的输入就是API序列。</li>
</ol>
<h3 id="2-Adversarial-Examples"><a href="#2-Adversarial-Examples" class="headerlink" title="2. Adversarial Examples:"></a>2. Adversarial Examples:</h3><p>​    一些其它的针对序列的对抗样本攻击：</p>
<blockquote>
<p>Nicolas Papernot, Patrick McDaniel, Ananthram Swami, and Richard Harang. Crafting adver</p>
<p>sarial input sequences for recurrent neural networks. In <em>Military Communications Conference,</em></p>
<p><em>MILCOM 2016-2016 IEEE</em>, pages 49–54. IEEE, 2016.</p>
<p>Kathrin Grosse, Nicolas Papernot, Praveen Manoharan, Michael Backes, and Patrick McDaniel.</p>
<p>Adversarial perturbations against deep neural networks for malware classifification. <em>arXiv preprint</em></p>
<p><em>arXiv:1606.04435</em>, 2016.</p>
</blockquote>
<h3 id="4-Attacking-RNN-based-Malware-Detection-Algorithms"><a href="#4-Attacking-RNN-based-Malware-Detection-Algorithms" class="headerlink" title="4. Attacking RNN based Malware Detection Algorithms"></a>4. Attacking RNN based Malware Detection Algorithms</h3><p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210830150941.png" alt=""></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210830151007.png" alt=""></p>
<h3 id="5-实验"><a href="#5-实验" class="headerlink" title="5. 实验"></a>5. 实验</h3><p>​    Adam 用于训练所有模型；</p>
<p>​    LSTM由于其在处理长序列的优秀表现，也被应用在实验的所有RNN中。</p>
<h4 id="5-1-数据集："><a href="#5-1-数据集：" class="headerlink" title="5.1    数据集："></a>5.1    数据集：</h4><p>​    <strong>来源：</strong><a href="https://malwr.com/">https://malwr.com/</a>    （一个恶意样本分析网站，爬取180个项目，该网站可以分析用户上传的项目，并给出其API序列，网站中70%的项目都是恶意样本）</p>
<p>​    <strong>数据集划分：</strong>为了模拟真实的测试环境，数据集划分如下：（30%+10%）用于生成RNN，（30%+10%）用于受害者RNN，20%用于测试。</p>
<h4 id="5-2-受害者RNN："><a href="#5-2-受害者RNN：" class="headerlink" title="5.2 受害者RNN："></a>5.2 受害者RNN：</h4><p>​    尝试了不同模型：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210830110738.png" alt=""></p>
<p>​    <strong>结论如下：</strong></p>
<ol>
<li>与LSTM相比，BiLSTM不能提升模型的分类表现；</li>
<li>与Average-Pooling相比，注意力机制的效果更好；</li>
</ol>
<h4 id="5-3-生成（对抗样本）RNN测试结果："><a href="#5-3-生成（对抗样本）RNN测试结果：" class="headerlink" title="5.3 生成（对抗样本）RNN测试结果："></a>5.3 生成（对抗样本）RNN测试结果：</h4><p>​    介绍参数规范：</p>
<blockquote>
<p>The hyper-parameters of the generative RNN and the substitute RNN were tuned separately for each</p>
<p>black-box victim RNN. The learning rate and the regularization coeffificient were chosen by line</p>
<p>search along the direction 0.01, 0.001, et al.. The Gumbel-Softmax temperature was searched in the</p>
<p>range [1<em>,</em> 100]. Actually, the decoder length <em>L</em> in the generative RNN is also a kind of regularization</p>
<p>coeffificient. A large <em>L</em> will make the generative RNN have strong representation ability, but the whole</p>
<p>adversarial sequences will become too long, and the generative RNN’s size may exceed the capacity</p>
<p>of the GPU memory. Therefore, in our experiments we set <em>L</em> to 1.</p>
</blockquote>
<p>​    </p>
<p>​    给出实验结果：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210830140545.png" alt=""></p>
<ol>
<li>对于所有RNN模型，攻击都十分有效；</li>
<li>于LSTM的攻击效果最差，故替代RNN对LSTM的拟合效果并不好；</li>
<li>训练集与测试集的测试效果差别不大， 模型泛化能力强；</li>
<li>即使更换了模型与训练数据集，对抗样本仍效果很好。</li>
</ol>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>AD</tag>
        <tag>Malware Classifiers</tag>
        <tag>RNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Automatically Evading Classififiers----A Case Study on PDF Malware Classififiers</title>
    <url>/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Automatically%20Evading%20Classififiers----A%20Case%20Study%20on%20PDF%20Malware%20Classififiers/</url>
    <content><![CDATA[<h1 id="【论文阅读】Automatically-Evading-Classififiers——A-Case-Study-on-PDF-Malware-Classififiers"><a href="#【论文阅读】Automatically-Evading-Classififiers——A-Case-Study-on-PDF-Malware-Classififiers" class="headerlink" title="【论文阅读】Automatically Evading Classififiers——A Case Study on PDF Malware Classififiers"></a>【论文阅读】Automatically Evading Classififiers——A Case Study on PDF Malware Classififiers</h1><blockquote>
<p><strong>时间：2016</strong></p>
<p><strong>作者：Weilin Xu, Yanjun Qi, and David Evans    弗吉尼亚大学</strong></p>
<p><strong>会议：NDSS（ccf_B类）</strong></p>
</blockquote>
<h3 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h3><ol>
<li><p><strong>白盒黑盒？</strong></p>
<p><strong>黑盒攻击</strong>，需要知道生成样本在目标模型中的输出（分类分数）和目标模型所使用的特征（粗略知道）；</p>
</li>
<li><p><strong>针对什么目标？</strong></p>
<p>仅仅使用表层特征的分类器；</p>
</li>
<li><p><strong>攻击方法？</strong></p>
<p>3.1 <strong>如何制造对抗样本？</strong></p>
<p>​    使用<strong>遗传算法（GP-BASED）</strong>进行随机扰动</p>
<p>3.2 <strong>如何判别对抗样本的恶意能力？</strong></p>
<p>​    使用<strong><em>oracle</em></strong></p>
</li>
</ol>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract:"></a>Abstract:</h3><p>​    在本文，我们提出了一个一般化的方法来检验分类器的鲁棒性，通过在两个PDF恶意样本分类器，PDFrate和Hidost上来检验。其关键就是随机控制一个恶意样本来找到一个对抗样本。</p>
<p>​    我们的方法可以自动地对500个恶意样本种子中找到对于两个PDF分类器的对抗样本，我们的结果提出了一个严重的疑问，基于表面特征的分类器在面对对抗样本时是否还有效？</p>
<hr>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction:"></a>1. Introduction:</h3><p>​    主要贡献：</p>
<pre><code>1. 提出了一个一般化的方法用于自动寻找分类器的对抗样本；
2. 制作了一个原型系统用于自动生成对抗样本；
3. 我们的系统在对500个恶意样本种子寻找对抗样本的过程中，达到了100%的准确率。
</code></pre><hr>
<h3 id="2-Overview："><a href="#2-Overview：" class="headerlink" title="2. Overview："></a>2. Overview：</h3><h4 id="2-1-Finding-Evasive-Samples："><a href="#2-1-Finding-Evasive-Samples：" class="headerlink" title="2.1 Finding Evasive Samples："></a><em>2.1 Finding Evasive Samples</em>：</h4><p>​    <strong>整体思路：</strong></p>
<p>​    <img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210901185852.png" alt=""></p>
<p>​    <strong><em>oracle</em></strong>用于判断一个样本是否具有恶意行为；</p>
<hr>
<h3 id="3-PDF-Malware-and-Classifiers"><a href="#3-PDF-Malware-and-Classifiers" class="headerlink" title="3. PDF Malware and Classifiers"></a>3. PDF Malware and Classifiers</h3><h4 id="3-1-PDFmalware"><a href="#3-1-PDFmalware" class="headerlink" title="3.1 PDFmalware:"></a><em>3.1 PDFmalware:</em></h4><p>​    PDF文件的整体结构：</p>
<p>​        <img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210901191527.png" alt=""></p>
<p>​    早些的PDF恶意样本一般使用JavaScript嵌入，用户双击打开时出发执行恶意脚本。</p>
<p>​    因为不是所有的PDF恶意样本都是嵌入了JavaScript代码，最近的一些PDF恶意分类器就着重于PDF文件的结构化特征。在本文，我们的目标就是攻击这些有代表性的基于文件结构化特征的分类器。</p>
<h4 id="3-2-Target-Classififiers："><a href="#3-2-Target-Classififiers：" class="headerlink" title="3.2 Target Classififiers："></a><em>3.2 Target Classififiers：</em></h4><p>​    <strong>PDFrate：</strong>一个使用随机森林算法的分类器。</p>
<p>​    <strong>Hidost:</strong>一个SVM分类器。</p>
<p>​    </p>
<hr>
<h3 id="4-Evading-PDF-Malware-Classifiers："><a href="#4-Evading-PDF-Malware-Classifiers：" class="headerlink" title="4.  Evading PDF Malware Classifiers："></a>4.  Evading PDF Malware Classifiers：</h3><hr>
<h3 id="5-Experiment"><a href="#5-Experiment" class="headerlink" title="5.  Experiment:"></a>5.  Experiment:</h3><h4 id="5-1-Dataset"><a href="#5-1-Dataset" class="headerlink" title="5.1 Dataset:"></a><em>5.1 Dataset:</em></h4><p>​    <img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210901194138.png" alt=""></p>
<h4 id="5-2-Test："><a href="#5-2-Test：" class="headerlink" title="5.2 Test："></a><em>5.2 Test：</em></h4><p>​    <img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210901194328.png" alt=""></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210901194448.png" alt=""></p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>AD</tag>
        <tag>Malware Classifiers</tag>
        <tag>PDF</tag>
      </tags>
  </entry>
  <entry>
    <title>AD nlp Survey</title>
    <url>/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91AD%20nlp%20Survey/</url>
    <content><![CDATA[<h1 id="【论文阅读】AD-nlp-Survey"><a href="#【论文阅读】AD-nlp-Survey" class="headerlink" title="【论文阅读】AD nlp Survey"></a>【论文阅读】AD nlp Survey</h1><blockquote>
<p><strong>作者：Wei Emma Zhang（阿德莱德大学，澳大利亚）</strong></p>
<p>​             <strong>QUAN Z. SHENG（麦考瑞大学，澳大利亚）</strong></p>
<p>​             <strong>AHOUD ALHAZMI（麦考瑞大学，澳大利亚）</strong></p>
<p>​             <strong>李晨亮（武汉大学，中国）</strong></p>
</blockquote>
<h3 id="1-关键词：DNN，对抗样本，文本数据（textual-data），NLP"><a href="#1-关键词：DNN，对抗样本，文本数据（textual-data），NLP" class="headerlink" title="1. 关键词：DNN，对抗样本，文本数据（textual data），NLP"></a>1. 关键词：DNN，对抗样本，文本数据（textual data），NLP</h3><h3 id="2-摘要："><a href="#2-摘要：" class="headerlink" title="2. 摘要："></a>2. 摘要：</h3><blockquote>
<ol>
<li>传统对抗样本基本都针对计算机视觉领域；</li>
<li>本调查提供针对基于DNNs的NLP对抗样本攻击；</li>
<li>由于CV与NLP本身不同，方法不能直接移植；</li>
<li>集成了截止2017年所有的相关成果，综合性地总结，分析，讨论了40个代表性工作；</li>
<li>简单介绍了CV和NLP相关知识。</li>
</ol>
</blockquote>
<h3 id="3-Introduction"><a href="#3-Introduction" class="headerlink" title="3.Introduction:"></a>3.Introduction:</h3><blockquote>
<ol>
<li><p><strong>简单介绍了对抗样本</strong>；</p>
</li>
<li><p><strong>关于对抗样本的研究可以简单分为三类</strong>：</p>
<p>① 通过使用微小扰动来欺骗DNN，以此来评估它；</p>
<p>② 刻意改变DNN的输出；</p>
<p>③ 检测DNN中过敏感和过迟钝的点，寻找防御攻击的方法。</p>
<ol>
<li><p>==<strong>不能直接使用基于CV的对抗样本生成方法的原因：</strong>==</p>
<p>直接将对图像攻击的对抗样本生成方法应用到文本上，将得到毫无意义的词语和句子片段。这是因为在对图像的对抗样本生成中，即使略微改变每个像素的灰度，肉眼也可以识别原来的图像；但是对于文本串来说，即使改变一个字母，语句的语义也将完全不同或出错。</p>
</li>
</ol>
</li>
<li><p>==<strong>相关研究：</strong>==</p>
<p><u><strong>Reference [i] = 【i】</strong></u></p>
<p>​    ① 【9】：对<strong>针对不同类别的机器学习系统的攻击与防御</strong>做了综合性概述，提出了一种用于辨识和分析这些攻击的分类方法，并将将这些攻击应用到基于机器学习的应用上来证明这些攻击或者防御手段的有效性。例如，一个统计垃圾邮件过滤器。</p>
<p>​    ② 【13】：作者俯瞰了近十年（2008-2018）对抗样本攻击的<strong>发展史</strong>，聚焦点在于CV和网络空间安全。对非深度学习算法和深度学习算法都做了介绍，也从安全的角度仔细分析了这些攻击和防御手段的影响。</p>
<p>​    ③ 【79】：与【13】阐述的问题类似，从数据驱动的角度。</p>
<p>​    ④ 【154】：聚焦于对抗样本在深度学习模型上的使用。介绍了最近的几种不同的在应用上对DNN的攻击，同时全面调查了防御方法。但是，其只讨论了对抗样本在图像分类和物品识别上的攻击。</p>
<p>​    ⑤ 【2】：详细阐述了对抗样本在CV上的应用，是一篇应用程序主导的调查。</p>
<p>​    ⑥ 【35】：从安全的角度阐述了对抗样本的防御手段。（<strong>不仅从机器学习算法或者神经模型上，从所有与安全相关的应用上阐述对抗样本防御</strong>）作者发现现有的与防御相关的安全工作缺乏清晰的<strong>对攻击如何与真实安全问题相关联</strong>的动机和解释，以及这些攻击和防御如何被有意义地衡量，故提出了一种分类方法用于衡量这些。</p>
</li>
</ol>
</blockquote>
<h3 id="4-Overview-（对抗样本攻击-and-深度学习在NLP中的应用）"><a href="#4-Overview-（对抗样本攻击-and-深度学习在NLP中的应用）" class="headerlink" title="4. Overview （对抗样本攻击 and 深度学习在NLP中的应用）:"></a>4. Overview （对抗样本攻击 and 深度学习在NLP中的应用）:</h3><blockquote>
<ol>
<li><p>给出了<strong>DNN，Perturbations，Adversarial Examples</strong>的定义；</p>
</li>
<li><p>介绍了<strong>Treat Model</strong>：</p>
<p> 2.1 <em>Granularity（颗粒度）</em>:攻击的颗粒度指的是对抗样本生成的数据等级，例如对图像数据通常是像素，对文本数据就是字母，单词，句子嵌入等级。</p>
<p> 2.2 <em>Motivation（动机）</em>：生成对抗样本的动机通常有两种，攻击和防御：1.攻击的目的是检验DNN的健壮性；2. 防御的目的是使DNN更加稳固，第五部会给出更详细的讲解。</p>
</li>
<li><p>介绍了<strong>Measurements</strong>（评价<u>adversarial attack</u>的方法）：</p>
<p>3.1 控制扰动（<em>Perturbation Constraint</em>）：</p>
<p>​    根据前面所述，扰动 <em>η</em> 应该不影响样本原来的真实分类，<u>故如果一个分类器是理想的，那么扰动后的样本应不影响其分类结果</u>； <em>η</em> 同时也不能太小，以避免对目标DNN没有影响。在理想情况下，有效扰动是在一定范围内最有效果的噪声。</p>
<p>​    【132】首次在图像对抗样本攻击中约束了(x + <em>η</em>) ∈ [0, 1]^n^ 的范围，以保证对抗样本与原始数据有着相同的像素等级。</p>
<p>​    【40】简化了问题的解决方法，并使用了无穷范数来限制扰动，==这受到直觉的启发，即一个不改变任何特定像素的扰动量超过一定量 ϵ 就不能改变输出类。==（PS:WHY？）无穷范数在图像/物品分类识别任务中是足够有效的，其他的范数，例如L0和L2范数，过去被用于在对CV的DNN攻击中限制扰动。在文本对抗样本攻击中，这有所不同，第3.3节会给出更多细节。</p>
<p>3.2 评估攻击的有效性（<em>Attack Evaluation</em>）：</p>
<p>​     对抗样本攻击旨在降低DNNs的性能，因此，评估攻击的有效性是基于不同任务的性能指标。例如，分类任务中有评价指标准确度，F1-score，AUC-score。在本文中，我们将针对不同NLP的评价标准作为超范围内容，并建议读者参考特定的信息。</p>
<p>​    ==<strong><em>以上是总体分类与信息</em></strong>==</p>
</li>
</ol>
<hr>
<p>  ​    ==<strong><em>以下是深度学习在NLP中的应用</em></strong>==</p>
<p>  ​    除了向前传播的神经网络和CNN，RNN及其变式由于其天然的处理序列的能力，也被用于NLP中。</p>
<ol>
<li><p><strong>近几年深度学习对NLP的重大影响</strong>：</p>
<p>1.1 序列学习（<em>sequence-to-sequence learning</em>）</p>
<p>1.2 注意力机制（<em>attention mechanism</em>）</p>
<p>1.3 强化学习（reinforcement learning）和生成模型（generative models）</p>
<p>具体详细的神经网络在NLP中的应用见【100】，【152】</p>
<ol>
<li><strong>Feed-Forward Networks:</strong></li>
</ol>
<p><strong>缺点：</strong>不能很好地处理对于词语顺序很重要的文本序列，因为其并不记录元素的顺序。为了评价其健壮性，往往针对专门设计的前馈网络生成对抗实例，【3】，【43】，【44】作者研究了指定的恶意软件检测模型。</p>
<ol>
<li><strong>CNN：</strong></li>
</ol>
<p>​    CNN识别本地预测因子并将它们组合在一起，为输入生成一个固定大小的向量，该向量包含数据中最重要或最重要的信息方面。</p>
<p>​    CNN对顺序敏感，因此，它擅长做计算机视觉，随后被广泛用于NLP应用。</p>
<p>​    卷积操作被简直在词的序列方向上，而不是词的嵌入。</p>
<p>​    <strong>两个经典工作：</strong>1. 【59】使用CNN和Word2Vec进行句子分类 2.【156】使用CNN和热独编码进行文本分类。</p>
<ol>
<li><strong>RNN：</strong></li>
</ol>
<p>​    主要介绍RNN及其变式（LSTM，GRU）</p>
<ol>
<li><strong>Seq2Seq（<em>sequence-to-sequence learning</em>）：</strong></li>
</ol>
<p>​    Seq2Seq模型具有优越的能力，能够为具有编码器-解码器结构的给定序列信息生成另一个序列信息.</p>
<p>​    通常，一个Seq2seq由两个RNN结构组成，一个用于编码，一个用于解码。VHRED是一个最近很受欢迎的Seq2seq模型，它利用子序列之间的复杂依赖关系生成序列。</p>
<p>​    【24】是最初的使用Seq2seq模型的神经机器翻译模型（NMT）之一；</p>
<p>​    【63】是一个最近提出的 seq2seq NMT模型，是此领域的benchmark；</p>
<p>​    【22,30,98,127】有对其的攻击。</p>
<ol>
<li><strong>Attention Models：</strong></li>
</ol>
<p>​    注意力机制最初被设计用来克服seq2seq模型中对长序列编码的问题。</p>
<p>​    注意力允许解码器回溯源序列的隐藏状态，然后，隐藏状态提供一个加权平均作为解码器的额外输入。</p>
<ol>
<li><strong>Reinforcement Learning Models：</strong></li>
</ol>
<p>​    强化学习通过在代理执行离散动作后给予奖励来训练代理，在NLP中，强化学习框架通常由一个代理（DNN），一个策略部分（用于指导动作）和奖励组成。</p>
<p>​    代理基于策略做出一个动作（例如预测序列中下一个单词的位置），然后相应地更新其内部状态，直到到达序列的末尾，在这里奖励已经被计算完成。</p>
<p>​    强化学习需要正确处理每一步的动作和状态，这可能会限制模型的表现力和学习规模。但它在面向任务的对话系统中获得了很多好处，因为它们在决策过程共享着同一根本原则。</p>
<ol>
<li><strong>Deep Generative Models（深层生成模型）：</strong></li>
</ol>
<p>​    近些年，两种深层生成模型获得了很多关注：<strong>Generative Adversarial Networks (GANs) 【39】 and Variational Auto-Encoders (VAEs)</strong> </p>
<p>​    其可以在潜在空间中生成与真实数据分厂相似的数据样例，在NLP领域，它们被用来生成文本。</p>
<p>​    8.1 <strong>GANS:</strong></p>
<p>​    Gans由两个对抗网络组成：生成器（generator）和鉴别器（discriminator）。鉴别器的作用是鉴别真实样本和生成样本，生成器的作用是生成很真实的，用于欺骗鉴别器的样本。</p>
<p>​    Gan使用min-max loss function来同步训练两个神经网络。</p>
<p>​    8.2 <strong>VAES：</strong></p>
<p>​    Vaes由编码器（encoder）和生成器（generator）组成。编码器的作用是对输入编码为潜在空间，生成器的作用是从潜在空间中生成样本。</p>
<p><u>深度模型都不是很好训练，这个缺点阻碍了其在真实世界的应用中的广泛应用，尽管他们已经被用于生成文本，但目前没有工作去用对抗样本检验它们的健壮性。</u></p>
</li>
</ol>
</blockquote>
<h3 id="5-From-image-to-text"><a href="#5-From-image-to-text" class="headerlink" title="5. From image to text:"></a>5. From image to text:</h3><blockquote>
<p><strong>一. 构造对抗样本：</strong></p>
<ol>
<li><strong>、L-BFGS:</strong></li>
</ol>
<p>​    Szegedy【132】等人首次证明了可以通过对图像添加小量的人类察觉不到的扰动误导深度神经网络图像分类器做出错误的分类。他们首先尝试求解让神经网络做出误分类的最小扰动的方程。作者认为，深度神经网络所具有的强大的非线性表达能力和模型的过拟合是可能产生对抗性样本原因之一。</p>
<ol>
<li><strong>FGSM（Fast Gradient Sign Method）：</strong></li>
</ol>
<p>​    L-BFGS很有效但成本高昂，这使Goodfellow【40】等人找到一个简化问题的方法。</p>
<ol>
<li><strong>JSMA（Jacobian Saliency Map Adversary）：</strong></li>
</ol>
<p>​    与FGSM利用梯度攻击不同，Papernot【105】等人使用<strong>forward derivatives</strong>（远期衍生物？）生成对抗样本。这个方法通过使用其雅克比矩阵来评估神经模型对每个输入部分的输出敏感性。</p>
<ol>
<li><strong>DeepFool：</strong></li>
</ol>
<p>​    DeepFool是一种迭代的L2正则化算法，作者先假设神经网络是线性的，因此可以使用一个超平面来分离类。作者简化了问题并且基于以上假设找到了问题最优解，并构建了对抗样本、</p>
<p>​    为了解决神经网络是非线性的事实，作者重复他们的步骤直到一个真正的对抗样本被生成了。</p>
<p>PS：正则化：<a href="https://www.zhihu.com/question/20924039">(23 封私信 / 54 条消息) 机器学习中常常提到的正则化到底是什么意思？ - 知乎 (zhihu.com)</a></p>
<ol>
<li><strong>Subsititute Attack：</strong></li>
</ol>
<p>​    前面四中攻击方式都是<strong>白盒攻击</strong>， Papernot【104】等人提出了黑盒攻击策略，他们训练了一个与目标模型决策边界相似的替代模型，对此替代模型进行白盒攻击，生成相应对抗样本。</p>
<p>​    在生成对抗样本的过程中，他们使用了FSGM和JSMA。</p>
<ol>
<li><p><strong>GAN-like Attack：</strong></p>
<p>​    这是一种通过深度生成模型的黑盒攻击方法，Zhao【157】等人首先基于数据集 X 训练了一个生成模型WGAN，WGAN可以生成与X分布相同的数据点。</p>
</li>
</ol>
<p><strong>二. 对图像DNN攻击与对文本DNN攻击的对比：</strong></p>
<p>​    <strong>1. 二者的主要不同：</strong></p>
<p>​        1.1 离散与连续输入：</p>
<p>​            图像输入是连续的而文本输入是离散的，在图像输入中，通常使用L~p~来衡量原始数据点和扰动点的距离，但是由于文本输入是离散的，很难定义文本上的扰动大小（==为什么？==）。这就需要构造对文本扰动的衡量方法。还有一种方式是将文本输入当做连续值，然后应用CV方法，在3.3节上将会详细讨论。</p>
<p>​        1.2 可察觉与不可察觉：</p>
<p>​            与图像相比，文本数据即使更改一个字母也会造成很大变化，故即使做很小的扰动，也可以被很明显的察觉到。</p>
<p>​        1.3 有语义和无语义：</p>
<p>​            原理同上，在文本中做很小的改动往往会极大地影响到文本的语法和语义信息。</p>
<p>​    基于以上不同，目前主流对文本DNN的攻击有两种：1. 调整图像DNN的攻击方法，添加额外限制；2. 使用新技术提出一个新方法。</p>
<p><strong>三. 向量化文本输入 and 扰动的衡量方法</strong></p>
<ol>
<li><p><strong>三种向量化文本输入的方法：</strong></p>
<p>1.1 <strong>基于计数的编码（<em>Word-Count-based Encoding</em>）</strong>：</p>
<p>​    ① <strong>BOW（Bag-of-words）</strong>方法，将一个文档中出现的词语编号为向量的0,1,2…..i维度，每个维度的值代表词语出现的次数。（缺点：不能记住词语顺序）</p>
<p>​    ②  <strong>Term frequency-inverse document frequency (TF-IDF)</strong> ，具体见：</p>
<p><a href="https://blog.csdn.net/asialee_bird/article/details/81486700">TF-IDF算法介绍及实现_Asia-Lee-CSDN博客_tf-idf</a></p>
<p>​    1.2 <strong>热独编码（<em>One-hot Encoding</em>）</strong>:</p>
<p>​    具体介绍略。</p>
<p>​    由于普通顺序编码的值存在大小关系，当模型得到输入后会将其当做实际值来处理，这就使得原本平行的数据有了大小关系，独热编码巧妙地解决了这个问题，使得所有单词或者字母低位平等。</p>
<p>​    1.3 <strong>稠密编码：</strong></p>
<p>​    Word2Vec使用连续BOW模型和skip-gram 模型来做代码嵌入。</p>
<p>​    <strong>一个潜在的假设是，出现在相似语境下的词语有着相似的含义。</strong> 词嵌入在一定程度上缓解了文本数据向量化的离散性和数据稀疏性问题【36】，词嵌入的扩展如doc2vec和paragraph2vec【69】将句子/段落编码为稠密向量。</p>
</li>
</ol>
<ol>
<li><p><strong>扰动的衡量方法：</strong></p>
<p>2.1 <strong>基于范数的方法（<em>Norm-based measurement</em>）</strong>：</p>
<p>​    直接使用范数需要输入数据是连续的。一个解决方法是使用连续且稠密的表示方法（如嵌入），但这通常会得到无意义的文本。</p>
<p>2.2 <strong>基于语法和句法的方法（<em>Grammar and syntax related measurement</em>）：</strong></p>
<p>​    通过确认文本语法的正确性来保证对抗样本不易被识别。</p>
<p>​    可以使用<strong>Perplexity</strong>【91】，<strong>Paraphrase</strong>（4.3.3）确保对抗样本的有效性。</p>
<p>2.3 <strong>基于语义保持的方法（<em>Semantic-preserving measurement</em>）：</strong></p>
<p>​    ① 计算欧拉距离:</p>
<p><img src="http://shaw-typora.oss-cn-beijing.aliyuncs.com/20210715215755.png" alt=""></p>
<p>​    ② 计算<strong>Cosine Similarity</strong>（余弦相似度）：</p>
<p><img src="http://shaw-typora.oss-cn-beijing.aliyuncs.com/20210715215851.png" alt=""></p>
<p>​    </p>
<p>2.4 <strong>基于编辑距离的方法：</strong></p>
<p>​    <strong>编辑距离（Edit Distance）</strong>，又称Levenshtein距离，是指两个字串之间，由一个转成另一个所需的最少编辑操作次数。许可的编辑操作包括将一个字符替换成另一个字符，插入一个字符，删除一个字符。一般来说，编辑距离越小，两个串的相似度越大。</p>
<p>​    不同定义使用不同的转换操作。</p>
<p>2.5 <strong>基于Jaccard相似系数的方法：</strong></p>
<p>​    Jaccard相似系数定义见百度百科。</p>
<p>​    就是把两个集合的交集除以两个集合的并集，简单地看集合中的元素是不是大量相同。</p>
<p><img src="http://shaw-typora.oss-cn-beijing.aliyuncs.com/20210715220447.png" alt=""></p>
</li>
</ol>
</blockquote>
<h3 id="6-Attacking-Neural-Models-in-NLP"><a href="#6-Attacking-Neural-Models-in-NLP" class="headerlink" title="6. Attacking Neural Models in NLP:"></a>6. Attacking Neural Models in NLP:</h3><blockquote>
<ol>
<li><p><strong>常见攻击方法：</strong></p>
<p>白盒，黑盒……</p>
<p><img src="http://shaw-typora.oss-cn-beijing.aliyuncs.com/20210715221355.png" alt=""></p>
<p>​    </p>
</li>
<li><p>提供了数据集来源，<strong>但没有提供生成对抗样本的数据集，所提供的的数据集仅用于评估攻击效果。</strong></p>
</li>
</ol>
</blockquote>
<h3 id="7-Defense"><a href="#7-Defense" class="headerlink" title="7. Defense:"></a>7. Defense:</h3><blockquote>
<ul>
<li>背景：两种在DNN中常用的防御方法：<u>1. 对抗训练(adversarial training) 2. 知识蒸馏（knowledge distillation）.</u></li>
<li>Knowledge distillation：<a href="https://zhuanlan.zhihu.com/p/102038521">【经典简读】知识蒸馏(Knowledge Distillation) 经典之作 - 知乎 (zhihu.com)</a></li>
</ul>
<p><strong>一. 对抗训练</strong></p>
<ol>
<li><p><strong>数据增强（<em>Data Augmentation</em>）：</strong></p>
<p>​    数据增强将原始数据集加上对抗样本一起，在训练的过程中让模型见到更多数据，数据增强常被用来对抗黑盒攻击，实现的方式是通过在被攻击的DNN上使用对抗样本增加额外的epoch。</p>
<p>​    【54】证明了这种方法是有效的，但仅仅对同一对抗样本有效（数据增强中的样本与测试对抗样本）</p>
<p><img src="http://shaw-typora.oss-cn-beijing.aliyuncs.com/20210716100311.png" alt=""></p>
<p>​    【142】也提出了类似的观点</p>
<p>​    【56】作者提出了3种生成更多具有不同特征的数据的方法</p>
<p>​    【12】<strong>作者提出了一种新的数据增强的方法</strong>，它将平均字符嵌入作为一个词表示，并将其纳入输入。这种方法本质上对字符的置乱不敏感，例如交换、mid和Rand，因此可以抵抗这些置乱攻击引起的噪声。但是，这种防御方法对不是针对字符顺序的扰乱不起作用。</p>
</li>
<li><p><strong>模型正则化（<em>Model Regularization</em>）：</strong></p>
<p>模型正则化将生成的对抗样本实例作为正则化器：</p>
<p><a href="https://blog.csdn.net/weixin_41503009/article/details/104594972">模型正则化_少年吉的博客-CSDN博客_模型正则化</a></p>
<p>正则化( Regularization)的目的在于提高模型在未知测试数据上的泛化力,避免参数过拟合。</p>
<ol>
<li><strong>健壮性最优化方法（<em>Robust Optimization</em>）：</strong></li>
</ol>
<p>Madry【84】等人将DNN学习问题转化为了一个包含内非凹最大化问题(攻击)和外非凸最小化问题(防御)的健壮性优化问题。</p>
</li>
</ol>
<p><strong>二. 知识蒸馏</strong></p>
<p>​    详见论文和博客。</p>
</blockquote>
<h3 id="8-Discuss-and-Open-issues"><a href="#8-Discuss-and-Open-issues" class="headerlink" title="8.Discuss and Open issues"></a>8.Discuss and Open issues</h3><blockquote>
<ol>
<li><p><strong>可察觉性（<em>Perceivability</em>）</strong>：</p>
<p>见前文</p>
</li>
<li><p><strong>可转移性（<em>Transferability</em>）</strong>：</p>
<p>no-tatgeted攻击的可转移性更强。</p>
<p>可转移性可以在三个地方体现：</p>
<p>​    2.1 同样的架构，不同的数据；</p>
<p>​    2.2 同样的应用场景，不同的架构；</p>
<p>​    2.3 不同的架构，不同的数据。</p>
<p><u><strong>尽管现有的工作囊括了以上三种情况，但对抗样本攻击的可移植性效果仍不好，需要更多的工作。</strong></u></p>
</li>
<li><p><strong>自动化（<em>Automation</em>）</strong>：</p>
<p>​    一些工作可以做到对抗样本的自动生成，而另一些则不行。</p>
<p>​    在白盒攻击中，利用DNN的损失函数可以自动识别文本中受影响最大的点(如字符、词)，以此做到在文本中自动化。</p>
<p>​    在黑盒攻击中，一些攻击例如替代训练（substitution train）可以训练出一个替代用模型，对其进行白盒攻击，也可以实现自动化。但是大多数对抗样本的生成都是人工生成。【54】会关联人工选择的无意义的文本段落来欺骗阅读理解系统，以此来发现DNN的脆弱性。很多研究工作跟随【54】，其目的不是实际攻击，而是更多的在检测目标网络的健壮性上，这些人工工作是耗时且不切实际的。我们相信在未来更多的努力会用来克服这个困难。</p>
</li>
<li><p><strong>新架构（<em>New Architectures</em>）</strong>：</p>
<p>​    尽管大多数普通的文本DNN都注意到了对抗样本攻击，但是很多DNN并没有被攻击过。例如GANS与VAES，它们被用作生成文本。深度生成模型需要更复杂的技巧去训练，这就可以解释为什么这些技术忽略了对抗样本攻击。未来的工作可能考虑对这些DNN进行对抗样本攻击。</p>
<p>​    注意力机制（Attention Mechanism）目前是大多数序列模型的标准组成部分，但是没有工作去检验注意力机制本身。故可能的攻击工作要么攻击包含注意的整体系统，要么利用注意分数来识别干扰词【14】。</p>
</li>
<li><p><strong>迭代 VS 一次性（<em>Iterative versus One-of</em>）</strong>：</p>
<p>​    <strong>迭代攻击</strong>：效果好，耗时长；</p>
<p>​    <strong>一次性攻击</strong>：效果略差，耗时短。</p>
<p>​    在设计攻击方法时，攻击者需要仔细考虑效果与效率的平衡。</p>
</li>
</ol>
</blockquote>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>AD</tag>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>A Benchmark API Call Dataset For Windows PE Malware Classification</title>
    <url>/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91A%20Benchmark%20API%20Call%20Dataset%20For%20Windows%20PE%20Malware%20Classification/</url>
    <content><![CDATA[<h1 id="【论文阅读】A-Benchmark-API-Call-Dataset-For-Windows-PE-Malware-Classification"><a href="#【论文阅读】A-Benchmark-API-Call-Dataset-For-Windows-PE-Malware-Classification" class="headerlink" title="【论文阅读】A Benchmark API Call Dataset For Windows PE Malware Classification"></a>【论文阅读】A Benchmark API Call Dataset For Windows PE Malware Classification</h1><blockquote>
<p><strong>作者：Ferhat Ozgur Catak（土耳其）</strong></p>
<p>​            <strong>Ahmet Faruk Yazi（土耳其）</strong></p>
<p><strong>时间：2021.2.23</strong></p>
<p><strong>关键词：恶意软件分析，网络空间安全，数据集，沙箱环境，恶意软件分类</strong></p>
</blockquote>
<h3 id="1-Abstract"><a href="#1-Abstract" class="headerlink" title="1. Abstract"></a>1. Abstract</h3><p>​    在Windows操作系统中，系统API调用的使用在监控恶意PE程序中是一个很有前途的方法。这个方法被定义为在安全隔离的沙箱环境中运行恶意软件，记录其调用的Windows系统API，再顺序分析这些调用。<br>​    在这里，我们在隔离沙箱中分析了7107个属于不同家族（病毒，后门，木马等）的恶意软件，并把这些分析结果转化为了不同分类算法和方法可以使用的形式。<br>​    <strong>首先</strong>，我们会解释如何得到这些恶意软件；<strong>其次</strong>，我们会解释如何将这些软件捆绑至家族中；<strong>最后，</strong>我们会描述如何使用这些数据集来通过不同的方法实现恶意软件的分类。</p>
<hr>
<h3 id="2-Introduction"><a href="#2-Introduction" class="headerlink" title="2. Introduction"></a>2. Introduction</h3><h4 id="2-1-简单介绍了恶意软件"><a href="#2-1-简单介绍了恶意软件" class="headerlink" title="2.1 简单介绍了恶意软件"></a>2.1 简单介绍了恶意软件</h4><h4 id="2-2-恶意软件与恶意软件识别之间的竞争"><a href="#2-2-恶意软件与恶意软件识别之间的竞争" class="headerlink" title="2.2 恶意软件与恶意软件识别之间的竞争"></a>2.2 恶意软件与恶意软件识别之间的竞争</h4><p>​    相互促进</p>
<h4 id="2-3-变形恶意软件（Metamorphic-malware）"><a href="#2-3-变形恶意软件（Metamorphic-malware）" class="headerlink" title="2.3 变形恶意软件（Metamorphic malware）"></a>2.3 变形恶意软件（Metamorphic malware）</h4><p>​        恶意软件家族里很先进的一种，这种软件可以持续不断的改变自身源代码以此改变自身结构，通过这种方式来改变自身代码特征。还有，这种软件可能还可以通过强度反算（counter-analysis）来识别自身运行的环境，以此来隐藏自身的恶意功能。</p>
<p>​        变形恶意软件很难识别。</p>
<h4 id="2-4-恶意软件的识别："><a href="#2-4-恶意软件的识别：" class="headerlink" title="2.4 恶意软件的识别："></a>2.4 恶意软件的识别：</h4><p>​        所有恶意软件都会有恶意行为以达成其目的，如果可以很好的分析恶意行为，就可以做成恶意软件的识别与分类。<br>​        恶意软件的识别包括了很多需要解决的问题，例如在汇编中不正确的跳转操作码，PE文本段代码隐藏，代码加密。本研究收集了现有的恶意软件及其变式，例如WannaCry，Zeus，特别是在Github上。</p>
<p>​        我们通过在VirusTotal网站上寻找每个恶意软件的哈希值，从而获得了得到了其家族类。</p>
<p>​        最后，所有我们记录的行为都是在Cuckoo沙盒环境中运行的。</p>
<p>​        我们发现几乎所有恶意软件都会使用很多方法改变其行为，但即使这样，恶意软件还是有一个目标，有一个确定的模式来达到此目标。还有，恶意软件会做出一些不必要的API调用，但其还是可以被一个训练好的分析器识别，因为其行为模式是相同的。</p>
<p>​        恶意软件分析被视为网络空间安全的一个分支，其由两方面组成：</p>
<h5 id="1-静态分析-："><a href="#1-静态分析-：" class="headerlink" title="1. 静态分析 ："></a><strong>1. 静态分析 </strong>：</h5><p>​                静态分析可以可以定义为通过执行一个孤立的环境检查可执行文件而不查看实际指令。例如MD5校验和，其通过反病毒检测攻击识别，查找字符串。</p>
<h5 id="2-动态分析"><a href="#2-动态分析" class="headerlink" title="2. 动态分析"></a>2. 动态分析</h5><p>​                动态分析指运行恶意程序来理解其功能，观察其表现，识别其技术指标。几乎所有的重要行为都包含API调用序列。</p>
<p>​        <strong>大多数动态分析领域的研究都只关注分类算法，有个基本问题是没有标准的数据集来检查所提出模型的效率。</strong></p>
<p>​        <strong>我们在Github上分享了我们的数据集：<a href="https://github.com/ocatak/malware_api_class">https://github.com/ocatak/malware_api_class</a> ，该数据集包含了基于Cuckoo沙箱的已知恶意软件执行和基于VirusTotal的文件MD5特征分类的原始数据。</strong></p>
<hr>
<h3 id="3-Methods"><a href="#3-Methods" class="headerlink" title="3. Methods"></a>3. Methods</h3><h4 id="3-1-Windows-API-Calls："><a href="#3-1-Windows-API-Calls：" class="headerlink" title="3.1 Windows API Calls："></a>3.1 Windows API Calls：</h4><p>​    软件安全知识，略</p>
<h4 id="3-2-Cuckoo-SandBox"><a href="#3-2-Cuckoo-SandBox" class="headerlink" title="3.2 Cuckoo SandBox"></a>3.2 Cuckoo SandBox</h4><p>​    免费软件，高度集成，开源，可以自动分析Winodws,OS X,Linux,Android系统下的恶意文件。</p>
<h4 id="3-3-VirusTotal"><a href="#3-3-VirusTotal" class="headerlink" title="3.3 VirusTotal"></a>3.3 VirusTotal</h4><p>​    可以在线免费分析文件或者URL。其提供了一个API，可以不通过浏览器来提供分析结果，可以自动分析。其以JSON文件的形式提供分析结果，不同反病毒应用引擎和浏览器的分析结果会分开存放。</p>
<h4 id="3-4-数据集生成"><a href="#3-4-数据集生成" class="headerlink" title="3.4 数据集生成"></a>3.4 数据集生成</h4><p>​    本文的数据集有着简单明了的结构。数据集以CVS格式文件提供来提高互操作性，而且并不需要特定的软件或者库来读取他们。数据由来自不同Github页面的Git命令实施收集，数据集中的每一行都是在沙箱中分析的Windows操作系统的API调用序列。</p>
<p>​    数据集的生成过程如下：</p>
<p>​    <strong>1. 沙箱环境准备：</strong></p>
<p>​    分析机器使用Ubuntu系统，将Cuckoo沙箱安装在其中，分析机运行虚拟服务，Windows操作系统就运行在虚拟服务上，同时关掉防火墙，系统升级。</p>
<p>​    <strong>2. 分析恶意软件:</strong></p>
<p>​    虚拟机中同时运行超过20000个恶意软件，应用程序会将每个恶意软件的分析结果写入MongoDB数据库，分析结果中包含恶意软件的行为数据，这些数据都是恶意软件在Win7上的API调用请求。</p>
<p>​    <strong>3. 处理API调用：</strong></p>
<p>​    我们在数据集中收集到了342种API调用，这些调用会被以0-341来标记，以此生成一个新数据集。我们使用了该数据集中至少有10个不同API调用的恶意软件的分析结果。</p>
<p>​    <strong>4. 使用Virus Total公用API分析恶意软件：</strong></p>
<p>​    作为分析的补充，所有在数据集中的恶意软件也会被Virus Total所分析，通过这种方式，每个恶意软件都会被不同的反病毒引擎所分析，结果会被记录。</p>
<p>​    <strong>5. 处理分析结果：</strong></p>
<p>​    Virus Total服务使用大约66个不同的防病毒应用程序进行文件分析。利用我们利用这个服务得到的每个研究结果，我们识别了每个恶意软件的家族。通过观察，我们发现对于同一恶意软件，不同的防病毒应用程序给出了不同的结果。此外，观察到并非每一个防病毒应用程序都能检测到一些恶意软件。因此，在检测每一个恶意软件类时，认为它属于所有分析中的大多数类。</p>
<p><img src="http://shaw-typora.oss-cn-beijing.aliyuncs.com/20210716172418.png" alt=""></p>
<p><img src="http://shaw-typora.oss-cn-beijing.aliyuncs.com/20210716172518.png" alt=""></p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>AD</tag>
        <tag>Malware Classifiers</tag>
      </tags>
  </entry>
  <entry>
    <title>Generic Black-Box End-to-End Attack Against State of the art API Call Based Malware Classifiers</title>
    <url>/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Generic%20Black-Box%20End-to-End%20Attack%20Against%20State%20of%20the%20art%20API%20Call%20Based%20Malware%20Classifiers/</url>
    <content><![CDATA[<h1 id="【论文阅读】Generic-Black-Box-End-to-End-Attack-Against-State-of-the-art-API-Call-Based-Malware-Classifiers"><a href="#【论文阅读】Generic-Black-Box-End-to-End-Attack-Against-State-of-the-art-API-Call-Based-Malware-Classifiers" class="headerlink" title="【论文阅读】Generic Black-Box End-to-End Attack Against State of the art API Call Based Malware Classifiers"></a>【论文阅读】Generic Black-Box End-to-End Attack Against State of the art API Call Based Malware Classifiers</h1><blockquote>
<p><strong>作者：Ishai Rosenberg </strong></p>
<p><strong>大学：Ben-Gurion University of the Negev</strong></p>
<p><strong>时间：2018.6.4</strong></p>
</blockquote>
<h3 id="1-做了什么？"><a href="#1-做了什么？" class="headerlink" title="1. 做了什么？"></a>1. 做了什么？</h3><ul>
<li><p>​    对一个通过机器学习训练的，通过API调用来分类恶意软件的分类器的攻击。</p>
<p>​    这个攻击可以使分类器不能成功识别恶意软件，并且不改变原有软件的功能。</p>
</li>
<li><p>​    实现了<strong>GADGET</strong>，一个可以直接将二进制恶意软件文件转换为分类器无法检测的二进制文件，<strong>并不需要访问文件源代码。</strong></p>
</li>
</ul>
<h3 id="2-一些概念："><a href="#2-一些概念：" class="headerlink" title="2. 一些概念："></a>2. 一些概念：</h3><h4 id="2-1-Machine-learning-malware-classififiers（基于机器学习的恶意软件分类器）"><a href="#2-1-Machine-learning-malware-classififiers（基于机器学习的恶意软件分类器）" class="headerlink" title="2.1 Machine learning malware classififiers（基于机器学习的恶意软件分类器）"></a>2.1 Machine learning malware classififiers（基于机器学习的恶意软件分类器）</h4><p>​    优点：1. 可以自动训练，节省时间；</p>
<p>​                2. 只要分类器并不是基于指纹特征或者某个特定的特征（如Hash值）来分类，面对不可见威胁时泛化能力较强。</p>
<h4 id="2-2-Adversarial-Examples（对抗样本）"><a href="#2-2-Adversarial-Examples（对抗样本）" class="headerlink" title="2.2 Adversarial Examples（对抗样本）"></a>2.2 Adversarial Examples（对抗样本）</h4><p><strong>对输入样本故意添加一些人无法察觉的细微的干扰，导致模型以高置信度给出一个错误的输出。</strong></p>
<ol>
<li><strong>可以针对一张已经有正确分类的image，对其进行细微的像素修改，可以在DNN下被错分为其他label。</strong></li>
</ol>
<p><img src="%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Generic%20Black-Box%20End-to-End%20Attack%20Against%20State%20of%20the%20art%20API%20Call%20Based%20Malware%20Classifiers/v2-ed60089ae25c81ba2677ec34ffa2a47f_720w.jpg" alt=""></p>
<p>​    样本x的label为熊猫，在对x添加部分干扰后，在人眼中仍然分为熊猫，但对深度模型，却将其错分为长臂猿，且给出了高达99.3%的置信度。</p>
<p><img src="%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Generic%20Black-Box%20End-to-End%20Attack%20Against%20State%20of%20the%20art%20API%20Call%20Based%20Malware%20Classifiers/v2-59a3afcc069df94927ffe1efd62822e9_720w.jpg" alt=""></p>
<p>像素攻击：改动图片上的一个像素，就能让神经网络认错图，甚至还可以诱导它返回特定的结果。</p>
<p>改动图片上的一个像素，就能让神经网络认错图，甚至还可以诱导它返回特定的结果</p>
<p><strong>2. 同样，根据DNN，很容易产生一张在人眼下毫无意义的image，但是在DNN中能够获得高confidence的label。</strong></p>
<p><img src="%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Generic%20Black-Box%20End-to-End%20Attack%20Against%20State%20of%20the%20art%20API%20Call%20Based%20Malware%20Classifiers/v2-0390bba1f2c35220c8b099b8ab0f4ebc_720w.jpg" alt=""></p>
<p>两种EA算法生成的样本，这些样本人类完全无法识别，但深度学习模型会以高置信度对它们进行分类，例如将噪声识别为狮子。</p>
<h5 id="2-2-1：-Adversarial-examples-for-API-sequences-生成API序列对抗样本与生成图像对抗样本并不同"><a href="#2-2-1：-Adversarial-examples-for-API-sequences-生成API序列对抗样本与生成图像对抗样本并不同" class="headerlink" title="2.2.1： Adversarial examples for API sequences(生成API序列对抗样本与生成图像对抗样本并不同):"></a>2.2.1： Adversarial examples for API sequences(生成API序列对抗样本与生成图像对抗样本并不同):</h5><ol>
<li>API序列由长度可变的离散符号组成，但图像可以用固定维度的矩阵表示为矩阵，且矩阵的值是连续的。</li>
<li>对于对抗API序列，其必须验证原始的恶意功能是完整的。</li>
<li><strong>对抗样本的迁移性</strong>：针对一种模型的对抗样本通常对另一种模型也奏效，即使这两个模型不是用同一数据集训练的。</li>
</ol>
<h4 id="2-3-几种攻击方法："><a href="#2-3-几种攻击方法：" class="headerlink" title="2.3 几种攻击方法："></a>2.3 几种攻击方法：</h4><blockquote>
<p><strong>White-box attack</strong>：白盒攻击，对模型和训练集完全了解。</p>
<p><strong>Black-box attack</strong>：黑盒攻击：对模型不了解，对训练集不了解或了解很少。</p>
<p><strong>Real-word attack</strong>：在真实世界攻击。如将对抗样本打印出来，用手机拍照识别。</p>
<p><strong>targeted attack</strong>：使得图像都被错分到给定类别上。</p>
<p><strong>non-target attack</strong>：事先不知道需要攻击的网络细节，也不指定预测的类别，生成对抗样本来欺骗防守方的网络。</p>
<p><strong>mimicry attack</strong>: 编写恶意的exploit，该exp模拟良性代码系统调用的痕迹，因为能够逃逸检测。</p>
<p><strong>disguise attack:</strong> 仅修改系统调用的参数使良性系统调用生成恶意行为 。</p>
<p><strong>No-op attack</strong>: 添加语义的no-ops-系统调用，其没有影响，或者是不相干的影响，即，打开一个不存在的文件。</p>
<p><strong>Equivalence attack</strong>: 使用一个不同的系统调用来达到恶意的目的.</p>
</blockquote>
<h4 id="2-4-decision-boundary-决策界限"><a href="#2-4-decision-boundary-决策界限" class="headerlink" title="2.4 decision boundary(决策界限)"></a>2.4 decision boundary(决策界限)</h4><h4 id="2-5-end-to-end"><a href="#2-5-end-to-end" class="headerlink" title="2.5 end-to-end:"></a>2.5 end-to-end:</h4><h4 id="2-6-结果分类："><a href="#2-6-结果分类：" class="headerlink" title="2.6 结果分类："></a>2.6 结果分类：</h4><p>虑一个二分问题，即将实例分成正类（positive）或负类（negative）。对一个二分问题来说，会出现四种情况。如果一个实例是正类并且也被 预测成正类，即为真正类（True positive）,如果实例是负类被预测成正类，称之为假正类（False positive）。相应地，如果实例是负类被预测成负类，称之为真负类（True negative）,正类被预测成负类则为假负类（false negative）。</p>
<p>列联表如下表所示，1代表正类，0代表负类。（预测正确：true，预测是正类：positive）</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th></th>
<th>预测</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td>1</td>
<td>0</td>
<td>合计</td>
</tr>
<tr>
<td>实际</td>
<td>1</td>
<td>True Positive（TP）</td>
<td>False Negative（FN）</td>
<td>Actual Positive(TP+FN)</td>
</tr>
<tr>
<td></td>
<td>0</td>
<td>False Positive（FP)</td>
<td>True Negative(TN)</td>
<td>Actual Negative(FP+TN)</td>
</tr>
<tr>
<td>合计</td>
<td></td>
<td>Predicted Positive(TP+FP)</td>
<td>Predicted Negative(FN+TN)</td>
<td>TP+FP+FN+TN</td>
</tr>
</tbody>
</table>
</div>
<p>从列联表引入两个新名词。</p>
<p>其一是真正类率(true positive rate ,TPR), 计算公式为 <em>TPR=TP</em>/ ( <em>TP</em>+ <em>FN</em>)，刻画的是分类器所识别出的 正实例占所有正实例的比例。</p>
<p>另外一个是负正类率(false positive rate, FPR),计算公式为 <em>FPR= FP / (FP + TN)，</em>计算的是分类器错认为负类的正实例占所有负实例的比例。</p>
<p>还有一个真负类率（True Negative Rate，TNR），也称为specificity,计算公式为TNR= <em>TN</em>/ ( <em>FP</em>+ <em>TN</em>) = 1 - <em>FPR</em>。</p>
<h3 id="3-如何实现？"><a href="#3-如何实现？" class="headerlink" title="3. 如何实现？"></a>3. 如何实现？</h3><p>一些问题：程序调用API的过程；</p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>AD</tag>
        <tag>Malware Classifiers</tag>
      </tags>
  </entry>
  <entry>
    <title>【组原实验】全相联Cache设计</title>
    <url>/2021/06/14/%5B%E7%BB%84%E5%8E%9F%E5%AE%9E%E9%AA%8C%5D%20%E5%85%A8%E7%9B%B8%E8%81%94Cache%E8%AE%BE%E8%AE%A1/</url>
    <content><![CDATA[<h1 id="【组原实验】全相联Cache设计"><a href="#【组原实验】全相联Cache设计" class="headerlink" title="【组原实验】全相联Cache设计"></a>【组原实验】全相联Cache设计</h1><h3 id="1-实验要求："><a href="#1-实验要求：" class="headerlink" title="1. 实验要求："></a>1. 实验要求：</h3><p>“结合引脚功能说明，实现全相联 cache 模块，该 cache 模块共包括<strong>8个 cache 行</strong>，每个数据块包含包括<strong>4个字节共32位数据</strong>。”</p>
<p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210612105210.png" alt="image-20210612105209418"></p>
<h3 id="2-电路分析："><a href="#2-电路分析：" class="headerlink" title="2. 电路分析："></a>2. 电路分析：</h3><h4 id="2-1-读操作："><a href="#2-1-读操作：" class="headerlink" title="2.1 读操作："></a>2.1 读操作：</h4><h5 id="2-1-1-Cache行："><a href="#2-1-1-Cache行：" class="headerlink" title="2.1.1 Cache行："></a>2.1.1 Cache行：</h5><p>​    一个Cache行包括：==有效位（1）+Tag（？）+数据位（32）==</p>
<p>​    下面计算tag：</p>
<p>​    一个内存地址共有16位宽，由于一块有4字节，故<strong>块内地址</strong>需要2位，所以有：</p>
<blockquote>
<p>块号（14位）+ 块内地址（2位）</p>
</blockquote>
<p>​    故Tag也应为14位，在实际应用中，由于要考虑替算法，故还要做一个<strong>淘汰计数器</strong>。这里的替换算法我们使用LRU，考虑到266次的测试数据，我们使用一个8位计数器即可。</p>
<p>​    所以一个Cache行包括：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">1位有效位     +    14位Tag     +     8位计数器    +     32位数据块</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
</div>
<p>故Cache行的设计如下：</p>
<p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210612161048.png" alt="image-20210612161047398"></p>
<h5 id="2-1-2-Cache存储体："><a href="#2-1-2-Cache存储体：" class="headerlink" title="2.1.2 Cache存储体："></a>2.1.2 Cache存储体：</h5><p>​    将2.1的cache行拓展到8行即可：</p>
<p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210612161246.png" alt="image-20210612161245664"></p>
<h5 id="2-1-3-多路并发比较电路："><a href="#2-1-3-多路并发比较电路：" class="headerlink" title="2.1.3 多路并发比较电路："></a>2.1.3 多路并发比较电路：</h5><p>​    多路并发比较使用8个比较器即可，加上V位，8路结果取或得到Hit信号，Hit去反得到Miss信号：</p>
<p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210612161515.png" alt="image-20210612161514214"></p>
<h5 id="2-1-4-选择输出电路："><a href="#2-1-4-选择输出电路：" class="headerlink" title="2.1.4 选择输出电路："></a>2.1.4 选择输出电路：</h5><p>​    选择输出电路将slotdata的32位信息送入多选择器中，由Hit和Block共同控制选择：</p>
<p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210612161618.png" alt="image-20210612161617443"></p>
<hr>
<h4 id="2-2-写操作："><a href="#2-2-写操作：" class="headerlink" title="2.2 写操作："></a>2.2 写操作：</h4><p>​    只有在Miss=1时才会出发写操作，写操作主要涉及到两部分：<strong>替换算法</strong>，<strong>数据写入</strong>。</p>
<h5 id="2-2-1-替换算法："><a href="#2-2-1-替换算法：" class="headerlink" title="2.2.1 替换算法："></a>2.2.1 替换算法：</h5><p>​    在cache写入时：</p>
<ol>
<li><p><em>cache行未满：</em></p>
<p>则直接使用优先编码器，按编码规则依次填充。</p>
</li>
</ol>
<p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210612163240.png" alt="image-20210612163238678"></p>
<p>​    其中，0-7个有效位取反输入，这样做的目的是可以得到一个full输出，full本来是多路选择器的Os位（使能端有效且输入全为0时输出1），当输入变量取反后则此位的含义表示当==使能信号有效==且==输入全1==时输出1。</p>
<p>​    not_full是一个三位宽度的地址，其表示将要填充的空cache行的序号。</p>
<ol>
<li><p><em>cache行已满：</em></p>
<p>若cache行已满，full=1，此时应比较各行计数器的值，替换数字计数值最大的一行。</p>
<p>这里，可以利用自带的归并比较电路MAX3：3</p>
<p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210612165351.png" alt="image-20210612165350132"></p>
<p>比较8个计数值，输出数值最大的序号Max_cnt：</p>
<p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210612170621.png" alt="image-20210612170620445"></p>
</li>
</ol>
<ul>
<li>至此，我们有两个写入选择组，full和not_full，故应使用一个二路选择器，在Miss和BlkReady同时为1时选择合适的写入信号组合：</li>
</ul>
<p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210612175012.png" alt="image-20210612175011066"></p>
<hr>
<p>​    BTW: ==由于每次写入对应行计数器值清零，其他行计数器的值加一，故计数器的清零信号连接在对应行的命中信号（Hi)上。==</p>
<p>总：</p>
<p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210612174946.png" alt="image-20210612174945662"></p>
]]></content>
      <categories>
        <category>●	课内</category>
      </categories>
  </entry>
  <entry>
    <title>【安全攻防实验】电子数据取</title>
    <url>/2021/06/14/%5B%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E5%AE%9E%E9%AA%8C%5D%20%E7%94%B5%E5%AD%90%E6%95%B0%E6%8D%AE%E5%8F%96%E8%AF%81/</url>
    <content><![CDATA[<h1 id="【安全攻防实验】电子数据取证"><a href="#【安全攻防实验】电子数据取证" class="headerlink" title="【安全攻防实验】电子数据取证"></a>【安全攻防实验】电子数据取证</h1><h3 id="1-磁盘镜像和证据固定"><a href="#1-磁盘镜像和证据固定" class="headerlink" title="1. 磁盘镜像和证据固定"></a>1. 磁盘镜像和证据固定</h3><h5 id="1-1-在磁盘上创建一个文本文件："><a href="#1-1-在磁盘上创建一个文本文件：" class="headerlink" title="1.1 在磁盘上创建一个文本文件："></a>1.1 在磁盘上创建一个文本文件：</h5><ul>
<li><p>以‘abcdefgh’开头，后续随机填充一些字串。</p>
<p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210609194142.png" alt=""></p>
</li>
<li><p>把文本文件的拓展名改成学号：</p>
</li>
</ul>
<p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210609194319.png" alt=""></p>
<h5 id="1-2-在X-Ways-Forensics中创建一个案件，添加目标存储器："><a href="#1-2-在X-Ways-Forensics中创建一个案件，添加目标存储器：" class="headerlink" title="1.2 在X-Ways Forensics中创建一个案件，添加目标存储器："></a>1.2 在X-Ways Forensics中创建一个案件，添加目标存储器：</h5><p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210609194404.png" alt=""></p>
<h5 id="1-3-对该U盘存储器创建磁盘镜像："><a href="#1-3-对该U盘存储器创建磁盘镜像：" class="headerlink" title="1.3 对该U盘存储器创建磁盘镜像："></a>1.3 对该U盘存储器创建磁盘镜像：</h5><p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210609194429.png" alt=""></p>
<h3 id="2-判断文件类型"><a href="#2-判断文件类型" class="headerlink" title="2. 判断文件类型"></a>2. 判断文件类型</h3><h5 id="2-1-在案件中去除原来的存储器，添加上一步的镜像文件"><a href="#2-1-在案件中去除原来的存储器，添加上一步的镜像文件" class="headerlink" title="2.1 在案件中去除原来的存储器，添加上一步的镜像文件:"></a>2.1 在案件中去除原来的存储器，添加上一步的镜像文件:</h5><p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210609194448.png" alt=""></p>
<h5 id="2-2-2-3-用表格软件打开File-Type-Signatures-Search-txt："><a href="#2-2-2-3-用表格软件打开File-Type-Signatures-Search-txt：" class="headerlink" title="2.2 /2.3 用表格软件打开File Type Signatures Search.txt："></a>2.2 /2.3 用表格软件打开File Type Signatures Search.txt：</h5><p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210609194450.png" alt=""></p>
<ul>
<li>添加一个文件类型：</li>
</ul>
<p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210609194456.png" alt=""></p>
<ul>
<li>在专业工具中选择‘进行磁盘快照’，对磁盘进行快照操作：</li>
</ul>
<p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210609194500.png" alt=""></p>
<ul>
<li>在选项中开启目录浏览器；</li>
<li>在X-Ways中查看新类型的文件添加是否成功：</li>
</ul>
<p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210609194503.png" alt=""></p>
<p>​    可以看出，新文件类型添加成功，成功识别了拓展名，文件类型与签名状态。</p>
<h5 id="2-4-修改文件签名数据库中的内容，再次分析："><a href="#2-4-修改文件签名数据库中的内容，再次分析：" class="headerlink" title="2.4 修改文件签名数据库中的内容，再次分析："></a>2.4 修改文件签名数据库中的内容，再次分析：</h5><ul>
<li><p>​    修改文件签名数据库中的文件头签名内容，再次使用 文件快照对指定存储器进行分析，查看3中文件的文件类型、扩展名、签名状态等信息的变化。</p>
</li>
<li><p>更改文件头签名为‘zzzzz’：</p>
</li>
</ul>
<p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210609195832.png" alt=""></p>
<ul>
<li>重新进行快照，检查：</li>
</ul>
<p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210609195711.png" alt=""></p>
<p>​    可以发现，在更改文件头签名内容后，签名状态变为了“未确认”。</p>
<h5 id="2-5-删除添加到文件签名数据库中新的文件类型签名，再次使用文件快照对指定存储器进行分析："><a href="#2-5-删除添加到文件签名数据库中新的文件类型签名，再次使用文件快照对指定存储器进行分析：" class="headerlink" title="2.5 删除添加到文件签名数据库中新的文件类型签名，再次使用文件快照对指定存储器进行分析："></a>2.5 删除添加到文件签名数据库中新的文件类型签名，再次使用文件快照对指定存储器进行分析：</h5><p>​    具体步骤同2.4，结果如下：</p>
<p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210609200431.png" alt=""></p>
<h3 id="3-文件搜索："><a href="#3-文件搜索：" class="headerlink" title="3. 文件搜索："></a>3. 文件搜索：</h3><h5 id="3-1-搜索“华中科技大学”word文档："><a href="#3-1-搜索“华中科技大学”word文档：" class="headerlink" title="3.1 搜索“华中科技大学”word文档："></a>3.1 搜索“华中科技大学”word文档：</h5><ul>
<li>去除上一个任务的存储器，添加自己电脑的C盘：</li>
</ul>
<p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210609202255.png" alt=""></p>
<ul>
<li>提前验证C盘是否存在包含“华中科技大学“的文档：</li>
</ul>
<p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210609202623.png" alt=""></p>
<ul>
<li>设置搜索：</li>
</ul>
<p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210609205543.png" alt=""></p>
<ul>
<li><p>搜索结果：</p>
</li>
<li><p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210609205439.png" alt=""></p>
</li>
</ul>
<h5 id="3-2-搜索WEB邮件："><a href="#3-2-搜索WEB邮件：" class="headerlink" title="3.2  搜索WEB邮件："></a>3.2  搜索WEB邮件：</h5><ul>
<li><p>首先发一封邮件给别人（用的是QQ邮箱，edge浏览器）</p>
</li>
<li><p>直接搜索”mail”字串：</p>
<p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210609221822.png" alt=""></p>
</li>
<li><p>搜索结果：</p>
</li>
</ul>
<p><img src="http://shaw-typora.oss-cn-beijing.aliyuncs.com/20210614201318.png" alt=""></p>
<p>可以看出，成功找到了发送邮件的记录。</p>
<h5 id="3-3-搜索电话号码："><a href="#3-3-搜索电话号码：" class="headerlink" title="3.3 搜索电话号码："></a>3.3 搜索电话号码：</h5><ul>
<li><p>电话号码有11位，故使用grep表达式： <strong>189[0-9]{8}</strong>：</p>
</li>
<li><p>设置搜索如下：</p>
</li>
</ul>
<p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210609215841.png" alt=""></p>
<ul>
<li>搜索结果如下：</li>
</ul>
<p><img src="https://gitee.com/sswdqnxz/typora/raw/master/20210609215920.png" alt=""></p>
]]></content>
      <categories>
        <category>●	课内</category>
      </categories>
  </entry>
</search>
