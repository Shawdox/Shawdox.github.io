<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Shaw&#39;s blog</title>
    <url>/2021/09/03/Welcome/</url>
    <content><![CDATA[<p>论文阅读/技术学习/比赛积累</p>
]]></content>
  </entry>
  <entry>
    <title>(论文阅读)Fuzzing-A Survey for Roadmap</title>
    <url>/2023/06/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Fuzzing-A-Survey-for-Roadmap/</url>
    <content><![CDATA[<h1 id="fuzzing-a-survey-for-roadmap">Fuzzing: A Survey for Roadmap</h1>
<blockquote>
<p><strong>时间：</strong>2022</p>
<p><strong>作者：</strong>Xiaogang Zhu、Sheng
Wen（澳洲斯威本科技大学）</p>
<p><strong>期刊：</strong>ACM Computing Surveys（中科院一区）</p>
</blockquote>
<h2 id="abstract">Abstract</h2>
<p>​
最近，模糊测试（fuzzing）在检测安全缺陷方面有着大量使用，它产生了大量的测试案例，并监控缺陷的执行情况，fuzzing已经在各种应用程序中发现了成千上万的错误和漏洞。</p>
<p>​
Fuzzing虽然有效，但对其所面临的问题缺乏系统的分析。作为一种缺陷检测技术，fuzzing需要缩小整个输入空间（<strong><em>input
space</em></strong>）和缺陷空间（<strong><em>defect
space</em></strong>）之间的差距。如果对生成的输入没有限制，输入空间是无限的，然而，<u>应用中的缺陷是稀疏的，这表明缺陷空间要比整个输入空间小得多</u>。此外，由于fuzzing会产生大量的测试用例来反复检查目标，这就要求fuzzing以自动的方式进行，由于应用程序和漏洞的复杂性，对不同的应用程序进行自动化执行具有挑战性</p>
<p>​
在这篇文章中，我们系统地回顾和分析了这些gap以及它们的解决方案，同时考虑了广度和深度。这项调查可以作为初学者和高级开发人员更好地了解fuzzing的路线图。</p>
<span id="more"></span>
<h2 id="generating-input-optimization">Generating input
optimization</h2>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230629135135.png" /></p>
<p>​
如上图所示为fuzzing的基本流程，<strong><u>在生成输入时</u></strong>，其可以对<strong><em>seed
set,seed schedule,byte schedule</em></strong>和<strong><em>mutation
schedule</em></strong>做优化。</p>
<h3 id="seed-set-selection">1. Seed Set Selection</h3>
<p>​ <strong>在保障代码覆盖率的前提下，<u>seed
set越小越好。</u></strong>这是因为多余的种子会浪费算力，重复检测已经检测过的代码块。COVERSET[158]将最小化种子集的问题表述为最小集合覆盖问题（MSCP），它最小化包含所有元素的子集。由于MSCP是一个NP-hard问题，COVERSET使用贪心多项式近似算法来获得最小集。</p>
<h3 id="seed-schedule">2. Seed Schedule</h3>
<p>​ 在选择了Seed set之后，Seed
Schedule的任务是<u>从其中选择对应的种子用于后续操作</u>，并<u>为所选种子分配其可运行的最大时间</u>。</p>
<p>​ 由于 PUTs
与defects的复杂性，未发现代码覆盖率与未发现漏洞是不可知的，我们无法知道一个输入是否能触发漏洞，类似地在检索代码之前我们也不能获得程序行为的概率分布，数学上几乎不可能找到一个全局最优解法，因此研究人员基于多种优化方法来近似地解决这个问题。</p>
<h4 id="fitness-by-bugs">2.1 Fitness by #Bugs</h4>
<p>​ Fitness == 衡量seed/input指标。Fitness by
Bugs意味着以发现bug的多少作为种子的评价标准。</p>
<ul>
<li>为了使bug最多，一种方法是在随机或按顺序选择种子的同时，分配每个种子的时间预算。如果不考虑执行状态，最大化问题可以简化为整数线性规划（<strong>ILP</strong>）问题。也<u>就是说，ILP打算在线性约束条件（例如每个种子的时间预算的上限值）下最大化bug的数量。</u>通过解决ILP问题，可以自动计算每个种子的时间预算。</li>
<li>另一种见解是将发现bug的过程视为<strong>WCCP</strong>问题。<a
href="https://www.cnblogs.com/no-tears-girl/p/7476175.html">经典概率问题：优惠券收集问题
- cnblogs.com</a></li>
<li>ILP和WCCP都会给更可能发现bug的种子分配更多可用时间。</li>
</ul>
<blockquote>
<p>ILP和WCCP这两种理论上可以计算出全局最优解的算法需要知道环境的全部信息，由于这并不可能，所以基本效果都不好（例如强化学习中动态规划算法虽然可以直接求得全局最优策略，但由于<u>环境信息不可知</u>或<u>算力限制</u>，基本没有实际应用场景），只在早期使用。</p>
</blockquote>
<h4 id="fitness-by-state-transition-markov-chain">2.2 Fitness by State
Transition (Markov Chain)</h4>
<p>​
<strong>因为在PUT中，bug是稀疏的，当使用bug的数量作为fitness时，优化过程将迅速收敛到局部优化</strong>。因此，它可能会错过探索更多代码覆盖的机会，由复杂条件包裹的深层bug就会避开fuzzing。</p>
<p>​
为了缓解这个问题，fuzzer基于执行状态（如代码覆盖率）作为fitness，因为执行状态可以为fuzzing提供更多的信息。目前大多数现有的fuzzer都是基于代码覆盖率计算fitness。使用代码覆盖率的另一个原因是，更大的代码覆盖率表明发现错误的可能性更高[130]。</p>
<p>​ 两种建模方法：</p>
<ul>
<li><p><strong>Block transition</strong></p>
<p>Fuzzing之前通过蒙特卡洛采样（Monte Carlo
method），计算出程序CFG中每个基本块跳转的概率P<sub>ij</sub>，进而计算出某个种子在执行过程中执行路径的概率（经过的基本块概率相乘）。种子对应的概率越低则fitness越高。</p></li>
<li><p><strong>Path transition</strong></p>
<p>P<sub>ij</sub>这里代表从Seed<sub>i</sub>变异到Seed<sub>j</sub>的概率，每个P通过之前执行fuzzing结果计算，同样是概率越小fitness越高，更倾向于生成稀有的path。这里AFLFast[23]使用1/p<sub>ij</sub>为每个种子分配能量，其还有变式：directed
greybox fuzzing (DGF) [22, 217]和regression greybox fuzzing (RGF)
[214]。</p></li>
</ul>
<blockquote>
<p>使用马尔科夫理论对state transition建模，以此优化seed
schedule有一定效果，但其缺点是MC需要计算所有状态的概率。实际使用中，很多状态并没有被检测，故MC方法也容易陷入局部最优解（还是环境信息获取不全面的问题）。</p>
</blockquote>
<h4 id="fitness-by-state-transition-multi-armed-bandit">2.3 Fitness by
State Transition (Multi-armed Bandit)</h4>
<p>​ 前置知识：</p>
<blockquote>
<ul>
<li><p>rule of
three(statistics)：如果前n次采样事件a都没有发生，则有95%的置信度表明至多3/n的概率事件a会发生。<a
href="https://handwiki.org/wiki/Rule_of_three_(statistics)#:~:text=In%20statistical%20analysis%2C%20the%20rule%20of%20three%20states,good%20approximation%20of%20results%20from%20more%20sensitive%20tests.">Rule
of three (statistics) - HandWiki</a>；</p></li>
<li><p>Round-Robin Scheduling：轮询调度算法；</p></li>
</ul>
</blockquote>
<p>​ 对于MC建模方法导致的问题：</p>
<ul>
<li><p><strong>对于使用MC的Block
transition：</strong>可以使用统计学中的<strong><em>rule of
three</em></strong>规则来为未出现的state赋概率值；</p></li>
<li><p><strong>对于使用MC的Path transition：</strong>使用Round-Robin
Scheduling先为每个seed赋相同的time
budget，后续经过不断采样再使用计算的概率值。但这么做的问题就是不好平衡Round-Robin和Markov，搜索有所seed和聚焦于某个seed是一个“exploration
and exploitation”问题（又是经典的e and e问题）。</p></li>
</ul>
<p>​ 综上，为了解决这个问题引入了<strong>Multi-armed
Bandit</strong>模型。</p>
<pre><code>多摇臂老虎机，Multi-armed Bandit是强化学习中的经典模型，老虎机有n个摇杆，每个摇杆i有P~i~的概率中奖，每次可以选择一个摇杆拉下。&lt;u&gt;玩家的目的是通过有策略的尝试，找到中奖率最高的摇杆（因为这么做就可以reward期望最大化）。&lt;/u&gt;在MAB游戏中，其exploration代表不断尝试不同的摇杆，获取其对应reward的期望，也就是对环境采样；其exploitation代表找到最好的策略使reward最大化，这里最好的策略就是只拉下中奖概率最高的摇杆。</code></pre>
<p>​
<u>在fuzzing中，一个seed就是一个摇杆（arm），对应的reward就是该seed运行时的一系列发现</u>。</p>
<p>​ EcoFuzz[203]将其建模为一个MAB问题，并使用<span
class="math inline">\(E(t_i)=1-\frac{P_{ii}}{\sqrt{i}}\)</span>来表示每个seed
t<sub>i</sub>的期望（而不是最开始的新路径数/变异次数，因为这样会导致期望越来越小，梯度过小，比较结果不明显），这里P<sub>ii</sub>表示一个种子变异后仍走原来路径的概率，故EcoFuzz更偏向可以生成新路径的种子；</p>
<p>​ AFL-HIER[88]也将其建模为一个MAB问题，不同于EcoFuzz只使用了单一的edge
coverage来retain新的种子，AFL-HIER利用了更多评价标准（函数，edge，基本块等），其使用一个MAB算法UCB1来解决多等级评价标准MAB问题。</p>
<h4 id="fitness-by-state-discovery">2.4 Fitness by State Discovery</h4>
<p>​
物种发现问题：生态学家从野外收集大量样本，样本中的物种可能是丰富的或罕见的。生态学家根据这些样本推断出一个完整组合的属性，包括未发现的物种。</p>
<p>​
同样地，fuzzer产生的输入是收集的样本，而程序的输入空间是整个集合体。fuzzing算法根据特定的指标将输入归类为不同的种类。例如，一个执行路径可以是一个物种，所有行使该路径的输入都属于这个物种。在这种情况下，一个罕见的物种是一个只有少数输入行使的执行路径。<u>物种发现中的一个重要假设是，未发现的物种的属性几乎只能由已发现的稀有物种来解释[31]。这个假说意味着fuzzing可以给稀有物种（稀有路径）分配更多的能量来发现新的状态。</u></p>
<p>​
基于物种发现的问题，Entropic[21]将fuzzing理解为一个学习过程；即fuzzer逐渐学习更多关于程序行为的信息（物种）。Entropic建议使用Shannon’s
entropy（香农熵）[170]来衡量物种发现的效率，原始的香农熵H衡量物种的平均信息，计算公式为<span
class="math inline">\(H =
-\sum_i{p_ilog(p_i)}\)</span>，其中p<sub>i</sub>是选择物种S<sub>i</sub>的概率。如果收集的样本包含许多物种，熵H就大（信息量大）；否则，如果收集的样本包含少数物种，熵H就小（信息量小）。</p>
<p>​
同时，Entropic认为，物种的发现率可以量化fuzzer的效率。根据香农理论推导，Entropic衡量种子的物种发现效率。具体来说，<span
class="math inline">\(p_i^t\)</span>是变异种子t并产生属于物种S<sub>i</sub>的输入的概率。种子t的学习率是根据概率<span
class="math inline">\(p_i^t\)</span>和改进的熵估计器计算的。通过熵得出的结论是，更多的能量被分配给学习率较大的种子；也就是说，发现新物种更有效的种子被分配更多的能量。</p>
<h3 id="byte-schedule">3. Byte Schedule</h3>
<p>​ <u>Byte
Schedule的作用是决定在种子中选择一个字节来进行变异的频率</u>。大多数fuzzer通过运行信息来启发式或随机地选择字节。相较于Seed
Schedule，Byte
Schedule需要对程序有着跟深入的理解，例如对路径条件和数据流的分析。</p>
<p>​ 定义<strong><em>The importance of
bytes</em></strong>：bytes如何影响fuzzing。</p>
<ul>
<li><strong>影响branch behavior：</strong>NEUZZ [172]和MTFuzz
[171]将输入bytes和branch
behaviors之间的关系通过深度学习模型建模，DL模型的梯度量化了bytes的重要性，因为一个bytes的梯度越大，该bytes的很小的扰动就会导致branch
behaviors的重大差异。故对于接下来的种子变异，fuzzing将优先考虑具有较高重要性的bytes进行突变。</li>
<li><strong>影响fitness：</strong>AFLChurn [214]利用了Ant Colony
Optimization (ACO)，蚁群优化算法来学习bytes如何影响种子的fitness。</li>
</ul>
<h3 id="mutation-operator-schedule">4. Mutation Operator Schedule</h3>
<p>​ <u>Mutation Operator
Schedule的作用是选择一个变异操作来对所选bytes进行变异，Mutation
Schedule决定了下一次变异bytes时使用那种变异方法，即变异器（mutator）</u>。</p>
<p>​ Classfuzz
[42]认为探索了更多新状态的mutator被选中的概率应该更高，因此，Classfuzz假设<strong>Markov
Chain Monte Carlo (MCMC)</strong>可以对Mutation
Schedule的过程进行建模，其采用了H-M(Metropolis-Hastings)算法。具体来说，每个突变器都有一个成功率，它可以量化突变器所探索的新状态。Classfuzz首先随机选择下一个变体，然后根据当前变体和所选变体的成功率来接受或拒绝选择。</p>
<p>​ MOPT[116]采用了Particle Swarm Optimization
(PSO)，粒子群优化算法来对mutator选择过程建模，构建mutator选择的概率分布。</p>
<h3 id="diverse-information-for-fitness">5. Diverse Information for
Fitness</h3>
<p>​ Fitness除了应用于schedule of seeds, bytes,
和mutators，<u>也可以被应用于seed
retention</u>。Fuzzers通常利用遗传算法（GA）来制定种子保留的过程。具体来说，fuzzer通过变异种子生成输入，如果输入探索到新的执行状态（即更好的fitness），则该输入会被保留为新的种子。当为下一轮测试选择种子时（基于seed
schedule），fuzzing可能会选择这个新的种子。</p>
<p>​
为了提高对defect发现的能力，需要更敏感的代码覆盖率来揭示更多的执行状态信息。另一方面，针对一些特定的场景，如深度学习模型[148]或机器人车辆[82]，设计了新的fitness类型。请注意，fitness信息的多样性在前面提到的seed
retention和schedule问题上都得到了利用。</p>
<h4 id="sensitive-code-coverage">5.1 Sensitive Code Coverage</h4>
<p>​
<strong>Fitness的敏感性表明其区别不同程序运行状态的能力。</strong></p>
<p>​ 许多coverage-guided
fuzzers会实现一个bitmap用于向fuzzing提供edge-coverage的信息，bitmap本质上是一个紧凑的vector，其索引代表了对应edge的标识符，标识符是<span
class="math inline">\(hash(b_i,b_j)\)</span>，bi和bj是随机分配的块标识符。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230630152254.png" style="zoom:50%;" /></p>
<p>​ 如上图所示，如果存在哈希碰撞，导致<span
class="math inline">\(id_{AB}=id_{AC} ,
id_{BD}=id_{CD}\)</span>，则路径ABD和ACD就会被认为是一条路径。如果存在Bug路径ACDEG，则其会被fuzzer忽略。虽然这种实现在执行过程中速度很快，但它牺牲了edge-coverage的精度。</p>
<p>​
有了bitmap，fuzzing可以确定一个输入是否行覆盖了新的edge，如果有的话，就保留这个输入作为新的种子。具体来说，fuzzing维护一个总体bitmap，它是单个执行的bitmap的联合。当确定新边时，fuzzing将单个bitmap与整体bitmap进行比较，以检查单个bitmap中是否存在新边。</p>
<p>​
然而，位图的联合会失去执行的信息[118]。<u>例如，如果图3(a)中的路径ABDEG和ACDFG已经被执行，那么执行新路径ACDEG的输入将不会被保留为种子，因为所有的边已经存在于整体bitmap中</u>。因此，一个解决方案是将所有单个的bitmap组合起来[118]。因为bitmap的组合会引入太多的种子，一个关键的挑战是如何平衡fuzzing的效率和保持覆盖率的敏感性。一个潜在的解决方案是使用动态主成分分析[191]来降低数据集的维度[118]。</p>
<p>​
其他提高edge-coverage灵敏度的解决方案包括路径哈希[198]、调用上下文[37,
87,
171]、多级覆盖[88]和代码复杂性[105]，这些都为边缘覆盖增加了额外的信息。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230630153603.png" style="zoom:50%;" /></p>
<p>​
<strong>专注于代码覆盖率的fuzzing也不一定适合探索复杂的执行状态</strong>。上图是一个迷宫程序，每次走一步，只有当走到出口时才会出发Bug。然而，由于switch语句只有四条edge，很快就会探索完，在这之后fuzzing就很难继续根据代码覆盖率来指导测试。</p>
<h4 id="diverse-fitness">5.2 Diverse Fitness</h4>
<p>​ Fitness并不一定非得用code coverage，实际上，code
coverage不是一直是最好的适合fuzzing反馈信息。如果没有code
coverage，一个直觉上的做法是根据执行结果保留种子，如执行结果的合法性[141]或协议实现的状态机[154]。不同的fitness如下：</p>
<ul>
<li><strong><em>Legality of execution
result：</em></strong>一个面向对象的程序（如Java）由一连串的方法调用组成，执行结果要么合法，要么抛出异常。Fuzzing生成并获得可以可以探索更多新的、合法的对象状态新的方法调用序列[141]
；</li>
<li><strong><em>State machine of protocol
implementations：</em></strong>一个状态机由状态集合和转变其状态的输入组成。由于协议的复杂性，fuzzer通常通过逐渐向状态机添加新的状态来推断状态机[55,
61, 64, 69,
154]。状态机从一个种子（即初始状态机）开始，fuzzer对状态机的当前状态进行突变以探索新的状态。漏洞的分析是基于状态机的，其目的是为了搜索导致漏洞的转换[55]；</li>
<li><strong><em>Safety policy of robotic
vehicles：</em></strong>安全策略是对机器人车辆的物理或功能安全的要求，例如车辆发动机的最高温度[82]。当一个输入更接近于违反政策时，该输入就会被保留下来，供以后突变使用；</li>
<li><strong><em>Fitness for deep learning systems：</em></strong>The
fuzzing of deep learning systems (DLSs) 旨在提高它们的鲁棒性和可靠性[68,
115,
148]。为了实现这一目标，fuzzer设计了不同类型的fitness，例如用于发现角落状态的神经元覆盖率[148]，用于增强训练数据的损失函数[68]，或者用于探索深度学习推理引擎（即框架和库）的操作者级覆盖率[115]。</li>
<li><strong><em>Validation log of Android
SmartTVs：</em></strong>验证日志是正在执行的Android智能电视的信息[1]。验证日志被用来推断有效输入和提取输入边界。有效输入为fuzzing提供了有效的种子，而输入边界则减少了输入的搜索空间。</li>
<li><strong><em>Behavioral asymmetry of differential
testing：</em></strong>对于差分测试(differential
testing)，错误是通过观察不同实现的行为差异发现的，这些实现具有相同的功能，在相同的输入上。行为的不对称性表明各种实现的差异程度。模糊测试的目的是生成能够发现更多差异的测试案例；</li>
<li><strong><em>Alias coverage for data
race：</em></strong>别名覆盖是为了检测内核文件系统中的数据竞争[194]。数据竞争是一个并发的错误，其中两个线程访问一个共享的内存位置而没有适当的同步。因此，别名覆盖跟踪可能相互交错的内存访问对；</li>
<li><strong><em>Dangerous locations for
bugs：</em></strong>危险的位置（Dangerous
locations）是那些有更高概率触发错误的代码区域。因此，fuzzer可以将资源引向这些位置，以提高fuzzing的效果和效率。对于并发性错误，危险位置通常是指导致违反原子性的代码区域[97]、数据竞赛[84,
167]或可疑的交织[35]。对于非并发性错误，危险位置可以通过补丁测试[122]、崩溃再现[155]、静态分析报告[48]或信息流检测[123]获得。此外，危险位置可能是内存访问[84，182，188]，sanitizer检查[40，140]，或提交历史[214]。</li>
</ul>
<p>​</p>
<h3 id="evaluation-theory">6. Evaluation Theory</h3>
<p>​
Fuzzing的评测通常与检测阶段分开进行，然而，我们认为评估是fuzzing过程的一部分，因为适当的评估可以帮助提高fuzzing的性能[215]。适当的评价包括有效的实验corpus[215]、公平的评价环境/平台[30,
104, 126]、合理的fuzzing时间[17, 20]和全面的比较指标[96,
104]。尽管这些研究工作在适当的评价方面做出了努力，但关于如何评价技术（即fuzzing
algorithms）而不是实现（即实现算法的代码），仍然是一个开放的问题[18]。一个广泛使用的解决方案是基于统计测试来评估fuzzer，它提供了一个反映模糊技术之间差异的可能性[96]。</p>
<h3 id="summary">7. Summary</h3>
<p>​ 下表表明了不同fuzzing
processes使用的不同优化方法来优化<strong><u>input
generation</u></strong>：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230629135704.png" /></p>
<blockquote>
<p><strong><em>Solution:</em></strong></p>
<p><strong>MC:</strong>Markov Chain</p>
<p><strong>MSCP:</strong>Minimal Set Cover Problem，最小集合覆盖问题；
<a
href="https://zhuanlan.zhihu.com/p/408556395">Tutorial-覆盖问题</a></p>
<p><strong>ILP:</strong>Integer Linear Programming
Problem，整数规划问题；</p>
<p><strong>WCCP:</strong>Weighted Coupon Collector’s
Problem，彩票收集问题；</p>
<p><strong>VAMAB:</strong>Variant of Adversarial Multi-Armed
Bandit，对抗性多臂老虎机的变种；</p>
<p><strong>UCB1:</strong>Upper Confidence
Bound算法，解决MAB问题的一种算法；</p>
<p><strong>MH:</strong>Metropolis-Hastings采样；</p>
<p><strong>PSO:</strong>Particle Swarm Optimization，粒子群优化；</p>
<p><strong>Shannon:</strong>香农理论；</p>
<p>**Species*:**Models of Species Discovery，物种发现模型；</p>
<p><strong>ACO:</strong>Ant Colony Optimization，蚁群优化；</p>
<p><strong>SA:</strong>Simulated Annealing，模拟退火算法；</p>
<p><strong>NN:</strong> 神经网络；</p>
<p><strong>MTNN:</strong>Multi-task Neural Networks，多任务NN；</p>
<p><strong>GA:</strong>Genetic Algorithm，遗传算法；</p>
<p><strong>GD:</strong>Gradient Descent，梯度下降；</p>
<p><strong>MOO:</strong>Multi-objective Optimization，多目标优化；</p>
<p><strong>R:</strong>Random，随机。</p>
</blockquote>
<blockquote>
<p><strong>set:</strong>Seed Set Selection</p>
<p><strong>seed:</strong>Seed Schedule</p>
<p><strong>byte:</strong>Byte Schedule</p>
<p><strong>mutation:</strong>Mutation Schedule</p>
<p><strong>rete:</strong>Seed
Retention-&gt;将测试过程中生成的有价值的input加入population</p>
</blockquote>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230629141731.png" style="zoom:67%;" /></p>
<h2 id="input-space-optimization">Input space optimization</h2>
<p>​
上一节描述了fuzzer可以通过优化输入的生成来提高效率，这一节讲解其如何通过减少输入空间来优化。</p>
<p>​
Fuzzer可以将输入中的相关bytes分组，并对每组应用特定的mutator。假设一个输入包括a×b个字节，并被平均分成a个部分；那么在解决一个特定的路径约束时，fuzzing的搜索空间是<span
class="math inline">\(a\times256^b\)</span>，而不是<span
class="math inline">\(256^{a\times b}\)</span>。</p>
<p>​ 相关联的字节可以是构建相同数据结构的字节[16,
201]，影响相同路径约束的字节[37, 38, 65, 67, 157, 160,
187]，或者符合语法的相同部分[78, 115, 120, 136, 181, 197,
212]。Mutator包括字节突变（例如，比特翻转、字节删除和字节插入）[23,
206]和块突变（例如，块替换、块删除和块插入）。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230701103408.png" style="zoom:67%;" /></p>
<p>​
如上图所示，输入被分为了变量i、k和数组a，如果前面的条件满足（line13），则当判断到14行时，整个搜索空间就只剩1bytes了。例如，如果在全局输入空间对上图（a）中的line14的条件进行检验，fuzzing需要生成<span
class="math inline">\(256^{11}\)</span>个输入来遍历所有可能的情况（输入有11个字节）。但如果根据源码分析，只有第11个字节才影响a[2]的值，那么只需要变异这一个字节即可，故只需要生成256个输入就可以遍历所有可能情况。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230701104025.png" style="zoom:67%;" /></p>
<p>​
一种特殊的输入是高度结构化的输入，它被用于协议实现、文档对象模型（DOM）引擎和编译器等应用。如图上图所示，cJSON解析器要求一个输入的片段以某些特定的字符开始，如果一个输入违反了这个要求，那么这个输入就不允许检查解析器所保护的功能。</p>
<h3 id="byte-constraint-relation">1. Byte-constraint Relation</h3>
<p>​
对于大多数路径约束，<strong><u>它们只受输入的一小部分影响</u></strong>。如果fuzzer只对相关的字节进行变异，那么通过减少输入的搜索空间，fuzzing的性能可以得到明显的改善（如上图a)，这就是<strong><em>byte-constraint
relation</em></strong>。</p>
<p>​ 在获得Byte-constraint
relation后，一个简单的变异方案是随机地变异相关的字节[67, 157,
187]。一个更统一的方法是将一个字节的值分别从0到255设置[172]。然而，这两种方案是无效的，因为它们并不了解其生成的输入的质量。如果byte-constraint
relation的推断过程可以获得程序中<u>比较指令的值</u>，fuzzing就可以突变相关的字节，并选择在通过路径约束方面取得进展的输入。<u>此外，fuzzer可以利用梯度下降算法来突变相关字节并逐渐解决路径约束[37,
38]。</u></p>
<h4 id="dynamic-taint-analysis">1.1 Dynamic Taint Analysis</h4>
<p>​ 动态污点分析，Dynamic taint analysis
(DTA)，是一种常见的技术，用于建立输入字节和路径约束之间的关系。DTA在输入中标记某些数据，并在执行过程中传播这些标签，如果程序中的一个变量获得了一个标签，该变量就会被连接到具有该标签的数据上。Fuzzer[37,
38, 67, 157, 160,
187]一般利用DTA在输入字节和安全敏感节点（系统/库调用，条件跳转）之间建立关系。</p>
<blockquote>
<p>DTA需要大量的手工工作，并且由于隐含的数据流，也可能导致不准确的关系。</p>
</blockquote>
<h4 id="relation-inference">1.2 Relation Inference</h4>
<p>​
由于fuzzing用许多测试用例测试目标程序，一个轻量级的解决方案是在运行时推断bytes
relation。一种方法是观察一个字节的突变是否改变了一个变量的值[65]、一个比较指令的结果[7,
103,
200]或一个分支的命中率[101]，如果改变了，该字节就会分别与该变量、比较指令或分支相联系；另一种推理方法是基于深度学习[172]在输入字节和分支行为之间建立近似的联系。</p>
<h3 id="concolic-execution">2. Concolic Execution</h3>
<p>​ Concolic
Execution也被成为动态符号执行，同时利用符号执行和fuzzing的技术被称为<strong><em>hybrid
fuzzing</em></strong>或<strong><em>whitebox fuzzing</em></strong>。</p>
<p>​ Hybrid fuzzing一个改进是优先选择最难最复杂的路径让Concolic
Execution解决[210]。除了路径选择，Hybrid
fuzzing的性能还可以通过开发近似的SMT约束条件求解器来提高；约束解算器也可以根据目标的特点进行改进。在嵌套条件方面（如图4（a）中的第13-15行），Pangolin[81]提出了多面体路径抽象来解决嵌套路径约束。多面体路径抽象保留了历史约束的解空间，并重用该解空间来满足当前路径约束的可达性。例如，为了解决图4(a)第14行的约束，输入必须首先满足第13行的条件。为了在需要高度结构化输入的程序中利用混合模糊法，Godefroid等人[71]首先将语法中的token符号化为符号变量。然后，他们使用上下文自由约束解算器来生成新的输入。</p>
<h3 id="program-transformation">3. Program Transformation</h3>
<p>​
对于fuzzing来说，程序转换的目的是<u>去除阻碍fuzzing发现更多执行状态的合理性检查</u>。通过移除这些检查，fuzzing可以探索目标程序中的深层代码并暴露出潜在的bug[150]。<strong>去除后会引入许多错误位置的假阳性</strong>，这可以通过符号执行来进一步验证。因此，程序转换通过专注于可能潜在触发bug的输入来减少搜索空间。</p>
<h3 id="input-model">4. Input Model</h3>
<p>​
例如像协议处理、DOM引擎、JS引擎、PDF阅读器、系统调用或编译器等程序都需要高度结构化的输入，i<u>nput
model代表着构建高度结构化输入的一系列规则，包括结构、格式、数据限制等</u>。为了生成满足规范的输入，生成过程限制只能做特定的操作，如果一个输入违反了目标程序的语法或语义，该输入将在早期阶段被程序拒绝，换句话说，<strong>input
space要受制于input model</strong>。</p>
<h4 id="accessible-models-or-tools">4.1 Accessible Models or Tools</h4>
<p>​ 许多fuzzer通过Accessible
Models或者现有的工具来生成有效输入，由于规范的解析很复杂，所以容易出错。图4(b)中的cJSON解析器是对JSON规范的实现，由于对不同数据类型的复杂解析，它虽然简单，但却容易出错。<strong>因此，研究界已经开源了一些用于高度结构化输入的工具，例如QuickCheck[50]和ANTLR[146]。</strong>例如，NAUTILUS[5]和Superion[186]基于ANTLR生成新的输入。然后，NAUTILUS和Superion都使用代码覆盖率来优化变异过程。在某些情况下，input
model可以只是生成的数据符合的类型（例如，API参数或物理信号的类型）[1,
41, 70,
179]。例如，网络物理系统（CPSs）的执行器的数据可以是二进制的开或关[41]。</p>
<h4 id="integration-of-implementations">4.2 Integration of
Implementations</h4>
<p>​ 另一种有效方法是<u>将fuzzing与目标应用程序的实现相结合[64, 89,
173]</u>。这种整合允许fuzzing通过定制输入生成过程来检查目标应用程序的预期属性。例如，TLS-Attacker[173]创建了一个框架，可以根据每个片段的类型突变输入，并操纵协议信息的顺序。这个框架包括一个完整的传输层安全（TLS）协议实现。</p>
<h4 id="intermediate-representation">4.3 Intermediate
Representation</h4>
<p>​ 一个更复杂的方法是将input
model转换为中间表示法（IR）。对于高度结构化的输入，对原始输入文件的突变过于复杂，无法保持语法和语义，因此，研究人员将原始文件翻译成IR，使其更简单和统一。Fuzzer对IR进行突变，然后将突变后的IR再翻译成原始输入格式，<strong>这种变异策略可以保持句法或语义的正确性</strong>，并产生更多不同的输入。例如，IR被用来测试数据库管理系统（DBMS）[212]，检查DOM引擎[197]，或模糊不同的语言处理器（例如，编译器或解释器）[43]。</p>
<h3 id="fragment-recombination">5. Fragment Recombination</h3>
<p>​
<u>片段重组的基本思想是将输入文件分成许多小块（即片段），然后通过合并不同输入文件的小块来生成一个新的输入文件。</u>每个片段都符合输入的规格，因此重新组合的输入文件在语法上是正确的。理想情况下，重新组合的输入文件将行使一个新的执行路径或暴露出一个新的错误。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230701115517.png" style="zoom: 67%;" /></p>
<p>​
如图5所示，fuzzer首先将输入文件解析成一棵树（如抽象语法树（AST）），它保持了句法的正确性。为了正确解析输入，输入语料库必须是valid的[78,
180, 185, 199] ，其可以从网络上下载。</p>
<p>​
除了有效的输入，fuzzer也会收集有问题的输入，这些输入之前已经引起了无效的行为[80，99，145]
。<strong><u>基本假设是，在输入已经发现错误的位置或附近，可能仍然存在新的错误[80]</u></strong>。有问题的输入已经行使了复杂的执行路径，导致无效的行为。因此，片段的重新组合可能会行使相同或相邻的复杂路径，这有助于fuzzer探索深层代码行。在第二阶段，输入文件被分离成许多片段，这些片段被储存在片段池中。因为模糊分析器将输入解析成AST，所以片段可以是包含非终端的子树。当重组片段时，要求新生成的输入文件在语法上是正确的。因此，模糊器基于随机选择[80,
120,
199]、遗传算法[180]或机器学习[185]来重组句法兼容的片段。除了句法上的正确性，语义上的正确性对fuzzing的有效性也有很大影响。例如，为了生成句法和语义正确的JavaScript输入，CodeAlchemist[78]用汇编约束来标记片段。也就是说，只有当约束条件得到满足时，不同的片段才会被合并。</p>
<h3 id="format-inference">6. Format Inference</h3>
<p>​ 如果input
model无法访问，推断输入的格式是产生有效输入的一个有效方法。此外，一个input
model只能生成具有特定格式的输入，为了支持更多格式的输入，开发者必须利用新的input
model，并在生成输入时选择相应的input
model。因此，格式推理比基于模型的方法更具可扩展性。</p>
<h4 id="corpus-based">6.1 Corpus-based</h4>
<p>​
为了推断格式，<u>一个直接的方法是向有效的输入语料库学习</u>。由于缺乏input
model，研究人员建立端到端的深度学习模型来替代input
model。RNN是fuzzer生成结构化输入的一个较好的深度学习模型[74, 79, 111,
112]。然而，通过使用深度学习来代替input
model的方案可能会受到生成无效输入的影响。例如，DeepFuzz[112]生成有效语法输入的最高比率仅为82.63%。</p>
<p>​
为了提高有效输入的生成率，需要对训练数据进行相应的改进。例如，在生成PDF文件时，训练数据是由PDF对象的序列组成的，而不是文本数据。对于智能合约，训练数据是关于交易的序列[79]，类似地，LipFuzzer[208]训练对抗性语言学模型以生成语音命令，其中训练数据是通过语言结构呈现的。此外，fuzzing可以根据有效的输入语料库合成一个context-free
grammar（例如，重复和交替等规则属性）[12]，然后利用合成的语法来生成高度结构化的输入。</p>
<blockquote>
<p>基于语料库的解决方案要求训练数据全面覆盖输入规范，这可能并不实际。此外，它不使用来自内部执行状态的知识（例如，代码覆盖率），这可能导致低代码覆盖率。</p>
</blockquote>
<h4 id="coverage-based">6.2 Coverage-based</h4>
<p>​
<strong><u>从本质上讲，输入的格式表明输入中不同字节之间的关系。</u></strong>因此，在代码覆盖率的基础上，fuzzer推断字节与字节之间的关系，以促进fuzzing过程。</p>
<ul>
<li>GRIMOIRE
[16]使用代码覆盖率来推断目标程序所需的格式，它的目的是识别输入的格式边界。具体来说，它改变了输入中的一些字节，并检查这些改变是否会导致不同的代码覆盖率。<u>如果代码覆盖率保持不变，则可以随机地改变该字节。否则，这些位置就需要仔细地进行变异</u>；</li>
<li>ProFuzzer[201]首先定义了六种数据类型，涵盖了大多数输入内容。然后，根据边缘覆盖率的分布，它推断出每个字节的类型，并将属于同一类型的连续字节合并。</li>
</ul>
<h4 id="encoding-function">6.3 Encoding Function</h4>
<p>​
与上述所有专注于输入的方法不同，<u>一些fuzzer聚焦于搜索编码输入格式的代码区域</u>。因为这样的代码区通常负责生成结构化的输入，所以fuzzer在编码输入的格式之前进行变异操作。尽管PUT的源代码可能无法访问，但其生成结构化的输入的相应实现通常可以访问。</p>
<p>​
举例来说，物联网设备中的大多数是通过配套的应用程序控制的，这些应用程序生成与目标设备通信的消息[36]。通过定位与编码格式相关的代码区域，可以对函数的参数[36,
159]或计算格式的指令[92]进行变异操作。例如，IoTFuzzer[36]钩住此类函数，并对这些函数的参数数据进行突变。</p>
<blockquote>
<p>Format
inference主要用于满足程序所需的句法格式，但其仍可能生成错误的数据。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230701152722.png" style="zoom:50%;" /></p>
<p>如上图js代码所示，虽然snippet
2满足程序所需的数据格式，但line2-5有一个语义错误，原因是errf()函数未定义。</p>
</blockquote>
<h3 id="dependency-inference">7. Dependency Inference</h3>
<p>​
许多应用程序要求输入中的<strong><u>数据依赖性正确</u></strong>，而这些数据通常是由语句序列组成的。这些序列包括内核代码的系统调用[77,
95, 142]，面向对象程序的处理器的对象[59,
117]，服务/库的应用编程接口（API）[8, 83,
110]，或智能合约的应用二进制接口（ABIs）[86]。一方面，这些应用大多需要在使用输入的数据之前进行定义/声明，如图6所述。另一方面，执行一些语句的输出是其他一些语句的参数数据。</p>
<h4 id="documents-or-source-code">7.1 Documents or Source Code</h4>
<p>​
序列的数据依赖性通常是通过<u>静态分析</u>推断出来的。因为许多应用程序都有描述其界面的文件或源代码，研究人员根据这些资源推断出数据依赖性[8,
53, 59, 86, 110,
117]。这些资源包含了如何使用一个接口的信息和接口的预先需求。当fuzzing生成包括接口的输入时，fuzzing也需要生成接口的先决条件，否则，生成的输入将在早期阶段被拒绝。</p>
<p>​
然而，<strong><u>静态分析会带来很高的误报率，并且会遗漏接口的依赖关系</u></strong>。因此，当有机会接触到PUT的源代码时，更好的解决方案是结合静态分析和动态分析[95]。</p>
<h4 id="real-world-programs">7.2 Real-world Programs</h4>
<p>​
许多现实世界的程序实现了调用接口的代码行，这些代码行已经考虑了接口的数据依赖性。因此，fuzzing可以根据对现实世界程序进行的程序切片，合成调用接口的新程序[10]。</p>
<p>​ 此外，通过分析那些真实世界程序的执行日志，可以推断出数据的依赖性[77,
83,
142]。执行日志明确地包含了接口的排序信息，也就是哪个接口先被执行的信息。此外，执行日志还隐含了接口之间的参数依赖性信息。为了获得显性和隐性信息，在执行真实世界的程序时，fuzzing会钩住每个接口并记录所需的信息。</p>
<h3 id="summary-1">8. Summary</h3>
<p>​
下表描述了减少搜索空间的方法和用于分组输入字节的关系，其方法都减少了输入空间：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230701104327.png" /></p>
<h2 id="automation">Automation</h2>
<p>​
自动化分为三个部分：自动化运行PUT；自动化检测是否发生了bug；更快的运行速度。针对这三个部分：</p>
<ul>
<li>大多数fuzzer已经成功地自动化运行命令行软件，但它们不能直接用于其他目标，如硬件或多语言软件；</li>
<li>目前fuzzing一般使用crash作为是否发生Bug的检测指标，但类似data
race等bug可能并不会发生crash。</li>
</ul>
<h3 id="automatic-execution-of-puts">1. Automatic Execution of PUTs</h3>
<p>​ 这一段介绍了fuzzing针对不同应用场景下自动化执行程序的方法。</p>
<h4 id="command-line-programs">1.1 Command-line Programs</h4>
<p>​ Fuzzing在命令行程序的测试上取得了巨大的成功。</p>
<p>​
Fuzzing<u>在一个子进程中运行PUTs，然后将程序需要的参数和输入传递给它</u>。为了提高执行速度，fuzzing不会重复执行测试一个PUT的所有步骤。相反，它克隆了一个子进程，以便跳过预处理步骤，如将程序文件加载到内存中等。</p>
<p>​
通常，fuzzing对所有测试只采取同一个命令行选项，也就是说，所有生成的输入都使用同一个命令行参数。因为不同的选项表示不同的代码覆盖率，所以一个彻底的测试需要在fuzzing期间列举所有的命令选项。一个有效的方案是，如果一个输入对一个选项无效，fuzzing会跳过对所有其余选项的测试[176]。这个方案的一个重要观察点是，<strong><u>如果一个输入对一个选项无效，那么这个输入将使所有其他的选项失效</u></strong>。</p>
<h4 id="deep-learning-systems">1.2 Deep Learning Systems</h4>
<p>​ 对于深度学习系统，输入就是training data、test
data甚至是深度学习模型。输入的fitness可以是neuron
coverage（神经元覆盖率）、loss function或者operator-level coverage。</p>
<p>​
对于深度学习系统，fuzzing不仅检测其可能出现的错误，<u>还可以检测其鲁棒性</u>。</p>
<h4 id="operating-system-kernels">1.3 Operating System Kernels</h4>
<p>​
对于操作系统，其更为复杂，内核包括许多中断和内核线程，导致非确定性的执行状态。Fuzzing一般选择用hypervisor虚拟机（QEMU、KVM等）来运行目标内核，同时通过Intel的Processor
Trace (PT)技术来获取代码覆盖率。</p>
<p>​ 操作系统的输入通常是文件系统镜像（file system
image）或系统调用序列，fuzzer可以通过对内核进行数据独立性分析后生成对应的系统调用序列来测试内核，然后检测该序列的运行情况来判断结果。另一种fuzzing操作系统内核的方法是模拟外部设备，由于内核与仿真设备进行通信，fuzzer可以产生输入来测试内核中的驱动程序。</p>
<h4 id="cyber-physical-systems">1.4 Cyber-Physical Systems</h4>
<blockquote>
<p>Cyber-Physical
Systems（CPS），信息物理系统，物理和软件组件在不同的空间和时间尺度上运行。其应用包括<strong>自动汽车系统</strong>、<strong>医疗监控</strong>、<strong>过程控制系统</strong>、<strong>机器人系统</strong>、<strong>自动飞行员电子设备</strong>、<strong>智能电网</strong>、<strong>交通物流系统</strong>等。</p>
</blockquote>
<p>​
CPS包括两个主要部件，计算单元和物理进程。一个广泛使用的计算单元是可编程逻辑控制器（PLC），它控制执行器来管理物理过程并接收来自传感器的输入。因此，在对CPS进行fuzzing时，fuzzer可以取代PLC，直接通过网络向执行器发送大量指令[41]。另一种fuzzing测试CPS的方法是检查PLC的控制应用程序和运行时间[179]。然而，PLC的二进制文件不能像摸索命令行程序那样被摸索。因为PLC应用程序有各种二进制格式，并与物理组件进行复杂的通信，这些应用程序的自动化程度各不相同。基于对PLC二进制文件及其开发平台（如Codesys）的分析，在PLC设备上运行PLC二进制文件时，有可能自动进行fuzzing[179]。</p>
<h4 id="internet-of-things">1.5 Internet of Things</h4>
<p>​
对物联网的fuzzing包括了模拟（emulation）和网络层级测试（network-level
test）。仿真器（emulator）[34,
205]可以模拟执行原本在物联网固件上运行的程序，在仿真器的帮助下，fuzzer以灰盒方式运行目标程序[211]。</p>
<p>​
另一方面，网络层面的fuzzing以黑箱方式检查物联网设备，由于物联网设备可以通过网络与外界进行通信，fuzzer自动向物联网设备发送消息（请求），并等待物联网设备的执行结果（响应）[36,
63,
159]。通过对响应进行分类，fitness是类别的数量，也就是说，目的是为了探索更多的类别[63]。</p>
<h4 id="applications-with-graphical-user-interface">1.6 Applications
with Graphical User Interface</h4>
<p>​
GUI程序的执行速度比命令行程序慢很多，而在fuzzing中执行速度又很重要，故一般对GUI程序的测试都将其<u>替换为一个更快的命令行执行方法</u>。举例来说，fuzzer可以对用户界面的互动进行建模，从而为Android应用程序生成事件序列。此外，fuzzer还可以利用准备好执行环境的约束条件，直接调用图形用户界面中的目标函数。</p>
<h4 id="applications-with-network">1.7 Applications with Network</h4>
<p>​
一些例如智能合约、协议处理、云服务、安卓原生服务、智能驾驶等应用程序<u>通过网络接受输入</u>，因此，输入可以在本地生成，而目标应用程序的执行可以在远程进行。自动测试的效率依赖于生成的输入的质量，以及反映执行状态的fitness。例如，智能合约的输入是合约交易的序列，即不同账户之间的信息。当收到交易时，智能合约中的功能在其区块链的基础设施上执行。</p>
<h3 id="automatic-detection-of-bugs">2. Automatic Detection of Bugs</h3>
<p>​
这一段介绍了如何自动的检测是否发生了bug，介绍了6中成功被fuzzing检测的bug：</p>
<h4 id="memory-violation-bugs">2.1 Memory-violation Bugs</h4>
<p>​
Memory-violation，内存损坏，是一种最古老又最严重的安全bug，其可以分为两类（如下图）：</p>
<ul>
<li><strong><em>spatial safety
violations</em></strong>：out-of-bounds，内存越界访问，如（a）；
<ul>
<li>Buffer overflow是Out-of-bounds的一种经典样例，<u>Dowser
[76]认为其主要由于在循环中访问数组引起。</u>为了检测循环中的缓冲区溢出，Dowser对循环中访问缓冲区的指令进行排序，并对行使较高等级访问的输入进行优先排序。然后，它使用污点分析和concolic
execution来解决所选输入的路径约束。由于Dowser专注于循环中的数组，因此只需要对少量指令进行检测。这种关注提高了污点分析和concolic
execution的执行速度。</li>
</ul></li>
<li><strong><em>temporal safety
violations</em></strong>：UAF，如图（b）;
<ul>
<li>UAF是temporal safety
violation的经典样例，其包含了分配、释放和再次使用三个步骤，这种错误模式促使UAFL[184]（<strong><em>ICSE‘2020</em></strong>）生成能够逐渐覆盖潜在UaF的整个序列的输入，潜在的UaF序列是通过基于错误模式的静态类型状态分析得到的。</li>
</ul></li>
</ul>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230702150351.png" style="zoom: 67%;" /></p>
<p>​
尽管有很多方法被发明出来用于减轻这两种漏洞的影响，但由于成本以及低兼容性问题，几乎没有在实际上使用。</p>
<h4 id="concurrency-bugs">2.2 Concurrency Bugs</h4>
<p>​ 并发错误被分为以下几类：</p>
<ul>
<li><p><strong><em>deadlock bugs</em></strong></p>
<p>发现死锁的一个解决方案是检测锁序图，其中每个节点代表一个锁[4]，如果图中存在一个闭环，就会检测到一个潜在的死锁[90]。为了提高循环检测的效率和可扩展性，MagicFuzzer[27]迭代地删除图中的锁，如果这些锁不包括在任何循环中。然后，MagicFuzzer根据一个随机调度器检查剩余的周期。</p></li>
<li><p><strong><em>non-deadlock bugs</em></strong></p>
<ul>
<li><p><strong>atomicity-violation bugs</strong>：</p>
<p>违反原子性原则bug，如下图（a）所示，line3需要在line1之后运行，但由于Thread
2在中间改变了<code>p-&gt;info</code>的值，导致产生错误。</p>
<p>ATOMFUZZER[144]观察到一个典型的错误模式，即一个原子块内的锁被两个线程反复获取和释放。具体来说，如果一个原子块内的线程t要获取一个之前已经被t获取和释放的锁L，ATOMFUZZER会延迟线程t的执行，并等待另一个线程t
′获取该锁L，当另一个线程t
′在线程t的延迟期间获取该锁L时，就是一种原子性违反。</p></li>
<li><p><strong>order-violation bugs</strong>：</p>
<p>内存被以错误的顺序访问，如下图（b）所示，Thread2中的mThd-&gt;State在线程1中的mThd初始化之前被执行，这就产生了一个错误，使用未初始化的变量。</p></li>
</ul>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230702152016.png" /></p></li>
</ul>
<p>​ 更为普遍的说
，<u>并发错误的发生是由于线程的不正确交织</u>。挑战在于，并发程序可能有太多的交错状态，无法逐一检查（即状态爆炸问题）。CalFuzzer[166]基于以下事实缓解了状态爆炸问题：一些交织是等价的，因为它们来自非交互指令的不同执行顺序。这种等价性表明，对它们的执行将导致相同的状态。CalFuzzer随机选择一组线程，这些线程的后续指令互不交互，并同时执行这些指令。因此，CalFuzzer[166]可以更有效地检查不同的交织。</p>
<h4 id="algorithmic-complexity">2.3 Algorithmic Complexity</h4>
<p>​ Algorithm complexity
(AC)漏洞指的是当一个算法的最坏情况下的复杂性导致大大降低性能，这可能导致拒绝服务（DoS）攻击。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230702195317.png" style="zoom: 67%;" /></p>
<p>​ 如上图所示的代码，array =
[8,5,3,7,9]和[1,5,6,7,9]两种输入导致quicksort的算法复杂度是完全不同的。</p>
<ul>
<li>SlowFuzz[152]通过引导fuzzing向增加执行指令数量的方向发展，来检测AC错误；</li>
<li>HotFuzz[15]通过最大化单个method的资源消耗来检测Java
method中的AC错误；</li>
<li>MemLock[44]根据边缘覆盖率和内存消耗这两个指标来检测AC错误，它将fuzzing引向那些能够发现更多边缘或消耗更多内存的输入;</li>
<li>前面提到的fuzzer直接生成最差性能的输入（WPI）来发现AC错误。相反，Singularity[190]根据对这些WPI总是遵循一个特定模式的观察，合成了用于生成输入的程序。</li>
</ul>
<h4 id="spectre-type-bugs">2.4 Spectre-type Bugs</h4>
<p>​
有零漏洞是一种微架构攻击，利用错误预测的分支推测来控制内存访问[139]。例如，在图10中，攻击者可以为变量input发送几个in-bound值，这将训练分支预测器来推测第2行的检查是否总是真的。当攻击者为输入发送一个超限值时，预测器将错误地预测分支行为，第3-4行被投机性地执行（即在没有第2行检查的情况下被执行）。由于输入实际上并不满足第2行的检查，第3-4行的执行会导致缓冲区超读。</p>
<p>​
因此，SpecFuzz[139]对目标程序进行分析，以模拟投机执行，它可以强制执行错误预测的代码路径。然后，错误预测的路径中的任何无效内存访问都会被触发。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230702200332.png" style="zoom:67%;" /></p>
<h4 id="side-channels">2.5 Side Channels</h4>
<p>​
侧信道漏洞通过观察系统的非功能行为（如执行时间）泄露秘密信息。例如，如果一个秘密是语句
"if (a &gt;
0){...}else{...}"中的变量a，人们可以观察then-branch和else-branch的执行时间来判断a的值是否大于0。一种特殊的边信道被称为JIT诱导的边信道，它是由及时优化（JIT）引起的[25]。与前面提到的Spectre型bug类似，人们可以反复运行程序来训练JIT编译器，使其优化the
then-branch或else-branch的执行时间。然后，训练过的分支（如the
then-branch）和未训练过的分支（如else-branch）的执行时间将有足够的偏差，可以被观察到。因此，变量a的秘密值被泄露了。</p>
<h4 id="integer-bugs">2.6 Integer Bugs</h4>
<p>​
当一个算术表达式的值超出机器类型所决定的范围时，就会发生整数溢出/下溢漏洞。另一方面，整数转换错误发生在将一种整数类型错误地转换为另一种整数类型时。</p>
<p>​
为了检测整数bug，SmartFuzz[132]根据不同的整数bug在符号仿真中加入了特定的约束。然后，符号解算器打算生成可能触发整数错误的具体输入。</p>
<h3 id="improvement-of-execution-speed">3. Improvement of Execution
Speed</h3>
<p>​
<strong><u>提升运行的速度对fuzzing非常重要</u></strong>，因为fuzzing会在time
budget上会运行多个测试样例。</p>
<h4 id="binary-analysis">3.1 Binary Analysis</h4>
<p>​
作为一个预处理过程，fuzzing主要利用静态工具来获取执行状态，因为静态工具为fuzzing提供了高执行速度[58,
134]。一个广泛使用的静态分析工具是LLVM[113]，它在编译过程中对程序进行分析。</p>
<p>​
当面对不开源应用时，传统的额二进制插桩工具（如Dyninst）应用到fuzzing上时时间开销过大，为了解决这个问题：</p>
<ul>
<li>RetroWrite[58]提出使用基于可重构汇编的静态二进制重写技术。它的重点是通过利用PIC的重定位信息对汇编文件进行仪器化的64位独立代码（PIC）的二进制文件。由于RetroWrite可以对内联的代码片段进行检测，因此性能开销有所降低。尽管很快，RetroWrite只支持64位PIC二进制；</li>
<li>为了维护低运行时开销和可扩展性，FIBRE[134]通过四个IR修改阶段简化了代码插桩过程。这四个阶段通过静态重写、内联、跟踪寄存器的有效性和考虑各种二进制格式来检测程序。上述重写技术只重写一次二进制文件，这可能导致不健全的二进制重写，特别是对于剥离的二进制文件[189]；</li>
<li>为了解决这个问题，STOCHFUZZ[209]基于模糊处理重复执行目标程序的事实，提出了增量和随机重写技术。具体来说，STOCHFUZZ对目标二进制文件进行多次改写，并逐步修复之前改写结果所带来的问题。</li>
</ul>
<h4 id="execution-process">3.2 Execution Process</h4>
<p>​ 程序执行速度也可以提高。</p>
<ul>
<li>UnTracer[133]观察到，<strong><u>在模糊处理过程中产生的大多数测试用例并没有发现新的覆盖范围</u></strong>。这表明，追踪所有的测试用例（AFL使用）会产生大量的运行时间开销。因此，UnTracer只跟踪覆盖率增加的测试案例，以提高执行速度。这是通过在基本块的开头插入中断来完成的。<u>当一个块被检查时，UnTracer会删除该块的插桩代码，这样将来执行时就不会在该块被中断</u>；</li>
<li>由于block
coverage失去了执行状态的信息，CSI-Fuzz[216]利用边缘覆盖来改进UnTracer；</li>
<li>Zeror[213]通过在Untracer-instrumented二进制和AFL-instrumented二进制之间自适应切换来改进UnTracer。对于hybrid-fuzzing，concolic
execution被用来解决路径约束。然而，concolic
execution中的符号模拟在制定路径约束时很慢，这是混合模糊法在扩展到现实世界应用时受到影响的主要因素;</li>
<li>QSYM[204]通过删除一些耗时的组件，如IR翻译和快照，缓解了性能瓶颈。此外，它只收集和解决了一部分路径约束。尽管由QSYM生成的具体输入可能不是路径约束的精确解，但QSYM使用fuzzing通过改变这些具体输入来搜索有效输入；</li>
<li>Intriguer[46]观察到，由于QSYM解决了许多不必要的约束，所以QSYM仍然存在性能瓶颈。然后，Intriguer对更多的相关指令进行了符号仿真，这是由动态污点分析决定的。除了插桩和hybrid-fuzzing，另一个优化是提高并行模式下的执行速度。Xu等人[195]观察到，AFL[206]在120个内核上并行运行时，速度明显减慢。这促使他们设计新的操作原语来提高执行速度。</li>
</ul>
<h4 id="various-applications">3.3 Various Applications</h4>
<p>​
除了一般的应用，fuzzing也被用来检测不同领域目标的缺陷，如物联网、操作系统内核和虚拟机监视器（VMM）。由于这些目标通常有特殊的功能，所以模糊测试是为目标定制的，以便以有效的方式进行测试。</p>
<p>​
虽然仿真是一种很有前途的模糊物联网固件的方法，但全虚拟化的吞吐量很低。全虚拟化的运行时间开销主要来自于翻译内存访问的虚拟地址和仿真系统调用。</p>
<ul>
<li>FIRM-AFL[211]通过结合用户模式虚拟化和全系统虚拟化来减轻开销，它主要在用户模式仿真中运行程序；</li>
<li>为了对VMM进行模糊处理，Schumilo等人[162,
163]设计了一个定制的操作系统和一个快速的快照恢复机制，以便有效地进行模糊处理。</li>
<li>至于文件系统，由于image太大，突变整个磁盘image会大大降低模糊处理的吞吐量。JANUS[196]只对种子image的元数据进行了修改；也就是说，它利用了结构化数据的特性。这个解决方案减少了输入的搜索空间，从而提高了吞吐量;</li>
<li><u>操作系统内核也可以通过外部设备被破坏，也就是说，漏洞是沿着硬件-操作系统边界发生的</u>。为了检测设备-驱动通信中的缺陷，PeriScope[174]提出了基于内核的页面故障处理机制的Fuzz；</li>
<li>Windows的应用程序与Linux的不同，因为它们大量使用图形界面，而且Windows缺乏快速克隆进程的方法。WINNIE[91]合成了一个运行没有图形界面的应用程序的约束。此外，它还为Windows实现了fork()来有效地克隆进程；</li>
<li>BigFuzz[207]将数据密集型可扩展计算（DISC）应用程序转换为语义等价的程序，该程序独立于DISC框架。由于DISC框架引入了较长的延迟，独立于框架的执行方式显著提高了执行速度。</li>
</ul>
<h2 id="gap">Gap</h2>
<p>​ 综上所述，目前fuzzing解决的三个gap：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230629100103.png" style="zoom: 67%;" /></p>
<h4 id="gap-1-sparse-defect-space-of-inputs">Gap 1: Sparse defect space
of inputs</h4>
<p>​
在应用程序中的漏洞分布是分散的，而仅有部分特定的输入能够触发漏洞；浅显的漏洞可以在短时间内被
fuzz
到，但许多安全漏洞需要测试复杂的执行路径并解决严格的路径约束，因此一个高效的
fuzzing 算法需要同时对 待测试程序（program under test，
<strong>PUTs</strong>）与 安全缺陷（security
flaws）足够精通，以在一个更有可能存在漏洞的代码区域分配计算资源。</p>
<h4 id="gap-2-strict-valid-input-space">Gap 2: Strict valid input
space</h4>
<p>​
每种应用程序都有着自己的特定输入格式，现代程序越来越大，导致了越来越复杂的输入，因此，生成有效输入是有挑战性的。</p>
<p>​
此外，为了提高fuzzing的效率，生成的输入最好能执行不同的执行状态（例如，代码覆盖率）。这就要求fuzzing为有效输入的生成开发更先进的方案。如果没有对PUT的系统性分析，几乎不可能精确限制输入空间。例如，PDF文件的随机突变可能违反PDF的规范。模糊法需要仔细地突变PDF文件，使生成的输入属于有效输入空间。</p>
<h4 id="gap-3-various-targets">Gap 3: Various targets</h4>
<p>​ 由于 fuzzing 大量重复地测试 PUTs，这需要高效的自动化方法。PUTs
与漏洞都是多种多样的，有的程序可以简单直接地被自动化地测试（命令行），但许多程序在自动化测试前都需要做大量的工作（例如硬件）；此外，安全缺陷同样需要自动化的
indicator 以记录潜在的真正漏洞，<strong>程序崩溃</strong>是一个常用的
indicator 因为其可以被 OS
自动捕获，但有的安全缺陷<strong>并不会表现出崩溃</strong>（例如data
race），这需要精心设计的 indicator。</p>
<blockquote>
<p>PS: data race(数据争用) &amp; race condition(竞态条件)</p>
<p><a href="https://zhuanlan.zhihu.com/p/560773428">竞态条件（Race
condition）与数据竞争（Data Race）的区别</a></p>
</blockquote>
<h2 id="direction-of-future-research">Direction of future research</h2>
<p>​ 未来可能的几个方向：</p>
<h3 id="more-sensitive-fitness">1. More sensitive fitness</h3>
<p>​
提高代码覆盖率的效率和效果，尤其是其敏感性（Fitness的敏感性表明其区别不同程序运行状态的能力）。最近，研究人员意识到，代码覆盖率在发现复杂的bug方面有其局限性。因此，他们通过引入通过分析bug获得的信息（如危险代码区域）来扩展代码覆盖率。未来的工作可以分析bug，并根据bug的特征进行检测，特别是分析那些逃避当前fuzzing的bug。</p>
<h3 id="more-sophisticated-fuzzing-theories">2. More sophisticated
fuzzing theories</h3>
<p>​
目前的fuzzing理论研究都是部分地定制了fuzzing的某个过程（第3节）。大多数现有的工作旨在制定seed
schedule，而关注其他fuzzing过程的工作则少得多。<u>由于fuzzing的复杂性，现有的工作中很少有制定整个fuzzing过程的</u>。</p>
<p>​
<strong>从数学理论上制定整个fuzzing过程是<em>non-trivial</em>的</strong>。然而，制定一个以上的fuzzing过程是可能的，如博弈论，其同时考虑seed
schedule和bytes schedule。</p>
<p>​
更长远来看，关于fuzzing的理论限制也可以是研究方向（例如，灰盒fuzzing的限制）。另一方面，用多种类型的fitness来制定fuzzing过程是建立更复杂的fuzzing理论的另一种方式。例如，未来的工作可以同时考虑错误的到来和状态的转换来制定fuzzing过程。</p>
<h3 id="sound-evaluation">3. Sound evaluation</h3>
<p>​
少部分研究工作关注评价的合理性，但没有得出确切的结论（3.6节）。这些工作只为合理的评价提供了建议，如时间预算或评价指标，更多的问题仍然有待回答。</p>
<blockquote>
<ul>
<li>我们应该使用合成的bug还是真实世界的bug作为评价体例？</li>
<li>统计测试是区分两种fuzzing技术的最终答案吗？</li>
<li>终止fuzzing的合理时间预算是什么？</li>
<li>当不存在用于比较fuzzer时，我们如何评估特殊的目标应用，如硬件？</li>
</ul>
</blockquote>
<h3 id="scalable-input-inference">4. Scalable input inference</h3>
<p>​
如果在fuzzing过程中使用特定格式或数据依赖性，其效率可以得到显著提高。静态分析被广泛用于格式推断和数据依赖性推断。然而，静态分析是特定于应用程序的；也就是说，推理方法的实现需要考虑不同应用程序的特点。目前，动态分析侧重于格式推断，很少有作品在数据依赖性推断方面做出努力。<u>具有动态分析的推理方法有可能被用于多种应用</u>；也就是说，动态分析比静态分析更具可扩展性。更多的研究可以集中在基于动态分析的数据依赖性推断上。</p>
<h3 id="efficient-mutation-operators">5. Efficient mutation
operators</h3>
<p>​
<u>几乎所有的fuzzer在fuzzing过程中都使用了固定的mutator</u>。也就是说，fuzzer根据目标应用程序的特点提前设计了一些mutator，<u>并且在摸索过程中并不改变mutator</u>。有几项工作打算优化mutator，但没有人关注可改变的mutator，是否有可能设计出在fuzzing过程中可以改变的mutator来提高性能？因为mutator
schedule与bytes schedule密切相关，所以在设计mutator时考虑到bytes
schedule可能是有希望的。此外，高度结构化输入的mutator可能对一般应用有不同的属性，因此，高度结构化输入的mutator
schedule可能也值得研究。</p>
<h3 id="more-types-of-applications">6. More types of applications</h3>
<p>​
Fuzzing在检测命令行程序的错误方面取得了巨大成功。研究人员也在对更多类型的应用程序进行fuzzing方面做出了许多努力（第5.1节）。由于不同应用程序的复杂性，fuzzing在实际检测更多类型的应用程序时有其局限性。例如，一些工作探索了对网络物理系统进行fuzzing的可能性，但fuzzing的能力是有限的[41,
179]。由于执行速度对fuzzing至关重要，因此hard-fuzzing应用的一个潜在方向是提高其执行速度。</p>
<h3 id="more-types-of-bugs">7. More types of bugs</h3>
<p>​ Fuzzing已经成功地检测到了诸如memory-violation bugs, concurrency
bugs, 或者algorithmic complexity
bugs。<u>然而，它很难检测到许多其他类型的错误，如特权升级或逻辑错误</u>。</p>
<p>​
目前的挑战是为这些错误设计适当的指标，以便在fuzzing过程中自动记录它们。因为这种指标反映了相应的bug的特征，所以指标的设计需要研究人员对fuzzing和目标bug都有很好的理解。例如，即使触发了逻辑错误，程序也会在没有异常的情况下运行。为了设计逻辑错误的自动指标，需要对开发代码的功能需求有深刻的理解。</p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Fuzzing</tag>
      </tags>
  </entry>
  <entry>
    <title>(论文阅读) Concolic Execution for WebAssembly</title>
    <url>/2023/06/20/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Concolic-Execution-for-WebAssembly/</url>
    <content><![CDATA[<h1 id="concolic-execution-for-webassembly">Concolic Execution for
WebAssembly</h1>
<blockquote>
<p>时间：2022</p>
<p>作者：Filipe Marques、José Fragoso Santos、Nuno
Santos（里斯本大学）</p>
<p>会议：ECOOP’2022（软工CCF-B）</p>
</blockquote>
<h2 id="abstract">Abstract</h2>
<p>​
WebAssembly（Wasm）是一种新的二进制指令格式，允许用高级语言编写的目标编译代码以接近原生的速度被浏览器的JavaScript引擎执行。<u>尽管Wasm有明显的性能优势，但它为网络程序引入错误或安全漏洞提供了机会，因为用不安全语言编写的程序中已有的问题可以转移到交叉编译的二进制文件中。</u>这种二进制文件的源代码经常无法用于静态分析，这就需要有能够直接处理Wasm代码的工具。尽管这种潜在的安全关键情况，仍然明显缺乏分析Wasm二进制文件的工具支持。</p>
<p>​
我们提出了WASP，一个用于测试Wasm模块的符号执行引擎，它直接在Wasm代码上工作，并建立在一个符合标准的Wasm参考实现之上。我们对WASP进行了全面的评估：它被用来符号执行测试C语言的通用数据结构库和C语言的亚马逊加密SDK，证明它可以为真实世界的C语言应用找到错误并产生高覆盖率的测试输入；并进一步针对Test-Comp基准进行测试，获得了与成熟的C语言符号执行和测试工具相当的结果。</p>
<span id="more"></span>
<h2 id="问题背景">问题背景</h2>
<h3 id="concolic-execution">1. Concolic execution</h3>
<p>​ Concolic
execution是符号执行的一种特殊变体，在这种情况下，人们将具体的执行与纯粹的符号执行配对，通过一次探索一个执行路径来避免与底层SMT求解器的交互。<u>Concolic执行引擎为符号输入分配具体数值，并同时以具体和符号方式执行给定的程序，只遵循具体路径，但像纯符号执行那样构建与该路径对应的路径条件。</u></p>
<p>​
更具体地说，它可以用来为符号变量生成新的具体输入，从而强制探索不同的路径。为此，人们需要否定上一次执行获得的路径条件，并查询底层求解器，以获得公式的模型。<u>通过跟踪所有通过Concolic执行产生的路径条件，引擎可以列举出所有的程序执行路径，直到一个边界，其优点是每个探索的路径只需要与底层求解器交互一次。<strong>请注意，在纯粹的符号执行中，引擎必须在每次遇到分支点时查询求解器，以确定其then-和else-分支是否可行。</strong></u></p>
<p>​ 以如下代码为例(<em>参考《Robust Symbolic Execution for
WebAssembly》</em>)：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230620193746.png" style="zoom:50%;" /></p>
<p>​ <strong>目标：测试assert语句成立的条件。</strong></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230620210915.png" style="zoom:50%;" /></p>
<p>​ 如上图所示，程序有三条可能的执行路径，对于每一个执行路径（execution
path），我们称其为一个<strong><em>concolic iteration</em></strong>。</p>
<p>​ 在Concolic execution中：</p>
<ol type="1">
<li><p>第一个concolic
iteration开始前，变量x与y被赋予具值0与2，这些输入导致Concolic
execution引擎探索上图最右边的路径，产生最后的路径条件：<strong>X≤0</strong>；</p></li>
<li><p>第二个concolic iteration开始前，Concolic
execution引擎查询底层SMT求解器，为符号输入寻找一个满足公式<strong>x&gt;0</strong>的输入值，即对应于第一个路径条件的否定。让我们假设求解器返回x=1和y=0。这些输入导致引擎探索中间的执行路径，产生路径条件：<strong>（x&gt;0）∧（x≥y）</strong>；</p></li>
<li><p>第三个concolic
iteration开始前，同2，引擎继续利用SMT求解器查找对2生成条件的否定，得到：(x
&gt; 0) ∧ ((x ≤ 0) ∨ (x &lt; y))，也就是等价于：<strong>(x &gt; 0) ∧ (x
&lt;
y)</strong>。假设这里得到了具体输入x=1和y=2，程序探索了最左边的执行路径，<strong><u>但此时这个输入并没有触发断言，其导致a=4，b=6</u></strong>。当这条路径执行到断言语句时，条件为：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230620195227.png" style="zoom:50%;" /></p>
<p>符号执行引擎会继续对这个条件做分析，即在满足PC条件（x&gt;0 and
x&lt;y）下，是否可以推出：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230620195505.png" style="zoom:50%;" /></p>
<p>即是否存在反例：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230620195611.png" style="zoom:50%;" /></p>
<p>SMT求解这个式子很容易得出，x=1,y=4，故这条路径上存在导致断言失败的输入。</p></li>
</ol>
<h3 id="现有wasm符号执行工具">2. 现有WASM符号执行工具</h3>
<p>​ 据我们所知，目前只有两个工具用于象征性地执行Wasm代码：
WANA[73]和Manticore[51]。然而，这两个工具主要是针对智能合约的分析，并有重要的限制，限制了它们对独立的Wasm模块的应用。<u>WANA[73]处于初步开发阶段，只能应用于EOSIO和Ethereum智能合约，因为它不包括可以独立运行的Wasm的符号执行引擎。</u><u>Manticore[51]最近获得了对Wasm[33]的支持，但尚未对Wasm代码进行系统的评估。此外，它对Wasm模块的应用需要为每个可能的输入内存手动设置一个复杂的Python脚本，这使得它很麻烦，难以实现自动化。</u></p>
<p>​</p>
<h2 id="贡献">贡献</h2>
<p>​
我们提出了WebAssembly符号处理器，WASP，一个用于测试Wasm（1.0版）模块的新型Concolic
execution引擎。WASP遵循所谓的Concolic discipline[28,
64]，将具体执行与符号执行相结合，一次探索一条执行路径。<strong><u>然而，与大多数通过对程序插桩的Concolic
execution引擎[65, 79, 64,
63]不同，我们通过对Haas等人[30]开发的Wasm解释器的插桩实现WASP。</u></strong>为此，我们将作者的参考解释器从具体数值提升到具体数值和符号数值对。通过将插桩转移到解释器层面，我们为Concolic
execution中的一系列优化提供了可能性。</p>
<pre><code>1. WASP能够分析独立的Wasm模块（不同于WANA），它能够被用作一个通用的平台，为编译成Wasm的高级编程语言建立符号分析；
2. WASP能够分析大多数C语言库；</code></pre>
<h2 id="模型">模型</h2>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230620210942.png" /></p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Symbolic Execution</tag>
        <tag>WASM</tag>
      </tags>
  </entry>
  <entry>
    <title>(论文阅读) WANA-Symbolic Execution of Wasm Bytecode for Extensible Smart Contract Vulnerability Detection</title>
    <url>/2023/06/19/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91WANA-Symbolic-Execution-of-Wasm-Bytecode-for-Extensible-Smart-Contract-Vulnerability-Detection/</url>
    <content><![CDATA[<h1
id="论文阅读wana-symbolic-execution-of-wasm-bytecode-for-extensible-smart-contract-vulnerability-detection">(论文阅读)WANA:
Symbolic Execution of Wasm Bytecode for Extensible Smart Contract
Vulnerability Detection</h1>
<blockquote>
<p><strong>时间：</strong> 2021</p>
<p><strong>作者：</strong> B Jiang, Y Chen, D Wang（北航）</p>
<p><strong>会议：</strong> QRS‘2021 （软工CCF-C）</p>
<p><strong>开源：</strong> https://github.com/gongbell/WANA</p>
</blockquote>
<h2 id="abstract">Abstract</h2>
<p>​
许多流行的区块链平台支持智能合约，以建立去中心化的应用程序。然而，智能合约内的漏洞已经证明导致其终端用户的严重经济损失。特别是EOSIO智能合约平台上的智能合约导致了大约38万个EOS代币的损失，在攻击发生时，价值约为190万美元。<u>EOSIO智能合约平台是基于Wasm虚拟机的，它也是支持其他智能合约平台以及网络应用的底层系统</u>。<strong>在这项工作中，我们提出了WANA，一个基于Wasm字节码符号执行的可扩展智能合约漏洞检测工具。WANA提出了一套基于Wasm字节码分析的算法来检测EOSIO智能合约的漏洞。</strong>我们的实验分析表明，WANA可以有效地、高效地检测EOSIO智能合约中的漏洞。此外，我们的案例研究还表明，WANA可以扩展到有效检测Ethereum智能合约的漏洞。</p>
<span id="more"></span>
<h2 id="问题背景">问题背景</h2>
<p>​
EOSIO是一个流行的公共区块链平台，支持智能合约技术。然而，EOSIO智能合约中的漏洞导致了其终端用户的经济损失。对于EOSIO智能合约来说，区块信息依赖漏洞、假的EOS转移漏洞和伪造的转移通知漏洞总共导致了大约38万个EOS代币的损失
。在攻击发生时，这些漏洞的累计损失金额约为价值190万美元。因此，需要有效的漏洞检测工具来保护EOSIO区块链平台的生态系统。</p>
<p>​
Wasm不仅被EOSIO公共区块链平台采用作为智能合约执行引擎[35]，也被其他区块链平台的议程项目采用。例如，以太坊区块链平台已经计划为以太坊2.0采用Ethereum
Wasm（EWasm）虚拟机。Polkadot平台[40]进一步采用Wasm作为其parachain运行时和智能合约执行的编译目标。Wasm在构建Web应用程序中也很受欢迎，因为Wasm模块可以调用到JavaScript上下文，并通过从JavaScript访问的相同Web
API访问浏览器的功能。<u>Wasm的综合符号执行引擎有希望为任何以Wasm为目标的应用程序提供一个可扩展的安全分析框架。</u></p>
<h2 id="贡献">贡献</h2>
<ol type="1">
<li>它为Wasm提出了一个通用的符号执行框架WANA；</li>
<li>它提出了一个基于符号执行引擎的智能合约漏洞检测工具的新的可扩展架构；</li>
<li>它提出了一个全面的实验研究，以评估WANA对EOSIO智能合约的漏洞检测效果；</li>
<li>它提出了一个案例研究，以评估WANA在Ethereum平台上漏洞检测方面的可扩展性。</li>
</ol>
<h2 id="模型">模型</h2>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230619183309.png" style="zoom:50%;" /></p>
<p>​
如上图所示，Wasm字节码被解析、加载，并在Wasm符号执行引擎中被初始化。<u>WANA的符号执行引擎是作为一个新的虚拟机实现的，它可以根据WASM规范评估具体和符号输入。它已经实现了Wasm规范1.0版中的所有指令。</u>当一个模块被加载到WANA
Wasm虚拟机中时（在加载和初始化阶段），WANA的符号执行引擎会准备一个执行环境，其中包括存储器、各种表（包括函数表和符号表）、全局变量和一个执行堆栈，以保持模块的执行上下文。</p>
<h3 id="符号执行引擎">1. 符号执行引擎</h3>
<p>​
<strong>WANA会在所有exported函数上进行符号执行</strong>，对于每个导出的函数正文中的指令所调用的每个Wasm函数，WANA首先准备一个框架作为其执行环境，其中包括参数、局部变量、返回值和对其模块的引用。然后，它开始依次符号执行被调用函数的code
section的指令。</p>
<p>​
在所有的Wasm指令中，主要有四种指令，包括数字、内存、控制和函数调用指令,下面介绍WANA如何处理:</p>
<ul>
<li><p><strong>Numeric instructions:</strong></p>
<p>WANA实现了基于堆栈的执行逻辑。WANA的符号执行引擎首先弹出操作数，进行符号计算，并将结果推回堆栈。所有关于整数和浮点值类型的数字指令都支持。</p></li>
<li><p><strong>Control instructions:</strong></p>
<p>有两种分支指令：无条件分支（如br）和条件分支（如br_if）。</p>
<ol type="a">
<li><p>非条件性分支：
在Wasm中，执行无条件分支将直接跳到指令参数指定的标签上继续执行，这对实现循环很有用。然而，当循环的深度增加时，符号执行引擎将变得缓慢或由于状态爆炸而被困住。因此，WANA在路径探索过程中对每个标签的最大嵌套循环深度设置了一个上限。</p></li>
<li><p>条件性分支：
对于指令br_if，其执行将取决于该指令表达式的评估结果。WANA将记录每个分支的执行环境，并遍历各个分支以实现路径覆盖。对于每个分支，在遍历之前，相应的路径约束将被输入到z3[15]进行约束解算，这可以通过修剪那些不可行的路径来提高执行效率。和上面一样，WANA在路径探索过程中也对每个标签的最大嵌套循环深度设置了一个上限。</p></li>
</ol></li>
<li><p><strong>Memory and Memory instructions:</strong></p>
<p>在Wasm中，有三种类型的内存操作指令：load、store和增加内存的大小。一个Wasm模块可以在任何字节地址上从/向线性存储器加载和存储值。由于Wasm中对整数和浮点数据类型有许多位操作指令，WANA被设计为用z3中的位向量数据类型来表示整数和浮点数据类型。WANA使用32位（64位）位向量数据类型来表示32位（64位）整数和浮点符号数据类型。由于字节数组不能存储位向量或其表达式，WANA使用线性列表来存储位向量的具体值和符号值的引用，以模拟模块的内存。</p>
<p><strong>在符号执行过程中，WANA在执行存储操作时，将把键值对（address,
value）插入字典中。在load操作中，如果符号内存地址存在于字典中，WANA将直接从字典中获取相应的值。否则，WANA将从线性列表中随机选择一个内存地址并返回其值。此后，符号内存地址将被绑定到一个随机选择的内存地址。</strong></p></li>
<li><p><strong>Function call:</strong></p>
<p>在Wasm中，有两种类型的函数调用：直接和间接。</p>
<p>对于间接函数调用，WANA的符号执行引擎首先从执行堆栈的顶部框架获得一个索引。然后，符号执行引擎使用该索引从函数表中获得具体的函数地址。对于当前Wasm模块中的函数，WANA直接进入函数，继续进行符号执行。</p></li>
</ul>
<h3 id="对库函数建模">2. 对库函数建模</h3>
<p>​
一个智能合约可能会调用底层区块链平台提供的各种库函数。WANA根据这些库函数的效果来处理这些库函数的调用，并相应地模拟其行为。由于库函数与平台有关，WANA为不同的平台模拟了不同的库函数行为。当把WANA扩展到一个新的平台时，其相应的库函数也应被模拟。</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230619201024.png" /></p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Symbolic Execution</tag>
        <tag>WASM</tag>
      </tags>
  </entry>
  <entry>
    <title>(论文阅读) Eunomia-enabling User-specified Fine-Grained Search in Symbolically Executing WebAssembly Binaries</title>
    <url>/2023/06/18/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Eunomia-Enabling-User-specified-Fine-Grained-Search-in-Symbolically-Executing-WebAssembly-Binaries/</url>
    <content><![CDATA[<h1
id="eunomia-enabling-user-specified-fine-grained-search-in-symbolically-executing-webassembly-binaries">Eunomia:
Enabling User-specified Fine-Grained Search in Symbolically Executing
WebAssembly Binaries</h1>
<blockquote>
<p><strong>时间：</strong>2023.4</p>
<p><strong>作者：</strong>Ningyu He、Zhehao Zhao（北大）/Haoyu
Wang（华科）</p>
<p><strong>会议：</strong>ISSTA‘2023</p>
<p><strong>开源：</strong> https://github.com/HNYuuu/Eunomia-ISSTA23</p>
</blockquote>
<h2 id="abstract">Abstract</h2>
<p>​
尽管现有的技术已经提出了自动化的方法来缓解符号执行的路径爆炸问题，但用户仍然需要通过仔细应用各种搜索策略来优化符号执行。由于现有的方法主要只支持粗粒度的全局搜索策略，它们不能有效地遍历复杂的代码结构。<strong><u>在本文中，我们提出了Eunomia，一种符号执行技术，允许用户指定局部领域知识，以实现细粒度搜索</u></strong>。</p>
<p>​
在Eunomia中，我们设计了一个富有表现力的领域特定语言(DSL)，即AES，让用户可以精确地将本地搜索策略定位到目标程序的不同部分。为了进一步优化局部搜索策略，我们设计了一种基于区间的算法，该算法可以自动隔离不同局部搜索策略的变量背景，避免同一变量的局部搜索策略之间的冲突。</p>
<p>​
我们将Eunomia作为一个针对WebAssembly的符号执行平台来实现，这使我们能够分析用各种语言（如C和Go）编写但可以编译成WebAssembly的应用程序。据我们所知，<u>Eunomia是第一个支持WebAssembly运行时全部功能的符号执行引擎。</u></p>
<p>​
我们用一个专门的符号执行微基准套件和六个真实世界的应用来评估Eunomia。我们的评估显示，Eunomia在现实世界的应用中加速了错误检测，最多可达到三个数量级。根据一项全面的用户研究结果，用户可以通过编写一个简单直观的AES脚本来显著提高符号执行的效率和效果。除了验证六个已知的真实世界的bug，Eunomia还在一个流行的开源项目Collections-C中检测到两个新的0-day
bug。</p>
<span id="more"></span>
<h2 id="background">Background</h2>
<h3 id="样例">1. 样例</h3>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230619160638.png" style="zoom:50%;" /></p>
<h4 id="代码功能">1.1 代码功能</h4>
<p>​
以上图代码为例，其为一个工业网络协议处理函数<code>check_sections</code>。函数的输入是一个section
向量<code>sec_vec</code>和每个section所含的fields数<code>sec_field_cnt</code>。每个section最多有5个fields（<strong><em>L4</em></strong>）。具体来说，前三个section：<code>token</code>、<code>index</code>和<code>checksum</code>，呈现了每个部分的元数据，它们分别指的是发送方的token、收到的相应部分的索引，以及数据的校验和。<code>len</code>表示数据的长度，其正确性由上述的校验和验证。</p>
<p>​
综上，函数<code>check_sections</code>检验<code>sec_field_cnt</code>限制下的所有字段，以两层嵌套循环的方式实现，<u>外层循环遍历所有收到的部分，而内部循环遍历所有字段并进行相应的验证。</u></p>
<h4 id="现有工具问题">1.2 现有工具问题</h4>
<h5 id="klee">1.2.1 Klee</h5>
<p>​
由于<strong>路径爆炸</strong>问题，直接在上述代码上使用符号执行无法在合理的时间内完成验证。在实践中，开发者可以提供两块领域知识来加速分析，如下所示：</p>
<p>​ <strong><em>DK1.</em></strong>
优先考虑成本较低的else分支，推迟分析昂贵的函数foo，同时验证用户令牌（<strong><em>L23
- L29</em></strong>）；</p>
<p>​ <strong><em>DK2.</em></strong>
为了避免在分析复杂的数据（<strong><em>L41</em></strong>）时陷入困境，符号执行可以首先完成对简单场的分析，即tokn、index，以及checksum。</p>
<p>​
<strong>Klee</strong>不能有效地应用DK1和DK2，因为它没有确定优先级的原语。通常，我们使用KLEE原语，如<code>klee_assume(cond)</code>和<code>klee_prefer_cex(obj, cond)</code>来指定符号执行中的额外约束。不幸的是，这些原语只能修剪不需要的状态，而不能优先考虑有趣的路径。具体来说，<code>klee_assume(cond)</code>可以用来插入额外的约束，不符合cond的路径将被剪除。至于<code>klee_prefer_cex(obj, cond)</code>，它为待测函数的符号参数增加了一个优先值。<u>它只能在测试驱动中使用，而不是在代码中的任何地方（只能在产生输入时使用，故其不能直接引导符号执行去偏好某一部分代码）。</u></p>
<p>​
对于DK1，KLEE能做的最接近的做法是添加<code>klee_assume(isValid(token)==0)</code>，这样就可以删去包含foo()的分支。然而，在DK1中，我们只想优先处理通向bar()的分支，直接修剪掉的路径可能会破坏分析的合理性。同样地，KLEE也不能利用DK2，其最接近的做法是在<strong><em>L22</em></strong>后面加上<code>klee_assume(j&lt;3)</code>。然而，这种方法也影响了分析的合理性，因为KLEE直接放弃了对LEN和DATA字段的分析。</p>
<blockquote>
<p>综上，利用Klee只能做到舍弃某部分的控制流分支而做不到“偏好”，但舍弃部分控制流并不符合分析工作的初衷。</p>
</blockquote>
<h5 id="其他方法">1.2.2 其他方法</h5>
<p>​ 虽然有其他工作对执行路径进行优先排序[33, 34, 46, 53,
68]，但它们也不能正确利用用户定义的领域知识。现有的路径优先化方法要么依赖于预先定义的启发式方法、黑盒策略，甚至是机器学习算法。他们的目标是加速一般的符号执行，而不是采用用户定义的领域知识。因此，它们与我们的工作大多是正交的。</p>
<h4 id="解决方法">1.3 解决方法</h4>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230619162515.png" style="zoom:50%;" /></p>
<p>​
上图是为样例代码生成的AES自定义脚本，其可以实现DK1与DK2。每个语句由两部分组成，即<u>定位部分</u>和<u>知识部分</u>。我们可以看到，这两个语句被包裹在一个checker中，该checker为一个函数<code>check_sections()</code>（<strong><em>L1</em></strong>）工作。上图脚本的语义为：</p>
<p>​ （1）验证前三个元数据section；</p>
<p>​ （2）跳到内循环条件检查，不验证长度和数据；</p>
<p>​ （3）移动到下一个部分，重复（1）和（2）；</p>
<p>​ （4）一旦所有前三个步骤完成，处理剩余的长度和数据字段。</p>
<h3 id="问题背景">2. 问题背景</h3>
<p>​
目前已知的符号执行技术的问题是往往过于粗·略，无法满足某些分析目的。现有的方法大多支持应用于整个程序的全局搜索策略。<u>然而，全局策略并不是最优的，因为一个程序的不同代码块具有明显的特征，可能适合不同的局部搜索策略。</u></p>
<p>​
假设代码的一个嵌套循环部分负责解析收到的网络数据包，开发者想检查嵌套循环中是否存在缓冲区溢出。然而，内层循环有一个复杂的函数，需要大量的时间来验证。因此，开发者可能想优先考虑内层循环中的其他轻量级部分，以最大化符号执行的覆盖率。不幸的是，现有的方法不能优先考虑内循环的一个子集。这导致了要么在处理复杂函数时被卡住，要么产生不健全的分析结果。因此，有必要让用户为不同程序代码块的局部搜索策略提供提示。</p>
<p>​ 要实现为不同程序代码块提供不同局部搜索策略，需要面对的问题有：</p>
<ol type="1">
<li><p>如何为目标程序的不同部分有效地指定本地搜索策略；</p></li>
<li><p>实现本地搜索策略，同时避免潜在的冲突：</p>
<p><u>同一个变量可能同属于不同的代码结构</u>，例如，一个变量可能同时被多层循环结构共享。因此，多个本地搜索策略可能因为相同的变量产生冲突。</p></li>
</ol>
<p>​
<strong>已知的对Wasm做符号执行的方法缺少对WASI的支持，因此限制了应用的范围。</strong></p>
<h2 id="contributions">Contributions</h2>
<ol type="1">
<li>提出并实现了一个新的符号执行框架<strong><em>Eunomia</em></strong>，它的路径搜索过程可以通过用户指定的领域知识进行细化调整，而无需对目标程序进行任何修改；</li>
<li>提出一个原创的领域特定语言(DSL)，即<strong><em>AES</em></strong>，其可以可以绑定一组局部适配函数来加速分析过程。此外，用户还可以为语句或函数引入前置和后置条件，甚至可以在任意位置上引入to-checked谓词；</li>
<li>提出一个新的路径搜索策略，<strong><em>interval-based path
searching</em></strong>，它可以将符号状态隔离到不同的语境中。为此，状态可以被任意修剪和重新排序而不影响最终结果的一致性；</li>
<li>Eunomia在GitHub的一个2.5千星的项目（Collections-C）中发现了两个新的漏洞，开发人员已经承认并修补了这些漏洞；</li>
<li>Eunomia是第一个支持Wasm全符号特性的符号执行引擎，并且比其他state-of-the-art表现更好。</li>
</ol>
<h2 id="model">Model</h2>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230619163047.png" /></p>
<p>​
如上图所示，Eunomia将待分析程序的源代码和一个Aes脚本作为输入。给定程序的CFG将被划分为不同区间（详见第3.2.1节），其中每个区间都可以被视为一个独立的上下文。基于分割出的区间，我们提出一种基于区间的路径搜索算法。该算法为状态维持一个优先级队列，这些状态的优先级分数由Aes脚本中提供的局部适配函数来评估。为此，该算法从队列中弹出分数最高的状态和它接下来的一个基本块作为指令模拟器的输入。模拟器根据基本块中的指令对状态进行符号执行，如果有必要进行路径分叉，则返回一个或多个状态。注意，状态将在其相应的上下文下被评估。这样的迭代一直持续到队列中没有候选状态或分析终止。Eunomia最后会输出所有可满足的路径。</p>
<h2 id="webassembly">WebAssembly</h2>
<p>​ 目前最先进的符号执行引擎是一个商业的开源工具，Manticore
[48]，它需要大量的手工工作来对Wasm运行时的API进行建模，以分析Wasm应用程序。为了减轻安全研究人员分析Wasm二进制文件的负担，我们实现了Eunomia作为第一个支持具有约8K
Python3代码的商用现成Wasm应用程序符号执行引擎。</p>
<h3 id="memory-modeling">1. Memory Modeling</h3>
<p>​
WebAssembly采用线性内存作为内存模型。其内存中的数据是原始的比特串，可以被索引和解释。为了模拟通过具体指针的load和store指令，我们采用了[35]提出的映射结构，其中值是由BitVector建模的原始位串，而键是其对应的地址范围。然而，这个模型并不能正确地处理符号指针。</p>
<p>​
为了解决符号指针问题[40]，我们采用完全符号化的内存模型[4]。具体来说，如果加载的地址是一个符号，Eunomia会考虑其所有可能的位置。<u>我们没有像KLEE[7]那样对多个状态进行分叉，这引入了巨大的开销，而是将负担转移给SMT求解器，因为它在解决这种约束时不断地更新[7,
8, 19,
55]</u>。换句话说，我们利用if-then-else（<strong><em>ite</em></strong>）语句来列举所有可能的位置，如下图所示，v代表load操作，内存的范围是（0-5），指针可能指向任意位置，store指令类似。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230619171322.png" style="zoom: 67%;" /></p>
<h3 id="external-functions-emulating">2. External Functions
Emulating</h3>
<p>​
在Runomia引擎中，我们应用基于摘要的技术来处理这个问题。具体来说，有一个WebAssembly接口（WASI）[66]，它定义了一个Wasm二进制文件与外部环境互动的标准接口。WASI主要包括IO相关的函数，如fd_write和fd_open。为此，我们参考了文档，对所有这些与IO相关的函数进行建模，以模拟来自外部环境的响应。此外，我们还总结了C和Go中常见的标准库函数的行为，包括算术运算，以及字符串和内存操作函数。因此，所有对外部的调用都将被拦截。每个状态中的相应字段将根据函数总结进行更新。</p>
<h3 id="smt-query-cache">3. SMT-Query Cache</h3>
<p>​
我们设计了一个用于查询的缓存池来缓解这个问题。从形式上看，我们将SMTquery缓存定义为一个包含所有已解决约束条件的集合𝐶=[𝑐1,
𝑐2, ..., 𝑐𝑛]。对于每个𝑐𝑖∈
𝐶，我们的缓存池都会缓存其结果和所有从中推断出的公理。然后，对于一个给定的约束𝑐𝑠𝑜𝑙𝑣𝑒需要解决，在要求SMT求解器进行求解之前，Eunomia首先按照三个规则查询缓存
𝐶：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230619171633.png" style="zoom: 67%;" /></p>
<p>​ 如果𝑐𝑠𝑜𝑙𝑣𝑒 不符合所有三个规则，Eunomia将𝑐𝑠𝑜𝑙𝑣𝑒
发送给SMT解算器并缓存结果。</p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Symbolic Execution</tag>
        <tag>WASM</tag>
      </tags>
  </entry>
  <entry>
    <title>(论文复现)GREBE-Unveiling Exploitation Potential for Linux Kernel Bugs</title>
    <url>/2023/06/11/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91GREBE-Unveiling-Exploitation-Potential-for-Linux-Kernel-Bugs/</url>
    <content><![CDATA[<h1
id="论文复现grebe-unveiling-exploitation-potential-for-linux-kernel-bugs">(论文复现)GREBE:
Unveiling Exploitation Potential for Linux Kernel Bugs</h1>
<p>源码：<a href="https://github.com/Markakd/GREBE">Markakd/GREBE
(github.com)</a></p>
<span id="more"></span>
<h1 id="analysis">1. Analysis</h1>
<h2 id="关键内核结构确定">1.1 关键内核结构确定</h2>
<h3 id="report来源">1.1.1 <strong>report来源：</strong></h3>
<p>​
syzbot是一个基于syzkaller的自动化fuzzing系统。它能持续不停的运行syzkaller，对linux内核各个分支进行模糊测试，自动报告crash，监控bug的当前状态（是否已被修复等），监测对于bug的patch是否有效，完成发现-报告-复现-修复的整个流程。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230410171230.png" alt="syzbot报告的错误列表" style="zoom:80%;" /></p>
<p>​ 对每个错误，syzbot会发布其对应的报告以及可能存在的POC程序：</p>
<figure>
<img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230615150648.png"
alt="某个错误报告" />
<figcaption aria-hidden="true">某个错误报告</figcaption>
</figure>
<p>​ 如上图所示，syzbot发布了某个错误发生时其对应的寄存器内容，call
trace以及3次crashes（底部）的对应信息，可以看到，该错误提供了一个syz脚本编写的reproducer，也就是Poc程序。</p>
<p>​ syzkaller
repro是用特殊的syzkaller符号编写的程序，它们可以在目标系统上执行。并且，syzkaller
repro可以转化为对应的C语言poc，如果syzbot没有提供C语言的repro，它就无法使用C语言程序来触发该错误（这可能只是因为该错误是由一个竞态条件触发的）。</p>
<p>​ GREBE就是从这些报告中提取call trace进行后续分析。</p>
<h3 id="编译analyzer">1.1.2 编译Analyzer</h3>
<p>​ 安装llvm–10（<a href="https://apt.llvm.org/">LLVM Debian/Ubuntu
packages</a>）：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">#To install a specific version of LLVM:</span>
<span class="token function">wget</span> https://apt.llvm.org/llvm.sh
<span class="token function">chmod</span> +x llvm.sh
<span class="token function">sudo</span> ./llvm.sh <span class="token operator">&lt;</span>version number<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
clang-10被安装在<code>/usr</code>中，故将analyer的make文件修改来指定clang，如下（这里直接指定C与C++编译器）：</p>
<pre class="line-numbers language-makefile" data-language="makefile"><code class="language-makefile">CUR_DIR <span class="token operator">=</span> <span class="token variable">$</span><span class="token punctuation">(</span><span class="token keyword">shell</span> pwd<span class="token punctuation">)</span>
SRC_DIR <span class="token operator">:=</span> <span class="token variable">$</span><span class="token punctuation">&#123;</span>CURDIR<span class="token punctuation">&#125;</span>/src
BUILD_DIR <span class="token operator">:=</span> <span class="token variable">$</span><span class="token punctuation">&#123;</span>CURDIR<span class="token punctuation">&#125;</span>/build

<span class="token keyword">include</span> Makefile.inc

NPROC <span class="token operator">:=</span> <span class="token variable">$</span><span class="token punctuation">&#123;</span>shell nproc<span class="token punctuation">&#125;</span>

build_ka_func <span class="token operator">=</span> \
	<span class="token punctuation">(</span>mkdir -p <span class="token variable">$</span><span class="token punctuation">&#123;</span>2<span class="token punctuation">&#125;</span> \
		&amp;&amp; cd <span class="token variable">$</span><span class="token punctuation">&#123;</span>2<span class="token punctuation">&#125;</span> \
        &amp;&amp;    cmake <span class="token variable">$</span><span class="token punctuation">&#123;</span>1<span class="token punctuation">&#125;</span> \
				-DCMAKE_CXX_COMPILER<span class="token operator">=</span>/home/wx/Shaw/llvm/patched_llvm/bin/clang++\
				-DCMAKE_C_COMPILER<span class="token operator">=</span>/home/wx/Shaw/llvm/patched_llvm/bin/clang\
                -DCMAKE_BUILD_TYPE<span class="token operator">=</span>Release \
                -DCMAKE_CXX_FLAGS_RELEASE<span class="token operator">=</span><span class="token string">"-std=c++14 -fno-rtti -fpic -g"</span> \
		&amp;&amp; make -j<span class="token variable">$</span><span class="token punctuation">&#123;</span>NPROC<span class="token punctuation">&#125;</span><span class="token punctuation">)</span>

<span class="token symbol">all</span><span class="token punctuation">:</span> analyzer

<span class="token symbol">analyzer</span><span class="token punctuation">:</span>
	<span class="token variable">$</span><span class="token punctuation">(</span><span class="token keyword">call</span> build_ka_func, <span class="token variable">$</span><span class="token punctuation">&#123;</span>SRC_DIR<span class="token punctuation">&#125;</span>, <span class="token variable">$</span><span class="token punctuation">&#123;</span>BUILD_DIR<span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 接着修改analyzer/src中的CMakeLists.txt文件来指定LLVM：</p>
<pre class="line-numbers language-cmake" data-language="cmake"><code class="language-cmake"><span class="token keyword">cmake_minimum_required</span><span class="token punctuation">(</span><span class="token property">VERSION</span> <span class="token number">2.8.8</span><span class="token punctuation">)</span>
<span class="token keyword">project</span><span class="token punctuation">(</span>KANALYZER<span class="token punctuation">)</span>
<span class="token comment">#指定LLVM版本</span>
<span class="token keyword">set</span><span class="token punctuation">(</span>LLVM_DIR <span class="token string">"/home/wx/Shaw/llvm/patched_llvm/lib/cmake/llvm"</span><span class="token punctuation">)</span>

<span class="token keyword">find_package</span><span class="token punctuation">(</span>LLVM REQUIRED CONFIG<span class="token punctuation">)</span>

<span class="token keyword">message</span><span class="token punctuation">(</span>STATUS <span class="token string">"Found LLVM <span class="token interpolation"><span class="token punctuation">$&#123;</span><span class="token variable">LLVM_PACKAGE_VERSION</span><span class="token punctuation">&#125;</span></span>"</span><span class="token punctuation">)</span>
<span class="token keyword">message</span><span class="token punctuation">(</span>STATUS <span class="token string">"Using LLVMConfig.cmake in: <span class="token interpolation"><span class="token punctuation">$&#123;</span><span class="token variable">LLVM_DIR</span><span class="token punctuation">&#125;</span></span>"</span><span class="token punctuation">)</span>

<span class="token comment"># Set your project compile flags.</span>
<span class="token comment"># E.g. if using the C++ header files</span>
<span class="token comment"># you will need to enable C++14 support</span>
<span class="token comment"># for your compiler.</span>
<span class="token comment"># Check for C++14 support and set the compilation flag</span>
<span class="token keyword">include</span><span class="token punctuation">(</span>CheckCXXCompilerFlag<span class="token punctuation">)</span>
<span class="token comment">#CHECK_CXX_COMPILER_FLAG("-std=c++14" COMPILER_SUPPORTS_CXX14)</span>
<span class="token comment"># if(COMPILER_SUPPORTS_CXX14)</span>
<span class="token comment"># 	set(CMAKE_CXX_FLAGS "$&#123;CMAKE_CXX_FLAGS&#125; -std=c++14 -fno-rtti -fPIC -Wall")</span>
<span class="token comment"># else()</span>
<span class="token comment"># 	message(STATUS "The compiler $&#123;CMAKE_CXX_COMPILER&#125; has no C++14 support. Please use a different C++ compiler.")</span>
<span class="token comment"># endif()</span>

<span class="token keyword">include_directories</span><span class="token punctuation">(</span><span class="token punctuation">$&#123;</span>LLVM_INCLUDE_DIRS<span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
<span class="token keyword">add_definitions</span><span class="token punctuation">(</span><span class="token punctuation">$&#123;</span>LLVM_DEFINITIONS<span class="token punctuation">&#125;</span><span class="token punctuation">)</span>

<span class="token keyword">add_subdirectory</span> <span class="token punctuation">(</span>lib<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 编译好的analyer位于GREBE/analyzer/build/lib中。</p>
<h3 id="编译内核bitcode文件">1.1.3 编译内核bitcode文件</h3>
<h4 id="安装带补丁的llvm">1.1.3.1 安装带补丁的LLVM</h4>
<p>​
内核bitcode文件指的是待测试的Linux内核，需要将其编译为bc文件后进行分析。</p>
<p>​
这里需要使用llvm-10并且给LLVM编译器打上补丁，以便在调用任何编译器优化通道之前转储比特码。通过这种方式，可以防止编译器优化影响分析的准确性。<u>故这里单独准备一个llvm并安装到特定文件夹中，以避免对全局llvm的影响：</u></p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">git</span> clone https://github.com/llvm/llvm-project
<span class="token builtin class-name">cd</span> llvm-project
<span class="token function">git</span> checkout 5521236a18074584542b81fd680158d89a845fca<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>​ 打补丁：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">patch -p0 <span class="token operator">&lt;</span> WriteBitcode.patch<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230531152450.png" style="zoom: 50%;" /></p>
<p>​ build clang:</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">mkdir</span> build <span class="token operator">&amp;&amp;</span> <span class="token builtin class-name">cd</span> build
cmake -DCMAKE_INSTALL_PREFIX<span class="token operator">=</span>/home/wx/Shaw/llvm/patched_llvm -DLLVM_ENABLE_PROJECTS<span class="token operator">=</span>clang -DCMAKE_BUILD_TYPE<span class="token operator">=</span>Release  -G <span class="token string">"Unix Makefiles"</span> <span class="token punctuation">..</span>/llvm
<span class="token function">sudo</span> <span class="token function">make</span> -j<span class="token variable"><span class="token variable">$(</span>nproc<span class="token variable">)</span></span> <span class="token operator">&amp;&amp;</span> <span class="token function">make</span> <span class="token function">install</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>​
这里通过指定<code>DCMAKE_INSTALL_PREFIX</code>的方式指定其安装位置。注意，LLVM编译后体积非常大，如果在虚拟机中编译需要给足够内存和硬盘空间（80G+）。</p>
<h4 id="编译内核">1.1.3.2 编译内核</h4>
<p>​
编译安装完带有特定补丁的LLVM，接下来就需要使用其来编译Linux内核源码。</p>
<p>​ 以<a
href="https://syzkaller.appspot.com/bug?extid=4b52080e97cde107939d">KASAN:
slab-use-after-free Read in
hfsplus_read_wrapper</a>为例，其附带的.config文件中详细的说明了漏洞的内核版本、config编译选项等信息。</p>
<p>​ 在<a
href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/refs/tags">kernel/git/torvalds/linux.git
- Linux kernel source
tree</a>处下载对应版本的内核源码，解压后先安装编译所需的包：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> <span class="token function">git</span> fakeroot build-essential ncurses-dev xz-utils libssl-dev <span class="token function">bc</span> flex libelf-dev bison<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​
使用如下命令编译,<code>CC</code>和<code>CXX</code>指定为带补丁的clang，由于LLVM-10存在一定bug，这里令<code>LLVM_IAS</code>为0关闭<strong>integrated
assembler</strong>：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">make</span> <span class="token assign-left variable">CC</span><span class="token operator">=</span>/home/wx/Shaw/llvm/patched_llvm/bin/clang <span class="token assign-left variable">CXX</span><span class="token operator">=</span>/home/wx/Shaw/llvm/patched_llvm/bin/clang++ <span class="token assign-left variable">LLVM_IAS</span><span class="token operator">=</span><span class="token number">0</span> all -j<span class="token variable"><span class="token variable">$(</span>nproc<span class="token variable">)</span></span> <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​ analyzer编译完成后，使用如下命令运行：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">python run_analyze.py ./case<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​ 可以在对应case目录下看到对应的解析结果<code>sys.txt</code>：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230615150924.png" style="zoom: 50%;" /></p>
<p>​ 注意：</p>
<blockquote>
<ol type="1">
<li><p><strong>编译analyzer与源码的LLVM一定要相同版本；</strong></p></li>
<li><p><strong>作者给出的LLVM-10是可以成功运行的，但是存在的问题如下：</strong></p>
<ol type="a">
<li><p>目前使用LLVM编译新版本的内核最低要求其版本为11，其无法编译内核；</p></li>
<li><p>如果使用LLVM-11，其编译analyzer存在错误（见文末错误日志）；</p></li>
</ol>
<p><u>故目前作者仓库中给出的代码仅适合版本不高的内核。</u></p></li>
<li><p><strong>部分工作已通过脚本自动化，整个内核的下载+解压+编译已自动化为<code>/analyzer/scripts/get_kernel.py</code>，复现analyzer需要：</strong></p>
<ol type="a">
<li><p>在/analyzer/Testcase/下创建对应case文件夹，命名格式为case+数字；</p></li>
<li><p>将对应report中的.config文件与report文件以名称<code>.config</code>和<code>report</code>复制到case文件夹中；</p></li>
<li><p>修改/analyzer/scripts/下的三个py文件中的<code>CASE_DIR</code>，<code>PATCHED_LLVM</code>和<code>AnalyzerPath</code>变量，使其分别对应Testcase，打过补丁的LLVM和编译好的analyzer；</p></li>
<li><p>按次序运行<code>get_cg.py</code>、<code>get_kernel.py</code>和<code>run_analyze.py</code>，其参数为case序号，例如：</p></li>
</ol></li>
</ol>
<p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">#分析/analyzer/Testcases/case7</span>
python get_cg.py <span class="token number">7</span>
python get_kernel.py <span class="token number">7</span>
python run_analyze.py <span class="token number">7</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></p>
</blockquote>
<h3 id="静态分析代码解析">1.1.3 静态分析代码解析</h3>
<p>​ 见<a
href="https://shawdox.github.io/2023/05/09/%5B代码分析%5DGREBE-Analyzer污点分析代码解析/">(代码分析)GREBE-Analyzer污点分析代码解析
| Shaw (shawdox.github.io)</a></p>
<h1 id="fuzzing">2. Fuzzing</h1>
<h2 id="编译gcc">2.1 编译GCC</h2>
<p>​ 使用作者提供的gcc-9.3.0来编译内核，首先进入其文件夹中编译GCC：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">./contrib/download_prerequisites
<span class="token function">mkdir</span> gcc-bin
<span class="token builtin class-name">export</span> <span class="token assign-left variable">INSTALLDIR</span><span class="token operator">=</span><span class="token variable"><span class="token variable">`</span><span class="token builtin class-name">pwd</span><span class="token variable">`</span></span>/gcc-bin
<span class="token function">mkdir</span> gcc-build
<span class="token builtin class-name">cd</span> gcc-build
<span class="token punctuation">..</span>/configure --prefix<span class="token operator">=</span><span class="token variable">$INSTALLDIR</span> --enable-languages<span class="token operator">=</span>c,c++
<span class="token function">make</span> -j<span class="token variable"><span class="token variable">`</span>nproc<span class="token variable">`</span></span> <span class="token operator">&amp;&amp;</span> <span class="token function">make</span> <span class="token function">install</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​</p>
<h2 id="使用gcc编译内核">2.2 使用GCC编译内核</h2>
<p>​ 在内核代码中运行：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">export</span> <span class="token assign-left variable">OBJ_FILE</span><span class="token operator">=</span><span class="token string">"/home/wx/Shaw/GREBE/analyzer/TestCases/case7/sts.txt"</span>
<span class="token function">make</span> <span class="token assign-left variable">CC</span><span class="token operator">=</span><span class="token string">"/home/wx/Shaw/GREBE/gcc-9.3.0/gcc-bin/bin/gcc"</span> -j<span class="token variable"><span class="token variable">`</span>nproc<span class="token variable">`</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​
注意，内核的.config文件标志了其编译所需的最低版本，故不论是用clang编译还是gcc都需要符合对应版本。</p>
<h2 id="编译fuzzer">2.3 编译Fuzzer</h2>
<p>​
GREBE的Fuzzer是syzkaller的改版，其使用方法与syzkaller基本相同。根据syzkaller官方给出的方法编译，这里集成为/fuzzer/compile_fuzzer.py：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#Author: xiao wu</span>
<span class="token comment">#Time: 2023.6.16</span>
<span class="token comment">#Functionality:</span>
<span class="token comment">#   Complie the modified syzkaller</span>

<span class="token keyword">import</span> sys
<span class="token keyword">import</span> os
<span class="token keyword">assert</span> <span class="token punctuation">(</span><span class="token string">'linux'</span> <span class="token keyword">in</span> sys<span class="token punctuation">.</span>platform<span class="token punctuation">)</span>

GO_DIR <span class="token operator">=</span> <span class="token string">"/home/wx/Shaw/go"</span>
FUZZ_DIR <span class="token operator">=</span> <span class="token string">"/home/wx/Shaw/GREBE/fuzzer"</span>

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"PATH"</span><span class="token punctuation">]</span> <span class="token operator">+=</span> GO_DIR<span class="token operator">+</span><span class="token string">"/bin"</span>
os<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span>FUZZ_DIR<span class="token punctuation">)</span>
os<span class="token punctuation">.</span>system<span class="token punctuation">(</span><span class="token string">"make"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
这里需要在脚本中指定Go语言环境以及fuzzer的位置，Go的版本需要大于等于1.11。编译好的fuzzer位于/fuzzer/bin中。</p>
<h2 id="测试qemu">2.4 测试QEMU</h2>
<p>​
syz-manager需要通过ssh来与ssh-fuzzer通信，后者运行在QEMU中，故在运行syzkaller之前，需要手动测试QEMU连通性：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">qemu-system-x86_64 <span class="token punctuation">\</span>
  -m 2G <span class="token punctuation">\</span>
  -smp <span class="token number">2</span> <span class="token punctuation">\</span>
  -kernel <span class="token variable">$KERNEL</span>/arch/x86/boot/bzImage <span class="token punctuation">\</span>
  -append <span class="token string">"console=ttyS0 root=/dev/sda earlyprintk=serial net.ifnames=0"</span> <span class="token punctuation">\</span>
  -drive <span class="token assign-left variable">file</span><span class="token operator">=</span><span class="token variable">$IMAGE</span>/bullseye.img,format<span class="token operator">=</span>raw <span class="token punctuation">\</span>
  -net user,host<span class="token operator">=</span><span class="token number">10.0</span>.2.10,hostfwd<span class="token operator">=</span>tcp:127.0.0.1:10021-:22 <span class="token punctuation">\</span>
  -net nic,model<span class="token operator">=</span>e1000 <span class="token punctuation">\</span>
  -enable-kvm <span class="token punctuation">\</span>
  -nographic <span class="token punctuation">\</span>
  -pidfile vm.pid <span class="token punctuation">\</span>
  <span class="token operator"><span class="token file-descriptor important">2</span>></span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">|</span> <span class="token function">tee</span> vm.log<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
注意，QEMU需要当前系统支持KVM虚拟化，如果是虚拟机可以直接查找对应处理器设置，如果是物理机需要在BIOS中开启。</p>
<p>​ 成功开启QEMU后另开一个bash，用ssh测试其连通性：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">ssh</span> -i <span class="token variable">$IMAGE</span>/bullseye.id_rsa -p <span class="token number">10021</span> -o <span class="token string">"StrictHostKeyChecking no"</span> root@localhost<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​
如果成果连通则说明QEMU通信部分没有问题，具体配置过程以及相关可能的问题可见：<a
href="https://shawdox.github.io/2023/06/11/%5B技术积累%5DSyzkaller环境配置/">(技术积累)Syzkaller环境配置
| Shaw (shawdox.github.io)</a></p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230616155831.png" /></p>
<p>​</p>
<h2 id="运行fuzzer">2.5 运行fuzzer</h2>
<p>​
直接使用/fuzzer/scripts/run_fuzzer.py脚本即可运行fuzzer，其会自动定位case文件夹并创建对应的config文件，运行syz-manager:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">python run_fuzzer.py <span class="token punctuation">[</span>case_number<span class="token punctuation">]</span>
<span class="token comment">#python run_fuzzer.py 8</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​ 下面是run_fuzzer.py的运行逻辑：</p>
<ol type="1">
<li><p>首先在对应的case文件夹下创建其config文件：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230624193501.png" style="zoom:50%;" /></p>
<ol start="2" type="1">
<li>然后将config文件复制到workdir（如上图）中：</li>
</ol></li>
</ol>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230624192531.png" style="zoom: 67%;" /></p>
<p>​
如上图fuzzer源码所示，注意到poc是默认位于workdir中的，<strong><u>故在使用命令时仅传入poc文件名称即可</u></strong>（此次复现中，poc.txt默认位于对应的case文件夹中，这里run_fuzzer.py脚本会在运行syz-manager前将对应的poc.txt复制过来）。</p>
<pre><code>3. 运行syz-manager:</code></pre>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">syz-manager -config /home/wx/Shaw/GREBE/analyzer/TestCases/case8/syzconfig.cfg --auxiliary poc.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​
再次注意，由于fuzzer源码限制，使用<code>--auxiliary</code>标志传入poc.txt只能传入该名称，并且poc.txt文件应该位于workdir文件夹下。</p>
<p>​ 运行即可得到对应结果：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230624193915.png" /></p>
<h2 id="原理解析">2.6 原理解析</h2>
<blockquote>
<p>​ 对gcc和kernel都做了修改，使其在编译内核时可以将特定的basic
block的16bit地址替换为一个magic_number，这样在代码覆盖率反馈中就可以识别哪些basic
block属于关键内核对象。</p>
</blockquote>
<h3 id="syzkaller原理">2.6.1 Syzkaller原理</h3>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230701154658.png" /></p>
<p>​ 如上图所示，具体描述见：<a
href="https://github.com/google/syzkaller/blob/master/docs/internals.md">syzkaller/docs/internals.md
at master · google/syzkaller · GitHub</a></p>
<h3 id="syscall-descriptions">2.6.2 Syscall descriptions</h3>
<p>​
Syzkaller使用声明性的系统调用描述来控制程序（系统调用的序列），举例：</p>
<pre class="line-numbers language-none"><code class="language-none">open(file filename, flags flags[open_flags], mode flags[open_mode]) fd
read(fd fd, buf buffer[out], count len[buf])
close(fd fd)
open_mode &#x3D; S_IRUSR, S_IWUSR, S_IXUSR, S_IRGRP, S_IWGRP, S_IXGRP, S_IROTH, S_IWOTH, S_IXOTH<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
翻译后的系统调用描述被用来生成、变异、执行、最小化、序列化和反序列化程序，程序指的是有着一系列具体参数的系统调用，例如：</p>
<pre class="line-numbers language-c" data-language="c"><code class="language-c">r0 <span class="token operator">=</span> <span class="token function">open</span><span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token punctuation">(</span><span class="token number">0x7f0000000000</span><span class="token punctuation">)</span><span class="token operator">=</span><span class="token string">"./file0"</span><span class="token punctuation">,</span> <span class="token number">0x3</span><span class="token punctuation">,</span> <span class="token number">0x9</span><span class="token punctuation">)</span>
<span class="token function">read</span><span class="token punctuation">(</span>r0<span class="token punctuation">,</span> <span class="token operator">&amp;</span><span class="token punctuation">(</span><span class="token number">0x7f0000000000</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">42</span><span class="token punctuation">)</span>
<span class="token function">close</span><span class="token punctuation">(</span>r0<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>​
在实际操作中，syzkaller使用类似AST的内存表示法，由prog/prog.go中定义的Call和Arg值组成。这种表示法被用来分析、生成、变异、最小化、验证等程序。内存中的表示法可以转换为文本形式，以存储在磁盘语料库中，并展示给人类，等等。还有另一种程序的二进制表示法（称为exec），它更简单，不包含丰富的类型信息（不可逆），用于实际执行（解释）程序。</p>
<h3 id="coverage">2.6.3 Coverage</h3>
<h4 id="syzkaller-coverage">2.6.3.1 Syzkaller Coverage</h4>
<p>​
覆盖率通过追踪<code>coverage points</code>的方式获取，<code>coverage points</code><u>一般通过编译器插入对象代码中。</u><code>coverage points</code>一般指一个基本块或者CFG边（取决于编译器，例如clang默认是cfg边而gcc是基本块），<u>编译器在翻译转换和优化代码的过程中插入<code>coverage points</code></u>。</p>
<p>​
因此，覆盖率与源代码的关系可能很差。例如，你可能会在一个非覆盖行之后看到一个覆盖行，或者你可能在你期望看到的地方没有看到覆盖点，反之亦然（如果编译器拆分基本块，或将控制流结构变成没有控制流的条件动作，就可能发生这种情况。）。</p>
<blockquote>
<p>https://github.com/google/syzkaller/blob/master/docs/coverage.md#syz-cover这里可以参照官网的syz-cover来从原始覆盖数据中生成报告。</p>
</blockquote>
<p>​
Syzkaller使用<code>kcov</code>来从Linux内核中获取代码覆盖率，<code>kcov</code>会输出每个被运行的基本块的地址，然后syzkaller会用objdump、nm、addr2line、readelf等<code>binutils</code>工具来将该地址映射到源码对应的行数。</p>
<h4 id="grebe-coverage">2.6.3.2 GREBE Coverage</h4>
<ul>
<li><strong>GREBE-GCC</strong></li>
</ul>
<p>​ <a
href="https://github.com/whoismissing/grebe-gcc/commit/172f8e6694c41c5c4cf532d86dc4edaaafaad6ed?diff=split">add
grebe code changes · whoismissing/grebe-gcc@172f8e6
(github.com)</a>这里可以看到GREBE对GCC9.3.0版本做了怎样的修改，其修改了两个文件：<code>sancov.c</code>和<code>sanitizer.def</code>。</p>
<p>​ 首先，GREBE在sancov.c中定义了存储关键对象的结构struct_maps:</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230702170621.png" style="zoom:67%;" /></p>
<p>​
定义了init_structs()函数，用于将从analyzer生成的内核关键对象读取到st_map-&gt;st数组中：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230702170920.png" style="zoom:67%;" /></p>
<p>​ 定义了process_tree()函数，用于匹配关键内核对象：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230702171220.png" style="zoom:67%;" /></p>
<p>​ 定义了find_st()函数，用于从tree中找出符合关键内核对象的子树：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230702171333.png" style="zoom:67%;" /></p>
<p>​ 然后在sancov_pass()函数中插入以下代码：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230702171718.png" style="zoom:67%;" /></p>
<p>​ 这段代码的大致作用是选择对basic
block做插桩的函数，<code>BUILT_IN_SANITIZER_COV_TRACE_PC</code>是kcov原本的插桩函数，<code>BUILT_IN_SANITIZER_OBJ_COV_TRACE_PC</code>是GREBE实现的插桩函数，二者都在对应内核的kernel/kcov.c文件中实现，二者的区别如下：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230702172042.png" /></p>
<p>​
其中，<code>_RET_IP_</code>代表当前函数的返回地址，可以发现，GREBE实现的<code>BUILT_IN_SANITIZER_OBJ_COV_TRACE_PC</code>相较于<code>BUILT_IN_SANITIZER_COV_TRACE_PC</code>就是将返回地址截取了前32位。</p>
<p>​
回到sancov_pass()，其遍历每个基本块，对于非空基本块判断其是否是关键内核对象，如果是则将<code>fndecl</code>设置为<code>BUILT_IN_SANITIZER_OBJ_COV_TRACE_PC</code>，否则设置为<code>BUILT_IN_SANITIZER_COV_TRACE_PC</code>。然后代码根据<code>fndecl</code>设置一个gcall，将其插入到代码块之前。</p>
<p>​
最后，在sanitizer.def文件中，将自己实现的__sanitizer_obj_cov_trace_pc()定义为sanitizer函数:</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230702173055.png" style="zoom:67%;" /></p>
<ul>
<li><strong>GREBE-Syzkaller</strong></li>
</ul>
<h1 id="错误日志">3. 错误日志</h1>
<ul>
<li><p><strong>问题1：编译llvm时报错：</strong></p>
<blockquote>
<p>Killed (program cc1plus) Please submit a full bug report, with
preprocessed source if appropriate. See <a
href="file:///usr/share/doc/gcc-5/README.Bugs"
class="uri">file:///usr/share/doc/gcc-5/README.Bugs</a> for
instructions.
lib/DebugInfo/CodeView/CMakeFiles/LLVMDebugInfoCodeView.dir/build.make:494:
recipe for target
'lib/DebugInfo/CodeView/CMakeFiles/LLVMDebugInfoCodeView.dir/EnumTables.cpp.o'
failed make[2]: ***
[lib/DebugInfo/CodeView/CMakeFiles/LLVMDebugInfoCodeView.dir/EnumTables.cpp.o]
Error 4 CMakeFiles/Makefile2:6769: recipe for target
'lib/DebugInfo/CodeView/CMakeFiles/LLVMDebugInfoCodeView.dir/all' failed
make[1]: ***
[lib/DebugInfo/CodeView/CMakeFiles/LLVMDebugInfoCodeView.dir/all] Error
2</p>
</blockquote></li>
</ul>
<p><strong>解决方法：</strong></p>
<p>编译时虚拟机的内存与硬盘空间太小，在服务器上跑即可成功编译。</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230615151312.png" /></p>
<ul>
<li><p><strong>问题2：在编译analyzer时报错：</strong></p>
<blockquote>
<p>error: no member named 'hasNPredecessorsOrMore' in
'llvm::BasicBlock'</p>
</blockquote></li>
<li><p><strong>解决方法：</strong></p>
<p>查看错误报告发现是LLVM的BasicBlock没找到对应的子数据结构<code>hasNPredecessorsOrMore</code>，首先在LLVM官网查找对应数据结构定义：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230413144329.png" style="zoom: 25%;" /></p>
<p>​
可以看到在<code>BasicBlock.cpp</code>的319行有该数据结构的定义，查找本机上下载的llvm源码：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230413144452.png" style="zoom: 50%;" /></p>
<p>​ 查找对应源码是可以发现对应数据结构定义的：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230413144554.png" style="zoom:50%;" /></p>
<p>​
阅读报错信息，发现编译时自动搜索到了以前安装的llvm-6.0旧版本，手动更改路径，上述问题解决，但是发现仍旧报错。</p>
<p>​ 在llvm的github项目中找到了一样错误：<a
href="https://github.com/google/autofdo/issues/87">Build failure when
targeting LLVM 11.0 · Issue #87 · google/autofdo
(github.com)</a>。<strong><u>可以基本确定这是LLVM-11的问题，换回LLVM-10版本即可解决</u></strong>。</p></li>
<li><p><strong>问题3：在编译analyzer时报错：</strong></p>
<blockquote>
<p>ld: cannot find -lz</p>
</blockquote>
<p><strong>解决方法：</strong></p></li>
</ul>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> zlib1g zlib1g-dev<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<ul>
<li><p><strong>问题4：在使用analyer时报错：</strong></p>
<blockquote>
<p>/home/wx/Shaw/GREBE/analyzer/build/lib/analyzer: error loading file
'./case/linux-bitcode/lib/dump_stack.c.bc'</p>
</blockquote>
<p><strong>解决方法：</strong></p>
<p>问题定位到KAMain.cc文件使用ParseIR()函数解析bc文件：</p>
<pre class="line-numbers language-c" data-language="c"><code class="language-c">std<span class="token operator">::</span>unique_ptr<span class="token operator">&lt;</span>Module<span class="token operator">></span> M <span class="token operator">=</span> <span class="token function">parseIRFile</span><span class="token punctuation">(</span>InputFilenames<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> Err<span class="token punctuation">,</span> <span class="token operator">*</span>LLVMCtx<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span>M <span class="token operator">==</span> <span class="token constant">NULL</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
     <span class="token function">errs</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> argv<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">&lt;&lt;</span> <span class="token string">": error loading file '"</span> <span class="token operator">&lt;&lt;</span> InputFilenames<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">&lt;&lt;</span> <span class="token string">"'\n"</span><span class="token punctuation">;</span>
     <span class="token keyword">continue</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p><strong>问题5：编译内核（部分版本）时报错：</strong></p>
<blockquote>
<p>error New address family defined, please update secclass_map.</p>
</blockquote>
<p><strong>解决方法：</strong></p>
<p><a
href="https://blog.csdn.net/zhangpengfei991023/article/details/109672491">编译错误
error New address family defined, please update
secclass_map.解决-CSDN博客</a></p></li>
<li><p><strong>问题6：编译内核（部分版本）时报错：</strong></p>
<blockquote>
<p><strong>passing argument 1 to restrict-qualified parameter aliases
with argument 5 [-Werror=restrict]</strong></p>
<p>cc1: all warnings being treated as errors</p>
</blockquote>
<p><strong>解决方法：</strong></p>
<p>对<code>tools/lib/str_error_r.c</code>打如下补丁：</p>
<p><a
href="https://lore.kernel.org/all/b5d9ea0f-3a3e-ec87-df76-10be4bd72b90@redhat.com/">Re:
New -Werror=restrict error with incremental gcc - Laura Abbott
(kernel.org)</a></p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/image-20230607224055657.png" /></p></li>
<li><p><strong>问题7：无法使用py脚本（在其中使用export）改变环境变量</strong></p>
<p><strong>解决方法：</strong></p>
<p><a
href="https://stackoverflow.com/questions/1506010/how-to-use-export-with-python-on-linux">How
to use export with Python on Linux - Stack Overflow</a></p></li>
</ul>
<h2 id="reference">Reference</h2>
<ul>
<li>GREBE:
<ul>
<li><a
href="https://github.com/Markakd/GREBE/tree/master/analyzer">GREBE/analyzer
at master · Markakd/GREBE (github.com)</a></li>
<li><a
href="https://github.com/Markakd/LLVM-O0-BitcodeWriter/tree/master">Markakd/LLVM-O0-BitcodeWriter:
patch for LLVM to generate O0 bitcode (github.com)</a></li>
</ul></li>
<li>LLVM:
<ul>
<li><a href="https://apt.llvm.org/">LLVM Debian/Ubuntu packages</a></li>
</ul></li>
<li>Kernel:
<ul>
<li><a href="https://phoenixnap.com/kb/build-linux-kernel">How To Build
Linux Kernel {Step-By-Step} | phoenixNAP KB</a></li>
<li><a
href="https://android.googlesource.com/platform/external/syzkaller/+/HEAD/docs/linux/setup_ubuntu-host_qemu-vm_x86-64-kernel.md">Setup:
Ubuntu host, QEMU vm, x86-64 kernel (googlesource.com)</a></li>
<li><a
href="https://www.kernel.org/doc/html/latest/dev-tools/kcov.html">KCOV:
code coverage for fuzzing — The Linux Kernel documentation</a></li>
<li><a
href="https://www.kernel.org/doc/html/latest/translations/zh_CN/dev-tools/testing-overview.html#id3">内核测试指南
— The Linux Kernel documentation</a></li>
</ul></li>
<li>Syzkaller：
<ul>
<li><a
href="https://github.com/google/syzkaller/blob/master/docs/internals.md">syzkaller/docs/internals.md
at master · google/syzkaller · GitHub</a></li>
<li><a
href="https://github.com/google/syzkaller/blob/master/docs/linux/setup_ubuntu-host_qemu-vm_x86-64-kernel.md">syzkaller/docs/linux/setup_ubuntu-host_qemu-vm_x86-64-kernel.md
at master · google/syzkaller · GitHub</a></li>
<li><a
href="https://shawdox.github.io/2023/06/11/%5B技术积累%5DSyzkaller环境配置/">(技术积累)Syzkaller环境配置
| Shaw (shawdox.github.io)</a></li>
<li><a
href="https://davejingtian.org/2017/06/01/understanding-kcov-play-with-fsanitize-coveragetrace-pc-from-the-user-space/#:~:text=kcov%20is%20a%20kernel%20feature%20used%20to%20support,patched%20to%20enable%20this%20feature%20where%20is%20propriate.">Understanding
kcov – play with -fsanitize-coverage=trace-pc from the user space |
davejingtian.org</a></li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Vulnerability</tag>
        <tag>AEG</tag>
      </tags>
  </entry>
  <entry>
    <title>(技术积累)Syzkaller环境配置</title>
    <url>/2023/06/11/%E3%80%90%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF%E3%80%91Syzkaller%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<h1 id="syzkaller环境配置">Syzkaller环境配置</h1>
<blockquote>
<p>Syzkaller内核模糊测试工具环境搭建，简单测试</p>
<p>项目地址：<a
href="https://github.com/google/syzkaller">google/syzkaller: syzkaller
is an unsupervised coverage-guided kernel fuzzer (github.com)</a></p>
</blockquote>
<span id="more"></span>
<h1 id="install">Install</h1>
<blockquote>
<p>gcc 6.10 or later;</p>
<p>go 1.20 or later;</p>
</blockquote>
<ul>
<li><p>C compiler with coverage support</p></li>
<li><p>Linux kernel with coverage additions</p></li>
<li><p>Virtual machine or a physical device</p></li>
<li><p>syzkaller itself</p>
<p>更新apt并安装相关编译器：</p></li>
</ul>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt</span> update
<span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> <span class="token function">make</span> gcc flex bison libncurses-dev libelf-dev libssl-dev<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​ 下载内核源码：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">git</span> clone --branch v6.2 git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git <span class="token variable">$KERNEL</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​ 内核编译常用的配置参数：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">#文本对话式，基于命令行的一种配置,其会在命令行一个个询问具体配置选择</span>
<span class="token function">make</span> config
<span class="token comment">#基于图形界面配置</span>
<span class="token function">make</span> menuconfig
<span class="token comment">##将当前系统存在的.config 文件拷贝至源码目录，并询问新符号如何设置</span>
<span class="token function">make</span> oldconfig
<span class="token comment">#将当前系统存在的.config 文件拷贝至源码目录，新符号设为默认值，不提示</span>
<span class="token function">make</span> olddefconfig
<span class="token comment">#基于当前config和加载的模块创建一个配置</span>
<span class="token function">make</span> localmodconfig
<span class="token comment">#基于QT的配置工具</span>
<span class="token function">make</span> xconfig
<span class="token comment">#使用系统中的默认符号值创建一个config</span>
<span class="token function">make</span> defconfig
<span class="token comment">#基于GTK+的配置工具</span>
<span class="token function">make</span> gconfig
<span class="token comment">#为kvm客户内核支持启用其他选项</span>
<span class="token function">make</span> kvm_guest.config<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 进入源码目录：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">make</span> olddefconfig<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​ 手动在.config文件中添加编译选项（一定去掉原来的注释）：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># Coverage collection.</span>
<span class="token assign-left variable">CONFIG_KCOV</span><span class="token operator">=</span>y

<span class="token comment"># Debug info for symbolization.</span>
<span class="token assign-left variable">CONFIG_DEBUG_INFO_DWARF4</span><span class="token operator">=</span>y

<span class="token comment"># Memory bug detector</span>
<span class="token assign-left variable">CONFIG_KASAN</span><span class="token operator">=</span>y
<span class="token assign-left variable">CONFIG_KASAN_INLINE</span><span class="token operator">=</span>y

<span class="token comment"># Required for Debian Stretch and later</span>
<span class="token assign-left variable">CONFIG_CONFIGFS_FS</span><span class="token operator">=</span>y
<span class="token assign-left variable">CONFIG_SECURITYFS</span><span class="token operator">=</span>y

<span class="token comment">#这个一定要加上</span>
<span class="token assign-left variable">CONFIG_CMDLINE_BOOL</span><span class="token operator">=</span>y
<span class="token assign-left variable">CONFIG_CMDLINE</span><span class="token operator">=</span><span class="token string">"net.ifnames=0"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 再次make：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">make</span> olddefconfig<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​ 编译：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">make</span> -j<span class="token variable"><span class="token variable">`</span>nproc<span class="token variable">`</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​ 编译好的内核文件夹内应出现：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/image-20230415160954894.png" style="zoom:80%;" /></p>
<p>​
<code>debootstrap</code>是debian/ubuntu下的一个工具，用来构建一套基本的系统(根文件系统)。生成的目录符合Linux文件系统标准(FHS)，即包含了/boot、/etc、/bin、/usr等等目录，但它比发行版本的Linux体积小很多，当然功能也没那么强大，因此，只能说是“基本的系统”。</p>
<p>​ 这里以创建一个Debian Bullseye版本的Linux镜像为例：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> <span class="token function">debootstrap</span>

<span class="token function">mkdir</span> <span class="token variable">$IMAGE</span>
<span class="token builtin class-name">cd</span> <span class="token variable">$IMAGE</span>/
<span class="token function">wget</span> https://raw.githubusercontent.com/google/syzkaller/master/tools/create-image.sh -O create-image.sh
<span class="token function">chmod</span> +x create-image.sh
./create-image.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 创建好后对应文件夹下应该有一个<code>bullseye.img</code>文件。</p>
<p>​
如果Host使用的是虚拟机，需要在设置处开启虚拟化引擎（若是物理机则需要在BIOS上开启）：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/image-20230415170223601.png" style="zoom:80%;" /></p>
<p>​ 测试qemu：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">qemu-system-x86_64 <span class="token punctuation">\</span>
  -m 2G <span class="token punctuation">\</span>
  -smp <span class="token number">2</span> <span class="token punctuation">\</span>
  -kernel /home/wx/SyzKaller/linux/arch/x86/boot/bzImage <span class="token punctuation">\</span>
  -append <span class="token string">"console=ttyS0 root=/dev/sda earlyprintk=serial net.ifnames=0"</span> <span class="token punctuation">\</span>
  -drive <span class="token assign-left variable">file</span><span class="token operator">=</span>/home/wx/SyzKaller/image/bullseye.img,format<span class="token operator">=</span>raw <span class="token punctuation">\</span>
  -net user,host<span class="token operator">=</span><span class="token number">10.0</span>.2.10,hostfwd<span class="token operator">=</span>tcp:127.0.0.1:10021-:22 <span class="token punctuation">\</span>
  -net nic,model<span class="token operator">=</span>e1000 <span class="token punctuation">\</span>
  -enable-kvm <span class="token punctuation">\</span>
  -nographic <span class="token punctuation">\</span>
  -pidfile vm.pid <span class="token punctuation">\</span>
  <span class="token operator"><span class="token file-descriptor important">2</span>></span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">|</span> <span class="token function">tee</span> vm.log<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 另开一个终端，测试ssh连接：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">ssh</span> -i <span class="token variable">$IMAGE</span>/bullseye.id_rsa -p <span class="token number">10021</span> -o <span class="token string">"StrictHostKeyChecking no"</span> root@localhost<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​
测试完成后就可以关闭qemu（直接poweroff），下面进行syzkaller安装：</p>
<p>​ 安装go：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">#如果显示地址不可达</span>
<span class="token comment">#在站长工具处查询dl.google.com</span>
<span class="token comment">#找到可以Ping的IP</span>
<span class="token comment">#修改本机hosts文件即可</span>
<span class="token function">wget</span> https://go.dev/dl/go1.20.3.linux-amd64.tar.gz
<span class="token comment">#如果之前安装过go，一定要先删除原来的</span>
<span class="token function">tar</span> -C /usr/local -xzf go1.20.3.linux-amd64.tar.gz
<span class="token comment">#添加环境变量</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">GOROOT</span><span class="token operator">=</span><span class="token variable"><span class="token variable">`</span><span class="token builtin class-name">pwd</span><span class="token variable">`</span></span>/go
<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token variable">$GOROOT</span>/bin:<span class="token environment constant">$PATH</span>
<span class="token comment">#测试</span>
go version
<span class="token comment">#-> go version go1.20.3 linux/amd64</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 安装syzkaller:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">git</span> clone https://github.com/google/syzkaller
<span class="token builtin class-name">cd</span> syzkaller
<span class="token comment">#安装之前一定要保证gcc和go的版本正确</span>
<span class="token function">make</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="crash-test">Crash Test</h1>
<p>​
在$linux/fs/open.c文件中的chmod_common（）添加一段代码，使得当连续两次<code>chmod</code>调用的<code>mode</code>参数值为0时会产生空指针解引用异常：</p>
<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">static</span> <span class="token class-name">umode_t</span> old_mode <span class="token operator">=</span> <span class="token number">0xffff</span><span class="token punctuation">;</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>old_mode <span class="token operator">==</span> <span class="token number">0</span> <span class="token operator">&amp;&amp;</span> mode <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        path <span class="token operator">=</span> <span class="token constant">NULL</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
old_mode <span class="token operator">=</span> mode<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 重新编译Linux内核，设置Syzkaller配置文件如下：</p>
<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">&#123;</span>
	<span class="token property">"target"</span><span class="token operator">:</span> <span class="token string">"linux/amd64"</span><span class="token punctuation">,</span>
	<span class="token property">"http"</span><span class="token operator">:</span> <span class="token string">"127.0.0.1:56741"</span><span class="token punctuation">,</span>
	<span class="token property">"workdir"</span><span class="token operator">:</span> <span class="token string">"/home/wx/SyzKaller/syzkaller/workdir"</span><span class="token punctuation">,</span>
	<span class="token property">"kernel_obj"</span><span class="token operator">:</span> <span class="token string">"/home/wx/SyzKaller/linux/"</span><span class="token punctuation">,</span>
	<span class="token property">"image"</span><span class="token operator">:</span> <span class="token string">"/home/wx/SyzKaller/image/bullseye.img"</span><span class="token punctuation">,</span>
	<span class="token property">"sshkey"</span><span class="token operator">:</span> <span class="token string">"/home/wx/SyzKaller/image/bullseye.id_rsa"</span><span class="token punctuation">,</span>
	<span class="token property">"syzkaller"</span><span class="token operator">:</span> <span class="token string">"/home/wx/SyzKaller/syzkaller"</span><span class="token punctuation">,</span>
	<span class="token property">"enable_syscalls"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"chmod"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
	<span class="token property">"procs"</span><span class="token operator">:</span> <span class="token number">8</span><span class="token punctuation">,</span>
	<span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"qemu"</span><span class="token punctuation">,</span>
	<span class="token property">"vm"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
		<span class="token property">"count"</span><span class="token operator">:</span> <span class="token number">4</span><span class="token punctuation">,</span>
		<span class="token property">"kernel"</span><span class="token operator">:</span> <span class="token string">"/home/wx/SyzKaller/linux/arch/x86/boot/bzImage"</span><span class="token punctuation">,</span>
		<span class="token property">"cpu"</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
		<span class="token property">"mem"</span><span class="token operator">:</span> <span class="token number">2048</span>
	<span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li><code>enable_syscalls</code>选项表明了仅对其中的系统调用做fuzzing，如果其中的某个系统调用依赖其他调用，syzkaller会提醒你。</li>
<li>同理，<code>disable_syscalls</code>选项表明了不对哪些系统调用fuzzing。</li>
</ul>
<p>​ 执行：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">syz-manager --config config.json<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/image-20230416210618032.png" style="zoom:80%;" /></p>
<p>​
在对应的web<code>127.0.0.1:56741</code>上就可以看到当前fuzzing的情况：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/image-20230416210718938.png" style="zoom:67%;" /></p>
<p>​ 可以看到已经抓到了一个内核Crash：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/image-20230416210814372.png" style="zoom: 67%;" /></p>
<p>​ <a
href="https://www.collabora.com/news-and-blog/blog/2020/04/17/using-syzkaller-to-detect-programming-bugs-in-linux/">Using
syzkaller, part 2: Detecting programming bugs in the Linux kernel
(collabora.com)</a>这个Blog详细说明了网站里各个模块的作用。</p>
<p>​ 查看报告：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/image-20230416210930515.png" /></p>
<p>​ 打开目录workdir/carsh/···/log0：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/image-20230416211532552.png" style="zoom:80%;" /></p>
<h1 id="problem-summary">Problem Summary</h1>
<ul>
<li><p><strong>问题1：在使用ssh连接qemu时无法连接，报错：</strong></p>
<p><strong>“ssh_exchange_identification: Connection closed by remote
host”</strong></p></li>
</ul>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/image-20230415200044323.png" style="zoom:80%;" /></p>
<p>​ <strong>解决方法：</strong></p>
<p>​ 查看QEMU虚拟机内sshd服务状态，发现其服务没有开启：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/image-20230415200148895.png" style="zoom:80%;" /></p>
<p>​ 尝试使用命令<code>service sshd start</code>，无效。</p>
<p>​ 尝试google，发现如下帖子：<a
href="https://groups.google.com/g/syzkaller/c/n8BDOc5cXds">ssh : Why
sshd does not start on qemu booting (google.com)</a></p>
<figure>
<img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/image-20230415202522042.png"
alt="这也能遇到自己老师hh" />
<figcaption aria-hidden="true">这也能遇到自己老师hh</figcaption>
</figure>
<p>​
故重新检查linux源码的config后发现，由于手动修改后没有删除原来对应的“xxx
not
set”注释，导致当时的修改在后续<code>make olddefconfig</code>时又被改回去了。</p>
<p>​ 重新修改.config文件，重新编译，创建qemu虚拟机，再次尝试登陆：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/image-20230415211857811.png" style="zoom:80%;" /></p>
<p>​
<u>这里的问题其实就出现在没有去掉注释，在.config文件中注释也会被扫描分析。</u></p>
<ul>
<li><p><strong>问题二：sshd服务错误定位</strong></p>
<p><strong>解决方法：</strong></p>
<ol type="1">
<li><code>/usr/bin/sshd -T</code>命令可以显示出sshd配置文件的错误之处；</li>
<li>在ssh连接时使用命令-v/-vv可以查看调试信息</li>
</ol></li>
<li><p><strong>问题三：开启syzkaller后一直没有虚拟机连接</strong></p>
<p><strong>解决方法：</strong>在使用命令<code>./bin/syz-manager -config=my.cfg</code>后面加上<code>-debug</code>，查看调试信息后发现qemu虚拟机显示<strong>”Failed
to start Raise network
interfaces“</strong>，查找官方文档后发现需要在内核config上加上：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token assign-left variable">CONFIG_CMDLINE_BOOL</span><span class="token operator">=</span>y
<span class="token assign-left variable">CONFIG_CMDLINE</span><span class="token operator">=</span><span class="token string">"net.ifnames=0"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
</ul>
<h1 id="reference">Reference</h1>
<ul>
<li><a href="https://github.com/google/syzkaller">google/syzkaller:
syzkaller is an unsupervised coverage-guided kernel fuzzer
(github.com)</a></li>
<li><a
href="https://github.com/google/syzkaller/blob/master/docs/setup.md">syzkaller/setup.md
at master · google/syzkaller (github.com)</a></li>
<li><a
href="https://fuchsia.googlesource.com/third_party/syzkaller/+/usb-fuzzer/docs/linux/setup.md">How
to set up syzkaller (googlesource.com)</a></li>
<li><a href="https://groups.google.com/g/syzkaller/c/n8BDOc5cXds">ssh :
Why sshd does not start on qemu booting (google.com)</a></li>
<li><a
href="https://github.com/hardenedlinux/Debian-GNU-Linux-Profiles/blob/master/docs/harbian_qa/fuzz_testing/test.c">Debian-GNU-Linux-Profiles/test.c
at master · hardenedlinux/Debian-GNU-Linux-Profiles
(github.com)</a></li>
<li><a
href="http://pwn4.fun/2019/10/29/Syzkaller-Fuzz-Android-Kernel/">Syzkaller
Fuzz Android Kernel | BruceFan's Blog (pwn4.fun)</a></li>
</ul>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Vulnerability</tag>
        <tag>AEG</tag>
      </tags>
  </entry>
  <entry>
    <title>(技术积累)Klee安装使用</title>
    <url>/2023/05/30/%E3%80%90%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF%E3%80%91Klee%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h1 id="klee安装使用">Klee安装使用</h1>
<blockquote>
<p>Linux系统下著名符号执行工具Klee的安装使用 <span id="more"></span></p>
</blockquote>
<h2 id="prerequisites">Prerequisites</h2>
<ol type="1">
<li>删除旧版本（非官方发行版的Docker）</li>
</ol>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token keyword">for</span> <span class="token for-or-select variable">pkg</span> <span class="token keyword">in</span> docker.io docker-doc docker-compose podman-docker containerd runc<span class="token punctuation">;</span> <span class="token keyword">do</span> <span class="token function">sudo</span> <span class="token function">apt-get</span> remove <span class="token variable">$pkg</span><span class="token punctuation">;</span> <span class="token keyword">done</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<ol start="2" type="1">
<li>设置GPG key和仓库，确保下载源</li>
</ol>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">#Update the apt package index and install packages to allow apt to use a repository over HTTPS:</span>
<span class="token function">sudo</span> <span class="token function">apt-get</span> update
<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> ca-certificates <span class="token function">curl</span> gnupg

<span class="token comment">#Add Docker’s official GPG key:</span>
<span class="token function">sudo</span> <span class="token function">install</span> -m 0755 -d /etc/apt/keyrings
<span class="token function">curl</span> -fsSL https://download.docker.com/linux/ubuntu/gpg <span class="token operator">|</span> <span class="token function">sudo</span> gpg --dearmor -o /etc/apt/keyrings/docker.gpg
<span class="token function">sudo</span> <span class="token function">chmod</span> a+r /etc/apt/keyrings/docker.gpg

<span class="token comment">#Set up the repository:</span>
<span class="token builtin class-name">echo</span> <span class="token punctuation">\</span>
  <span class="token string">"deb [arch="</span><span class="token variable"><span class="token variable">$(</span>dpkg --print-architecture<span class="token variable">)</span></span><span class="token string">" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
  "</span><span class="token variable"><span class="token variable">$(</span><span class="token builtin class-name">.</span> /etc/os-release <span class="token operator">&amp;&amp;</span> <span class="token builtin class-name">echo</span> <span class="token string">"<span class="token variable">$VERSION_CODENAME</span>"</span><span class="token variable">)</span></span><span class="token string">" stable"</span> <span class="token operator">|</span> <span class="token punctuation">\</span>
  <span class="token function">sudo</span> <span class="token function">tee</span> /etc/apt/sources.list.d/docker.list <span class="token operator">></span> /dev/null<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ol start="3" type="1">
<li>安装Docker：</li>
</ol>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">#install</span>
<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
<span class="token comment">#test</span>
<span class="token function">sudo</span> docker run hello-world<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="install">Install</h2>
<p>​ 这里使用现成的Docker环境，直接pull即可：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> docker pull klee/klee<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230530145106.png" style="zoom:50%;" /></p>
<p>​ 运行：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">docker run --rm -ti --ulimit<span class="token operator">=</span><span class="token string">'stack=-1:-1'</span> klee/klee<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​
其中，<code>--rm</code>表明容器停止，即使用命令<code>docker stop</code>后直接删除容器；<code>-ti</code>表明为容器重新分配一个伪输入终端（-t）并且以交互模式运行容器(-i)；<code>--ulimit</code>表明将栈设置为无限大。</p>
<p>​ 进入容器后检查Klee：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230530150453.png" style="zoom: 67%;" /></p>
<h2 id="klee">Klee</h2>
<h3 id="small-function">1. Small Function</h3>
<blockquote>
<p>测试一个简单函数get_sign()</p>
</blockquote>
<p>​ 以<code>get_sign</code>函数为例：</p>
<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token comment">//First KLEE tutorial: testing a small function</span>

<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">"klee/klee.h"</span></span>

<span class="token keyword">int</span> <span class="token function">get_sign</span><span class="token punctuation">(</span><span class="token keyword">int</span> x<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
  <span class="token keyword">if</span> <span class="token punctuation">(</span>x <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span>
     <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
  <span class="token keyword">if</span> <span class="token punctuation">(</span>x <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">)</span>
     <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>
  <span class="token keyword">else</span> 
     <span class="token keyword">return</span> <span class="token number">1</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span> 

<span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
  <span class="token keyword">int</span> a<span class="token punctuation">;</span>
  <span class="token function">klee_make_symbolic</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>a<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"a"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">return</span> <span class="token function">get_sign</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 首先将其编译为bc文件：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">clang -I <span class="token punctuation">..</span>/<span class="token punctuation">..</span>/include -emit-llvm -c -g -O0 -Xclang -disable-O0-optnone get_sign.c<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​
其中，<code>-I+&lt;dir&gt;</code>表明添加搜索路径，用于引入头文件klee/klee.h；<code>-c</code>表明只进行预处理、编译和汇编；<code>-Xclang+&lt;arg&gt;</code>用于给clang编译器传递参数，这里禁止了优化。</p>
<p>​ 运行klee：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">klee get_sign.bc<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230530154204.png" style="zoom: 67%;" /></p>
<p>​
由上图可见klee探索了程序中的3条路径并生成了3个测试样例，并生成了两个目录：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230530154657.png" style="zoom: 67%;" /></p>
<p>​
其中<code>klee-out-0</code>是输出结果目录，<code>klee-last</code>是其符号链接，每次都链接到最新的测试输出中，其包含：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230530154911.png" style="zoom:67%;" /></p>
<p>​
klee生成的测试样例都以<code>.ktest</code>结尾，借助<code>ktest-tool</code>工具来查看：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230530155115.png" style="zoom:67%;" /></p>
<p>​ 使用libkleeRuntest工具手动复现测试样例：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">export</span> <span class="token assign-left variable">LD_LIBRARY_PATH</span><span class="token operator">=</span>path-to-klee-build-dir/lib/:<span class="token variable">$LD_LIBRARY_PATH</span>
gcc -I <span class="token punctuation">..</span>/<span class="token punctuation">..</span>/include -L path-to-klee-build-dir/lib/ get_sign.c -lkleeRuntest
<span class="token assign-left variable">KTEST_FILE</span><span class="token operator">=</span>klee-last/test000001.ktest ./a.out
<span class="token builtin class-name">echo</span> <span class="token variable">$?</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230530155831.png" style="zoom:67%;" /></p>
<p>​
如图所示，最后一个测试样例返回255（-1）的原因是-1转换为0-255范围内的有效退出代码值。</p>
<p>​ 可见，klee通过对C代码插装，并接受bc输入的方式进行符号执行测试。</p>
<h3 id="test-gnu-coreutils">2. Test GNU coreutils</h3>
<h4 id="安装coreutils-wllvm">2.1 安装coreutils &amp; WLLVM</h4>
<p>​ 下载GNU coreutils源码，这里选用6.11版本（可以用其他版本）：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">#下载</span>
<span class="token function">wget</span> https://ftp.gnu.org/gnu/coreutils/coreutils-6.11.tar.gz
<span class="token comment">#解压</span>
<span class="token function">tar</span> -zxvf coreutils-6.11.tar.gz <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 配置并编译coreutils：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">#如果该版本的coreutils有Bug,就使用如下补丁</span>
<span class="token function">wget</span> http://web.cs.ucla.edu/classes/winter16/cs35L/assign/coreutils.diff
patch -p0 <span class="token operator">&lt;</span> coreutils.diff
<span class="token comment">#编译</span>
<span class="token function">mkdir</span> obj-gcov
<span class="token builtin class-name">cd</span> obj-gcov
<span class="token punctuation">..</span>/configure --disable-nls <span class="token assign-left variable">CFLAGS</span><span class="token operator">=</span><span class="token string">"-g -fprofile-arcs -ftest-coverage"</span>
<span class="token function">make</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
编译好的文件位于coreutils/src目录下。通过编译加上<code>CFLAGS="-g -fprofile-arcs -ftest-coverage"</code>配置选项，使其支持gcov，每次你运行它时其就会生成一个.gcda文件表明其运行覆盖率如何，例如：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">rm</span> -f *.gcda <span class="token comment"># Get rid of any stale gcov files</span>
./echo**

<span class="token function">ls</span> -l echo.gcda
<span class="token builtin class-name">:</span><span class="token string">'
-rw-rw-r-- 1 klee klee 896 Nov 21 22:00 echo.gcda
'</span>
gcov <span class="token builtin class-name">echo</span>
<span class="token builtin class-name">:</span><span class="token string">'
File '</span><span class="token punctuation">..</span>/<span class="token punctuation">..</span>/src/echo.c<span class="token string">'
Lines executed:24.27% of 103
Creating '</span>echo.c.gcov<span class="token string">'

File '</span><span class="token punctuation">..</span>/<span class="token punctuation">..</span>/src/system.h<span class="token string">'
Lines executed:0.00% of 3
Creating '</span>system.h.gcov<span class="token string">'
'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 安装WLLVM：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip3 <span class="token function">install</span> --upgrade wllvm
<span class="token builtin class-name">export</span> <span class="token assign-left variable">LLVM_COMPILER</span><span class="token operator">=</span>clang<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​ 使用WLLVM编译coreutils：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">mkdir</span> obj-llvm
<span class="token builtin class-name">cd</span> obj-llvm
<span class="token assign-left variable">CC</span><span class="token operator">=</span>wllvm <span class="token punctuation">..</span>/configure --disable-nls <span class="token assign-left variable">CFLAGS</span><span class="token operator">=</span><span class="token string">"-g -O1 -Xclang -disable-llvm-passes -D__NO_STRING_INLINES  -D_FORTIFY_SOURCE=0 -U__OPTIMIZE__"</span>
<span class="token function">make</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 这里：</p>
<ul>
<li><code>-fprofile-arcs -ftest-coverage</code>表明使用gcov对即将用klee测试的文件插桩，这里舍弃了这个flag；</li>
<li><code>-O1 -Xclang -disable-llvm-passes</code>表明不使用优化，由于LLVM5.0以上版本的O0优化会影响Klee本身的优化措施，故这里使用O1优化并禁止所有LLVM
Pass运行；</li>
<li><code>D__NO_STRING_INLINES</code>表明不使用内联字符串；<code>-D_FORTIFY_SOURCE=0</code>表明不使用fortify安全技术，<u>因为其可能会替换现有的函数（fprintf
-&gt;
__fprintf_chk）导致Klee无法对其建模而将其视为外部函数</u>；<code>-U__OPTIMIZE__</code>取消
<code>__OPTIMIZE__</code> 的宏定义，禁用编译器所有优化。</li>
</ul>
<p>​
可以通过<code>extract-bc</code>命令从生成的可执行文件中提取bitcode：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">find</span> <span class="token builtin class-name">.</span> -executable -type f <span class="token operator">|</span> <span class="token function">xargs</span> -I <span class="token string">'&#123;&#125;'</span> extract-bc <span class="token string">'&#123;&#125;'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h4 id="使用klee测试文件">2.2 使用Klee测试文件</h4>
<p>​ 接下来就可以使用klee运行bc文件：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">klee --libc<span class="token operator">=</span>uclibc --posix-runtime ./cat.bc --version<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<ul>
<li><code>--libc=uclibc</code>指定了Klee外部函数库，其中定义了程序可能调用的外部函数；</li>
<li><code>--posix-runtime</code>指定 KLEE 使用 POSIX
标准库作为程序的运行时环境；</li>
<li><code>--version</code>是传递给cat命令的参数。</li>
</ul>
<p>​
当Klee指定了uclibc和POSIX，它就会替换程序的main()函数为库中的klee_init_env()函数，这个函数用于支持符号参数的构建。</p>
<figure>
<img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230601145325.png"
alt="运行结果" />
<figcaption aria-hidden="true">运行结果</figcaption>
</figure>
<p>​ 分析以上WARNING：</p>
<ul>
<li><code>*undefined reference to function: ___ctype_b_loc*</code>表明<code>__ctype_b_loc</code>函数未定义；</li>
<li><code>*executable has module level assembly (ignoring)*</code>表明一些被编译进应用程序的文件有内嵌汇编语句，Klee无法分析，故跳过（来自uClibc，这里安全）；</li>
<li><code>*calling external: getpagesize()*</code>表明调用的函数未定义。在这种情况下，Klee尝试调用该函数的本地版本，如果它存在的话。这有时是安全的，只要该函数不写入任何程序内存或试图处理符号值。例如，getpagesize()只是返回一个常数。</li>
</ul>
<p>​ 下面尝试用符号化输入测试echo：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">klee --optimize --libc<span class="token operator">=</span>uclibc --posix-runtime ./echo.bc --sym-arg <span class="token number">3</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​ 使用如下命令查看统计结果：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">klee-stats klee-last
------------------------------------------------------------------------
<span class="token operator">|</span>  Path   <span class="token operator">|</span>  Instrs<span class="token operator">|</span>  Time<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token operator">|</span>  ICov<span class="token punctuation">(</span>%<span class="token punctuation">)</span><span class="token operator">|</span>  BCov<span class="token punctuation">(</span>%<span class="token punctuation">)</span><span class="token operator">|</span>  ICount<span class="token operator">|</span>  TSolver<span class="token punctuation">(</span>%<span class="token punctuation">)</span><span class="token operator">|</span>
------------------------------------------------------------------------
<span class="token operator">|</span>klee-last<span class="token operator">|</span>   <span class="token number">64546</span><span class="token operator">|</span>     <span class="token number">0.15</span><span class="token operator">|</span>    <span class="token number">22.07</span><span class="token operator">|</span>    <span class="token number">14.14</span><span class="token operator">|</span>   <span class="token number">19943</span><span class="token operator">|</span>       <span class="token number">62.97</span><span class="token operator">|</span>
------------------------------------------------------------------------<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 其中：</p>
<ul>
<li><strong>ICov</strong>为LLVM指令覆盖率；</li>
<li><strong>BCov</strong>为分支覆盖率；</li>
</ul>
<p>​
可以看到覆盖率并不高，其中一个原因是由于这些数字是用比特码文件中的所有指令或分支来计算的，包括很多可能是不可执行的库代码。故对于这种情况使用–optimize优化去除死代码会更好：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">klee --optimize --libc<span class="token operator">=</span>uclibc --posix-runtime ./echo.bc --sym-arg <span class="token number">3</span>
klee-stats klee-last
------------------------------------------------------------------------
<span class="token operator">|</span>  Path   <span class="token operator">|</span>  Instrs<span class="token operator">|</span>  Time<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token operator">|</span>  ICov<span class="token punctuation">(</span>%<span class="token punctuation">)</span><span class="token operator">|</span>  BCov<span class="token punctuation">(</span>%<span class="token punctuation">)</span><span class="token operator">|</span>  ICount<span class="token operator">|</span>  TSolver<span class="token punctuation">(</span>%<span class="token punctuation">)</span><span class="token operator">|</span>
------------------------------------------------------------------------
<span class="token operator">|</span>klee-last<span class="token operator">|</span>   <span class="token number">33991</span><span class="token operator">|</span>     <span class="token number">0.13</span><span class="token operator">|</span>    <span class="token number">30.16</span><span class="token operator">|</span>    <span class="token number">21.91</span><span class="token operator">|</span>    <span class="token number">8339</span><span class="token operator">|</span>       <span class="token number">80.66</span><span class="token operator">|</span>
------------------------------------------------------------------------<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
可以看到各项覆盖率都高了一些，klee执行的更快，执行的代码指令更少。</p>
<h4 id="可视化klee进程">2.3 可视化klee进程</h4>
<p>​
<code>KCachegrind</code>是一个优秀的可视化工具，可以直接用apt安装。</p>
<p>​
<img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230601162143.png" style="zoom:67%;" /></p>
<blockquote>
<p>PS:</p>
<p>​
Kcachegrind是一个图形化工具，如果是通过windows使用ssh服务连接Linux系统，则需要在windows端安装X11服务并在Linux端修改ssh配置使其可以允许X11服务。</p>
<p>相关参考：<a href="https://zhuanlan.zhihu.com/p/66075449">X11
forwarding，Windows与Linux结合的最佳开发环境【编程环境优化篇】 - 知乎
(zhihu.com)</a></p>
</blockquote>
<h4 id="结果分析">2.4 结果分析</h4>
<p>​ 可以通过<code>ktest-tool</code>工具查看每个单独的测试样例：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ ktest-tool klee-last/test000001.ktest
ktest <span class="token function">file</span> <span class="token builtin class-name">:</span> <span class="token string">'klee-last/test000001.ktest'</span>
args       <span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token string">'./echo.bc'</span>, <span class="token string">'--sym-arg'</span>, <span class="token string">'3'</span><span class="token punctuation">]</span>
num objects: <span class="token number">2</span>
object    <span class="token number">0</span>: name: <span class="token string">'arg0'</span>
object    <span class="token number">0</span>: size: <span class="token number">4</span>
object    <span class="token number">0</span>: data: <span class="token string">'<span class="token entity" title="\x00">\x00</span><span class="token entity" title="\x00">\x00</span><span class="token entity" title="\x00">\x00</span><span class="token entity" title="\x00">\x00</span>'</span>
object    <span class="token number">1</span>: name: <span class="token string">'model_version'</span>
object    <span class="token number">1</span>: size: <span class="token number">4</span>
object    <span class="token number">1</span>: data: <span class="token string">'<span class="token entity" title="\x01">\x01</span><span class="token entity" title="\x00">\x00</span><span class="token entity" title="\x00">\x00</span><span class="token entity" title="\x00">\x00</span>'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 可以使用<code>ktest-reply</code>工具来复现：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">klee-replay ./echo <span class="token punctuation">..</span>/<span class="token punctuation">..</span>/obj-llvm/src/klee-last/*.ktest<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="binary">3. Binary</h3>
<p>​</p>
<h2 id="reference">Reference</h2>
<ul>
<li>Install:
<ul>
<li><a
href="https://docs.docker.com/engine/install/ubuntu/#prerequisites">Prerequisites
| Docker Documentation</a></li>
<li><a href="https://docs.docker.com/engine/install/ubuntu/">Install
Docker Engine on Ubuntu | Docker Documentation</a></li>
<li><a href="http://klee.github.io/docker/">Docker · KLEE</a></li>
<li><a
href="https://blog.csdn.net/weixin_39998006/article/details/99680522">docker
run 参数详解_-CSDN博客</a></li>
<li><a
href="https://github.com/travitch/whole-program-llvm">travitch/whole-program-llvm:
A wrapper script to build whole-program LLVM bitcode files
(github.com)</a></li>
</ul></li>
<li>Tutorial:
<ul>
<li><a href="http://klee.github.io/docs/files/">Files · KLEE</a></li>
<li><a href="http://klee.github.io/tutorials/">Tutorials · KLEE</a></li>
<li><a href="http://klee.github.io/tutorials/testing-coreutils/">Testing
Coreutils · KLEE</a></li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>Project</category>
      </categories>
      <tags>
        <tag>Klee</tag>
        <tag>Symbolic Execution</tag>
      </tags>
  </entry>
  <entry>
    <title>(论文阅读)Automated WebAssembly Function Purpose Identification With Semantics-Aware Analysis</title>
    <url>/2023/05/29/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Automated-WebAssembly-Function-Purpose-Identification-With-Semantics-Aware-Analysis/</url>
    <content><![CDATA[<h1
id="automated-webassembly-function-purpose-identification-with-semantics-aware-analysis">Automated
WebAssembly Function Purpose Identification With Semantics-Aware
Analysis</h1>
<blockquote>
<p><strong>会议：</strong>WWW'23（International World Wide Web
Conference，CCF-A）</p>
<p><strong>作者：</strong>Alan Romano、Weihang Wang（USC）</p>
<p><strong>时间：</strong>2023.4</p>
</blockquote>
<h1 id="abstract">ABSTRACT</h1>
<p>​
WebAssembly是最近建立的一个网络标准，用于提高网络应用的性能。该标准定义了一种二进制代码格式，作为各种语言的编译目标，如C、C++和Rust。该标准还定义了一种可读性的文本表示法，不过，WebAssembly模块很难被人类读者解释，无论他们的经验水平如何。这使得理解和维护任何现有的WebAssembly代码变得困难。因此，第三方WebAssembly模块需要被开发者隐含地信任，因为验证功能本身可能是不可行的。</p>
<p>​
为此，我们构建了<strong>WASPur</strong>，一个自动识别WebAssembly函数功能的工具。为了构建这个工具，我们首先构建了一个广泛的WebAssembly样本集，代表了WebAssembly的状态。其次，我们分析数据集，并确定所收集的WebAssembly模块的不同使用情况。我们利用WebAssembly模块的数据集来构建模块中功能的语义感知的中间表示（IR）。我们对函数IR进行编码，用于机器学习分类器，我们发现这个分类器可以预测一个给定函数与已知命名函数的相似性，其准确率为88.07%。我们希望我们的工具能够检查优化和减化的WebAssembly模块，这些模块去除了函数名称和大多数其他语义标识符。</p>
<span id="more"></span>
<h1 id="知识背景">知识背景</h1>
<p>​ <strong>WebAssembly阅读困难的原因：</strong></p>
<ol type="1">
<li>WebAssembly只有四种数字数据类型，i32、i64、f32和f64，这使得例如字符串操作和加密散列等操作的指令序列变得十分相似，难以阅读;</li>
<li>其次，它的堆栈机设计使得在某个位置推导出一个变量的值很困难。必须从一个给定的位置追踪堆栈，以确定特定代码位置的计算值。</li>
</ol>
<p>​
由于许多第三方模块交付时并没有源码，故确定该WASM模块的功能就需要手工验证。有以前的工作研究了WASM样本本身的目的，但是没有工作帮助开发者理解WASM模块的函数功能。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/image-20230526213539080.png" style="zoom: 67%;" /></p>
<p>​
WebAssembly模块有一个明确的结构定义。每个模块由10个部分组成，分别描述模块的不同组成部分：</p>
<table>
<thead>
<tr class="header">
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Types</td>
<td>所有函数参数和返回值类型</td>
</tr>
<tr class="even">
<td>Functions</td>
<td>所有WASM函数的类型、使用的局部变量和WASM指令组成的函数体</td>
</tr>
<tr class="odd">
<td>Tables</td>
<td>间接调用目标函数表</td>
</tr>
<tr class="even">
<td>Memory</td>
<td>本模块线性内存部分属性</td>
</tr>
<tr class="odd">
<td>Globals</td>
<td>该模块使用的全局变量</td>
</tr>
<tr class="even">
<td>Elements</td>
<td>用于初始化指定函数表的函数索引</td>
</tr>
<tr class="odd">
<td>Data</td>
<td>用于初始化指定的线性内存部分的字节序列</td>
</tr>
<tr class="even">
<td>Start</td>
<td>模块初始化函数</td>
</tr>
<tr class="odd">
<td>Import</td>
<td>从JS导入，并在WASM调用的函数</td>
</tr>
<tr class="even">
<td>Exports</td>
<td>导出到JS中被调用的函数</td>
</tr>
</tbody>
</table>
<p>​ 本工作的分类方法聚焦于<strong><em>Functions</em></strong>节。</p>
<h2 id="贡献">贡献</h2>
<ol type="1">
<li>我们提出了一个中间表示法（IR）来抽象WebAssembly应用程序的底层语义，以实现语法弹性分析；</li>
<li>构建了从真实网站、火狐插件、Chrome拓展和Github仓库中爬取的WASM样本数据集；</li>
<li>对WASM样本综合分析，将行为目的分为12类；</li>
<li>开发自动分类工具WASPur，以实现WASM函数的自动打标签，准确率达到88.07%。</li>
</ol>
<h2 id="模型方法">模型方法</h2>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230528195748.png" style="zoom: 67%;" /></p>
<h3 id="生成中间表示ir">1. 生成中间表示IR</h3>
<p>​ 对虚拟栈操作的抽象：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230528202454.png" style="zoom:67%;" /></p>
<h3 id="抽象处理">2. 抽象处理</h3>
<p>​
首先构建每个函数的内部cfg（iCFG）,再通过call调用连接各个iCFG构建程序间ICFG。为每个函数建立一个单独的ICFG，所需的函数被用作图形遍历的起始点。call的深度被限制为2，其防止了递归函数无限调用。</p>
<h3 id="分类器">3. 分类器</h3>
<ul>
<li><strong>模型：</strong>全连接层神经网络；</li>
<li><strong>输入：</strong>抽象序列（每个函数的）；</li>
<li><strong>输出：</strong>189个unit（对应人工分析的189个不同function类）</li>
</ul>
<h3 id="数据集">4. 数据集</h3>
<ul>
<li><p><strong>来源：</strong>Alexa、Chrome extensions、Firefox
add-ons、GitHub repositories。</p></li>
<li><p><strong>构建的数据集：</strong></p>
<ul>
<li><p><strong><em>Dataset for WebAssembly Binaries</em></strong></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230529111145.png" style="zoom:50%;" /></p>
<p>上表显示了从四个source爬取的：<u>样本总数</u>、<u>使用WASM的样本数</u>、<u>WASM程序数</u>。故这里共有6769个WASM样本，由于一个程序可能有多个WASM模块，这里共有1829个独立模块。</p></li>
<li><p><strong><em>Dataset for WebAssembly GitHub
Repositories</em></strong></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230529111746.png" style="zoom:50%;" /></p>
<p>从112M的Github仓库中定位了435个与WASM有关的仓库，上表表明了这些仓库的功能目的。</p></li>
</ul></li>
<li><p><strong>Module-level 分类</strong>：</p>
<p>首先将样本分为12类：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230529112849.png" style="zoom:50%;" /></p>
<p>对于每一类，下表给出其位置、文件大小信息：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230529113357.png" /></p>
<p>下表给出了每个类的特征数和特征例子：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230529114040.png" /></p></li>
<li><p><strong>Function-level 分类</strong>：</p>
<p>由于WASM在编译时会采用最小化函数名称的机制，会损失很多函数名称信息。这里从至少两个独立模块中出现的函数中创建标签，将类似malloc,
_malloc,
和memory.allocate的函数名称压缩为一个单独的标签组malloc。这里得到了189个不同功能的函数类别。</p></li>
</ul>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>WASM</tag>
      </tags>
  </entry>
  <entry>
    <title>(论文阅读)Binary-level Directed Fuzzing for Use-After-Free Vulnerabilities</title>
    <url>/2023/05/25/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Binary-level%20Directed%20Fuzzing%20for%20Use-After-Free%20Vulnerabilities/</url>
    <content><![CDATA[<h2
id="论文阅读binary-level-directed-fuzzing-for-use-after-free-vulnerabilities">(论文阅读)Binary-level
Directed Fuzzing for Use-After-Free Vulnerabilities</h2>
<blockquote>
<p><strong>时间：</strong>2020</p>
<p><strong>作者：</strong>Manh-Dung
Nguyen（巴黎萨克雷大学CEA）、Sébastien Bardin、Richard Bonichon</p>
<p><strong>会议：</strong>RAID</p>
<p><strong>开源：</strong>[1]https://github.com/strongcourage/uafuzz
;[2]https://github.com/strongcourage/uafbench</p>
</blockquote>
<h2 id="abstract">ABSTRACT</h2>
<p>​ Directed fuzzing聚焦于通过利用额外信息（bug stack
trace、补丁或者有风险的操作）来测试代码的特定部分，其重要的应用场景包括漏洞复现、补丁测试以及对静态分析报告的验证。尽管Directed
fuzzing最近受到了很多关注，但诸如UAF等难以检测的漏洞仍然没有得到很好的解决，特别是在二进制层面。</p>
<p>​ <strong><u>我们提出了UAFUZZ，第一个针对UAF漏洞的二进制级别directed
greybox
fuzzer。</u></strong>该技术包括了一个针对UAF特性设计的Fuzzer，一个轻量级的代码插装（code
instrumentation）工具和一个高效的bug处理步骤。</p>
<p>​
对<u>真实案例中的bug复现进行的实验评估表明</u>，UAFUZZ在故障检测率、暴露时间和bug处理方面明显优于最先进的Directed
fuzzer。<u>UAFUZZ在补丁测试中也被证明是有效的</u>，在Perl、GPAC和GNU
Patch等程序中发现了30个新的错误（7个CVEs）。最后，我们为社区提供了一个专门用于UAF的大型模糊测试基准，该基准建立在真实代码和真实bug之上。</p>
<span id="more"></span>
<h2 id="问题背景">问题背景</h2>
<blockquote>
<p><strong>CGF：</strong> <em>Coverage-based Greybox Fuzzing</em></p>
<p><strong>DGF：</strong> <em>Directed Greybox Fuzzing</em></p>
<p><strong>PUT：</strong> <em>program under test</em></p>
<p><strong>Regression Bug：</strong> <em>When some bugs are found to be
occurring as a result of the bug fix, those are known as regression
bugs.</em></p>
<p><strong>Bug stack traces：</strong> sequences of function calls at
the time a bug is triggered（KASAN、ASan、VALGRIND）</p>
<p><strong>Noninterference Bug：</strong>
原本应该隔离的部分发生了影响，例如多线程的静态条件漏洞</p>
<p><strong>Flaky bug：</strong>
不可靠的bug，其结果难以可靠的复现，其根本原因难以分析</p>
</blockquote>
<p>​ Directed fuzzing的应用场景：</p>
<ul>
<li>bug reproduction，漏洞复现[25, 28, 42, 61]</li>
<li>patch testing，补丁测试[25, 51, 59]</li>
<li>static analysis report verification，静态分析报告验证[31, 49]</li>
</ul>
<h3 id="触发特定漏洞的必要性">1. 触发特定漏洞的必要性</h3>
<p>​ 基于应用场景的不同，在Directed fuzzing中目标位置会被bug stack
traces、补丁文件或者静态分析报告所引导。<strong>本文聚焦于漏洞复现</strong>，由于信息缺失和用户隐私问题，通常只有54.9%的错误报告可以被重现，所以特别需要这种方法。即使错误报告中提供了PoC，开发人员在修复的过程中可能仍然需要考虑错误的所有情况，以避免regression
bug或不完整的修复。在这种情况下，<u>提供更多的触发错误的输入，对促进和加快bug的修复过程非常重要</u>。</p>
<h3 id="目前fuzzer的局限">2. 目前fuzzer的局限</h3>
<p>​ <u>目前的grey box
fuzzer（无论是否directed）仍然很难找到复杂的漏洞</u>，例如UAF、Noninterference或flaky漏洞，这些漏洞需要满足非常具体的属性的漏洞触发路径。例如，OSSFUZZ
或最近的grey box fuzzer 只发现了少量的UAF。</p>
<h3 id="uaf">3. UAF</h3>
<p>​
UAF漏洞相比其他类型的漏洞缺乏解决的技术，并且危害十分严重，如数据损坏、信息泄露和Dos攻击。并且要检测UAF还需要面对两个问题：</p>
<ol type="1">
<li><p><strong>状态空间的复杂性：</strong>一个UAF的产生需要经过<code>分配(alloc)</code>-<code>释放(free)</code>然后<code>利用(use)</code>三个顺序过程，在时间和空间上都有限制；</p></li>
<li><p><strong>隐性性状：</strong>UAF漏洞经常没有例如segmentation
fault的显性表现，单纯观察崩溃行为的fuzzer就无法发现这种错误。<u>如今流行的内存检测工具：ASan、VALGRIND由于其开销过大不能在fuzzing中使用。</u></p>
<p>（ps：如果是仅仅漏洞复现，可以利用其产生的报告信息，参考<a
href="https://shawdox.github.io/2023/04/10/%5B论文阅读%5DGREBE-Unveiling-Exploitation-Potential-for-Linux-Kernel-Bugs/">[GREBE|
shawdox.github.io]</a>）</p></li>
</ol>
<p>​ 目前的state-of-the-art：AFLGO和HAWKEYE没法处理UAF并且成本过高。</p>
<h2 id="创新点贡献">创新点&amp;贡献</h2>
<p>​ 下表是UAFUZZ与state-of-the-art的比较：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230509225227.png" style="zoom:50%;" /></p>
<p>​ 创新点与贡献：<strong>针对UAF的Directed
Fuzzing，比state-of-the-art的方法准确率更高，速度更快；开源发布了针对UAF漏洞的测试benchmark，包括了从公开软件中提取的30个真实的Bug</strong>。</p>
<h2 id="方法">方法</h2>
<figure>
<img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230510123625.png"
alt="Overview of UAFUZZ" />
<figcaption aria-hidden="true">Overview of UAFUZZ</figcaption>
</figure>
<h3 id="bug-trace-flattening">1. Bug Trace Flattening</h3>
<p>​ <code>Bug Trace Flattening</code>指重构从report中提取的bug
trace，以下图的report为例:</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230510164151.png" style="zoom: 67%;" /></p>
<p>​ 将上述report生成的3个call trace合并为一个call
tree，并将其按照UAF漏洞的执行顺序（i.e
alloc-&gt;free-&gt;use）的顺序生成分支：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230510164412.png" style="zoom:67%;" /></p>
<p>​ 如上图所示，该树状图共有三个分支，分别对应了stack trace for the
Alloc、stack trace for the free和stack trace for the bad
USE的调用路径。按照0到6的顺序遍历该树，就是UAF漏洞的执行过程，漏洞在6处触发。</p>
<p>​ 0 → 1 → 2 → 3(n<sub>alloc</sub>) → 4(n<sub>free</sub>) → 5 →
6(n<sub>use</sub>)</p>
<h3 id="seed-selection">2. Seed Selection</h3>
<h4 id="similarity-metrics">2.1 Similarity Metrics</h4>
<p>​ s代表某个input，T代表report中的目标UAF bug trace，t(s, T
)代表s与T的相似度。这里定义了4个测试标准：</p>
<ul>
<li><strong>Target prefix t<sub>P</sub>(s, T
)：</strong>s与T的轨迹覆盖前缀（遇到第一个不同就停止）；</li>
<li><strong>UAF prefix t<sub>3TP</sub>(s, T
)：</strong>s与T的UAF轨迹覆盖前缀（只关注trace中的UAF事件）；</li>
<li><strong>Target bag t<sub>B</sub>(s, T
)：</strong>s与T的轨迹覆盖数；</li>
<li><strong>UAF bag t<sub>3TB</sub>(s, T
)：</strong>s与T的UAF轨迹覆盖数。</li>
</ul>
<p>​
以下图为例，其需要在buf数组的前三个字节填充“AFU”来触发UAF漏洞，当s='ABUA'时，上述的四个标准值分别为：t<sub>P</sub>(s,
T ) = 2，t<sub>3TP</sub>(s, T ) = 1，t<sub>B</sub>(s, T ) =
3，t<sub>3TB</sub>(s, T ) = 2。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230511142942.png" style="zoom:50%;" /></p>
<p>​ 将四个metrics结合，得到P-3TP-B： <span class="math display">\[
t_{P-3TP-B} = &lt;t_{P}(s,T),t_{3TP}(s,T),t_{B}(s,T)&gt;
\]</span> ​
上述式子代表，衡量Similarity的标准首先是轨迹前缀覆盖，若其相同则次要考虑UAF轨迹的前缀，最后考虑轨迹的整体覆盖率。这样做兼顾了精度与广度，UAFUZZ的默认种子衡量算法使用P-3TP-B。</p>
<h4 id="seed-selection-algorithm">2.2 Seed Selection Algorithm</h4>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230510165352.png" alt="Seed Selection Algorithm" style="zoom: 67%;" /></p>
<p>​ 如上图所示，种子的选择策略是：要么其与report中的目标bug trace
T有着更高的重合度，要么其可以提升代码覆盖率。</p>
<h4 id="uaf-based-seed-distance">2.3 UAF-based Seed Distance</h4>
<p>​
AFL使用原始CFG图，图中边的权重都是1；HAWKEYE通过修改边的权重来引导fuzzer。</p>
<p>​
如何引导Fuzzer按某种顺序依次运行？<u>这里定义了三个集合：R<sub>alloc,</sub>
R<sub>free</sub>,
和R<sub>use</sub>，分别表示可以执行alloc、free、use操作的函数集合。根据函数调用关系图来判断，例如，如果fa
∈ R<sub>alloc</sub>并且fb ∈ R <sub>free</sub> ∩
R<sub>use</sub>，则从a到b的调用则可能触发UAF漏洞。</u>如下图红色的边。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230511163739.png" style="zoom:50%;" /></p>
<p>​
确定了f<sub>a</sub>-&gt;f<sub>b</sub>的调用边，通过减少其边的权重来让fuzzer更容易执行它，在本工作的实验中，使用如下权重（β=0.25）：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230511163709.png" style="zoom:50%;" /></p>
<h4 id="cut-edge-coverage-metric">2.4 Cut-edge Coverage Metric</h4>
<p>​
<u>由于对基本块插装的成本过高，HAWKEYE使用对函数插装的方式来跟踪某个种子的运行轨迹（function
level）。</u></p>
<p>​ 本工作提出cut-edge coverage metric，在<strong>edge
level</strong>上衡量<strong>关键节点</strong>的程序运行轨迹，该方法是basic
block level和function level的平衡。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230525104634.png" style="zoom: 67%;" /></p>
<p>ps：</p>
<ul>
<li><p>cut-edge：两个basic block（source和sink）之间的cut
edge就是存在一条通过这条edge的路径，可以从source到达sink；</p></li>
<li><p>algorithm：算法3、4说明了如何在函数间/函数内部计算识别cut
edge；</p></li>
<li><p>想法：遍历更多cut-edge，更少non-cut
edge更容易达到目标轨迹。</p></li>
</ul>
<h4 id="power-schedule">2.5 Power Schedule</h4>
<p>​ Power Schedule结合了上述三种方法（<strong>target similarity metric
t<sub>P</sub>(s, T )</strong>、<strong>UAF-based seed distance d(s, T
)</strong>和<strong>cut-edge coverage metric e<sub>s</sub>(s, T
)</strong>）。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230525110851.png" style="zoom:50%;" /></p>
<p>​</p>
<h4 id="postprocess-and-bug-triage">2.6 Postprocess and Bug Triage</h4>
<p>​
UAF漏洞发生时一般并不会伴随显式的崩溃，故要检测某个种子是否触发了UAF，需要将其送入bug
triager中（例如VALGRIND）检测。因此，当fuzzer生成了大量的种子时，这么做成本很高。</p>
<p>​ 但由于本工作的<strong>target similarity
metric</strong>可以检测种子的指令路径是否包含了三个UAF关键事件，故bug
triager只需要检测包含这些事件的种子即可。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230525145138.png" style="zoom:50%;" /></p>
<p>​ 代码实现基于AFL和QEMU。</p>
<h2 id="测试结果">测试结果</h2>
<blockquote>
<p>baseline：AFL-QEMU</p>
<p>compare：AFLGO、HAWKEYE</p>
<p>benchmark：自行构建</p>
</blockquote>
<h2 id="reference">REFERENCE</h2>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Fuzzing</tag>
        <tag>UAF</tag>
      </tags>
  </entry>
  <entry>
    <title>(代码分析)GREBE-Analyzer污点分析代码解析</title>
    <url>/2023/05/09/%E3%80%90%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90%E3%80%91GREBE-Analyzer%E6%B1%A1%E7%82%B9%E5%88%86%E6%9E%90%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<h1
id="代码分析grebe-analyzer污点分析代码解析">(代码分析)GREBE-Analyzer污点分析代码解析</h1>
<blockquote>
<p><strong>Code：</strong><a
href="https://github.com/Markakd/GREBE">Markakd/GREBE
(github.com)</a></p>
<p><strong>Target：</strong>GREBE/analyzer <span id="more"></span> ## 一、get_cg.py
&amp; run_analyze.py</p>
</blockquote>
<h2 id="二analyzersrclib">二、analyzer/src/lib</h2>
<blockquote>
<p>前置知识：</p>
<ul>
<li><p>GREBE</p></li>
<li><p>LLVM IR</p></li>
<li><p>LLVM Pass(legacy manager &amp; new manager)</p></li>
<li><p>C++面向对象</p></li>
<li><p>taint analysis</p></li>
</ul>
</blockquote>
<h3 id="代码来源">2.1 代码来源</h3>
<p>​ analyzer的主要作用是用于污点分析，其基于的代码是ucr副教授Chengyu
Song 基于<a
href="https://github.com/CRYPTOlab/kint">kint</a>（2013年的分析工具）的工作《<a
href="https://www.researchgate.net/profile/Kangjie-Lu/publication/292156157_Enforcing_Kernel_Security_Invariants_with_Data_Flow_Integrity/links/56ab8bd408aed5a0135c201a/Enforcing-Kernel-Security-Invariants-with-Data-Flow-Integrity.pdf">Enforcing-Kernel-Security-Invariants-with-Data-Flow-Integrity</a>》，其在kint的基础上实现了自己的call
graph和taint
analysis。过去几年有多篇安全A类会议都使用了这份分析代码。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230502104803.png" style="zoom:67%;" /></p>
<p>​ 针对最新的LLVM(14)版本，目前也有开源的kint：<a
href="https://github.com/ganler/mini-kint">ganler/mini-kint: Enhanced
implementation of Kint in LLVM-14, in C++17. (github.com)</a></p>
<h3 id="总体结构">2.2 总体结构</h3>
<p>​
analyzer的源码分为几个模块：<code>KAMain</code>、<code>Annotation</code>、<code>CallGraph</code>、<code>CrashAnalyzer</code>、<code>PointerAnalysis</code>。KAMain.cc是程序的主模块，其引用模块：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/image-20230418154111392.png" style="zoom:50%;" /></p>
<h4 id="section"></h4>
<p>​
analyzer在<code>GlobalCtx</code>模块中定义了自己的Pass父类<code>IterativeModulePass</code>：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">class IterativeModulePass &#123;
  protected:
    GlobalContext *Ctx;
    const char *ID;
  public:
    &#x2F;&#x2F;构造者函数
    IterativeModulePass(GlobalContext *Ctx_, const char *ID_)
      : Ctx(Ctx_), ID(ID_) &#123; &#125;

    &#x2F;&#x2F; run on each module before iterative pass
    virtual bool doInitialization(llvm::Module *M)
      &#123; return true; &#125;

    &#x2F;&#x2F; run on each module after iterative pass
    virtual bool doFinalization(llvm::Module *M)
      &#123; return true; &#125;

    &#x2F;&#x2F; iterative pass
    virtual bool doModulePass(llvm::Module *M)
      &#123; return false; &#125;

    virtual void run(ModuleList &amp;modules);
&#125;;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
可以看到<code>IterativeModulePass</code>实现了四个虚函数<code>doInitialization</code>、<code>doFinalization</code>、<code>doModulePass</code>和<code>run</code>分别用于Pass的运行前后处理以及在多个modules上运行Pass。从虚函数的定义就可以看出该项目使用的是旧版的Pass
Manager。</p>
<p>​ 项目中实现了四个子类，其继承关系如图所示：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230502154428.png" /></p>
<h3 id="kamain.cc">2.3 KAMain.cc</h3>
<h4 id="iterativemodulepassrun">2.3.1 IterativeModulePass::run</h4>
<p>​
<code>IterativeModulePass::run</code>的完整实现在KAMain.cc中，run函数的参数是一个module列表(<strong>ModuleList
&amp;modules</strong>)，其数据结构是：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">typedef std::vector&lt; std::pair&lt;llvm::Module*, llvm::StringRef&gt; &gt; ModuleList;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​
<code>llvm:StringRef</code>类型表示一个固定不变的字符串的引用（包括一个字符数组的指针和长度），它支持可用在<code>std::string</code>类上的各种通用字符串操作。</p>
<p>​
①在run函数中，首先对传入的module列表进行遍历，并依次进行初始化操作：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;KAMain.cc
bool again &#x3D; true;
    while (again) &#123;
        again &#x3D; false;
        &#x2F;&#x2F;遍历所有modules初始化，这里没有做任何操作
        for (i &#x3D; modules.begin(), e &#x3D; modules.end(); i !&#x3D; e; ++i) &#123;
            KA_LOGS(3, &quot;[&quot; &lt;&lt; i-&gt;second &lt;&lt; &quot;]&quot;);
            &#x2F;&#x2F; doInitialization只返回false，循环结束后again为0
            again |&#x3D; doInitialization(i-&gt;first);
        &#125;
    &#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
这里的<code>doInitialization</code>和后续的<code>doModulePass</code>函数都是各个子类中定义的函数，其在父类的函数定义中出现是C++多态的体现，<code>doInitialization</code>函数并不通过<code>IterativeModulePass</code>类运行，而是通过其对应子类<code>ChildName::doInitialization</code>来运行子类特定的对应函数。由于所有子类中的<code>doInitialization</code>都只返回false，故这段初始化操作实际什么也没做。</p>
<p>​
②接着，对module列表中的每个module依次调用<code>doModulePass</code>函数，其调用各个子类中实现的Pass操作，并对结果进行统计。</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;KAMain.cc 
unsigned iter &#x3D; 0, changed &#x3D; 1;
    while (changed) &#123;
        ++iter;
        changed &#x3D; 0;
        for (i &#x3D; modules.begin(), e &#x3D; modules.end(); i !&#x3D; e; ++i) &#123;
            KA_LOGS(3, &quot;[&quot; &lt;&lt; ID &lt;&lt; &quot; &#x2F; &quot; &lt;&lt; iter &lt;&lt; &quot;] &quot;);
            &#x2F;&#x2F; FIXME: Seems the module name is incorrect, and perhaps it&#39;s a bug.
            KA_LOGS(3, &quot;[&quot; &lt;&lt; i-&gt;second &lt;&lt; &quot;]&quot;);
            &#x2F;&#x2F;运行Pass
            bool ret &#x3D; doModulePass(i-&gt;first);
            if (ret) &#123;
                ++changed;
                KA_LOGS(3, &quot;\t [CHANGED]&quot;);
            &#125; else &#123;
                KA_LOGS(3, &quot; &quot;);
            &#125;
        &#125;
        KA_LOGS(3, &quot;[&quot; &lt;&lt; ID &lt;&lt; &quot;] Updated in &quot; &lt;&lt; changed &lt;&lt; &quot; modules.&quot;);
    &#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
由于所有子类的<code>doModulePass</code>函数返回值都是false，故这里的change应该不会被触发。</p>
<p>​
③最后，与<code>doInitialization</code>相似，调用<code>doFinalization</code>函数对modules做后处理，这里实际上除了<code>CallGraphPass</code>类对module更新了相关caller和callee映射，其它类的<code>doFinalization</code>什么都没做。所有子类的<code>doFinalization</code>都返回了false，故这里也只遍历了一轮。</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;KAMain.cc
again &#x3D; true;
    while (again) &#123;
        again &#x3D; false;
        for (i &#x3D; modules.begin(), e &#x3D; modules.end(); i !&#x3D; e; ++i) &#123;
            again |&#x3D; doFinalization(i-&gt;first);
        &#125;
    &#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
综上，子类的run函数的作用就是接受一个module列表，对其中的每个module运行其对应的Pass。</p>
<h4 id="dobasicinitialization">2.3.2 doBasicInitialization</h4>
<p>​
KAMain.cc中实现了一个独立函数<code>doBasicInitialization</code>：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;KAMain.cc
void doBasicInitialization(Module *M) &#123;
    &#x2F;&#x2F; collect global object definitions
    &#x2F;&#x2F;llvm::GlobalVariable
    for (GlobalVariable &amp;G : M-&gt;globals()) &#123;
        &#x2F;&#x2F; bool llvm::GlobalValue::hasExternalLinkage() 查找全局变量是否外部可见 
        if (G.hasExternalLinkage())
            GlobalCtx.Gobjs[G.getName().str()] &#x3D; &amp;G;
    &#125;

    &#x2F;&#x2F; collect global function definitions
    for (Function &amp;F : *M) &#123;
        if (F.hasExternalLinkage() &amp;&amp; !F.empty()) &#123;
            &#x2F;&#x2F; external linkage always ends up with the function name
            StringRef FNameRef &#x3D; F.getName();
            std::string FName &#x3D; &quot;&quot;;
            if (FNameRef.startswith(&quot;__sys_&quot;))
                FName &#x3D; &quot;sys_&quot; + FNameRef.str().substr(6);
            else 
                FName &#x3D; FNameRef.str();
            GlobalCtx.Funcs[FName] &#x3D; &amp;F;
        &#125;
    &#125;
    return;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
其功能分为两个部分，将输入的module中的全局对象存储到GlobalCtx.Gobjs中，将输入modules中的全局函数存储到GlobalCtx.Funcs中。</p>
<h4 id="main">2.3.3 main()</h4>
<p>​ main函数的工作流程可以分为以下几部分：</p>
<h5 id="准备工作">2.3.3.1 准备工作：</h5>
<ul>
<li><strong>分配堆栈资源：</strong></li>
</ul>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;KAMain.cc -&gt; main()
#ifdef SET_STACK_SIZE
    &#x2F;&#x2F;struct rlimit&#123;
    &#x2F;&#x2F;   rlim_t rlim_cur; &#x2F;&#x2F;软限制
    &#x2F;&#x2F;   rlim_t rlim_max; &#x2F;&#x2F;应限制
    &#x2F;&#x2F;&#125;
    struct rlimit rl;
    &#x2F;&#x2F;getrlimit函数获取RLIMIT_STACK的当前资源限制
    &#x2F;&#x2F;RLIMIT_STACK表示最大的进程堆栈，以字节为单位
    if (getrlimit(RLIMIT_STACK, &amp;rl) &#x3D;&#x3D; 0) &#123;
        rl.rlim_cur &#x3D; SET_STACK_SIZE;
        setrlimit(RLIMIT_STACK, &amp;rl);
    &#125;
#endif<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
上述代码将进程的栈长度设置为预定义的SET_STACK_SIZE，以字节为单位。</p>
<ul>
<li><strong>打印stack trace：</strong></li>
</ul>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;KAMain.cc -&gt; main() 
&#x2F;&#x2F; Print a stack trace if we signal out.
#if LLVM_VERSION_MAJOR &#x3D;&#x3D; 3 &amp;&amp; LLVM_VERSION_MINOR &lt; 9
    sys::PrintStackTraceOnErrorSignal();
#else
    sys::PrintStackTraceOnErrorSignal(StringRef());
#endif
    PrettyStackTraceProgram X(argc, argv);
    &#x2F;&#x2F; Call llvm_shutdown() on exit.
    llvm_shutdown_obj Y; <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 如果程序发生错误，上述代码将打印Stack Trace。</p>
<ul>
<li><p><strong>命令行选项：</strong></p>
<p>KAMain.cc定义了如下命令行全局变量:</p></li>
</ul>
<pre class="line-numbers language-C++" data-language="C++"><code class="language-C++">&#x2F;&#x2F;KAMain.cc
cl::list&lt;std::string&gt; InputFilenames(
    cl::Positional, cl::OneOrMore, cl::desc(&quot;&lt;input bitcode files&gt;&quot;));

cl::opt&lt;unsigned&gt; VerboseLevel(
    &quot;debug-verbose&quot;, cl::desc(&quot;Print information about actions taken&quot;),
    cl::init(0));

cl::opt&lt;std::string&gt; DumpLocation(
    &quot;dump-location&quot;, cl::desc(&quot;dump found structures&quot;), cl::NotHidden, cl::init(&quot;&quot;));

cl::opt&lt;std::string&gt; CrashReport(
    &quot;crash-report&quot;, cl::desc(&quot;crash report&quot;), cl::Required, cl::init(&quot;&quot;));

cl::opt&lt;std::string&gt; CallGraph(&quot;call-graph&quot;, cl::desc(&quot;call graph from the report&quot;),
    cl::Required, cl::init(&quot;&quot;));<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
其中，<code>InputFilenames</code>是一个list，包含输入的文件名称；<code>VerboseLevel</code>代表输出等级（具体见Common.h）；<code>DumpLocation</code>代表dump文件存储的位置；<code>CrashReport</code>代表syzbot报告的位置；<code>CallGraph</code>代表从报告中提取的call
trace文件的位置。</p>
<h5 id="读取文件信息">2.3.3.2 读取文件信息</h5>
<p>​ 对<code>InputFilenames</code>列表中的每个LLVM
IR文件，需要依次对其做以下处理：</p>
<ul>
<li><strong>IR File -&gt; llvm::Module</strong></li>
</ul>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; KAMain.cc -&gt; main()
&#x2F;&#x2F; Use separate LLVMContext to avoid type renaming
LLVMContext *LLVMCtx &#x3D; new LLVMContext();
&#x2F;&#x2F;来自#include &lt;llvm&#x2F;IRReader&#x2F;IRReader.h&gt;
&#x2F;&#x2F;parseIRFile()函数接收一个bitcode文件，返回一个module
std::unique_ptr&lt;Module&gt; M &#x3D; parseIRFile(InputFilenames[i], Err, *LLVMCtx);
        if (M &#x3D;&#x3D; NULL) &#123;
            errs() &lt;&lt; argv[0] &lt;&lt; &quot;: error loading file &#39;&quot; &lt;&lt; InputFilenames[i] &lt;&lt; &quot;&#39;\n&quot;;
            continue;
        &#125;
&#x2F;&#x2F;std::unique_ptr智能指针相关
&#x2F;&#x2F;release()将指针的控制权转移给外部代码
Module *Module &#x3D; M.release();<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
<code>std::unique_ptr</code>是c++智能指针类型，用于对象对指针的使用权限管理，不必过于深究；这里<code>LLVM::LLVMContext</code>类用于多线程共享/线程独享，不必过于深究。</p>
<p>​
<code>parseIRFile()</code>来自llvm/IRReader/IRReader.h，其接收一个文件，判断其是否是bitcode文件，如果是则将其转化为Module。若分析失败则打印对应日志信息。</p>
<ul>
<li><strong>std::string -&gt; llvm::StringRef</strong></li>
</ul>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; KAMain.cc -&gt; main()
&#x2F;&#x2F;将string复制到一个StringRef上
&#x2F;&#x2F;string.data()返回string字符串的首地址
&#x2F;&#x2F;strdup()用于字符串复制
StringRef MName &#x3D; StringRef(strdup(InputFilenames[i].data()));<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
将函数名从<code>std::string</code>转化为<code>llvm::StringRef</code>，用于后续记录。</p>
<ul>
<li><strong>全局信息记录</strong></li>
</ul>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;GlobalCtx.Modules是ModuleList类型
&#x2F;&#x2F;ModuleList &#x3D; std::vector&lt; std::pair&lt;llvm::Module*, llvm::StringRef&gt;&gt;
&#x2F;&#x2F;lobalCtx.Modules存储[&amp;Module,ModuleName]键值对
GlobalCtx.Modules.push_back(std::make_pair(Module, MName));
GlobalCtx.ModuleMaps[Module] &#x3D; InputFilenames[i];
doBasicInitialization(Module);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
将读取的Module和其名称存到<code>GlobalCtx.Modules</code>和<code>GlobalCtx.ModuleMaps</code>中，并调用<code>doBasicInitialization</code>函数，将Module中的全局对象存储到<code>GlobalCtx.Gobjs</code>中，全局函数存储到<code>GlobalCtx.Funcs</code>中。</p>
<p>​ <u>完整代码</u>如下：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; Load modules
    KA_LOGS(0, &quot;Total &quot; &lt;&lt; InputFilenames.size() &lt;&lt; &quot; file(s)&quot;);
    &#x2F;&#x2F; 遍历每个文件
    for (unsigned i &#x3D; 0; i &lt; InputFilenames.size(); ++i) &#123;
        &#x2F;&#x2F; Use separate LLVMContext to avoid type renaming
        KA_LOGS(1, &quot;[&quot; &lt;&lt; i &lt;&lt; &quot;] &quot; &lt;&lt; InputFilenames[i] &lt;&lt; &quot;&quot;);
        LLVMContext *LLVMCtx &#x3D; new LLVMContext();
        &#x2F;&#x2F;来自#include &lt;llvm&#x2F;IRReader&#x2F;IRReader.h&gt;
        &#x2F;&#x2F;parseIRFile()函数接收一个bitcode文件，返回一个module
        std::unique_ptr&lt;Module&gt; M &#x3D; parseIRFile(InputFilenames[i], Err, *LLVMCtx);
        if (M &#x3D;&#x3D; NULL) &#123;
            errs() &lt;&lt; argv[0] &lt;&lt; &quot;: error loading file &#39;&quot; &lt;&lt; InputFilenames[i] &lt;&lt; &quot;&#39;\n&quot;;
            continue;
        &#125;
        &#x2F;&#x2F;std::unique_ptr智能指针相关
        &#x2F;&#x2F;release()将指针的控制权转移给外部代码
        Module *Module &#x3D; M.release();
        &#x2F;&#x2F;将string复制到一个StringRef上
        &#x2F;&#x2F;string.data()返回string字符串的首地址
        &#x2F;&#x2F;strdup()用于字符串复制
        StringRef MName &#x3D; StringRef(strdup(InputFilenames[i].data()));
        &#x2F;&#x2F;GlobalCtx.Modules是ModuleList类型
        &#x2F;&#x2F;ModuleList &#x3D; std::vector&lt; std::pair&lt;llvm::Module*, llvm::StringRef&gt;&gt;
        &#x2F;&#x2F;lobalCtx.Modules存储[&amp;Module,ModuleName]键值对
        GlobalCtx.Modules.push_back(std::make_pair(Module, MName));
        GlobalCtx.ModuleMaps[Module] &#x3D; InputFilenames[i];
        doBasicInitialization(Module);
    &#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="分析crashreport">2.3.3.3 分析CrashReport</h5>
<p>​
该部分的功能是分析从syzbot爬取的报告，其目的是分析报告中是否存在可check的点：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">std::ifstream report(CrashReport);
&#x2F;&#x2F; do we find explicit check expression
bool explicity &#x3D; false;
if (report.is_open()) &#123;
     &#x2F;&#x2F;std::istreambuf_iterator 输入流缓冲区迭代器
     &#x2F;&#x2F;从指定的流缓冲区中读取字符元素
     &#x2F;&#x2F;这句代码将report从文件流转化为了一个string
     std::string reportContent((std::istreambuf_iterator&lt;char&gt;(report)), 
     std::istreambuf_iterator&lt;char&gt;());
     &#x2F;&#x2F;如果report中有&quot;WARNNING&quot; 和 &quot;invalid_op&quot;
     &#x2F;&#x2F;代表存在可check点
     if (reportContent.find(&quot;WARNING&quot;) !&#x3D; string::npos &amp;&amp; reportContent.find(&quot;invalid_op&quot;) !&#x3D; string::npos) &#123;
     	explicity &#x3D; true;
     &#125;
     &#x2F;&#x2F;如果report中有&quot;kernel BUG at&quot;
     &#x2F;&#x2F;代表存在可check点
     if (reportContent.find(&quot;kernel BUG at&quot;) !&#x3D; string::npos) &#123;
     	explicity &#x3D; true;
     &#125;
     report.close();
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="分析callgraph">2.3.3.4 分析CallGraph</h5>
<p>​ CallGraph就是使用get_cg.py脚本从syzbot报告中提取的call
tarce，其以文本文件存储，CallGraph的每一行的组成是[函数名]+[空格]+[调用位置]，例如：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230503202218.png" alt="report_cg.txt" style="zoom: 50%;" /></p>
<p>​ 使用std::ifstream类打开文件：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">std::ifstream file(CallGraph);
&#x2F;&#x2F;用于定位Call Trace中的Crash点
std::string CrashLoc;
&#x2F;&#x2F;用于检查是否存在KASAN报错
bool kasan_check &#x3D; false;
if (file.is_open()) &#123;
	&#x2F;&#x2F;······
	file.close();
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
打开CallGraph后，逐行分析其中的每个函数是否在<code>GlobalCtx.h</code>中预定义的skipFunc函数集中，如果在call
trace中前一个函数在skipFunc中而当前函数不在，则认为当前的函数是crash
location。</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">if (file.is_open()) &#123;
     std::string line, curFunc;
     std::string lastFunc &#x3D; &quot;&quot;;
     bool skipped &#x3D; true;
     &#x2F;&#x2F;读取每一行call trace
     while (std::getline(file, line)) &#123;
          StringRef readin &#x3D; StringRef(line);
          &#x2F;&#x2F;函数名就是CallGraph每行的第一个单词
          curFunc &#x3D; readin.split(&quot; &quot;).first.str();
          &#x2F;* if previous function is in the skipped function list
          while current function is not, we set current function
          as the crash location *&#x2F;
          &#x2F;&#x2F;skipFunc有哪些是GlobalCtx.h中预定义的
          if (skipFunc.find(curFunc) !&#x3D; skipFunc.end()) &#123;
          	skipped &#x3D; true;
          &#125; 
          else &#123;
               if (skipped) 
                    &#x2F;&#x2F;上个函数在skipFunc中，而这个不在
                   CrashLoc &#x3D; line;
               skipped &#x3D; false;
          &#125;
          &#x2F;&#x2F; 检查是否存在KASAN报错
          if (curFunc.find(&quot;kasan_check_&quot;) !&#x3D; string::npos) &#123;
          	kasan_check &#x3D; true;
          &#125;
          if (lastFunc !&#x3D; &quot;&quot;) &#123;
               KA_LOGS(0, &quot;inserting &quot; &lt;&lt; lastFunc &lt;&lt; &quot; &quot; &lt;&lt; curFunc);
               &#x2F;&#x2F;std::map&lt;string, string&gt;
               &#x2F;&#x2F;记录调用关系
               GlobalCtx.CallGraph[lastFunc] &#x3D; curFunc;
          &#125;
          lastFunc &#x3D; curFunc;
     &#125;
     file.close();
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 在遍历CallGraph的过程中，会将函数的调用关系记录到
<code>GlobalCtx.CallGraph</code>中。</p>
<h5 id="运行pass-dump">2.3.3.5 运行Pass &amp;&amp; Dump</h5>
<p>​
接下来对<code>GlobalCtx.Modules</code>中存储的所有Module调用CallGraphPass和PointerAnalysisPass：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;调用CallGraphPass
CallGraphPass CGPass(&amp;GlobalCtx);
CGPass.run(GlobalCtx.Modules);
&#x2F;&#x2F;调用PointerAnalysisPass
PointerAnalysisPass PAPass(&amp;GlobalCtx);
PAPass.run(GlobalCtx.Modules);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 如果前文的分析过程中存在Crash check point，则调用CrashAnalyzer
Pass：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">assert(CrashLoc !&#x3D; &quot;&quot;);&#123;
    &#x2F;&#x2F;调用CrashAnalyzePass
    CrashAnalyzer CA(&amp;GlobalCtx, explicity, CrashLoc);
    CA.run(GlobalCtx.Modules);
    &#x2F;&#x2F; test_bit include&#x2F;asm-generic&#x2F;bitops&#x2F;instrumented-non-atomic.h:110
    if (DumpLocation !&#x3D; &quot;&quot;)
        CA.dump(DumpLocation);
    else
        CA.dump();
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 这是整个代码的核心部分，具体Pass的分析过程见后文。</p>
<h3 id="callgraphpass">2.4 CallGraphPass</h3>
<h4 id="cc特殊函数调用">2.4.1 C/C++特殊函数调用</h4>
<p>​
<strong>CallGraphPass的目的是构建文件的CallGraph，并将相关调用信息存储到Ctx全局变量中。</strong>在进行具体代码分析前，首先来关注一下C语言中函数的特殊调用问题。</p>
<h5 id="间接调用indirect-call">2.4.1.1 间接调用(indirect call)</h5>
<p>​ C中的间接调用一般是指通过函数指针调用函数：</p>
<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token comment">//directCall_test.c</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;stdio.h></span></span>
<span class="token keyword">void</span> <span class="token function">foo</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span> <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"function foo\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token punctuation">&#125;</span>
<span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword">int</span> argc<span class="token punctuation">,</span> <span class="token keyword">char</span> <span class="token operator">*</span><span class="token operator">*</span>argv<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
  <span class="token function">foo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token comment">//IndirectCall_test.c</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;stdio.h></span></span>
<span class="token keyword">void</span> <span class="token function">foo</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span> <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"function foo\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token punctuation">&#125;</span>
<span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword">int</span> argc<span class="token punctuation">,</span> <span class="token keyword">char</span> <span class="token operator">*</span><span class="token operator">*</span>argv<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
  <span class="token keyword">void</span> <span class="token punctuation">(</span><span class="token operator">*</span>fp<span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">=</span> foo<span class="token punctuation">;</span>
  <span class="token function">fp</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 将其编译为ll文件如下：</p>
<pre class="line-numbers language-assembly" data-language="assembly"><code class="language-assembly">&#x2F;&#x2F;directCall_test.ll
; Function Attrs: noinline nounwind optnone uwtable
define dso_local void @foo() #0 &#123;
  %1 &#x3D; call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str, i64 0, i64 0))
  ret void
&#125;

declare dso_local i32 @printf(i8*, ...) #1

; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 &#123;
  %1 &#x3D; alloca i32, align 4
  store i32 0, i32* %1, align 4
  call void @foo()
  ret i32 0
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-assembly" data-language="assembly"><code class="language-assembly">&#x2F;&#x2F;IndirectCall_test.ll
; Function Attrs: noinline nounwind optnone uwtable
define dso_local void @foo() #0 &#123;
  %1 &#x3D; call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str, i64 0, i64 0))
  ret void
&#125;

declare dso_local i32 @printf(i8*, ...) #1

; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 &#123;
  %1 &#x3D; alloca i32, align 4
  %2 &#x3D; alloca void (...)*, align 8
  store i32 0, i32* %1, align 4
  store void (...)* bitcast (void ()* @foo to void (...)*), void (...)** %2, align 8
  %3 &#x3D; load void (...)*, void (...)** %2, align 8
  call void (...) %3()
  ret i32 0
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
可以看到，直接调用指令的操作数就是确定Callee的地址（foo），但是间接调其操作数是一个虚拟寄存器<code>%3</code>（在汇编中就是一个确定的寄存器）。故当Pass分析到call语句时没有办法直接得出目标函数的地址，因为寄存器中的值可能是直接载入的确定的地址，也可能是其它地方载入的值。换句话说，直接调用语句可以确定call语句调用的foo函数，但是间接调用语句不能，因为调用什么函数取决于<code>%3</code>内加载了什么值。</p>
<p>​
在以上例子中，我们当然可以轻松看出间接调用的就是foo函数的地址，但是万一间接调用的地址取决于用户的输入/程序运行时的具体状态/读取的文件信息等，代码的分支情况就复杂了起来。在C++中的虚函数调用就是通过间接调用完成的，这也是其多态的基础。</p>
<h5 id="内联汇编语句">2.4.1.2 内联汇编语句</h5>
<p>​ 内联汇编语言（或“inline
asm”）是一些编程语言中的一项功能，允许在代码中直接包含汇编语言指令。在需要执行无法使用高级语言结构有效或清晰表达的特定操作时，使用内联汇编可能会很有用。例如，可以使用内联汇编访问硬件设备或优化性能关键的代码段。</p>
<p>​ 内联汇编语句中可以包含调用指令，例如：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">#include &lt;stdio.h&gt;
int main() &#123;
    int x &#x3D; 10;
    int y;
    &#x2F;&#x2F; 使用内联汇编语言调用一个汇编语言函数
    __asm__(&quot;movl %1, %%eax; call assembly_function; movl %%eax, %0;&quot; : &quot;&#x3D;r&quot;(y) : &quot;r&quot;(x));
    printf(&quot;The result is: %d\n&quot;, y);
    return 0;
&#125;
&#x2F;&#x2F; 汇编函数用于将输入参数加5并返回结果
__asm__(
    &quot;assembly_function:\n&quot;
    &quot;addl $5, %eax\n&quot;
    &quot;ret\n&quot;
);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
上述代码使用内联汇编语言调用一个在汇编语言中定义的函数<code>assembly_function</code>。该函数接受一个输入参数，将其加5，然后返回结果。将其转化为LLVM
IR如下：</p>
<pre class="line-numbers language-assembly" data-language="assembly"><code class="language-assembly">define dso_local i32 @main() #0 &#123;
  %1 &#x3D; alloca i32, align 4
  %2 &#x3D; alloca i32, align 4
  %3 &#x3D; alloca i32, align 4
  store i32 0, i32* %1, align 4
  store i32 10, i32* %2, align 4
  %4 &#x3D; load i32, i32* %2, align 4
  %5 &#x3D; call i32 asm &quot;movl $1, %eax; call assembly_function; movl %eax, $0;&quot;, &quot;&#x3D;r,r,~&#123;dirflag&#125;,~&#123;fpsr&#125;,~&#123;flags&#125;&quot;(i32 %4) #2, !srcloc !2
  store i32 %5, i32* %3, align 4
  %6 &#x3D; load i32, i32* %3, align 4
  %7 &#x3D; call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str, i64 0, i64 0), i32 %6)
  ret i32 0
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
<strong>可见其使用<code>call i32 asm</code>语句直接调用汇编，并不对其处理。CallGraphPass跳过了对内联汇编函数调用语句的分析。</strong></p>
<h5 id="intrinsic函数">2.4.1.3 Intrinsic函数</h5>
<p>​
Intrinsic函数是编译器内建的函数，由编译器提供，类似于内联函数。在LLVM中，Intrinsic函数一般是在IR级代码优化时引入的，也就是由前端产生。也可以在程序代码中写Intrinsic函数，并通过前端直接发射。这些函数名的前缀一般是保留字“llvm.”。LLVM后端选择用最高效的形式将Intrinsic函数转换给硬件执行，可以将Intrinsic函数拆分为一系列机器指令，也可以映射为单独一条机器指令，并直接调用相应的硬件功能。</p>
<p>​
<strong>这里CallGraphPass跳过了Intrinsic函数的调用分析，其与内核并无关系，是LLVM引入的。Intrinsic名必须全部以“
llvm”开头前缀。</strong></p>
<h4 id="代码分析">2.4.2 代码分析</h4>
<p>​ CallGraph的Pass执行代码如下：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;CallGraph.cc
bool CallGraphPass::doModulePass(Module *M) &#123;
    bool Changed &#x3D; true, ret &#x3D; false;
    while (Changed) &#123;
        Changed &#x3D; false;
        &#x2F;&#x2F;遍历Module中每个Function
        for (Function &amp;F : *M)
            &#x2F;&#x2F;对每个Function操作
            Changed |&#x3D; runOnFunction(&amp;F);
        ret |&#x3D; Changed;
    &#125;
    return ret;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 进入函数<code>CallGraph::runOnFunction</code>:</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;CallGraph.cc -&gt; runOnFunction()
&#x2F;&#x2F;llvm::GlobalObject -&gt; hasSection(): Check if this global has a custom object file section.
&#x2F;&#x2F;llvm::GlobalObject -&gt; getSection(): Get the custom section of this global if it has one.
if(F-&gt;hasSection() &amp;&amp; F-&gt;getSection().str() &#x3D;&#x3D; &quot;.init.text&quot;)
        return false;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
首先排除了初始化函数。在C代码中，使用__init宏声明的函数会在编译时将函数放在".init.text"这个代码区中。标记为初始化的函数,表明该函数供在初始化期间使用。在<strong>模块装载之后，模块装载就会将初始化函数扔掉。这样可以将该函数占用的内存释放出来。</strong></p>
<p>​
这里，程序通过使用<code>inst_iterator</code>直接遍历函数里的每条指令：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;CallGraph.cc -&gt; runOnFunction()
bool Changed &#x3D; false;
for (inst_iterator i &#x3D; inst_begin(F), e &#x3D; inst_end(F); i !&#x3D; e; ++i) &#123;
	&#x2F;&#x2F;......
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
对于每条指令，可能与inst_iterator的指针重载有关，需要重新取址获取指向每条指令的地址[<a
href="https://blog.csdn.net/qq_23599965/article/details/88538590">LLVM开发者手册</a>]。接着，排除了asm内联调用和intrinsic调用：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;&#x2F;&#x2F;CallGraph.cc -&gt; runOnFunction()
&#x2F;&#x2F;获取指向指令引用的指针
Instruction *I &#x3D; &amp;*i;
&#x2F;&#x2F; map callsite to possible callees
&#x2F;&#x2F; dyn_cast检查指针I是否是CallInst类型
if (CallInst *CI &#x3D; dyn_cast&lt;CallInst&gt;(I)) &#123;
&#x2F;&#x2F; ignore inline asm or intrinsic calls
if (CI-&gt;isInlineAsm() || (CI-&gt;getCalledFunction()
        &amp;&amp; CI-&gt;getCalledFunction()-&gt;isIntrinsic()))
    continue;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
接下来需要获取该CallInst的Callee，即该指令调用的函数。对于直接调用，使用<code>CI-&gt;getCalledFunction()</code>即可；对于间接调用，由于其调用存在多种情况，需要具体分析：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; CallGraph.cc -&gt; runOnFunction()
&#x2F;&#x2F; might be an indirect call, find all possible callees
FuncSet &amp;FS &#x3D; Ctx-&gt;Callees[CI];
if (!findCallees(CI, FS))
	continue;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ findCallees()函数流程如下：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; CallGraph.cc -&gt; findCallees()
&#x2F;&#x2F; typedef llvm::SmallPtrSet&lt;llvm::Function*, 32&gt; FuncSet;
bool CallGraphPass::findCallees(CallInst *CI, FuncSet &amp;FS) &#123;
    Function *CF &#x3D; CI-&gt;getCalledFunction();
    &#x2F;&#x2F; real function, S &#x3D; S + &#123;F&#125;
    if (CF) &#123;
        &#x2F;&#x2F; prefer the real definition to declarations
        &#x2F;&#x2F; 获取函数定义
        CF &#x3D; getFuncDef(CF);
        return FS.insert(CF).second;
    &#125;
	&#x2F;&#x2F;......
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
<code>CI-&gt;getCalledFunction()</code>函数用于获取直接调用call指令的callee地址，若其是一个间接调用/非调用指令则返回nullptr。如果返回不为nullptr，则进入以下调用过程：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230506144655.png" style="zoom:67%;" /></p>
<p>​ getFuncDef()过程如下：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; CallGraph.cc -&gt; getFuncDef()
Function* CallGraphPass::getFuncDef(Function *F) &#123;
    &#x2F;&#x2F; typedef std::unordered_map&lt;std::string, llvm::Function*&gt; FuncMap
    FuncMap::iterator it &#x3D; Ctx-&gt;Funcs.find(getScopeName(F));
    if (it !&#x3D; Ctx-&gt;Funcs.end())
        return it-&gt;second;
    else
        return F;
&#125; <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ getScopeName()过程如下：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; Annotation.h -&gt; getScopeName()
static inline std::string getScopeName(const llvm::GlobalValue *GV) &#123;
	if (llvm::GlobalValue::isExternalLinkage(GV-&gt;getLinkage()))
		return GV-&gt;getName().str();
	else &#123;
		llvm::StringRef moduleName &#x3D; llvm::sys::path::stem(
			GV-&gt;getParent()-&gt;getModuleIdentifier());
		return &quot;_&quot; + moduleName.str() + &quot;.&quot; + GV-&gt;getName().str();
	&#125;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
其中，<code>llvm::GlobalValue</code>类是<code>llvm::Function</code>类的父类<code>llvm::GlobalObject</code>的父类：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230506145059.png" style="zoom:50%;" /></p>
<p>​
getScopeName()的作用是检查一个函数是否为全局函数(extern)，如果是则直接返回其函数名，如果不是则查找该函数所属的Module，构建“_{ModuleName}.{FuncName}”字符串并返回。</p>
<p>​
回到getFuncDef()函数，其功能是在<code>Ctx-&gt;Funcs</code>中查找函数的定义，如果其在<code>Ctx-&gt;Funcs</code>中存在则返回<code>Ctx-&gt;Funcs</code>中的函数指针，否则返回输入的函数指针F本身。</p>
<p>​
回到findCallees()函数，如果输入的指令CI是一个直接调用，则获取其Callee函数指针CF，并调用getFuncDef()在<code>Ctx-&gt;Funcs</code>中查找并返回函数的定义。然后将指针插入FuncSet
FS中，如果第一次插入则返回true，否则返回false。因为CF这里传入的是<code>Ctx-&gt;Callees[CI]</code>，返回false就代表查找到的调用关系（CI-&gt;CF）已经存在。</p>
<p>​
如果findCallees()函数中CI指令并不是直接调用，则将其插入到Ctx-&gt;IndirectCallInst中：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; CallGraph.cc -&gt; findCallees()
    &#x2F;&#x2F; save called values for point-to analysis
    Ctx-&gt;IndirectCallInsts.push_back(CI);
#ifdef TYPE_BASED
    &#x2F;&#x2F; use type matching to concervatively find 
    &#x2F;&#x2F; possible targets of indirect call
    return findCalleesByType(CI, FS);
#else
    &#x2F;&#x2F; use assignments based approach to find possible targets
    &#x2F;&#x2F; const Value* llvm::CallInst::getCalledValue()
    &#x2F;&#x2F; getCalledValue() - Get a pointer to the function that is invoked by this instruction.
    return findFunctions(CI-&gt;getCalledValue(), FS);
#endif<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
接下来，调用<code>findFunctions</code>查找其所有可能的Callee，并存储到<code>Ctx-&gt;Callees[Ins]</code>中，具体细节这里不再展开。</p>
<p>​
至此，已经找到了当前Call指令的所有Callee，接下来分析callInst指令的所有参数，找到其可能存在的函数指针参数并分析其所有函数指针的Callee，将其存储到<code>Ctx-&gt;FuncPtrs[Id]</code>中：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;CallGraph.cc -&gt; runOnFunction()
#ifndef TYPE_BASED
            &#x2F;&#x2F; looking for function pointer arguments
            &#x2F;&#x2F; CI-&gt;getNumArgOperands():
            &#x2F;&#x2F; Return the number of invoke arguments
            for (unsigned no &#x3D; 0, ne &#x3D; CI-&gt;getNumArgOperands(); no !&#x3D; ne; ++no) &#123;
                &#x2F;&#x2F; CI-&gt;getArgOperand(no)
                &#x2F;&#x2F; Return the i-th invoke argument.
                Value *V &#x3D; CI-&gt;getArgOperand(no);
                
                if (!isFunctionPointerOrVoid(V-&gt;getType()))
                    continue;

                &#x2F;&#x2F; find all possible assignments to the argument
                FuncSet VS;
                if (!findFunctions(V, VS))
                    continue;

                &#x2F;&#x2F; update argument FP-set for possible callees
                for (Function *CF : FS) &#123;
                    if (!CF) &#123;
                        WARNING(&quot;NULL Function &quot; &lt;&lt; *CI &lt;&lt; &quot;\n&quot;);
                        assert(0);
                    &#125;
                    std::string Id &#x3D; getArgId(CF, no);
                    Changed |&#x3D; mergeFuncSet(Ctx-&gt;FuncPtrs[Id], VS);
                &#125;
            &#125;
#endif<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 如果I不是CallInst指令，而是StoreInst类型指令，则：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;CallGraph.cc -&gt; runOnFunction()
#ifndef TYPE_BASED
        if (StoreInst *SI &#x3D; dyn_cast&lt;StoreInst&gt;(I)) &#123;
            &#x2F;&#x2F; stores to function pointers
            Value *V &#x3D; SI-&gt;getValueOperand();
            if (isFunctionPointerOrVoid(V-&gt;getType())) &#123;
                std::string Id &#x3D; getStoreId(SI);
                if (!Id.empty()) &#123;
                    FuncSet FS;
                    findFunctions(V, FS);
                    Changed |&#x3D; mergeFuncSet(Id, FS, isFunctionPointer(V-&gt;getType()));
                &#125; else &#123;
                    &#x2F;&#x2F; errs() &lt;&lt; &quot;Empty StoreID: &quot; &lt;&lt; F-&gt;getName() &lt;&lt; &quot;::&quot; &lt;&lt; *SI &lt;&lt; &quot;\n&quot;;
                &#125;
            &#125;
        &#125; else if (ReturnInst *RI &#x3D; dyn_cast&lt;ReturnInst&gt;(I)) &#123;
            &#x2F;&#x2F; function returns
            if (isFunctionPointerOrVoid(F-&gt;getReturnType())) &#123;
                Value *V &#x3D; RI-&gt;getReturnValue();
                std::string Id &#x3D; getRetId(F);
                FuncSet FS;
                findFunctions(V, FS);
                Changed |&#x3D; mergeFuncSet(Id, FS, isFunctionPointer(V-&gt;getType()));
            &#125;
        &#125;
#endif<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
如果一个StoreInst类型指令，并且其操作数是函数指针，则获取其函数指针所有可能的Callee并存储到<code>Ctx-&gt;FuncPtrs[]</code>中。</p>
<p>​
在runOnFunction函数执行完毕后，其run函数调用<code>CallGraphPass::doFinalization</code>对每个Module进行善后处理：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;CallGraph.cc -&gt; doFinalization()
bool CallGraphPass::doFinalization(Module *M) &#123;
    &#x2F;&#x2F; update callee and caller mapping
    &#x2F;&#x2F; 遍历每个函数
    for (Function &amp;F : *M) &#123;
        &#x2F;&#x2F;遍历每条指令
        for (inst_iterator i &#x3D; inst_begin(F), e &#x3D; inst_end(F); i !&#x3D; e; ++i) &#123;
            &#x2F;&#x2F; map callsite to possible callees
            &#x2F;&#x2F; 如果该指令是CallInst类型
            &#x2F;&#x2F; 根据之前存储的Callees，反向计算Callers
            if (CallInst *CI &#x3D; dyn_cast&lt;CallInst&gt;(&amp;*i)) &#123;
                FuncSet &amp;FS &#x3D; Ctx-&gt;Callees[CI];
                &#x2F;&#x2F; calculate the caller info here
                for (Function *CF : FS) &#123;
                    CallInstSet &amp;CIS &#x3D; Ctx-&gt;Callers[CF];
                    CIS.insert(CI);
                &#125;
            &#125;
        &#125;
    &#125;
    return false;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 至此，CallGraphPass分析完毕。</p>
<p>​</p>
<h3 id="pointeranalysispass">2.5 PointerAnalysisPass</h3>
<h4 id="alias-analysis">2.5.1 Alias Analysis</h4>
<p>​ <u>Alias Analysis/Pointer
Analysis是一类试图确定两个指针是否可以指向内存中同一个对象的技术</u><a
href="https://llvm.org/docs/AliasAnalysis.html">[LLVM Alias Analysis
Infrastructure — LLVM 17.0.0]</a>。</p>
<p>​ Alias
Analysis（别名分析）是编译器理论中的一种技术，用于确定存储位置是否可以以多种方式访问。如果两个指针指向相同的位置，则称这两个指针为别名。
但是，它不能与Pointer
Analysis（指针分析）混淆，指针分析解决的问题是一个指针可能指向哪些对象或者指向哪些地址，而别名分析解决的是两个指针指向的是否是同一个对象。指针分析和别名分析通常通过静态代码分析来实现。</p>
<p>​
别名分析在编译器理论中非常重要，在代码优化和安全方面有着非常广泛且重要的应用。编译器级优化需要指针别名信息来执行死代码消除（删除不影响程序结果的代码）、冗余加载/存储指令消除、指令调度（重排列指令）等。编译器级别的程序安全使用别名分析来检测内存泄漏和内存相关的安全漏洞。</p>
<h4 id="代码分析-1">2.5.2 代码分析</h4>
<p>​ 定义相关数据结构：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;GlobalCtx.h
typedef DenseMap&lt;Value *, SmallPtrSet&lt;Value *, 16&gt;&gt; PointerAnalysisMap;
typedef unordered_map&lt;Function *, PointerAnalysisMap&gt; FuncPointerAnalysisMap;
typedef unordered_map&lt;Function *, AAResults *&gt; FuncAAResultsMap;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 分析代码：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;PointerAnalysis.cc
bool PointerAnalysisPass::doModulePass(Module *M) &#123;
    &#x2F;&#x2F;llvm::legacy::FunctionPassManager是旧版的Pass Manager
    legacy::FunctionPassManager *FPasses &#x3D; new legacy::FunctionPassManager(M);
    AAResultsWrapperPass *AARPass &#x3D; new AAResultsWrapperPass();
    FPasses-&gt;add(AARPass);
    &#x2F;&#x2F;return false
    FPasses-&gt;doInitialization();
    for (Function &amp;F : *M) &#123;
        &#x2F;&#x2F;如果该函数的定义在Module之外
        if (F.isDeclaration())
            continue;
        FPasses-&gt;run(F);
    &#125;
    FPasses-&gt;doFinalization();
    AAResults &amp;AAR &#x3D; AARPass-&gt;getAAResults();
    for (Module::iterator f &#x3D; M-&gt;begin(), fe &#x3D; M-&gt;end();
            f !&#x3D; fe; ++f) &#123;
        Function* F &#x3D; &amp;*f;
        PointerAnalysisMap aliasPtrs;
        if (F-&gt;empty())
            continue;
        detectAliasPointers(F, AAR, aliasPtrs);
        
        Ctx-&gt;FuncPAResults[F] &#x3D; aliasPtrs;
        Ctx-&gt;FuncAAResults[F] &#x3D; &amp;AAR;
    &#125;
    return false;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
其使用<code>legacy::FunctionPassManager</code>创建了一个旧版的Function
Pass Manager，并将Pointer Analysis分析Pass
<code>AAResultsWrapperPass</code>添加进去。</p>
<p>​ 接下来使用(Function &amp;F :
*M）语句遍历Module中的每个函数，如果该函数F的定义不在Module之外，则运行<code>AAResultsWrapperPass</code>，并通过<code>AAResult</code>结构获取分析结果。</p>
<p>​
接下来再次遍历Module中的每个Function，对其调用函数<code>detectAliasPointers</code>：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;PointerAnalysis.cc
void PointerAnalysisPass::detectAliasPointers(Function* F, AAResults &amp;AAR, 
        PointerAnalysisMap &amp;aliasPtrs) &#123;
    std::set&lt;Value *&gt; addr1Set;
    std::set&lt;Value *&gt; addr2Set;
    Value *Addr1, *Addr2;
    &#x2F;&#x2F;获取所有指针类型
    for (Argument &amp;A : F-&gt;args())
        if (A.getType()-&gt;isPointerTy())
            addr1Set.insert(&amp;A);
    for (Instruction &amp;I : instructions(*F))
        if (I.getType()-&gt;isPointerTy())
            addr1Set.insert(&amp;I);
    &#x2F;&#x2F;why??
    if (addr1Set.size() &gt; 1000) &#123;
        return;
    &#125;
    for (auto Addr1 : addr1Set) &#123;
        for (auto Addr2 : addr1Set) &#123;
            &#x2F;&#x2F;只分析不同的指针对
            if (Addr1 &#x3D;&#x3D; Addr2)
                continue;
            &#x2F;&#x2F;用于从总的分析结果里获取单对指针分析结果
            AliasResult AResult &#x3D; AAR.alias(Addr1, Addr2);
            bool notAlias &#x3D; true;
            if (AResult &#x3D;&#x3D; MustAlias || AResult &#x3D;&#x3D; PartialAlias) &#123;
                notAlias &#x3D; false;
              &#x2F;&#x2F;只要确定的
            &#125; else if (AResult &#x3D;&#x3D; MayAlias) &#123;
            &#125; 
            if (notAlias)
                continue;
            &#x2F;&#x2F;如果存在alias
            auto as &#x3D; aliasPtrs.find(Addr1);
            if (as &#x3D;&#x3D; aliasPtrs.end()) &#123;
                SmallPtrSet&lt;Value *, 16&gt; sv;
                sv.insert(Addr2);
                aliasPtrs[Addr1] &#x3D; sv;
            &#125; else &#123;
                as-&gt;second.insert(Addr2);
            &#125;
        &#125;
    &#125;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
<code>detectAliasPointers()</code>对每个输入的函数，首先用循环将其指针类参数和指针类指令都存储到集合addr1Set中，并且如果addr1Set存储的指针数量大于100则直接返回，不做分析（为什么？）。</p>
<p>​
接下来对addr1Set内的所有指针两两分析，使用AAResult.alias()函数获取两个指针的分析结果AResult，如果AResult为MustAlias/PartialAlias则将这个指针对存储到aliasPtrs中。</p>
<p>​
在<code>detectAliasPointers()</code>分析完后，将其Ailas分析结果存储到<code>Ctx-&gt;FuncPAResults[F]</code>中，将整个<code>AAResultsWrapperPass</code>的分析结果存储到<code>Ctx-&gt;FuncAAResults[F]</code>中，至此，PointerAnalysisPass分析完毕。</p>
<h3 id="crashanalyzer">2.6 CrashAnalyzer</h3>
<p>​ <strong>CrashAnalyzer用于确定反向污点分析的source。</strong></p>
<p>​ 在CrashAnalyzer.h中定义了CrashAnalyzer的构造函数：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;CrashAnalyzer.h
public:
    &#x2F;&#x2F;构造函数
    CrashAnalyzer(GlobalContext *Ctx_, bool cond_,
            &#x2F;*llvm::StringRef fn, 
            llvm::StringRef Sourcef_, unsigned l*&#x2F;
            llvm::StringRef CrashLoc
    )
        : IterativeModulePass(Ctx_, &quot;CrashAnalyzer&quot;) &#123;
        cond &#x3D; cond_;
        &#x2F;&#x2F; KA_LOGS(0, &quot;crash loc : &quot; &lt;&lt; CrashLoc &lt;&lt; &quot;\n&quot;);
        funcName &#x3D; CrashLoc.split(&quot; &quot;).first;
        auto loc &#x3D; CrashLoc.split(&quot; &quot;).second;
        source &#x3D; loc.split(&quot;:&quot;).first;
        line &#x3D; stoi(loc.split(&quot;:&quot;).second.str());
        &#x2F;&#x2F; KA_LOGS(0, &quot;parsed loc: &quot; &lt;&lt; funcName &lt;&lt; &quot;\n&quot;);
        &#x2F;&#x2F; KA_LOGS(0, &quot;source : &quot; &lt;&lt; source &lt;&lt; &quot;\n&quot;);
        &#x2F;&#x2F; KA_LOGS(0, &quot;Line: &quot; &lt;&lt; line &lt;&lt; &quot;\n&quot;);
        analyzed &#x3D; false;
        Ctx-&gt;InstNum &#x3D; 0;
    &#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
其继承了父类IterativeModulePass的构造函数，将Ctx设置为Ctx_，ID设置为“CrashAnalyzer”。接下来，设置cond（就是KAMain.cc中的explicity，用于表明是否在report中找到了显式可check点），并将CrashLoc中的函数名称与位置信息提取出来，分别赋值给变量funcName、loc、
source、line。最后将<code>Ctx-&gt;InstNum</code>设置为0。</p>
<p>​
<code>CrashAnalyzer::doModulePass</code>对每个函数运行<code>CrashAnalyzer::runOnFunction</code>
：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;CrashAnalyzer.cc
bool CrashAnalyzer::doModulePass(Module* M) &#123;
    &#x2F;&#x2F; some functions are defined in headers
    &#x2F;&#x2F; if (moduleName.str() !&#x3D; M-&gt;getSourceFileName()) 
    &#x2F;&#x2F;     return false;
    for (Function &amp;F : *M) 
        runOnFunction(&amp;F);
    return false;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
<code>CrashAnalyzer::runOnFunction()</code>会定位之前在<code>KAMain.cc</code>中定位的CrashLoc中的函数以及crash位置，并遍历该函数的每条指令：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;确定source
void CrashAnalyzer::runOnFunction(Function *F) &#123;
	&#x2F;&#x2F;只对carsh函数做分析
	if (funcName !&#x3D; F-&gt;getName() || analyzed)
          return;
     &#x2F;&#x2F;遍历每条指令
     for (inst_iterator i &#x3D; inst_begin(F), e &#x3D; inst_end(F); i !&#x3D; e; i++) &#123;
     	Instruction* I &#x3D; &amp;*i;
          &#x2F;&#x2F;DILocation metadata node provides information 
        	&#x2F;&#x2F;such as the file name, line number, 
       	&#x2F;&#x2F;and column number of the source code location 
        	&#x2F;&#x2F;corresponding to a particular instruction or operation in the IR
        	DILocation* Loc &#x3D; I-&gt;getDebugLoc();
          if (Loc &#x3D;&#x3D; nullptr) &#123;
            continue;
        	&#125;
          &#x2F;* remove &quot;.&#x2F;&quot; for header files *&#x2F;
        	StringRef sourceF &#x3D; Loc-&gt;getScope()-&gt;getFilename();
        	if (sourceF.startswith(&quot;.&#x2F;&quot;)) &#123;
            	sourceF &#x3D; sourceF.split(&quot;.&#x2F;&quot;).second;
        	&#125;
          
          if (line &#x3D;&#x3D; Loc-&gt;getLine() &amp;&amp; sourceF &#x3D;&#x3D; source) &#123;
          	&#x2F;&#x2F;显式&#x2F;隐式定位source
               &#x2F;&#x2F;......
          &#125;
     &#125;&#x2F;&#x2F;end of for
&#125;&#x2F;&#x2F;end of runOnFunction()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 由上述代码可知，定位到call trace中的crash函数后，代码根据LLVM
IR的debug信息来定位LLVM指令对应源代码的行数，以此定位到report中的crash行，例如对如下call
trace：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230509100607.png" style="zoom: 67%;" /></p>
<p>​
根据函数名来定位Module内的Crash函数，根据对应文件标志的代码行数来定位相关crash指令（遍历每个指令，根据metaData提供的debug信息查看指令对应的源码行数）。</p>
<h4 id="implicit-checking">2.6.1 Implicit Checking</h4>
<p>​
<strong><code>CrashAnalyzer::runOnFunction()</code>根据cond参数决定以显式/隐式的方式定位反向污点分析的source(即导致程序crash的指令)。</strong>当cond为false时，执行隐式检查(<em>Implicit
Checking</em>)：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;CrashAnalyzer.cc -&gt; runOnFunction()
&#x2F;&#x2F;Implicit Checking
&#x2F;&#x2F;如果没有可以明确check的点
&#x2F;&#x2F;则分析隐式Crash指令
if (!cond) &#123;
     &#x2F;&#x2F;isa&lt;&gt; 与 java中的instanceof用法一致
     &#x2F;&#x2F;用于测试I是否是LoadInst&#x2F;StoreInst类型
     &#x2F;&#x2F;是则返回true，否则返回false
     if (isa&lt;LoadInst&gt;(I) || isa&lt;StoreInst&gt;(I)) &#123;
         Ctx-&gt;TaintSrc.insert(I);
         Ctx-&gt;InstNum ++;
     &#125; 
     &#x2F;&#x2F;如果是Call指令
     else if (isa&lt;CallInst&gt;(I)) &#123;
         Function *F &#x3D; cast&lt;CallInst&gt;(I)-&gt;getCalledFunction();
         &#x2F;&#x2F;如果不是直接调用指令则直接返回
         if (F &#x3D;&#x3D; nullptr) &#123;
             KA_WARNS(0, &quot;Fail to find Function from the CallInst &quot;&lt;&lt;*I);
             continue;
         &#125;
         StringRef Fname &#x3D; F-&gt;getName();
         &#x2F;* since we skip some debugging functions in the first step
         let&#39;s taint starting from these functions&#39; argument *&#x2F;
          
         &#x2F;&#x2F;若Callee是skipFunc，则该Call指令作为source
         if (skipFunc.find(Fname) !&#x3D; skipFunc.end()) &#123;
             Ctx-&gt;TaintSrc.insert(I);
         &#x2F;&#x2F;若Callee函数名包含&quot;__write_once_size&quot;
         &#x2F;&#x2F;获取Call指令的第一个参数作为source
         &#125; else if (Fname.find(&quot;__write_once_size&quot;) !&#x3D; string::npos) &#123;
             Ctx-&gt;TaintSrc.insert(cast&lt;CallInst&gt;(I)-&gt;getArgOperand(0));
         &#125;else &#123;
             KA_WARNS(0, &quot;Unknown call here &quot;&lt;&lt;*I);
         &#125;
     &#125; 
     &#x2F;&#x2F;既不是存储&#x2F;加载指令，也不是call指令，放弃
     else &#123;
         KA_LOGS(1, &quot;Unknown Inst here &quot;&lt;&lt;*I);
     &#125;
&#125;&#x2F;&#x2F;end of implicit checking
&#x2F;&#x2F;explicit checking
else&#123;
     &#x2F;&#x2F;...
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 对于implicit checking：</p>
<p>​ 1） <u>若定位的指令是LoadInst/StoreInst类型：</u></p>
<p>​ 直接将此指令作为source。</p>
<p>​ 2） <u>若定位的指令是CallInst类型：</u></p>
<p>​
若该Call不是直接调用则直接丢弃；否则若其Callee是skipFunc，直接将该指令作为source；或者其Callee函数名包含“__write_once_size”，将该Call指令的第一个操作数作为source。</p>
<p>​ 3） <u>若以上二者都不是：</u></p>
<p>​ 丢弃。</p>
<h4 id="explicit-checking">2.6.2 Explicit Checking</h4>
<p>​ 当cond为ture时，执行显式检查(<em>Explicit
Checking</em>)。对于显式检查，GREBE文章中的定义是有明确错误检查功能的预定义宏（如WARN_ON和BUG_ON）、辅助函数等，其共性是在代码中直接进行检查，故代码中只分析CallInst类型指令：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;CrashAnalyzer.cc -&gt; runOnFunction()
&#x2F;&#x2F;explicit checking
else&#123;
	 if (isa&lt;CallInst&gt;(I)) &#123;
           CallInst *CI &#x3D; cast&lt;CallInst&gt;(I);
           &#x2F;&#x2F;获取直接调用子函数
           Function *F &#x3D; CI-&gt;getCalledFunction();
           StringRef Fname &#x3D; &quot;&quot;; &#x2F;&#x2F; if calling asm
           if (F !&#x3D; nullptr) &#123;
           	Fname &#x3D; F-&gt;getName();
           &#125;
      	&#x2F;&#x2F;......
      &#125;
&#123;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 针对不同的调用情况，其具体处理如下：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;* handle ODEBUG and DEBUG_OBJECTS_FREE.
* which generate warns using &quot;implicit&quot;
* checkings
*&#x2F;
if (Fname.find(&quot;init_work&quot;) !&#x3D; string::npos ||
    Fname.find(&quot;print_unlock_imbalance_bug&quot;) !&#x3D; string::npos ||
    Fname.find(&quot;debug_print_object&quot;) !&#x3D; string::npos ||
    Fname.find(&quot;debug_object_init&quot;) !&#x3D; string::npos ||
    Fname.find(&quot;debug_assert_init&quot;) !&#x3D; string::npos ||
    &#x2F;* DEBUG_OBJECTS_FREE *&#x2F;
    Fname.find(&quot;debug_check_no_obj_freed&quot;) !&#x3D; string::npos) &#123;
     Ctx-&gt;TaintSrc.insert(I);
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 对于子函数名中存在“printk”/内联汇编调用的，进行如下处理：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;定位指令属于的BB
BasicBlock *BB &#x3D; CI-&gt;getParent();
KA_LOGS(2, &quot;Found BB : &quot;&lt;&lt;*BB);
KA_LOGS(2, &quot;terminator : &quot;&lt;&lt;*BB-&gt;getTerminator());
Value *condV;
bool warnOnce &#x3D; false;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 接着进行如下处理：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">while (BB-&gt;getSinglePredecessor()) &#123;
     &#x2F;&#x2F;Predecessor，前身，指在控制流中一个基本块的上一个块
     BasicBlock *newBB &#x3D; BB-&gt;getSinglePredecessor();
     &#x2F;* heuristic: if sotring true to &#96;refcount_inc_checked.__warned&#96;
                             * exists in the skipped BB, there should exist an redundant
                             * checking for the &#96;refcount_inc_checked.__warned&#96; *&#x2F;
     &#x2F;&#x2F;遍历基本块中的每条指令
     for (Instruction &amp;BBInst : *BB) &#123;
          &#x2F;&#x2F;如果是StoreInst类型
          if (isa&lt;StoreInst&gt;(&amp;BBInst)) &#123;
               StoreInst *SI &#x3D; cast&lt;StoreInst&gt;(&amp;BBInst);
               &#x2F;&#x2F;如果StoreInst指令的第一个参数为常数
               &#x2F;&#x2F;&amp;&amp; 第二个参数为全局变量
               if (isa&lt;ConstantInt&gt;(SI-&gt;getOperand(0))
                   &amp;&amp; isa&lt;GlobalVariable&gt;(SI-&gt;getOperand(1))) &#123;
                    &#x2F;&#x2F;获取第二个参数的名称
                    StringRef GVName &#x3D; cast&lt;GlobalVariable&gt;(SI-&gt;getOperand(1))-&gt;getName();
                    KA_LOGS(0, &quot;Found Global Value: &quot;&lt;&lt;GVName);
                    &#x2F;&#x2F;如果全局变量名称包含“__warned”
                    &#x2F;&#x2F;并且子函数F存在（直接调用）
                    &#x2F;&#x2F;并且子函数名称包含“__warn_printk”
                    if (GVName.find(&quot;__warned&quot;) !&#x3D; string::npos &amp;&amp;
                        F &amp;&amp; F-&gt;getName().find(&quot;__warn_printk&quot;) !&#x3D; string::npos) &#123;
                         KA_LOGS(0, &quot;Warn ONCE checking here....&quot;);
                         warnOnce &#x3D; true;
                    &#125;
               &#125;
          &#125;
     &#125;
	&#x2F;&#x2F;如果是BranchInst类型
     if (isa&lt;BranchInst&gt;(newBB-&gt;getTerminator())) &#123;
          &#x2F;&#x2F;getTerminator()获取基本块的终止指令，例如分支指令br，ret等
          &#x2F;&#x2F;如果Predecessor块中的终止指令是BranchInst类型
          BranchInst *BI &#x3D; cast&lt;BranchInst&gt;(newBB-&gt;getTerminator());
          &#x2F;&#x2F;检查该br指令是否是条件跳转，isConditional()
	    &#x2F;&#x2F;isConditional()返回true&#x2F;false
          if (BI-&gt;isConditional()) &#123;
               KA_LOGS(0, &quot;Found first condition : &quot;&lt;&lt;*BI-&gt;getCondition());
               condV &#x3D; BI-&gt;getCondition();
               break;
          &#125;
     &#125;
     &#x2F;&#x2F;如果父块的终止指令不是conditional br，则继续向上寻找
     BB &#x3D; newBB;
     KA_LOGS(1, &quot;Skipping BB: &quot;&lt;&lt;*BB);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 如果指令的父基本块的终止指令是一个contional
br并且指令所在的基本块不存在上述的warn调用，则将condition指令设置为污点源source：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;*
* if we find a condition value and the logging is not WARN_ONCE,
* we mark the condition value as taint source and continue.
* *&#x2F;
if (condV &amp;&amp; !warnOnce ) &#123;
     Ctx-&gt;TaintSrc.insert(condV);
     continue;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 接下来进行广度优先搜索：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; null the condition
Value *SecondCondV &#x3D; nullptr;

&#x2F;&#x2F; breadth first search
std::vector&lt;BasicBlock *&gt; BBVec;
std::set&lt;BasicBlock *&gt; BBSet;
BBVec.push_back(BB);
&#x2F;&#x2F;......<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">while (!BBVec.empty() &amp;&amp; !SecondCondV) &#123;
     BB &#x3D; BBVec.back();
     BBVec.pop_back();

     &#x2F;&#x2F; cyclic basic block
     if (!BBSet.insert(BB).second) &#123;
          continue;
     &#125;

     if (!BB-&gt;hasNPredecessorsOrMore(1)) &#123;
          &#x2F;* no predecessor, let&#39;s find find its parents *&#x2F;
          &#x2F;&#x2F;getParent()用于获取当前基本块所在函数
          auto fName &#x3D; BB-&gt;getParent()-&gt;getName();
          &#x2F;&#x2F;如果该函数在report报告的Call trace中
          if (Ctx-&gt;CallGraph.find(fName) !&#x3D; Ctx-&gt;CallGraph.end()) &#123;
               auto callerName &#x3D; Ctx-&gt;CallGraph[fName];
               for (auto M : Ctx-&gt;Callers) &#123;
                    if (M.first-&gt;getName().endswith(fName)) &#123;
                         auto CISet &#x3D; M.second;
                         for (CallInst *caller : CISet) &#123;
                              &#x2F;&#x2F;根据调用图找到parent
                              if (caller-&gt;getFunction()-&gt;getName()
                                  &#x3D;&#x3D; callerName) &#123;
                                   BB &#x3D; caller-&gt;getParent();
                                   KA_LOGS(0, &quot;Backwarding to its parent &quot;&lt;&lt;callerName);
                                   break;
                              &#125;
                         &#125;
                    &#125;
               &#125;
          &#125;
     &#125;
	&#x2F;&#x2F;遍历其predecessors
     for (BasicBlock *Pred : predecessors(BB)) &#123;
          KA_LOGS(1, &quot;Found pre : &quot;&lt;&lt;*Pred);
          BBVec.push_back(Pred);
          if (isa&lt;BranchInst&gt;(Pred-&gt;getTerminator())) &#123;
               BranchInst *BI &#x3D; cast&lt;BranchInst&gt;(Pred-&gt;getTerminator());
               if (BI-&gt;isConditional()
                   &amp;&amp; condV !&#x3D; BI-&gt;getCondition()) &#123;
                    SecondCondV &#x3D; BI-&gt;getCondition();
                    assert(SecondCondV);
                    KA_LOGS(0, &quot;Found 1st condition : &quot;&lt;&lt;*condV);
                    KA_LOGS(0, &quot;Found 2nd condition : &quot;&lt;&lt;*SecondCondV);
                    break;
               &#125;
          &#125;
     &#125;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">if (SecondCondV) &#123;
     Ctx-&gt;TaintSrc.insert(SecondCondV);
     continue;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 这里具体为什么要这么做还需深入探索。</p>
<h3 id="backward-taint-analysis">2.7 Backward Taint Analysis</h3>
<p>​ 污点分析过程存储在<code>StructFinderPass::doAnalyze()</code>中：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; StructFinder.cc -&gt; doAnalyze()
&#x2F;&#x2F; v是污点源
void StructFinderPass::doAnalyze(Value *v) &#123;
    VSet vs;
    vs.clear();
    &#x2F;&#x2F; 将污点分析的结果存储到全局变量Ctx-&gt;CriticalSt中
    mergeSet(Ctx-&gt;CriticalSt, taintAnalysis(v, vs, false));
&#125;
&#x2F;&#x2F; StructFinderPass -&gt; mergeSet()
static void mergeSet(std::set&lt;llvm::StringRef&gt; &amp;a, std::set&lt;llvm::StringRef&gt; b) &#123;
    a.insert(b.begin(), b.end());
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
接下来进入正式的污点分析过程<code>StructFinderPass::taintAnalysis</code>，首先遍历污点源的用户指令，对其中的Cast指令进行处理：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;StructFinder.cc -&gt; taintAnalysis()
std::set&lt;llvm::StringRef&gt; result;
&#x2F;&#x2F;每个污点源单独一个result
result.clear();
if (!vs.insert(V).second) &#123;
     return result;
&#125;
&#x2F;&#x2F; debuging!!! remove this when deploying blockset
&#x2F;&#x2F; found &#x3D; false;
KA_LOGV(0, V);
&#x2F;&#x2F; find the casting...
&#x2F;&#x2F; V-&gt;users()获取污点源的用户指令
for (auto *user : V-&gt;users()) &#123;
     &#x2F;&#x2F;BitCastInst类型是LLVM的数据类型转换指令
     &#x2F;&#x2F;其转换数据格式但不改变其存储方式
     &#x2F;&#x2F;例如：
     &#x2F;&#x2F;%ptr &#x3D; alloca i32*
     &#x2F;&#x2F;%casted_ptr &#x3D; bitcast i32** %ptr to i8**
     if (isa&lt;BitCastInst&gt;(user)) &#123;
          BitCastInst *BCI &#x3D; dyn_cast&lt;BitCastInst&gt;(user);
          &#x2F;&#x2F; getDestTy &#x3D; get distination type
          Type *dst &#x3D; BCI-&gt;getDestTy();
          &#x2F;&#x2F; *Type -&gt; StringRef
          auto name &#x3D; handleType(dst);
          KA_LOGS(0, &quot;Found &quot;&lt;&lt;name&lt;&lt;&quot; in casting&quot;);
          addToSet(result, name);
     &#125;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
可见，只要污点源的用户指令是BitCastInst类型，就将该指令的DestType的名称加入result中。</p>
<p>​
接下来，对污点源本身分为三类：<code>Instruction</code>、<code>Argument</code>与<code>GlobalVaribal</code>，三类污点源分别进行不同的处理。无需赘述，<code>Instruction</code>类型就是指令类型；<code>Argument</code>类型用于描述函数声明，<code>GlobalVaribal</code>表示全局变量。</p>
<h4 id="structfinderpasshandletype">0. StructFinderPass::handleType</h4>
<p>​
handleType()函数用于获取struct/int的名称，如果传入的type是指针或数组则递归查找其指向类型。</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">StringRef StructFinderPass::handleType(Type *ty) &#123;
    
    if (ty &#x3D;&#x3D; nullptr)
        return StringRef(&quot;&quot;);

    if (ty-&gt;isStructTy()) &#123;
        StructType *ST &#x3D; dyn_cast&lt;StructType&gt;(ty);
        StringRef stname &#x3D; ST-&gt;getName();
        &#x2F;&#x2F;如果该结构以struct.为首，
        &#x2F;&#x2F;并且不是匿名结构
        if (stname.startswith(&quot;struct.&quot;)
                &amp;&amp; !stname.startswith(&quot;struct.anon&quot;))
            return stname;

    &#125; else if (ty-&gt;isPointerTy())&#123;
        ty &#x3D; cast&lt;PointerType&gt;(ty)-&gt;getElementType();
        return handleType(ty);
    &#125; else if (ty-&gt;isArrayTy())&#123;
        ty &#x3D; cast&lt;ArrayType&gt;(ty)-&gt;getElementType();
        return handleType(ty);
    &#125; else if (ty-&gt;isIntegerTy()) &#123;
        return StringRef(&quot;int&quot;);
    &#125;

    return StringRef(&quot;&quot;);    
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="instruction类型source">1.
<code>Instruction</code>类型source：</h4>
<p>​ 针对不同类型的Insturction再分别处理.</p>
<h5 id="instructionstore">1.1 Instruction::Store:</h5>
<ul>
<li>​ 在LLVM IR中，store指令的格式如下：</li>
</ul>
<pre class="line-numbers language-llvm" data-language="llvm"><code class="language-llvm"><span class="token variable">%value</span> <span class="token punctuation">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token variable">%ptr</span> <span class="token punctuation">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token keyword">store</span> <span class="token punctuation">&lt;</span><span class="token keyword">type1</span><span class="token punctuation">></span> <span class="token variable">%value</span><span class="token punctuation">,</span> <span class="token punctuation">&lt;</span><span class="token keyword">type2</span><span class="token punctuation">></span><span class="token punctuation">*</span> <span class="token variable">%ptr</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>​
其表明将type1格式的value存入type2格式的指针ptr所指向的内存中。type1与type2必须相同或者兼容。</p>
<ul>
<li>​ 在LLVM IR中，getelementptr指令的格式如下：</li>
</ul>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230512164203.png" style="zoom:50%;" /></p>
<pre class="line-numbers language-llvm" data-language="llvm"><code class="language-llvm"><span class="token variable">%array</span> <span class="token punctuation">=</span> <span class="token keyword">alloca</span> <span class="token punctuation">[</span><span class="token number">10</span> <span class="token keyword">x</span> <span class="token type class-name">i32</span><span class="token punctuation">]</span>
<span class="token variable">%element_ptr</span> <span class="token punctuation">=</span> <span class="token keyword">getelementptr</span> <span class="token punctuation">[</span><span class="token number">10</span> <span class="token keyword">x</span> <span class="token type class-name">i32</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">10</span> <span class="token keyword">x</span> <span class="token type class-name">i32</span><span class="token punctuation">]</span><span class="token punctuation">*</span> <span class="token variable">%array</span><span class="token punctuation">,</span> <span class="token type class-name">i32</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token type class-name">i32</span> <span class="token number">3</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​
<u>其用于计算结构中某个元素的指针，C语言中所有对数组/结构体的取值操作都会被翻译为getelementptr。</u></p>
<ul>
<li>​ 在LLVM
IR中，load/store指令经常与getelementptr指令一起使用，用于表示对数组/结构体的赋值操作，例如：</li>
</ul>
<pre class="line-numbers language-llvm" data-language="llvm"><code class="language-llvm"><span class="token variable">%arr</span> <span class="token punctuation">=</span> <span class="token keyword">alloca</span> <span class="token punctuation">[</span><span class="token number">10</span> <span class="token keyword">x</span> <span class="token type class-name">i32</span><span class="token punctuation">]</span>
<span class="token variable">%x</span> <span class="token punctuation">=</span> <span class="token keyword">load</span> <span class="token type class-name">i32</span><span class="token punctuation">,</span> <span class="token type class-name">i32</span><span class="token punctuation">*</span> <span class="token keyword">getelementptr</span> <span class="token keyword">inbounds</span> <span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10</span> <span class="token keyword">x</span> <span class="token type class-name">i32</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">10</span> <span class="token keyword">x</span> <span class="token type class-name">i32</span><span class="token punctuation">]</span><span class="token punctuation">*</span> <span class="token variable">%arr</span><span class="token punctuation">,</span> <span class="token type class-name">i64</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token type class-name">i64</span> <span class="token number">3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<pre class="line-numbers language-llvm" data-language="llvm"><code class="language-llvm"><span class="token variable">%arr</span> <span class="token punctuation">=</span> <span class="token keyword">alloca</span> <span class="token punctuation">[</span><span class="token number">10</span> <span class="token keyword">x</span> <span class="token type class-name">i32</span><span class="token punctuation">]</span>
<span class="token variable">%3</span> <span class="token punctuation">=</span> <span class="token keyword">getelementptr</span> <span class="token keyword">inbounds</span> <span class="token punctuation">[</span><span class="token number">10</span> <span class="token keyword">x</span> <span class="token type class-name">i32</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">10</span> <span class="token keyword">x</span> <span class="token type class-name">i32</span><span class="token punctuation">]</span><span class="token punctuation">*</span> <span class="token variable">%arr</span><span class="token punctuation">,</span> <span class="token type class-name">i64</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token type class-name">i64</span> <span class="token number">3</span>
<span class="token keyword">store</span> <span class="token type class-name">i32</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token type class-name">i32</span><span class="token punctuation">*</span> <span class="token variable">%3</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>​ 上述两个代码块分别表示从数组中取值和为数组某个成员赋值。</p>
<p>​ 针对store指令的分析过程如下：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; StructFinder.cc -&gt; taintAnalysis()
&#x2F;&#x2F; if (auto *I &#x3D; dyn_cast&lt;Instruction&gt;(V)) 
&#x2F;&#x2F; I-&gt;getOpcode() &#x3D;&#x3D; Instruction::Store:

case Instruction::Store:&#123;
     StoreInst *SI &#x3D; cast&lt;StoreInst&gt;(I);
     &#x2F;&#x2F;获取指针类型
     Type *SType &#x3D; SI-&gt;getPointerOperandType();
     &#x2F;&#x2F;*Type -&gt; StringRef
     StringRef stName &#x3D; handleType(SType);
	&#x2F;&#x2F;如果该指针类型已经在该source的result中了则跳过分析
     if (!addToSet(result, stName)) &#123;
          break;
     &#125;
	
     &#x2F;&#x2F; would find a GetElementType
     if (!isa&lt;GetElementPtrInst&gt;(SI-&gt;getOperand(0))) &#123;
          &#x2F;&#x2F; assert(0 &amp;&amp; &quot;didn&#39;t find a GetElementPtrInst before StoreInst&quot;);
     &#125;

     Value *GetV &#x3D; SI-&gt;getOperand(1);

     &#x2F;&#x2F; we skip these getElement since they are nested
     while (isa&lt;GetElementPtrInst&gt;(GetV)) &#123;
          GetElementPtrInst *GEI &#x3D; cast&lt;GetElementPtrInst&gt;(GetV);
          &#x2F;&#x2F;getSourceElementType()获取取值操作的原地址
          &#x2F;&#x2F;hanleType获取类型名称，例如结构的名称
          StringRef name &#x3D; handleType(GEI-&gt;getSourceElementType());
	    &#x2F;&#x2F;如果该结构已经处理则跳过
          if (!addToSet(result, name)) &#123;
               break;
          &#125;
	    &#x2F;&#x2F;继续递归，向上寻找其操作指针
          GetV &#x3D; GEI-&gt;getOperand(0);
     &#125;

     &#x2F;&#x2F; the outside GetElementPtrInst
     &#x2F;&#x2F; 处理最后的的GteV
     mergeSet(result, taintAnalysis(GetV, vs, found));
     break;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 正常来说，对于一个store指令，如果其value
（Operand(0)）为污点源，那污点就会通过该指令传播到对应的ptr中去（Operand(1)）。但由于C语言中存在对数组/结构体取值的操作，故store指令的Ptr也可能是<code>GetElementPtrInst</code>类型，所以代码中存在对store指令操作数的反复递归迭代，如下图所示：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230512171505.png" alt="store指令的迭代问题" style="zoom:50%;" /></p>
<h5 id="instructionload">1.2 Instruction::load</h5>
<p>​ load指令的作用是从目标地址取操作数，其格式如下：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230512172747.png" style="zoom:50%;" /></p>
<p>​ load指令将ptr所指向的数据以&lt; type
&gt;的形式取出，并存入%1中。</p>
<p>​ Load指令处理部分：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">case Instruction::Load:&#123;
     &#x2F;&#x2F; should pair with a GetElementPtr
     &#x2F;&#x2F; remember to check if it is nested
     LoadInst *LI &#x3D; cast&lt;LoadInst&gt;(I);
     Type *lType &#x3D; LI-&gt;getPointerOperandType();
     &#x2F;&#x2F;获取ptr指向的结构名称
     StringRef stName &#x3D; handleType(lType);
     if (!addToSet(result, stName)) &#123;
          break;
     &#125;
	&#x2F;&#x2F;如果Load指令的ptr指向的结构以&quot;struct.list_head&quot;开头
     &#x2F;&#x2F;并且Load指令的第一个参数为ConstantExpr(算术式)类型
     if (stName &#x3D;&#x3D; &quot;struct.list_head&quot; &amp;&amp;
         isa&lt;ConstantExpr&gt;(LI-&gt;getOperand(0))) &#123;
          &#x2F;&#x2F; looking type info in list_head
          Value *bitcastV &#x3D; nullptr;
		&#x2F;&#x2F;分析污点源的所有用户指令
          for (auto *user : V-&gt;users()) &#123;
               &#x2F;&#x2F;如果用户指令是phi指令
               if (isa&lt;PHINode&gt;(user)) &#123;
                    &#x2F;&#x2F;继续获取其父指令
                    for (auto *uuser : user-&gt;users()) &#123;
                         &#x2F;&#x2F;如果其是一个类型转换指令
                         if (isa&lt;BitCastInst&gt;(uuser)) &#123;
                              bitcastV &#x3D; uuser;
                         &#125;
                    &#125;
               &#125;
          &#125;
	    &#x2F;&#x2F;如果找不到类型转换指令则跳过
          if (bitcastV &#x3D;&#x3D; nullptr) &#123;
               break;
          &#125;
	    &#x2F;&#x2F;遍历bitcast指令的父指令
          for (auto *user : bitcastV-&gt;users()) &#123;
               &#x2F;&#x2F;如果其父指令也是bitcast
               if (isa&lt;BitCastInst&gt;(user)) &#123;
                    BitCastInst *BCI &#x3D; dyn_cast&lt;BitCastInst&gt;(user);
                    Type *src &#x3D; BCI-&gt;getDestTy();
                    &#x2F;&#x2F;将转换后的类型名称加入result
                    if (!addToSet(result, handleType(src))) &#123;

                    &#125;
               &#125;
          &#125;
          break;
     &#125;
     &#x2F;&#x2F; would find a GetElementType
     if (!isa&lt;GetElementPtrInst&gt;(LI-&gt;getOperand(0))) &#123;
          &#x2F;&#x2F; it may not in some cases
          &#x2F;&#x2F; outs() &lt;&lt; &quot;in &quot; &lt;&lt; LI-&gt;getFunction()-&gt;getName() &lt;&lt; &quot;\n&quot;;
          &#x2F;&#x2F; assert(0 &amp;&amp; &quot;didn&#39;t find a GetElementPtrInst before LoadInst&quot;);
     &#125;
	&#x2F;&#x2F;同store指令，继续递归分析
     Value *GetV &#x3D; LI-&gt;getOperand(0);
     &#x2F;&#x2F; we skip these getElement since they are nested
     while (isa&lt;GetElementPtrInst&gt;(GetV)) &#123;
          GetElementPtrInst *GEI &#x3D; cast&lt;GetElementPtrInst&gt;(GetV);
          StringRef name &#x3D; handleType(GEI-&gt;getSourceElementType());

          if (!addToSet(result, name)) &#123;
               break;
          &#125;

          GetV &#x3D; GEI-&gt;getOperand(0);
     &#125;
     &#x2F;&#x2F; the outside GetElementPtrInst
     mergeSet(result, taintAnalysis(GetV, vs, found));
     break;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
如上述代码所示，load指令与store指令相比增加了<code>struct.list_head</code>的分析部分，list_head是Linux内核中的经典双向链表，其定义如下：</p>
<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">struct</span> <span class="token class-name">list_head</span> <span class="token punctuation">&#123;</span>
	<span class="token keyword">struct</span> <span class="token class-name">list_head</span> <span class="token operator">*</span>next<span class="token punctuation">,</span> <span class="token operator">*</span>prev<span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>​
针对<code>struct.list_head</code>，若其满足<code>stName == "struct.list_head" &amp;&amp; isa&lt; ConstantExpr &gt;(LI&gt;getOperand(0))</code>：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230514193930.png" style="zoom:50%;" /></p>
<p>​
则代表其Load指令的type为<code>struct.list_head</code>类型且对应的指针ptr是<code>ConstantExpr</code>算术式类型，则分析该Load指令的所有父指令，其具体分析流程如下：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230514200619.png" style="zoom:50%;" /></p>
<p>​
对于某个Load指令污点源，分析其父指令里的phi指令，再分析phi指令的父指令，找到其中的bitcast指令，后续再次分析这个bitcast指令的父指令：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230514201549.png" style="zoom:50%;" /></p>
<p>​
如果bitcastV的父指令也为bitcast指令，则将其目标type（即上图最后一行的type2）所指向的结构名称加入result集中。接下来针对<code>GetElementPtrInst</code>的分析同store指令，具体过程见上述代码。</p>
<h5 id="instructioncall">1.3 Instruction::Call</h5>
<p>​
遍历Call指令的所有参数，如果如果该参数不是某个结构体中的引用则将其指向的结构名加入result，然后递归深入分析arg参数：</p>
<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">case</span> Instruction<span class="token operator">::</span>Call<span class="token operator">:</span><span class="token punctuation">&#123;</span>
     CallInst <span class="token operator">*</span>CI <span class="token operator">=</span> cast<span class="token operator">&lt;</span>CallInst<span class="token operator">></span><span class="token punctuation">(</span>I<span class="token punctuation">)</span><span class="token punctuation">;</span>
     <span class="token comment">//遍历其参数列表</span>
     <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">auto</span> AI <span class="token operator">=</span> CI<span class="token operator">-></span><span class="token function">arg_begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> E <span class="token operator">=</span> CI<span class="token operator">-></span><span class="token function">arg_end</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> AI <span class="token operator">!=</span> E<span class="token punctuation">;</span> AI<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
          <span class="token comment">//获取单个参数</span>
          Value<span class="token operator">*</span> arg <span class="token operator">=</span> dyn_cast<span class="token operator">&lt;</span>Value<span class="token operator">></span><span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token operator">*</span>AI<span class="token punctuation">)</span><span class="token punctuation">;</span>
          <span class="token comment">//跳过常数</span>
          <span class="token keyword">if</span> <span class="token punctuation">(</span>dyn_cast<span class="token operator">&lt;</span>Constant<span class="token operator">></span><span class="token punctuation">(</span>arg<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
               <span class="token keyword">continue</span><span class="token punctuation">;</span>
          <span class="token punctuation">&#125;</span>
          <span class="token comment">// if not &amp;a->b</span>
          <span class="token comment">// 如果该参数不是某个结构体中的引用（后续会分析）</span>
          <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>isa<span class="token operator">&lt;</span>GetElementPtrInst<span class="token operator">></span><span class="token punctuation">(</span>arg<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
               <span class="token keyword">auto</span> name <span class="token operator">=</span> <span class="token function">handleType</span><span class="token punctuation">(</span>arg<span class="token operator">-></span><span class="token function">getType</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
               <span class="token function">addToSet</span><span class="token punctuation">(</span>result<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">;</span>
          <span class="token punctuation">&#125;</span>
          <span class="token comment">// taint argument</span>
          <span class="token comment">// 继续递归分析</span>
          <span class="token function">mergeSet</span><span class="token punctuation">(</span>result<span class="token punctuation">,</span> <span class="token function">taintAnalysis</span><span class="token punctuation">(</span>arg<span class="token punctuation">,</span> vs<span class="token punctuation">,</span> found<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
     <span class="token punctuation">&#125;</span>
     <span class="token keyword">break</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="instructiongetelementptr">1.4 Instruction::GetElementPtr</h5>
<p>​ GetElementPtr指令的分析大体同上，也是递归分析，详见如下代码：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">case Instruction::GetElementPtr:&#123;
     &#x2F;&#x2F; this is nested
     GetElementPtrInst *GEI &#x3D; cast&lt;GetElementPtrInst&gt;(I);

     &#x2F;&#x2F; while (isa&lt;GetElementPtrInst&gt;(GEI-&gt;getOperand(0))) &#123;
     &#x2F;&#x2F;     &#x2F;&#x2F; nest struct
     &#x2F;&#x2F;     Type *src &#x3D; GEI-&gt;getSourceElementType();
     &#x2F;&#x2F;     GEI &#x3D; cast&lt;GetElementPtrInst&gt;(I);
     &#x2F;&#x2F; &#125;

     Type *src &#x3D; GEI-&gt;getSourceElementType();
     &#x2F;&#x2F; handle type
     auto name &#x3D; handleType(src);
     if (!addToSet(result, name)) &#123;
          break;
     &#125;
     &#x2F;&#x2F; addToSet(result, name);

     mergeSet(result, taintAnalysis(GEI-&gt;getOperand(0), vs, found));

     &#x2F;&#x2F; handle GetElementPtr other operands
     for (unsigned i &#x3D; 1, e &#x3D; I-&gt;getNumOperands(); i !&#x3D; e; i++) &#123;
          V &#x3D; I-&gt;getOperand(i);
          if (dyn_cast&lt;Constant&gt;(V)) &#123;
               continue;
          &#125;
          &#x2F;&#x2F; taint value
          mergeSet(result, taintAnalysis(V, vs, found));
     &#125;
     break;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="instructionphi">1.5 Instruction::PHI</h5>
<p>​ LLVM IR中PHI指令的格式如下所示:</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230514204040.png" style="zoom: 50%;" /></p>
<p>​
phi指令用于不同代码块的分支判断，其根据不同代码块转移来的label选择value，对phi指令的相关函数操作如下所示：</p>
<blockquote>
<p><code>PHINode::getNumIncomingValues()</code>：返回PHI节点的入边数量，即上图方括号的数量；</p>
<p><code>PHINode::getIncomingValues(i)</code>：返回第i个节点的value；</p>
</blockquote>
<p>​ 具体代码如下所示：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">case Instruction::PHI:&#123;
     &#x2F;&#x2F; check code coverage here to find the node
     PHINode *PN &#x3D; cast&lt;PHINode&gt;(I);
     &#x2F;&#x2F;遍历每个入边节点
     for (unsigned i &#x3D; 0, e &#x3D; PN-&gt;getNumIncomingValues(); i !&#x3D; e; i++) &#123;
          &#x2F;&#x2F;获取该节点的value
          Value* IV &#x3D; PN-&gt;getIncomingValue(i);
          &#x2F;&#x2F;这里什么都没做
          if (Instruction *II &#x3D; dyn_cast&lt;Instruction&gt;(IV)) &#123;
               &#x2F;&#x2F; if II not get covered
               &#x2F;&#x2F; continue
          &#125;
	    &#x2F;&#x2F;递归分析每个节点的value
          mergeSet(result, taintAnalysis(IV, vs, found));
     &#125;
     break;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="instructionalloca">1.6 Instruction::Alloca</h5>
<p>​ Alloca指令用于分配内存，这里遍历其所有父指令：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">case Instruction::Alloca:
     &#x2F;&#x2F; return
     &#x2F;&#x2F; solve alias
	&#x2F;&#x2F;遍历其所有父指令
     for (auto *user : V-&gt;users()) &#123;
          &#x2F;&#x2F;若是store指令
          if (isa&lt;StoreInst&gt;(user)) &#123;
               StoreInst *SI &#x3D; cast&lt;StoreInst&gt;(user);
               &#x2F;&#x2F;获取store的参数
               Value *next &#x3D; SI-&gt;getOperand(0);
               &#x2F;&#x2F;递归分析
               mergeSet(result, taintAnalysis(next, vs, found));
          &#125;
     &#125;
     break;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​</p>
<h5 id="instructionbitcast">1.7 Instruction::BitCast</h5>
<p>​ BitCast同理，具体见代码：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">case Instruction::BitCast:&#123;
     &#x2F;&#x2F; handle type info
     BitCastInst *BCI &#x3D; dyn_cast&lt;BitCastInst&gt;(V);
     Type *src &#x3D; BCI-&gt;getSrcTy();
     auto name &#x3D; handleType(src);
     if (!addToSet(result, name)) &#123;
          break;
     &#125;
     mergeSet(result, taintAnalysis(BCI-&gt;getOperand(0), vs, found));
     break;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="case-instructionselect">1.8 case Instruction::Select</h5>
<p>​ Select指令类似于C语言中的<code>x?:a:b</code>语法，其格式如下：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230514210450.png" style="zoom: 67%;" /></p>
<p>​ 其分析逻辑跟上述代码类似，详细见下：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">case Instruction::Select:
     for (unsigned i &#x3D; 0, e &#x3D; I-&gt;getNumOperands(); i !&#x3D; e; i++) &#123;
          V &#x3D; I-&gt;getOperand(i);
          &#x2F;&#x2F;排除常数
          if (dyn_cast&lt;Constant&gt;(V)) &#123;
               continue;
          &#125;
          &#x2F;&#x2F; taint value
          mergeSet(result, taintAnalysis(V, vs, found));
     &#125;
     break;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="argument类型source">2. <code>Argument</code>类型Source</h4>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">else if (auto *Arg &#x3D; dyn_cast&lt;Argument&gt;(V)) &#123;
     &#x2F;&#x2F; argument
     unsigned argNo &#x3D; Arg-&gt;getArgNo();
     StringRef name &#x3D; handleType(Arg-&gt;getType());

     if (!addToSet(result, name)) &#123;
          return result;
     &#125;
	&#x2F;&#x2F;获取参数属于的function
     Function* callee &#x3D; Arg-&gt;getParent();
	&#x2F;&#x2F;从Ctx-&gt;CallGraph中查找其父函数
     auto parentName &#x3D; findParents(callee-&gt;getName());
     bool matched &#x3D; false;

     CallInstSet CISet;
	&#x2F;&#x2F;遍历call graph
     &#x2F;&#x2F;typedef llvm::DenseMap&lt;llvm::CallInst*, FuncSet&gt; CalleeMap;
     for (auto M : Ctx-&gt;Callers) &#123;
          &#x2F;* use endswith here because functions in the Callers
             * are like &#96;filename&#96;.functionName
             *&#x2F; 
          if (M.first-&gt;getName().endswith(callee-&gt;getName()))
               CISet &#x3D; M.second;
          
		&#x2F;&#x2F;查找callee的所有caller
          for (CallInst *caller : CISet) &#123;
               &#x2F;&#x2F; TODO need pricise location check
               if (parentName.find(caller-&gt;getFunction()-&gt;getName())
                   !&#x3D; parentName.end()) &#123;
                    matched &#x3D; true;

                    auto parentFname &#x3D; caller-&gt;getFunction()-&gt;getName();
                    if (parentFname.find(&quot;_sys_&quot;) !&#x3D; string::npos)
                         continue;
                    if (BlockFunc.find(parentFname) !&#x3D; BlockFunc.end())
                         continue;

                    KA_LOGS(2, &quot;Taint to it&#39;s parent &quot;&lt;&lt;caller-&gt;getFunction()-&gt;getName()&lt;&lt;&quot; from &quot;&lt;&lt;callee-&gt;getName());
                    &#x2F;&#x2F;递归分析
                    mergeSet(result, taintAnalysis(caller-&gt;getArgOperand(argNo), vs, found));
               &#125;
          &#125;
     &#125;
     return result;
     &#x2F;* global variable *&#x2F;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="globalvariable类型source">3.
<code>GlobalVariable</code>类型Source</h4>
<p>​ 全局变量单纯的添加即可：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">else if (isa&lt;GlobalVariable&gt;(V)) &#123;
        GlobalVariable *GV &#x3D; cast&lt;GlobalVariable&gt;(V);
        StringRef name &#x3D; handleType(GV-&gt;getType());

        if (!addToSet(result, name)) &#123;
            return result;
        &#125;
    &#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​</p>
<p>​
综上所述，将污点分为instruction、argument和globalvariable三种类型，并分别分析，最终得到了一个结果集合result，这就是污点分析得到的关键结构对象。</p>
<p>​</p>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://github.com/Markakd/GREBE">Markakd/GREBE
(github.com)</a></li>
<li>LLVM Pass:
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/122522485">LLVM
Pass入门导引</a></li>
<li><a
href="https://github.com/llvm/llvm-project/tree/main/llvm">llvm-project/llvm
at main · llvm/llvm-project (github.com)</a></li>
<li><a href="https://llvm.org/docs/#llvm-design-overview">About — LLVM
17.0.0git documentation</a></li>
<li><a
href="https://llvm.org/devmtg/2019-04/slides/Tutorial-Bridgers-LLVM_IR_tutorial.pdf">PowerPoint
Presentation (llvm.org)</a></li>
<li><a
href="https://buaa-se-compiling.github.io/miniSysY-tutorial/pre/llvm_ir_ssa.html">LLVM
IR SSA 介绍 · GitBook (buaa-se-compiling.github.io)</a></li>
<li><a href="https://llvm.org/docs/WritingAnLLVMPass.html">Writing an
LLVM Pass — LLVM 17.0.0git documentation</a></li>
<li><a href="https://developer.aliyun.com/article/233367">LLVM每日谈之八
PASS例子分析- (aliyun.com)</a></li>
<li><a
href="https://blog.csdn.net/qq_23599965/article/details/88538590">LLVM开发者手册_llvm_shutdown_-CSDN</a></li>
<li><a href="https://www.llvm.org/docs/CommandLine.html">CommandLine 2.0
Library Manual — LLVM 17.0.0git documentation</a></li>
<li><a
href="https://llvm.org/doxygen/classllvm_1_1CallInst.html#details">LLVM:
llvm::CallInst Class Reference</a></li>
<li><a
href="https://groups.google.com/g/llvm-dev/c/CAExSXsHl0Q">LLVMdev]
indirect calls tracking and control flow graph (google.com)</a></li>
<li><a
href="https://stackoverflow.com/questions/44696177/llvm-declaring-an-indirect-function-call-in-c-that-becomes-a-storedinst">LLVM:
declaring an indirect function call in C that becomes a storedinst? -
Stack Overflow</a></li>
<li><a href="https://llvm.org/docs/AliasAnalysis.html">LLVM Alias
Analysis Infrastructure — LLVM 17.0.0git documentation</a></li>
<li><a
href="https://zhuanlan.zhihu.com/p/564950777">编译器优化：何为别名分析 -
知乎 (zhihu.com)</a></li>
<li><a href="https://llvm.org/docs/SourceLevelDebugging.html">Source
Level Debugging with LLVM — LLVM 17.0.0git documentation</a></li>
<li><a
href="https://blog.csdn.net/COMAC_919/article/details/130516527">I.users()_-CSDN博客</a></li>
</ul></li>
<li>kint：
<ul>
<li><a href="http://css.csail.mit.edu/kint/">KINT (mit.edu)</a></li>
<li><a
href="https://github.com/zhukailongaa/Kint-learn/blob/master/KINT学习记录.md">Kint-learn/KINT学习记录.md
at master · zhukailongaa/Kint-learn · GitHub</a></li>
<li><a href="https://github.com/CRYPTOlab/kint">CRYPTOlab/kint:
git://g.csail.mit.edu/kint (github.com)</a></li>
<li><a href="https://github.com/ganler/mini-kint">ganler/mini-kint:
Enhanced implementation of Kint in LLVM-14, in C++17.
(github.com)</a></li>
</ul></li>
<li>Paper:
<ul>
<li>Wang X, Chen H, Jia Z, et al. <strong>Improving integer security for
systems with KINT</strong>[C]//Presented as part of the 10th {USENIX}
Symposium on Opera。ting Systems Design and Implementation ({OSDI} 12).
2012: 163-177.</li>
<li>Song C, Lee B, Lu K, et al. <strong>Enforcing kernel security
invariants with data flow integrity</strong>[C]//NDSS. 2016.</li>
<li>Lin Z, Chen Y, Wu Y, et al. **GREBE: Unveiling exploitation
potential for Linux kernel bugs[**C]//2022 IEEE Symposium on Security
and Privacy (SP). IEEE, 2022.</li>
</ul></li>
<li>C/C++ &amp;&amp; Kernel:
<ul>
<li><a
href="https://zhuanlan.zhihu.com/p/50812510">被知乎大佬嘲讽后的一个月，我重新研究了一下内联函数
- 知乎 (zhihu.com)</a></li>
<li><a
href="https://stackoverflow.com/questions/28653072/how-can-i-get-function-name-of-indirect-call-from-callinst-in-llvm">c++
- How can I get Function Name of indirect call from CallInst in LLVM -
Stack Overflow</a></li>
<li><a
href="http://c.biancheng.net/view/228.html">函数指针及其定义和用法，C语言函数指针详解
(biancheng.net)</a></li>
<li><a
href="https://blog.csdn.net/tonny0832/article/details/12558493">内部链接(internal
linkage)和外部链接(external linkage)_CSDN博客</a></li>
<li><a
href="https://softwareengineering.stackexchange.com/questions/401110/difference-between-direct-and-indirect-function-calls">compiler
- Difference between direct and indirect function() calls - Software
Engineering Stack Exchange</a></li>
<li><a
href="https://blog.csdn.net/wanshilun/article/details/79747710">Linux内核中经典链表
list_head 常见使用方法解析_内核链表 CSDN博客</a></li>
</ul></li>
</ul>
<h2 id="ps">PS</h2>
<p>在人工分析前，先问问Cursor：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/image-20230418145234286.png" /></p>
<blockquote>
<p><strong>提问：这段代码的功能是什么？</strong></p>
<p><strong>AI：</strong>根据提供的代码，这是一个C++程序，用于对LLVM模块进行全局分析。它从输入文件中加载模块，执行基本初始化，并运行两个Pass：CallGraphPass和PointerAnalysisPass。</p>
<p>程序还从两个文件CrashReport和CallGraph中读取数据，以确定是否存在显式检查表达式并找到崩溃位置。如果在CrashReport文件中找到显式检查表达式，则程序将将“explicitly”标志设置为true。如果在CrashReport文件中找到“kernel
BUG
at”字符串，则程序还将将“explicitly”标志设置为true。然后，程序使用GlobalCtx和“explicitly”标志运行CrashAnalyzer来分析崩溃位置。</p>
<p>如果DumpLocation不为空，则程序将将分析结果转储到指定位置。否则，它将将结果转储到标准输出。最后，程序返回0。</p>
<p>因此，该程序的主要功能是对LLVM模块进行全局分析，并分析崩溃位置。</p>
<p><strong>提问：请介绍这段代码使用的LLVM API。</strong></p>
<p><strong>AI：</strong>根据提供的代码，该程序使用了LLVM的以下API：</p>
<p>- llvm::IRReader：用于从文件中读取LLVM IR。 -
llvm::LLVMContext：用于管理LLVM IR的上下文。 - llvm::Module：表示LLVM
IR模块。 - llvm::PassManager：用于管理LLVM Pass。 -
llvm::Verifier：用于验证LLVM IR的正确性。 -
llvm::ManagedStatic：用于管理静态对象的生命周期。 -
llvm::PrettyStackTrace：用于在程序崩溃时打印调用堆栈。 -
llvm::ToolOutputFile：用于将输出写入文件。 -
llvm::SystemUtils：提供了一些系统相关的实用函数。 -
llvm::FileSystem：提供了一些文件系统相关的实用函数。 -
llvm::SourceMgr：用于管理源文件和缓冲区。 -
llvm::Signals：用于处理信号。 -
llvm::Path：提供了一些路径相关的实用函数。</p>
<p>此外，该程序还使用了一些自定义的类和函数，如GlobalCtx、CallGraph、StructFinder、CrashAnalyzer和PointerAnalysis。</p>
<p><strong>提问：请问你能画出代码的结构图吗？</strong></p>
<p><strong>AI：</strong></p>
<p>main function ├── cl::list &lt; std::string&gt; InputFilenames ├──
cl::opt &lt; unsigned&gt; VerboseLevel ├── cl::opt &lt; std::string&gt;
DumpLocation ├── cl::opt &lt; std::string&gt; CrashReport ├──
CallGraphPass ├── PointerAnalysisPass ├── CrashAnalyzer └── return 0</p>
<p>其中，<code>InputFilenames</code>、<code>VerboseLevel</code>、<code>DumpLocation</code>和<code>CrashReport</code>是程序的命令行参数。<code>CallGraphPass</code>和<code>PointerAnalysisPass</code>是两个LLVM
Pass，用于分析LLVM模块的调用图和指针分析。<code>CrashAnalyzer</code>是一个自定义的类，用于分析崩溃位置。程序最后返回0。</p>
</blockquote>
]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>Vulnerability</tag>
        <tag>AEG</tag>
      </tags>
  </entry>
  <entry>
    <title>(论文阅读)The Use of Likely Invariants as Feedback for FuzzersVulnerabilities</title>
    <url>/2023/05/08/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91The-Use-of-Likely-Invariants-as-Feedback-for-FuzzersVulnerabilities/</url>
    <content><![CDATA[<h2
id="论文阅读the-use-of-likely-invariants-as-feedback-for-fuzzers">(论文阅读)The
Use of Likely Invariants as Feedback for Fuzzers</h2>
<blockquote>
<p><strong>时间：</strong>2021.8</p>
<p><strong>作者：</strong>Andrea Fioraldi、Daniele Cono D’Elia、Davide
Balzarotti</p>
<p><strong>会议：</strong>USENIX</p>
<p><strong>开源：</strong><a
href="https://github.com/eurecom-s3/invscov">eurecom-s3/invscov: The Use
of Likely Invariants as Feedback for Fuzzers (github.com)</a></p>
<p>截止2023.5.6被引23次</p>
</blockquote>
<h2 id="abstract">ABSTRACT</h2>
<p>​
如今Fuzzing的主要限制是以coverage-guided为基准设计的fuzzing方法是为了尽可能达到程序的不同部分而逐渐被优化，但若仅仅可达性不足以触发一个漏洞时，这种方法就会陷入困境。<u>实际上，许多bug的触发不仅依赖于特定的控制流，还依赖一些程序的变量的值（数据流）。</u>不幸的是，过去提出的捕捉程序状态的替代探索策略在实践中帮助不大，因为它们会立即导致状态爆炸问题。</p>
<p>​
在本文，我们提出了<strong>一个新型反馈机制，通过考虑到程序变量的”不变值“和其之间的关系来增强代码覆盖率</strong>。为此，我们在基本块层面上学习可能的变量“不变值”，并相应地划分程序状态空间。我们的反馈可以区分输入是否违反了一个或多个不变量，并对其进行奖励，从而完善代码覆盖通常提供的程序状态近似值。</p>
<p>​
基于<u>LLVM和AFPL++</u>，我们在一个名为<strong>INVSCOV</strong>的原型中实现了上述的技术。实验表明，与使用纯代码覆盖反馈的fuzzer相比，我们的方法可以发现更多、更不同的bug。此外，还发现了一个在OSS-Fuzz上每天测试的库中的两个漏洞，而且当时在其最新版本中仍然存在。</p>
<span id="more"></span>
<h2 id="问题背景">问题背景</h2>
<blockquote>
<p><strong><em>“code coverage alone is a necessary but not sufficient
condition to discover bugs”</em></strong></p>
<p><strong>代码覆盖率是发现bug的必要条件，不是充分条件。</strong></p>
</blockquote>
<h4 id="bug被触发的条件">1. bug被触发的条件</h4>
<p>​ 一个bug被触发应满足两个条件：</p>
<pre><code>1. 程序运行到特定的指令；
2. 程序满足确定的条件。</code></pre>
<p>​
少数情况下，程序不需要满足特定的条件也能触发bug，如LAVA-M数据集中的bug，其被人为的制造为只要运行到了特定的点就能触发。</p>
<h4 id="coverage-based-fuzzing的缺点">2. coverage-based
fuzzing的缺点</h4>
<p>​
对于现有的coverage-based的fuzzing方法，fuzzer没有任何动力去探索更多的状态，因为其已经观察到了那里。因此，对于现有的工具来说，检测涉及到对程序状态的复杂约束的bug是相当困难的。如果简单对fuzzer探索更多的状态空间的行为作出奖励，其也会导致<strong><u>路径爆炸问题</u></strong>，因为对于非离散的应用，其状态空间基本是无限多的。</p>
<h4 id="例子">3. 例子</h4>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230508201406.png" style="zoom: 67%;" /></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230508201539.png" style="zoom:67%;" /></p>
<p>​
如图所示的漏洞是libsndfile的WAV文件格式解析中的堆溢出漏洞（<code>Listing2</code>第9行），libsndfile是一个用于操作音频文件的流行库。在<code>Listing2</code>第9行，代码引用了pms-&gt;samples所指向的C99变长数组（<u>C99规定数组长度可以为变量</u>）。当<code>Listing1</code>中的pmssize（<code>Listing1</code>第8行）较小，且pms-&gt;blocksize值（<code>Listing1</code>第13行）足够高时，写入操作会到达数组边界之外，造成堆溢出。</p>
<p>​ <strong>Coverage-based
fuzzer很容易到达该错误的问题点，但是很难触发。由于其并不会提供更多的代码覆盖率，fuzzer不会为这个点分配更多的energy。</strong></p>
<h2 id="创新点">创新点</h2>
<p>​
在本文中，我们提出了一种新的模糊测试反馈，在考虑代码覆盖率的同时，也考虑到了程序状态中一些有趣的部分，以一种完全自动化的方式进行测试，并且不会引起状态爆炸。<strong>这项工作的创新点并不是“考虑代码覆盖率以外的东西”，这部分已经有人做过，但其问题是：</strong></p>
<ol type="1">
<li><p><strong>路径爆炸：</strong></p>
<p>一些fuzzer通过使用更敏感的反馈来模拟程序状态，例如引入堆栈信息，甚至引用从内存加载和存储的值。《Be
sensitive and collaborative: Analyzing impact of coverage metrics in
greybox
fuzzing》一文中就不仅考虑了控制流，还考虑了程序状态中的值。但其缺点就是会导致路径爆炸问题。</p></li>
<li><p><strong>需要人工标注：</strong></p>
<p>一些工作会使用人工辅助的方式进行，例如FUZZFACTORY让其开发者定义特定的目标，然后添加导航点，当生成的测试样例朝着这些目标前进（<u>例如，当两个比较操作数中有更多位相同时</u>），奖励Fuzzer。</p></li>
</ol>
<p>​
故此项工作的创新点是：<strong><u>“考虑代码覆盖率以外的东西”，并将其过程自动化，且不会引入路径爆炸问题。</u></strong></p>
<h2 id="方法">方法</h2>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230508211728.png" style="zoom:67%;" /></p>
<h3 id="program-state-partitions-程序状态分区">1. Program State
Partitions-程序状态分区</h3>
<p>​
以上图<code>Listing1</code>与<code>Listing2</code>为例，用标准的CGF系统对libsndfile进行一定时间的fuzzing（如24h），然后调查fuzzer保存的所有种子，分析这些种子中所有变量，为<code>Listing1</code>中的初始函数确定两个不变量，为<code>Listing2</code>中的循环确定一个不变量（上图绿色注释）。根据这些注释，将程序的状态空间分为四部分，如下图所示：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230508204234.png" style="zoom: 67%;" /></p>
<p>​
除了状态A，其余状态Fuzzer都没有访问过，通过如此抽象方法来向Fuzzer提供反馈，使其探索新的状态而又不会导致路径爆炸。</p>
<p>​
不变量能够在不引起状态爆炸的情况下划分程序状态空间，这也是方法的关键之一。在每个基本块中，N个不变量可以对状态进行局部划分，就像N条不平行的线可以将一个平面划分为<strong>N∗(N+1)/2+1</strong>个区域一样。在实践中，由于每个基本块通常只操纵几个变量，N通常是一个非常低的值（附录A中的统计数据）。</p>
<h3 id="using-invariants-as-feedback-使用不变量反馈">2. Using Invariants
as Feedback-使用“不变量”反馈</h3>
<p>​
动态“不变量”检测的常见限制是，所产生的“不变量”往往更多的是捕获测试套件的局部属性而不是程序的静态属性。然而这正是我们想要的，违反仅从Fuzzer语料库中学习到的可能的“不变量”可以提示Fuzzer哪些程序状态组合是不寻常的，进而定位错误的根源。</p>
<p>​
这里，使用“不变量”对Fuzzer进行反馈指的是<strong>edge-coverage</strong>与<strong>哪些“不变量”被违反的信息</strong>的组合。我们调整了大多数Coverage-based系统采用的新颖性算法，为每个被违反的“不变量”组合产生一个不同的搜索值，使其可以跟踪这些状态。</p>
<p>​ 上述漏洞触发在B分区，当{blockalign = 1280, samplesperblock =
8}时会触发。我们的方法可以通过结合或突变以前的种子，生成违反多个"不变量"的输入，每个都违反一个或多个不同的"不变量"。</p>
<h3 id="pruning-the-generated-checks-修剪生成的check">3. Pruning the
Generated Checks-修剪生成的Check</h3>
<p>​ 这里设计了三类修剪规则以排除不必要的/有害的“不变量”。</p>
<p>​ 1）第一类需要丢掉的“不变量”是不可能被违反的：</p>
<p>​ <strong><u>例如，unsigned integer &gt;=
0</u>。</strong>其不可能被违反，对测试没有帮助。</p>
<p>​
为了识别类似的情况，我们对被测程序的每个函数进行了价值范围分析[36]。参数和全局存储最初是不受限制的，分析产生的函数变量界限在任何执行中都是成立的。利用这些分析出来的范围信息，指示分析器永远不要生成逻辑上比这些静态分析出的限制更弱的逻辑“不变式”。</p>
<p>​ 2）第二类是包含无关变量：</p>
<p>​
为被测程序的每个函数计算可比较性集：每个变量只属于一个这样的集，将不同集的变量结合在一起的“不变量”被丢弃。</p>
<p>​
最初为每个变量创建一个单独的集合，然后使用基于统一的策略，遍历函数指令，并在两个变量作为同一语句的操作数出现时合并这两个变量的集合。最终，一个可比性集合包含了参与相关计算的变量。这很少有例外：例如，在一个数组指针计算中，我们不合并基数和索引元素的集合，因为它们没有直接关系。</p>
<p>​ 3） 第三类是与其他“不变量”的条件重叠：</p>
<p>​ 如果“不变量”逻辑重叠，就存在可以优化的空间。</p>
<h3 id="corpus-selection-语料库选择">4. Corpus Selection-语料库选择</h3>
<p>​ 仅使用有效文件是不够的。</p>
<p>​
只要该模糊器在达到新的覆盖点时有放缓的迹象，就可以作为语料库。（why？）</p>
<h2 id="reference">REFERENCE</h2>
<ul>
<li>软件分析：
<ul>
<li><a
href="https://blog.csdn.net/qq_41048815/article/details/118963223">南京大学《软件分析》课程笔记01
Introduction_CSDN</a></li>
</ul></li>
<li>C/C++:
<ul>
<li><a
href="https://gcc.gnu.org/onlinedocs/gcc/Variable-Length.html">Variable
Length (Using the GNU Compiler Collection (GCC))</a></li>
<li><a
href="https://blog.csdn.net/weixin_42141437/article/details/112239845">c99变长数组_C语言变长数组：使用变量指明数组的长度
CSDN博客</a></li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Fuzzing</tag>
      </tags>
  </entry>
  <entry>
    <title>(技术总结)The Kernel Address Sanitizer(KASAN)</title>
    <url>/2023/05/04/%E3%80%90%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BB%93%E3%80%91The%20Kernel%20Address%20Sanitizer(KASAN)/</url>
    <content><![CDATA[<h1 id="the-kernel-address-sanitizerkasan">The Kernel Address
Sanitizer(KASAN)</h1>
<h3 id="兼容性">1. 兼容性</h3>
<p>​
KASAN是一个动态内存安全错误检测器，旨在发现内核out-of-bounds和UAF错误。KASAN有三个模块：<code>Generic KASAN</code>、<code>Software Tag-Based KASAN</code>、<code>Hardware Tag-Based KASAN</code>。<code>Generic KASAN</code>兼容许多CPU架构，但性能开销很大；<code>Software Tag-Based KASAN</code>和<code>Hardware Tag-Based KASAN</code>都只兼容arm64架构的CPU，性能开销会更小。</p>
<p>​
一般的，称<code>Generic KASAN</code>和<code>Software Tag-Based KASAN</code>为<strong>software
KASAN</strong>；</p>
<p>​
称<code>Software Tag-Based KASAN</code>和<code>Hardware Tag-Based KASAN</code>为<strong>tag-based
KASAN</strong>。</p>
<p>​ <code>Generic KASAN</code>支持的指令集架构有：x86_64, arm, arm64,
powerpc, riscv, s390, 和
xtensa；<code>tag-based KASAN</code>只支持arm64。 <span id="more"></span> ### 2.
编译器要求</p>
<p>​
KASAN对内存检查的逻辑是在编译的时候在内存访问操作之前插入相关检查指令，故需要相应的编译器支持该操作。</p>
<blockquote>
<p>​ <code>Generic KASAN</code>需要GCC
8.3.0+/任何版本的Clang(只要内核支持)；</p>
<p>​ <code>Software Tag-Based KASAN</code>需要GCC
11+/任何版本的Clang(只要内核支持)；</p>
<p>​ <code>Hardware Tag-Based KASAN</code>需要GCC10+/Clang12+。</p>
</blockquote>
<h3 id="使用方法">3. 使用方法</h3>
<p>​ 开启KASAN需要在内核配置文件中开启对应配置：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token assign-left variable">CONFIG_KASAN</span><span class="token operator">=</span>y<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​
然后根据选择的KASAN类型选择标签：<code>CONFIG_KASAN_GENERIC</code>、<code>CONFIG_KASAN_SW_TAGS</code>、<code>CONFIG_KASAN_HW_TAGS</code>。</p>
<p>​ 对于software
KASAN，其需要指定其编译插装类型：<code>CONFIG_KASAN_OUTLINE</code>、<code>CONFIG_KASAN_INLINE</code>，outline类型生成体积更小的二进制代码，而inline类型速度比outline快两倍。</p>
<p>​ 为了在报告中包括受影响的slab对象的stack
traces，指定：<code>CONFIG_STACKTRACE</code>;包括受影响的物理页的stack
traces，指定<code>CONFIG_PAGE_OWNER</code>并<code>page_owner=on</code>。</p>
<h3 id="report">4. Report</h3>
<p>​ 默认情况下，KASAN只对第一个无效的内存访问打印错误报告。使用
<code>kasan_multi_shot</code>，KASAN对每一个无效的访问都打印一份报告。这会禁用
了KASAN报告的 <code>panic_on_warn</code>。</p>
<p>​ 典型的KASAN报告如下所示:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>
BUG: KASAN: slab-out-of-bounds <span class="token keyword">in</span> kmalloc_oob_right+0xa8/0xbc <span class="token punctuation">[</span>test_kasan<span class="token punctuation">]</span>
Write of size <span class="token number">1</span> at addr ffff8801f44ec37b by task insmod/2760

CPU: <span class="token number">1</span> PID: <span class="token number">2760</span> Comm: insmod Not tainted <span class="token number">4.19</span>.0-rc3+ <span class="token comment">#698</span>
Hardware name: QEMU Standard PC <span class="token punctuation">(</span>i440FX + PIIX, <span class="token number">1996</span><span class="token punctuation">)</span>, BIOS <span class="token number">1.10</span>.2-1 04/01/2014
Call Trace:
 dump_stack+0x94/0xd8
 print_address_description+0x73/0x280
 kasan_report+0x144/0x187
 __asan_report_store1_noabort+0x17/0x20
 kmalloc_oob_right+0xa8/0xbc <span class="token punctuation">[</span>test_kasan<span class="token punctuation">]</span>
 kmalloc_tests_init+0x16/0x700 <span class="token punctuation">[</span>test_kasan<span class="token punctuation">]</span>
 do_one_initcall+0xa5/0x3ae
 do_init_module+0x1b6/0x547
 load_module+0x75df/0x8070
 __do_sys_init_module+0x1c6/0x200
 __x64_sys_init_module+0x6e/0xb0
 do_syscall_64+0x9f/0x2c0
 entry_SYSCALL_64_after_hwframe+0x44/0xa9
RIP: 0033:0x7f96443109da
RSP: 002b:00007ffcf0b51b08 EFLAGS: 00000202 ORIG_RAX: 00000000000000af
RAX: ffffffffffffffda RBX: 000055dc3ee521a0 RCX: 00007f96443109da
RDX: 00007f96445cff88 RSI: 0000000000057a50 RDI: 00007f9644992000
RBP: 000055dc3ee510b0 R08: 0000000000000003 R09: 0000000000000000
R10: 00007f964430cd0a R11: 0000000000000202 R12: 00007f96445cff88
R13: 000055dc3ee51090 R14: 0000000000000000 R15: 0000000000000000

Allocated by task <span class="token number">2760</span>:
 save_stack+0x43/0xd0
 kasan_kmalloc+0xa7/0xd0
 kmem_cache_alloc_trace+0xe1/0x1b0
 kmalloc_oob_right+0x56/0xbc <span class="token punctuation">[</span>test_kasan<span class="token punctuation">]</span>
 kmalloc_tests_init+0x16/0x700 <span class="token punctuation">[</span>test_kasan<span class="token punctuation">]</span>
 do_one_initcall+0xa5/0x3ae
 do_init_module+0x1b6/0x547
 load_module+0x75df/0x8070
 __do_sys_init_module+0x1c6/0x200
 __x64_sys_init_module+0x6e/0xb0
 do_syscall_64+0x9f/0x2c0
 entry_SYSCALL_64_after_hwframe+0x44/0xa9

Freed by task <span class="token number">815</span>:
 save_stack+0x43/0xd0
 __kasan_slab_free+0x135/0x190
 kasan_slab_free+0xe/0x10
 kfree+0x93/0x1a0
 umh_complete+0x6a/0xa0
 call_usermodehelper_exec_async+0x4c3/0x640
 ret_from_fork+0x35/0x40

The buggy address belongs to the object at ffff8801f44ec300
 <span class="token function">which</span> belongs to the cache kmalloc-128 of size <span class="token number">128</span>
The buggy address is located <span class="token number">123</span> bytes inside of
 <span class="token number">128</span>-byte region <span class="token punctuation">[</span>ffff8801f44ec300, ffff8801f44ec380<span class="token punctuation">)</span>
The buggy address belongs to the page:
page:ffffea0007d13b00 count:1 mapcount:0 mapping:ffff8801f7001640 index:0x0
flags: 0x200000000000100<span class="token punctuation">(</span>slab<span class="token punctuation">)</span>
raw: 0200000000000100 ffffea0007d11dc0 0000001a0000001a ffff8801f7001640
raw: 0000000000000000 0000000080150015 00000001ffffffff 0000000000000000
page dumped because: kasan: bad access detected

Memory state around the buggy address:
 ffff8801f44ec200: fc fc fc fc fc fc fc fc fb fb fb fb fb fb fb fb
 ffff8801f44ec280: fb fb fb fb fb fb fb fb fc fc fc fc fc fc fc fc
<span class="token operator">></span>ffff8801f44ec300: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 03
                                                                ^
 ffff8801f44ec380: fc fc fc fc fc fc fc fc fb fb fb fb fb fb fb fb
 ffff8801f44ec400: fb fb fb fb fb fb fb fb fc fc fc fc fc fc fc fc
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ <code>BUG: KASAN:</code>
第一行报告了错误类型，slab-out-of-bounds；</p>
<p>​ <code>Call Trace</code>:表明了当前error的堆栈跟踪；</p>
<p>​
<code>Allocated by task 2760</code>:表明了所访问内存分配位置的堆栈跟踪（“where
the accessed memory was allocated ”）；</p>
<p>​
<code>Freed by task 815</code>:表明了对象被释放的位置的堆栈跟踪（“where
the object was freed”）；</p>
<p>​
<code>The buggy address belongs to ……</code>:表明了访问的slab对象的相关描述；</p>
<p>​
<code>Memory state around the buggy address:</code>表明了访问slab对象周围的内存情况。</p>
<h3 id="影子内存">5. 影子内存</h3>
<p>​
KASAN的原理是利用“额外”的内存来标记那些可以被使用的内存的状态。这些做标记的区域被称为影子区域（shadow
region）。了解 Linux
内存管理的读者知道，内存中的每个物理页在内存中都会有一个 struct page
这样的结构体来表示，即每 4KB 的页需要 40B 的结构体，大约 1%
的内存用来表示内存本身。Kasan 与其类似但“浪费”更为严重，影子区域的比例是
1:8，即总内存的九分之一会被“浪费”。用官方文档中的例子，如果有 128TB
的可用内存，需要有额外 16TB 的内存用来做标记。</p>
<figure>
<img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230504141838.png"
alt="Shadow Memory of KASAN" />
<figcaption aria-hidden="true">Shadow Memory of KASAN</figcaption>
</figure>
<p>​ 做标记的方法比较简单，将可用内存按照 8
子节的大小分组，如果每组中所有 8
个字节都可以访问，则影子内存中相应的地方用全零（0x00）表示；如果可用内存的前
N（1 到 7 范围之间）个字节可用，则影子内存中响应的位置用 N
表示；其它情况影子内存用负数表示该内存不可用（<em>KASAN使用不同的负值来区分不同类型的不可访问内存，如redzones
或已释放的内存，参见 mm/kasan/kasan.h</em>）。</p>
<p>​
上述Report中，箭头指向的影子字节<code>03</code>，表示访问的地址是部分可访问的。报告中可访问的内存是“00
00 00 00 00 00 00 00 00 00 00 00 00 00 00
03”，一共15个<code>00</code>和一个<code>03</code>，其表明了一共有15×8+3=123个字节可以访问，当试图访问这123个字节之外的内容时，就会报错out-of-bounds。</p>
<p>​ <strong>KASAN错误标题（如 <code>slab-out-of-bounds</code> 或
<code>use-after-free</code> ）
是尽量接近的KASAN根据其拥有的有限信息打印出最可能的错误类型。错误的实际类型
可能会有所不同。</strong></p>
<h2 id="reference">Reference</h2>
<ul>
<li><p>文档：</p>
<ul>
<li><a
href="https://www.kernel.org/doc/html/latest/dev-tools/kasan.html">The
Kernel Address Sanitizer (KASAN) — The Linux Kernel
documentation</a></li>
<li><a
href="https://www.kernel.org/doc/html/latest/translations/zh_CN/dev-tools/kasan.html">内核地址消毒剂(KASAN)
— The Linux Kernel documentation</a></li>
<li><a href="https://cloud.tencent.com/developer/article/1518011">Kasan
- Linux 内核的内存检测工具 - 腾讯云开发者社区-腾讯云
(tencent.com)</a></li>
</ul></li>
<li><p>内存分配:</p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/358891862">Linux 内核 |
内存管理——slab 分配器 - 知乎 (zhihu.com)</a></li>
<li><a
href="https://blog.csdn.net/weixin_42262944/article/details/119853846">(60条消息)
Linux内存子系统——分配物理页面（alloc_pages）_绍兴小贵宁的博客-CSDN博客</a></li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>Vulnerability</tag>
        <tag>AEG</tag>
      </tags>
  </entry>
  <entry>
    <title>(LLVM入门)编写LLVM PASS</title>
    <url>/2023/05/01/%E3%80%90%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF%E3%80%91(LLVM%E5%85%A5%E9%97%A8)%E7%BC%96%E5%86%99LLVM%20PASS/</url>
    <content><![CDATA[<h1 id="llvm入门编写llvm-pass">(LLVM入门)编写LLVM PASS</h1>
<p>​ 前置知识：</p>
<blockquote>
<ol type="1">
<li>LLVM IR结构；</li>
<li>C++ 面向对象；</li>
<li>CMake；</li>
</ol>
</blockquote>
<span id="more"></span>
<h2 id="一理论">一、理论</h2>
<h4 id="llvm-ir">LLVM IR</h4>
<ol type="1">
<li>LLVM IR 文件的基本单位称为
<code>module</code>，LLVM中的Module，代表了一块代码。它是一个比较完整独立的代码块，是一个最小的编译单元。；</li>
<li>一个 <code>module</code> 中可以拥有多个顶层实体，比如
<code>function</code> 和 <code>global variavle</code>；</li>
<li>一个 <code>function define</code> 中至少有一个
<code>basicblock</code>；</li>
<li>每个 <code>basicblock</code> 中有若干
<code>instruction</code>，并且都以 <code>terminator instruction</code>
结尾。</li>
</ol>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/image-20230420162739440.png" /></p>
<p>(详见：<a
href="https://llvm.org/devmtg/2019-04/slides/Tutorial-Bridgers-LLVM_IR_tutorial.pdf">PowerPoint
Presentation (llvm.org)</a>)</p>
<h4 id="what-is-a-pass">What is a PASS?</h4>
<ol type="1">
<li>pass 对LLVM IR的一些单元进行操作，例如module或者function；</li>
<li>pass有两类，Analysis pass和Transformation pass。Transformation
pass会对单元进行修改操作，Analysis
pass不修改，只观察并生成一些高层信息；</li>
</ol>
<p>​ Pass Manager：调度Pass在各IR层级按顺序运行。
（什么是各IR层级？）</p>
<h4 id="opt">opt</h4>
<p>​
opt是LLVM的代码优化器，其输入ll源文件，其可以对源文件进行优化（输出优化后的ll源文件）或者分析（输出分析结果）。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/image-20230429225221269.png" alt="opt workflow" style="zoom:80%;" /></p>
<p>​
在使用opt命令时，-{passname}提供了以任何顺序运行任何LLVM优化或分析Pass的能力。</p>
<h2 id="二代码实践">二、代码实践</h2>
<p>常见llvm编译命令：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">#.c -> .ll：</span>
clang -emit-llvm -S a.c -o a.ll
<span class="token comment">#.c -> .bc: </span>
clang -emit-llvm -c a.c -o a.bc
<span class="token comment">#.ll -> .bc: </span>
llvm-as a.ll -o a.bc
<span class="token comment">#.bc -> .ll: </span>
llvm-dis a.bc -o a.ll
<span class="token comment">#.bc -> .s: </span>
lc a.bc -o a.s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="hellow-world-pass">2. Hellow World PASS</h3>
<blockquote>
<p>目标：打印出编译程序中存在的非外部函数的名称，该 Pass
只是检查程序，不修改原程序。</p>
</blockquote>
<p>​ llvm安装编译过程略，详见github官方项目。</p>
<h4 id="old-manager">2.1 old manager</h4>
<p>​ <strong><u>旧版pass
manager采用继承对应PASS类，覆写父类虚函数的方式定义用户自己的pass类</u></strong>，编写old_hello.cpp如下：</p>
<pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token comment">//old_Hello.cpp</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">"llvm/Pass.h"</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">"llvm/IR/Function.h"</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">"llvm/Support/raw_ostream.h"</span></span>

<span class="token keyword">using</span> <span class="token keyword">namespace</span> llvm<span class="token punctuation">;</span>

<span class="token comment">//使用匿名命名空间，使得其中定义的函数对其它文件不可见；</span>
<span class="token comment">//防止命名空间污染</span>
<span class="token keyword">namespace</span><span class="token punctuation">&#123;</span>
    <span class="token comment">//FunctionPass每次操作一个函数,Hellp继承它</span>
    <span class="token keyword">struct</span> <span class="token class-name">Hello</span><span class="token operator">:</span><span class="token base-clause"><span class="token keyword">public</span> <span class="token class-name">FunctionPass</span></span><span class="token punctuation">&#123;</span>
        <span class="token keyword">static</span> <span class="token keyword">char</span> ID<span class="token punctuation">;</span>
        <span class="token function">Hello</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">:</span> <span class="token function">FunctionPass</span><span class="token punctuation">(</span>ID<span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
        <span class="token comment">//覆写父类的虚函数，override是覆写标志，使用它时当没有正确</span>
        <span class="token comment">//进行覆写操作时编译器会报error而不是warnning，且子类覆写</span>
        <span class="token comment">//的虚函数也不用再加virtual关键字；</span>
        <span class="token comment">//如果要禁止子类覆写虚函数，可以使用final关键字。</span>
        <span class="token keyword">bool</span> <span class="token function">runOnFunction</span><span class="token punctuation">(</span>Function <span class="token operator">&amp;</span>F<span class="token punctuation">)</span> override <span class="token punctuation">&#123;</span>
            <span class="token comment">//打印"Hello: 函数名称"</span>
            <span class="token function">errs</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> <span class="token string">"Hello: "</span><span class="token punctuation">;</span>
            <span class="token function">errs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">write_escaped</span><span class="token punctuation">(</span>F<span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> <span class="token string">'\n'</span><span class="token punctuation">;</span>
            <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span>
    <span class="token punctuation">&#125;</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span>
<span class="token comment">//初始化ID</span>
<span class="token keyword">char</span> Hello<span class="token operator">::</span>ID <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token comment">//Register for opt</span>
<span class="token keyword">static</span> RegisterPass<span class="token operator">&lt;</span>Hello<span class="token operator">></span> <span class="token function">X</span><span class="token punctuation">(</span><span class="token string">"hello"</span><span class="token punctuation">,</span><span class="token string">"Hello World Pass"</span><span class="token punctuation">,</span>
                            <span class="token boolean">false</span><span class="token comment">/* Only looks at CFG */</span><span class="token punctuation">,</span>
                            <span class="token boolean">false</span><span class="token comment">/* Only looks at CFG */</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 编写一个待测试文件test.cpp：</p>
<pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span><span class="token string">&lt;stdio.h></span></span>
<span class="token keyword">void</span> <span class="token function">fun1</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
    <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"111\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span>
<span class="token keyword">void</span> <span class="token function">fun2</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
    <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"222\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span>
<span class="token keyword">void</span> <span class="token function">fun3</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
    <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"333\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span>
<span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
    <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"%d\n"</span><span class="token punctuation">,</span><span class="token function">fun1</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"%d\n"</span><span class="token punctuation">,</span><span class="token function">fun2</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">//printf("%d\n",fun3());</span>
    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 编译pass和test文件：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">#编译pass，也可以自行定义CMakeLists文件，手动编译;</span>
<span class="token comment">#llvm-config提供了CXXFLAGS与LDFLAGS参数方便查找LLVM的头文件与库文件;</span>
<span class="token comment">#如果链接有问题，还可以用llvm-config --libs提供动态链接的LLVM库;</span>
<span class="token comment">#具体llvm-config打印了什么，请自行尝试或查找官方文档;</span>
<span class="token comment">#-fPIC -shared 是编译动态库的必要参数。</span>
<span class="token comment">#因为LLVM没用到RTTI，所以用-fno-rtti 来让我们的Pass与之一致;</span>
<span class="token comment">#-Wl,-znodelete是为了应对LLVM 5.0+中加载ModulePass引起segmentation fault的bug;</span>
<span class="token comment">#若Pass继承了ModulePass，务必加上。</span>
clang <span class="token variable"><span class="token variable">`</span>llvm-config --cxxflags<span class="token variable">`</span></span> -Wl,-znodelete -fno-rtti -fPIC -shared old_hello.cpp -o LLVMHello.so <span class="token variable"><span class="token variable">`</span>llvm-config --ldflags<span class="token variable">`</span></span>
<span class="token comment">#将待测试文件编译为bitcode</span>
clang -emit-llvm -c test.cpp -o test.bc<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 使用opt命令加载运行，运行结果：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">#-loda 选项表明要加载进程序的pass</span>
<span class="token comment">#-hello 是注册时规定的参数</span>
<span class="token comment">#由于此pass并不修改程序，故将opt的输出结果放入/dev/null(丢弃)</span>
<span class="token function">sudo</span> opt -load ./LLVMHello.so -hello <span class="token operator">&lt;</span> test.bc <span class="token operator">></span> /dev/null

Hello: _Z4fun1v
Hello: _Z4fun2v
Hello: _Z4fun3v
Hello: main<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 在命令中加入-time-passes参数，可以获得运行时间相关结果：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token variable">$sudo</span> opt -load ./LLVMHello.so -hello -time-passes <span class="token operator">&lt;</span> test.bc <span class="token operator">></span> /dev/null
Hello: _Z4fun1v
Hello: _Z4fun2v
Hello: _Z4fun3v
Hello: main
<span class="token operator">==</span>-------------------------------------------------------------------------<span class="token operator">==</span>
                      <span class="token punctuation">..</span>. Pass execution timing report <span class="token punctuation">..</span>.
<span class="token operator">==</span>-------------------------------------------------------------------------<span class="token operator">==</span>
  Total Execution Time: <span class="token number">0.0006</span> seconds <span class="token punctuation">(</span><span class="token number">0.0006</span> wall clock<span class="token punctuation">)</span>

---User Time---   --System Time--   --User+System--  ---Wall Time---  ---Name ---
   <span class="token number">0.0001</span> <span class="token punctuation">(</span> <span class="token number">61.1</span>%<span class="token punctuation">)</span>   <span class="token number">0.0002</span> <span class="token punctuation">(</span> <span class="token number">62.0</span>%<span class="token punctuation">)</span>   <span class="token number">0.0003</span> <span class="token punctuation">(</span> <span class="token number">61.7</span>%<span class="token punctuation">)</span>   <span class="token number">0.0003</span> <span class="token punctuation">(</span> <span class="token number">62.0</span>%<span class="token punctuation">)</span>  Bitcode Writer
   <span class="token number">0.0001</span> <span class="token punctuation">(</span> <span class="token number">33.7</span>%<span class="token punctuation">)</span>   <span class="token number">0.0001</span> <span class="token punctuation">(</span> <span class="token number">33.2</span>%<span class="token punctuation">)</span>   <span class="token number">0.0002</span> <span class="token punctuation">(</span> <span class="token number">33.3</span>%<span class="token punctuation">)</span>   <span class="token number">0.0002</span> <span class="token punctuation">(</span> <span class="token number">33.0</span>%<span class="token punctuation">)</span>  Hello World Pass
   <span class="token number">0.0000</span> <span class="token punctuation">(</span>  <span class="token number">5.3</span>%<span class="token punctuation">)</span>   <span class="token number">0.0000</span> <span class="token punctuation">(</span>  <span class="token number">4.8</span>%<span class="token punctuation">)</span>   <span class="token number">0.0000</span> <span class="token punctuation">(</span>  <span class="token number">5.0</span>%<span class="token punctuation">)</span>   <span class="token number">0.0000</span> <span class="token punctuation">(</span>  <span class="token number">5.0</span>%<span class="token punctuation">)</span>  Module Verifier
   <span class="token number">0.0002</span> <span class="token punctuation">(</span><span class="token number">100.0</span>%<span class="token punctuation">)</span>   <span class="token number">0.0004</span> <span class="token punctuation">(</span><span class="token number">100.0</span>%<span class="token punctuation">)</span>   <span class="token number">0.0006</span> <span class="token punctuation">(</span><span class="token number">100.0</span>%<span class="token punctuation">)</span>   <span class="token number">0.0006</span> <span class="token punctuation">(</span><span class="token number">100.0</span>%<span class="token punctuation">)</span>  Total
<span class="token operator">==</span>-------------------------------------------------------------------------<span class="token operator">==</span>
                                LLVM IR Parsing
<span class="token operator">==</span><span class="token operator">=</span>-------------------------------------------------------------------------<span class="token operator">==</span>
  Total Execution Time: <span class="token number">0.0005</span> seconds <span class="token punctuation">(</span><span class="token number">0.0005</span> wall clock<span class="token punctuation">)</span>

   ---User Time---   --System Time--   --User+System--   ---Wall Time---  --- Name ---
   <span class="token number">0.0002</span> <span class="token punctuation">(</span><span class="token number">100.0</span>%<span class="token punctuation">)</span>   <span class="token number">0.0003</span> <span class="token punctuation">(</span><span class="token number">100.0</span>%<span class="token punctuation">)</span>   <span class="token number">0.0005</span> <span class="token punctuation">(</span><span class="token number">100.0</span>%<span class="token punctuation">)</span>   <span class="token number">0.0005</span> <span class="token punctuation">(</span><span class="token number">100.0</span>%<span class="token punctuation">)</span>  Parse IR
   <span class="token number">0.0002</span> <span class="token punctuation">(</span><span class="token number">100.0</span>%<span class="token punctuation">)</span>   <span class="token number">0.0003</span> <span class="token punctuation">(</span><span class="token number">100.0</span>%<span class="token punctuation">)</span>   <span class="token number">0.0005</span> <span class="token punctuation">(</span><span class="token number">100.0</span>%<span class="token punctuation">)</span>   <span class="token number">0.0005</span> <span class="token punctuation">(</span><span class="token number">100.0</span>%<span class="token punctuation">)</span>  Total<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 如果想直接使用clang集成这个过程，需要在pass注册时添加：</p>
<pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">"llvm/IR/LegacyPassManager.h"</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">"llvm/Transforms/IPO/PassManagerBuilder.h"</span></span>

<span class="token comment">// Register for clang</span>
<span class="token keyword">static</span> RegisterStandardPasses <span class="token function">Y</span><span class="token punctuation">(</span>PassManagerBuilder<span class="token operator">::</span>EP_EarlyAsPossible<span class="token punctuation">,</span>
  <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token keyword">const</span> PassManagerBuilder <span class="token operator">&amp;</span>Builder<span class="token punctuation">,</span> legacy<span class="token operator">::</span>PassManagerBase <span class="token operator">&amp;</span>PM<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    PM<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token function">Hello</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 接下来无需提前编译bc文件再调用opt，直接使用clang即可：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">clang -Xclang -load -Xclang ./LLVMHello.so test.cpp -o clang_test

Hello: _Z4fun1v
Hello: _Z4fun2v
Hello: _Z4fun3v
Hello: main<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="new-manager">2.2 new manager</h4>
<p>​ llvm新版本的pass
manager定义依赖于多态，意味着并不存在显示的接口，所有的 Pass 是继承自
CRTP
模板<code>PassInfoMixin&lt;PassT&gt;</code>，其中需要有一个<code>run()</code>方法，接收一些
IR 单元和一个分析管理器，返回类型为 PreservedAnalyses。</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;new_hellp.cpp
#include &quot;llvm&#x2F;IR&#x2F;LegacyPassManager.h&quot;
#include &quot;llvm&#x2F;Passes&#x2F;PassBuilder.h&quot;
#include &quot;llvm&#x2F;Passes&#x2F;PassPlugin.h&quot;
#include &quot;llvm&#x2F;Support&#x2F;raw_ostream.h&quot;

using namespace llvm;

namespace&#123;
    void visitor(Function &amp;F)&#123;
        errs() &lt;&lt; &quot;(New Hello)FunctionName: &quot; &lt;&lt; F.getName() &lt;&lt; &quot;\n&quot;;
        errs() &lt;&lt; &quot;(New Hello)ArgSize: &quot; &lt;&lt; F.arg_size() &lt;&lt; &quot;\n&quot;;
    &#125;

    struct HelloWorld:PassInfoMixin&lt;HelloWorld&gt;&#123;
        PreservedAnalyses run(Function &amp;F,FunctionAnalysisManager &amp;)&#123;
            visitor(F);
            return PreservedAnalyses::all();
        &#125;
        static bool isRequired()&#123;return true;&#125;
    &#125;;
&#125;&#x2F;&#x2F;namespace

llvm::PassPluginLibraryInfo getHelloWorldPluginInfo()&#123;
    return&#123;
        LLVM_PLUGIN_API_VERSION,&quot;HelloWorld&quot;,LLVM_VERSION_STRING,
        [](PassBuilder &amp;PB)&#123;
            PB.registerPipelineParsingCallback(
                [](StringRef Name, FunctionPassManager &amp;FPM,
                ArrayRef&lt;PassBuilder::PipelineElement&gt;)&#123;
                    if(Name &#x3D;&#x3D; &quot;hello-world&quot;)&#123;
                        FPM.addPass(HelloWorld());
                        return true;
                    &#125;
                    return true;
                &#125;);
        &#125;
    &#125;;
&#125;

extern &quot;C&quot; LLVM_ATTRIBUTE_WEAK ::llvm::PassPluginLibraryInfo
llvmGetPassPluginInfo()&#123;
    return getHelloWorldPluginInfo();
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
以上代码分为两部分，Pass本体和Pass注册，具体含义和对应的CMakeLists.txt可参照<a
href="https://github.com/banach-space/llvm-tutor">llvm-tutor</a>，这里不做赘述。尝试运行：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">#编译Pass</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">LLVM_DIR</span><span class="token operator">=</span>/usr/local/include/llvm/
cmake -DLT_LLVM_INSTALL_DIR<span class="token operator">=</span><span class="token variable">$LLVM_DIR</span> <span class="token punctuation">..</span>/
<span class="token function">make</span>

<span class="token comment">#编译输入文件</span>
clang -O1 -S -emit-llvm <span class="token punctuation">..</span>/<span class="token punctuation">..</span>/data/test.cpp -o <span class="token punctuation">..</span>/<span class="token punctuation">..</span>/data/test.ll

<span class="token comment">#使用new manager加载pass</span>
opt -load-pass-plugin ./libHelloWorld.so -passes<span class="token operator">=</span>hello-world -disable-output <span class="token punctuation">..</span>/<span class="token punctuation">..</span>/data/test.ll<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230501140915.png" style="zoom: 67%;" /></p>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/416754155">LLVM IR 的第二个
Pass：上手官方文档 New Pass Manager HelloWorld Pass - 知乎
(zhihu.com)</a></li>
<li><a
href="https://zhuanlan.zhihu.com/p/290946850#:~:text=因此，LLVM%20pass管理机制的主要模块包括pass、pass管理器、pass注册及相关模块，如PassRegistry、AnalysisUsage、AnalysisResolver等。.%201、LLVM%20Pass及常用子类.,pass是一种编译器开发的结构化技术，用于完成编译对象（如IR）的转换、分析或优化等功能。.%20pass的执行就是编译器对编译对象进行转换、分析和优化的过程，pass构建了这些过程所需要的分析结果。.%20LLVM%20Pass是LLVM系统的重要组成部分，定义在llvmincludellvmPass.h中：.">LLVM中的pass及其管理机制
- 知乎 (zhihu.com)</a></li>
<li><a href="https://llvm.org/docs/NewPassManager.html">Using the New
Pass Manager — LLVM 17.0.0git documentation</a></li>
<li><a href="https://www.youtube.com/watch?v=ar7cJl2aBuU">2019 LLVM
Developers’ Meeting: A. Warzynski “Writing an LLVM Pass: 101” -
YouTube</a></li>
<li><a
href="https://github.com/banach-space/llvm-tutor">banach-space/llvm-tutor:
A collection of out-of-tree LLVM passes for teaching and learning
(github.com)</a></li>
</ul>
]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>LLVM</tag>
      </tags>
  </entry>
  <entry>
    <title>GREBE-Unveiling Exploitation Potential for Linux Kernel Bugs</title>
    <url>/2023/04/10/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91GREBE-Unveiling-Exploitation-Potential-for-Linux-Kernel-Bugs/</url>
    <content><![CDATA[<h1
id="grebe-unveiling-exploitation-potential-for-linux-kernel-bugs">GREBE:
Unveiling Exploitation Potential for Linux Kernel Bugs</h1>
<blockquote>
<p>时间：2022</p>
<p>作者：Zhenpeng Lin,Yueqi Chen,Yuhang Wu</p>
<p>会议：SP</p>
</blockquote>
<h1 id="abstract">ABSTRACT</h1>
<p>​
最近，动态测试工具显著提升了Linux内核漏洞的发掘速度，这些工具会在挖掘漏洞时自动地生成报告，具体说明Linux系统的error。报告中的error暗示了相应的内核错误的可能的exploitability，因此，许多安全分析员使用(报告中)表现出来的error来推断一个错误的可利用性，从而考虑其exploit开发的优先级。然而，使用报告中的error可能会低估一个错误的可利用性。报告中表现出的error可能取决于该error是如何被触发的。通过不同的路径或在不同的背景下，一个error可能表现出各种错误行为，意味着非常不同的利用潜力。</p>
<p>​
此文提出了一个新的内核fuzz技术来找到所有可能的内核漏洞的error的表现。<u>与传统的专注于内核代码覆盖率的内核fuzzing技术不同，我们的fuzzing技术更多的是针对有漏洞的代码片段。</u><strong>为了探索不同触发同一个bug的上下文/路径，文章引入了object-driven内核fuzzing技术。通过新探索的error，安全研究人员可以更好地推断出一个error的可利用性。</strong></p>
<p>​
为了评估我们提出的技术的有效性、效率和影响，我们将我们的fuzzing技术作为一个工具GREBE来实现，并将其应用于60个真实世界的Linux内核漏洞。平均来说，GREBE可以为每个内核漏洞表现出2个以上的额外错误行为。对于26个内核错误，GREBE发现了更高的开发潜力。我们向内核供应商报告了其中的一些错误--这些错误的可利用性被错误地评估了，相应的补丁还没有被仔细地应用--导致他们迅速地采用补丁。</p>
<span id="more"></span>
<h1 id="问题背景">问题背景</h1>
<h4 id="根据分析结果确定漏洞优先级">1. 根据分析结果确定漏洞优先级</h4>
<p>​
为了提高Linux其安全性，研究人员和分析人员引入了自动化的内核fuzzing技术和各种调试/sanitzation功能。在他们的推动下，安全研究人员和内核开发人员变得更容易确定Linux内核中的错误。<u>然而，要确定触发bug的条件是否足以代表安全漏洞，仍然是一个挑战。</u>例如，一个表现out-of-bound错误行为的bug通常意味着比那些表现出空指针解除引用错误行为的bug有更高的机会被利用。因此，我们的调查结果和以前的研究[1]、[2]、[3]都表明，在确定漏洞开发工作的优先次序时，漏洞的表现出的错误行为起着关键作用。</p>
<h4 id="自动化漏洞扫描工具提供的错误报告不完善">2.
自动化漏洞扫描工具提供的错误报告不完善</h4>
<p>​
在实践中，当现有的fuzzing工具识别出一个内核错误时，<u>该错误所表现出来的错误行为可能是其众多可能的错误行为之一</u>。它的其他可能的错误行为可能与已经暴露的错误行为相去甚远。通过遵循不同的路径或执行环境来触发内核错误，我们可以使内核错误不仅表现出不太可能被利用的GPF错误，而且表现出极可能被利用的UAF错误。因此，如果只使用单一表现的错误行为来推断该错误可能的可利用性，这可能会产生一定误导。</p>
<h4 id="解决思路">3. 解决思路</h4>
<p>​
为了解决上述问题，一种本能的反应是把一个内核错误报告作为输入，分析该内核错误的根本原因，并推断出该错误的根本原因可能带来的所有可能的后果（例如，内存越界、空指针解引用和内存泄漏等）。然而，根源诊断通常被认为是一项费时费力的工作。因此，我们认为，<strong>解决这个问题的一个更现实的策略是，在不进行根本原因分析的情况下，揭露出一个给定的内核错误的许多可能的后触发错误行为。然后，从公布的错误行为中，安全分析师可以更好地以更准确的方式推断其可能的可利用性。</strong></p>
<h4 id="已有的方法">4. 已有的方法</h4>
<p>​
我们可以借用内核fuzzing的概念。然而，现有的内核fuzzing方法主要是为了最大化代码覆盖率而设计的（例如，Syzkaller[4]、KAFL[5]和Trinity[6]等）。在我们的任务中使用这些方法不可避免地存在效率低下和效果差的问题，这只是因为代码覆盖率驱动的内核fuzzing法没有被在该问题下定制，也没有为寻找与同一错误代码片段相关的各种路径或上下文进行优化。</p>
<p>​
<u>为此，我们提出了一种定制的内核fuzzing处理机制，它将fuzzing处理的能量集中在有缺陷的代码区域，同时，将内核执行路径和上下文分散到目标有缺陷的代码片段。</u></p>
<h1 id="问题引入">问题引入</h1>
<p>​
我们提出的内核fuzzing技术可以被看作是一种定向fuzzing技术。它首先将一个内核错误报告作为输入，并提取与报告的内核错误相关的内核结构/对象。然后，该方法进行fuzzing测试，并利用已识别的内核结构/对象的点击率作为对fuzzer的反馈。由于确定的内核结构/对象对成功触发错误至关重要，利用它们来指导fuzzing可以缩小内核fuzzer的范围，使fuzzer主要关注与报告错误有关的路径和背景。在这项工作中，我们将这种方法作为一个内核对象驱动的fuzzing工具来实现，并以GREBE命名，意味着
"多行为探索fuzzing"。</p>
<h4 id="例子">1. 例子</h4>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230407161916.png" style="zoom:67%;" /></p>
<p>​
如上图所示，函数<code>tun_attach</code>是网络接口配置函数，它的参数<code>tun</code>是一个所有处于open状态的tun文件共享的全局变量。代码第3行表明，如果<code>IFF_NAPI</code>在<code>tun-&gt;flags</code>中被设定，内核将初始化一个定时器，并将相应的napi链接到网络设备napi_list的列表中。代码第12行表明，函数<code>tun_detach</code>负责清理tun_file中包含的数据以及关闭该文件。如果<code>IFF_NAPI</code>被设置，内核将取消定时器并从设备的napi_list中删除napi。在第24行，函数<code>free_netdev</code>将通过napi_list来删除列表中的napi。</p>
<p>​
<strong>这里的bug是由于<code>tun_attach</code>和<code>tun_detach</code>中的标志tun-&gt;flags的可能存在的不一致导致的。</strong></p>
<p>​ 以Syzkaller产生的内核错误报告为例：</p>
<p>​
报告所附的PoC显示，一个系统调用在<code>IFF_NAPI</code>未设置的情况下调用了<code>tun_attach</code>。这样一来，内核既没有初始化定时器，也没有将相应的napi添加到列表中。在这个设置之后，PoC程序进一步调用系统调用ioctl函数，在调用<code>tun_detach</code>之前在<code>tun-&gt;flags</code>中设置<code>IFF_NAPI</code>，这导致<code>tun_attach</code>和<code>tun_detach</code>的标志不一致。然后，在第17行，内核试图停止定时器，它解除了对<code>tun_detach</code>中的定时器对象所包含的指针的引用。然而，如上所述，定时器在<code>tun_attach</code>中没有被初始化，这导致了一个一般保护故障。一般保护故障意味着访问未被指定使用的存储。因此，基于这个单一的观察，许多分析人员可能会推断出这个错误可能是不可利用的。</p>
<p>​
<strong><u>然而，通过改变PoC程序，修改共享变量的赋值方式，我们可以让内核表现出一个UAF错误</u></strong>。具体来说，我们可以在调用函数<code>tun_attach</code>之前用<code>IFF_NAPI</code>设置tun-&gt;flags。这样，在调用<code>tun_attach</code>后，它可以将相应的tun_file添加到设备列表napi_list。在这个设置之后，我们可以进一步调用ioctl来清除tun_flags，然后再调用<code>tun_detach</code>。如上图，函数<code>tun_detach</code>在第18∼19行没有从列表中删除相应的napi，而是在第21行free了它。因此，当遍历设备列表时，拥有KASAN功能的内核将抛出UAF的错误。与报中显示的错误相比，这种非允许的访问不是访问一个无效的内核内存地址而产生一般的保护故障，而是与一个有效的内核内存地址联系在一起，并最终可以破坏内核内存。因此，基于这个UAF错误，许多分析人员可能认为这个错误可能是可利用的。</p>
<p>ps:</p>
<ul>
<li>Kernel Address
SANitizer(KASAN)是一种动态内存安全错误检测工具，主要功能是检查内存越界访问和使用已释放内存的问题；</li>
<li>UAF，Use after free。</li>
</ul>
<h4 id="设计原理">2. 设计原理</h4>
<p>​
鉴于内核错误报告展示了一个特定的错误行为，探索该错误其他可能的错误行为的一个本能反应是利用directed
fuzzing，即探索通往我们感兴趣的程序站点的路径。但这种方法有两个局限：</p>
<ul>
<li>首先，为了使用directed
fuzzing来暴露多种错误行为，我们需要确定有错误的代码片段（即错误的root），将其作为锚点，并将其提供给directed
fuzzer。然而，要正确和自动地确定内核错误的root是很有挑战性的。如果不正确地将一个非根本原因的点视为fuzzer的锚点，甚至可能使fuzzer无法触发该错误，更不用说找到该错误的多种错误行为了;</li>
<li>其次，即使我们能够指出内核错误的根源，也不意味着内核可以表现出多种错误行为。除了遵循不同的路径到达有缺陷的代码外，错误行为的展示也依赖于错误触发后的环境。例如，除了遵循一个特定的路径到有缺陷的代码片段，我们还需要一个单独的内核线程来改变一个全局变量，使触发错误和展示不同错误所需的背景多样化。根据设计，定向fuzzing法在接触到其感兴趣的目标代码后不能改变上下文。</li>
</ul>
<p>​
在本文，我们通过扩展现有的带有内核-对象指导的内核fuzzing方法来解决这个问题。根据我们对许多内核错误的观察，我们发现内核错误的根本原因通常来自两种：</p>
<ul>
<li><p><strong>对内核对象的不恰当使用。</strong>这进一步导致了内核错误（例如前面提到的为tun_struct类型的内核对象分配不一致的标志值的案例）；</p></li>
<li><p><strong>在使用内核对象进行计算时涉及到一个不正确的值，它被进一步传播到一个关键的内核操作中，迫使内核表现出一个错误</strong>（例如，一个未消毒的整数被用作内核对象的偏移量，导致一个越界的内存访问）。</p></li>
</ul>
<p>​
因此，在错误报告中指定的与错误相关的对象的指导下，我们可以让内核fuzzer远离那些与错误无关的路径和上下文，从而显著提高其效率。</p>
<h1 id="模型方法">模型方法</h1>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230407171021.png" /></p>
<p>​
如上图所示，首先将一个内核错误报告作为输入，运行所附带的PoC，并追踪那些涉及内核错误的内核结构（例如，例子中的结构tun_file）。进一步检查内核源代码，找出操作这些类型的对象的代码语句。我们将这些语句视为对内核错误触发的成功至关重要的锚点。因此，我们对这些语句进行检测，以便在进行内核fuzzing时收集对象覆盖率作为反馈，然后利用覆盖率来调整相应的PoC程序。在这项工作中，<strong>我们的内核fuzzing机制将错误报告中附加的原始PoC程序作为输入。使用一种新的突变和种子生成方法，它逐步改变PoC，提高了已知错误的多种错误行为探索的效率和效果。</strong></p>
<h4 id="确定关键结构">1. 确定关键结构</h4>
<p>​
利用后向污点分析来识别基本的内核结构（即参与给定报告中错误的相关结构）。</p>
<h5 id="报告分析-确定污点源">1.1 报告分析 &amp; 确定污点源</h5>
<h6 id="explicit-checking">1.1.1 Explicit Checking</h6>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230407171014.png" style="zoom:67%;" /></p>
<p>​
在上图中，函数<code>vhost_dev_cleanup()</code>的作用是：如果<code>dev-&gt;work_list</code>为空，清除连接到vhost_dev设备上的<code>worker</code>；否则通过<code>WARN_ON</code>内的宏报错。故在这里，污点分析的sources应该就是<code>dev-&gt;work_list</code>。在这个例子中，内核开发者明确地将预定义的条件制定为一个表达式，并将其传递给宏<code>WARN_ON</code>进行错误处理。然而，对于其他一些调试功能，检查是由编译器检测的，或者由硬件完成，而不是由内核开发者编写的一段源代码。对于这些功能，条件是隐含的，不能从内核的源代码中识别。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230408165002.png" style="zoom:67%;" /></p>
<p>​ Explicit
Checking就是对这一类明确条件的检查。内核开发者明确地将检查制定为一个表达式，并将其传递给标准调试功能，如WARN_ON和BUG_ON。这些宏是模式化的代码块，包括条件语句和日志语句，如果条件得到满足就会执行。除了这种标准化的记录内核错误的方式外，开发者还可以建立自己的宏，将日志语句包裹在一个辅助函数中（如上图15,16行）。</p>
<p>​
为了找到触发bug日志记录语句的源头，确定污点分析的sources，需要沿着支配树（如上图右半部分）回溯，直到找到一个条件跳转基本块。然后，我们将其相应的比较语句作为触发error记录操作的条件，从其中提取相应的变量作为sources。</p>
<h6 id="implicit-checking">1.1.2 Implicit Checking</h6>
<p>​ 对于由编译器检测或由硬件完成的相关条件检查，称之为隐式检查。</p>
<p>​
对于通过编译器工具完成的隐式检查，内核地址消毒器（KASAN）可以对每一个内存访问进行检测，这样就可以检查对一个内存地址的访问是否合法。KASAN依靠影子内存来记录内存状态。例如，如果被检测的内核触及一个已释放的内存区域，它将产生一个错误报告，<strong><u>指出引发使用后释放错误的指令</u></strong>。关于中断所做的隐性检查（例如，由MMU检测到的一般保护故障），中断处理程序负责记录相应的指令。<strong>从这些调试机制产生的错误报告中，我们可以很容易地确定执行无效内存访问的指令。有了这些信息，我们的下一步就是确定与该无效内存访问相关的变量。</strong></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230408162317.png" style="zoom:67%;" /></p>
<p>​
一般报告中所包含的错误指令是二进制指令。为了处理这个问题，从调试信息中，需要将二进制指令与源代码中的相应语句进行映射。假设对应的源代码是一个简单语句，只有一个加载或存储操作，在这种情况下，这个语句就是导致非法内存访问的语句，并将操作数变量作为污点源处理。然而，如果被识别的指令链接到一个涉及多个内存加载和存储的复合语句（如上图中描述的<code>walk-&gt;offset = sg-&gt;offset</code>），将进行进一步的分析。</p>
<p>​
具体来说，首先检查错误报告，并找出捕捉到内核错误的具体指令。然后，把与捕捉错误的指令相关的内存访问操作作为我们的sources。再次以上图中的情况为例。错误报告指出错误是由语句<code>kasan_check_read(&amp;sg-&gt;offset, sizeof(var))</code>捕获的，它与<code>sg-&gt;offset</code>有关。故这里认为第2行的<code>sg-&gt;offset</code>是污点源。</p>
<p>​</p>
<h5 id="污点传播-确定sink">1.2 污点传播 &amp; 确定sink</h5>
<p>​ 从错误报告中提取调用痕迹（call trace），基于call
trace构建cfg，并在该图上向后传播污点源。</p>
<ul>
<li><strong>如果被污染的变量是一个嵌套结构的字段或一个联合变量</strong>，则进一步污染其父结构变量，并将父结构视为一个关键结构（原因是，嵌套结构或联合变量是内存中父结构变量的一部分。如果嵌套结构或联合变量的某个字段带有一个无效的值，这很可能是由于对其父结构变量的不恰当使用造成的）；</li>
<li><strong>当污点传播遇到一个循环时</strong>，如果污点源在循环内被更新，那么也将循环计数器污染（举例，一些越界操作就是由于循环计数器被修改/破坏/扩大，导致访问了无效的内存区域）。</li>
</ul>
<p>​
当以下条件之一成立时终止污点传播，在进行污点向后传播的同时，也将传播扩展到被污点变量的别名上：</p>
<ol type="1">
<li>污点传播到了污点变量本身的定义语句；</li>
<li>污点传播到了系统调用的入口、中断处理程序或启动工作队列调度器的函数入口；</li>
</ol>
<h4 id="内核结构排序">2. 内核结构排序</h4>
<p>​
成功识别所有与报告中的错误有关的内核结构后，直接fuzzing可能导致效率低下问题，故这里做进一步缩小操作。</p>
<h5 id="内核结构选择">2.1 内核结构选择</h5>
<p>​ 在Linux内核中，提供了一个用来创建双向循环链表的结构
list_head。虽然linux内核是用C语言写的，但是list_head的引入，使得内核数据结构也可以拥有面向对象的特性，通过使用操作list_head
的通用接口很容易实现代码的重用。在整个内核代码库中，list_head结构被广泛地使用。如果将这种结构和相应的对象纳入内核模糊指导，内核模糊器将不可避免地探索一个大的代码空间，使模糊器偏离重心。因此，为了保持内核fuzzer探索的效率，我们需要将这些结构从我们的内核fuzzing中排除。</p>
<p>​
除了上面提到的结构，Linux内核开发者还实现了许多其他与抽象接口有关的结构。这些接口与实现层耦合在一起，以支持大量的设备和功能。例如，内核为所有从用户空间请求的网络服务创建了一个结构socket
，不管指定什么协议。因此，与struct
list_head类似，它们也应该在后期的内核fuzzing中被排除。</p>
<p>​
<u>为了精确定位并排除这些结构，这里设计了一种系统的方法，根据内核结构的流行程度对其进行排序。</u>在更高层次上，这个方法构建了一个描述内核结构之间引用关系的图。图中的每个节点代表一个内核结构，而节点之间的有向边表示参考关系。在该图上，应用PageRank算法，给每个结构分配一个权重，排除较高权值的结构。</p>
<h5 id="构建图结构">2.2 构建图结构</h5>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230408170355.png" style="zoom: 67%;" /></p>
<p>​
<strong>对于结构定义语句</strong>，给定一个结构，我们浏览它的所有字段成员。如果字段是一个指向另一个结构的指针，我们就把给定的结构与被引用的结构联系起来。如上图<code>extensions</code>是一个引用<code>struct skb_ext</code>的指针，就在图中把<code>sk_buff</code>结构链接到<code>skb_ext</code>结构。</p>
<p>​
<code>struct rb_node</code>是一个匿名union中的自我引用结构。这里就跳过匿名union，只将<code>struct sk_buff</code>直接链接到<code>struct rb_node</code>，而无需进一步扩展。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230408170845.png" style="zoom:67%;" /></p>
<p>​
<strong>对于类型转换语句，</strong>由于内核支持多态，例如上图中<code>ip6_fraglist_init</code>函数，<code>skb-&gt;data</code>从<code>void</code>被投射到<code>struct frag_hdr</code>。void*
是一个抽象的数据类型，而结构类型struct
frag_hdr*则更加具体化。因此，我们在结构图中增加了一条边，将结构skb_buff连接到结构frag_hdr。</p>
<p>​
利用构建的图，使用PageRank算法对其流行程度进行排序。只使用那些等级较低的内核结构和对象来指导fuzzing。</p>
<h5 id="技术性研讨">2.3 技术性研讨</h5>
<p>​
根据我们对数百个真实世界的内核错误的观察，大多数内核错误的根本原因与不太流行的结构有关。因此，删除流行的结构并不会对模糊器触发我们感兴趣的错误产生负面影响。</p>
<p>​
即使被消除的流行结构与我们感兴趣的内核错误的根源有关，让模糊器专注于这些不太流行的结构，仍然可以让我们接触到流行结构类型中的一些对象。原因是不太受欢迎的结构通常是由受欢迎的结构组成的（例如，list
1中罕见的结构struct napi_struct包含受欢迎的结构struct hrtimer）。</p>
<h4 id="对象驱动内核fuzzing">3. 对象驱动内核fuzzing</h4>
<p>​
传统的内核探索方法是利用跟踪函数来跟踪已经执行的基本块。在这项工作中，我们的探索机制保留了这种能力，并进一步引入了一个额外的工具化组件。其被设计成一个编译器插件，该插件检查基本块中的每条语句，并识别那些负责分配、删除和使用关键对象的基本块。更具体地说，组件引入了一个新的追踪功能，它将记录的基本块地址中最重要的16位替换为一个神奇的数字，以将这些基本块与其他基本块区分开来。有了这些工具，通过观察代码覆盖率反馈中最重要的16位地址，我们可以很容易地确定哪些与关键对象有关的基本块是在fuzzing程序的操作之下的。<strong>当运行一个模糊测试程序时，我们可以很容易地确定它是否接触到了一个关键对象</strong>。</p>
<h5 id="种子选择">3.1 种子选择</h5>
<p>​
若程序接触到了一个新的涉及关键对象的基本块/至少有一个系统调用涵盖了更多的代码（允许内核fuzzer积累内核状态，从而增加未来突变的可能性，以达到涉及关键对象的未见过的基本块。），并操作了关键对象时，将变异的种子添加到库中。</p>
<h5 id="种子生成-变异">3.2 种子生成 &amp; 变异</h5>
<p>​
<strong><u>使用报告中的POC程序用作初始种子，每次在生成新的种子时，只使用已经包含在种子库中的系统调用来组装新的种子。</u></strong></p>
<p>​
进一步引入了现有内核fuzzing（即Syzkaller）中使用的变异机制。这种突变机制将与种子库中已包含的系统调用相关的新系统调用引入种子中。</p>
<h5 id="变异优化">3.3 变异优化</h5>
<p>​
在对模糊程序进行突变时，Syzkaller的突变机制利用预定义的模板来指导新种子的合成。模板规定了系统调用之间的依赖关系和相应系统调用的参数格式。例如，Syzkaller的模板规定，系统调用read需要一个resource（即文件描述符）作为其参数之一，openat（）以及socket（）将产生相应的resource。在这个模板的指导下，Syzkaller可以通过在系统调用openat（）上附加系统调用read（）或socket（）来对模糊程序种子进行变异。模板指导下的突变确保了种子程序（也就是runner的输入）的合法性，从而避免了过早产生无效输入。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230410143107.png" style="zoom:67%;" /></p>
<p>​
但是，这种基于模板的突变方式也不一定符合我们的需求。以上图两个POC程序为例，Syzkaller在a中插入了socket()，显然增大了搜索空间，不利于fuzzing；在b中，Syzkaller根据@max变量的合法范围是[INT_MIN，INT_MAX]从而改变了@max的值，但在此Bug中，只有@max=-1时bug才会被触发，故这里的突变也是副作用的。</p>
<p>​
<strong>故为了更高效的fuzzing，这里需要进行变异优化。</strong>根据相应的系统调用所依据的资源类型对系统调用规范模板进行分组（例如将与网络套接字和设备文件有关的系统调用分别归类）。在每组中，再将系统调用分为两个子组。一个是负责资源的创建，另一个是负责资源的使用。当变异种子程序时，我们的模糊组件要么用同一组中的系统调用替换，要么插入与种子程序中显示的资源相关的系统调用。</p>
<h4 id="section"></h4>
<p>ps：</p>
<ul>
<li>污点分析：三元组&lt;sources, sinks,
sanitizers&gt;，代表污点源，污点会聚处和消毒器。</li>
</ul>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Vulnerability</tag>
        <tag>AEG</tag>
      </tags>
  </entry>
  <entry>
    <title>Demons in the Shared Kernel--Abstract Resource Attacks Against OS-level Virtualization</title>
    <url>/2023/03/15/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Demons-in-the-Shared-Kernel-Abstract-Resource-Attacks-Against-OS-level-Virtualization/</url>
    <content><![CDATA[<h1
id="demons-in-the-shared-kernel-abstract-resource-attacks-against-os-level-virtualization">Demons
in the Shared Kernel: Abstract Resource Attacks Against OS-level
Virtualization</h1>
<blockquote>
<p><strong>时间：</strong>2021.11</p>
<p><strong>作者：</strong>Nanzi Yang（西电）、Wenbo Shen（浙大）</p>
<p><strong>会议：</strong>CCS</p>
</blockquote>
<p>对docker的一种Ddos攻击，实现了自动化检测。</p>
<h2 id="abstract">ABSTRACT</h2>
<p>​ 由于其更快的启动速度和更好的资源利用效率，操作系统级虚拟化(OS-level
virtualization)已被广泛采用，并已成为云计算的一项基本技术。与硬件虚拟化相比，操作系统级虚拟化利用共享内核设计来达到更高的效率，并在共享内核上运行多个用户空间实例（又称容器）。然而，在本文中，我们揭示了一个新的攻击面，此漏洞是操作系统级虚拟化技术所固有的，会影响到Linux、FreeBSD和Fuchsia。</p>
<p>​
产生漏洞的根本原因是，<strong><u>操作系统级虚拟化中的共享内核设计导致容器直接或间接地共享成千上万的内核变量和数据结构。在不利用任何内核漏洞的情况下，非特权容器可以轻易地用尽共享的内核变量和数据结构实例，对其他容器进行DoS攻击。</u></strong>与物理资源相比，这些内核变量或数据结构实例（称为抽象资源）更普遍，但受到的保护不足。</p>
<p>​ 为了显示限制<strong>抽象资源</strong>（Abstract
Resources）的重要性，我们针对操作系统内核的不同方面进行了抽象资源攻击。结果表明，攻击抽象资源是非常实用和关键的。我们进一步进行了系统分析，以识别Linux内核中易受攻击的抽象资源，成功检测出1010个抽象资源，其中501个可以被动态地重复消耗。我们还在四大云厂商的自部署共享内核容器环境中进行了攻击实验。结果显示，所有环境都容易受到抽象资源的攻击。我们得出结论，限制抽象资源的使用是很难的，并给出了减轻此风险的多种策略。</p>
<span id="more"></span>
<h2 id="针对容器的抽象资源攻击">针对容器的抽象资源攻击</h2>
<p>​
操作系统级虚拟化可以在同一个内核上运行多个用户空间容器，与硬件虚拟化相比，其减轻了模拟操作系统内核的负担，故有着更快的速度和更高的资源利用率。用户空间的操作系统级虚拟化实例，在FreeBSD上叫jails、在Solaris上叫Zones、在Liunx上叫containers。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230315142400.png" style="zoom:67%;" /></p>
<p>​
<strong>由于共享内核机制的存在，注意到，底层的操作系统内核包含数为容器提供服务的十万个变量和数据结构实例</strong>。因此，这些容器直接或间接地共享这些内核变量和数据结构实例。</p>
<p>​
这些抽象资源可以被利用来进行DoS攻击，并且系统对它们的保护措施往往不足。内核和容器开发者更注重保护物理资源而不是抽象资源。例如，Linux内核提供控制组来限制每个容器实例的资源使用。然而，在13个控制组中，有12个是针对物理资源的，限制了CPU、内存、存储和IO的使用。只有PIDs控制组是为限制抽象资源PID而设计的。因此，数百个容器共享的抽象资源没有任何限制，如global
dirty ratio、open-file structs、pseudo-terminal
structs等，这使得它们容易受到DoS攻击。</p>
<p>​
举个例子，下图是Linux内核中的一个全局变量<strong>nr_files</strong>及其利用函数，nr_files是系统中任意时刻文件数量的上限值，限制的文件总数。然而Linux内核并没有对nr_files变量提供任何控制隔离措施，因此，所有容器都可以直接控制nr_files的值。</p>
<p>​
在Linux世界中，所有几乎所有操作都可以看做文件操作，计时器、事件生成、运行命令等。一个容器可以在几秒内轻松消耗完nr_files的值，这样导致的结果就是同一系统内的其它容器在系统资源还很充裕的时候，一条命令、一个程序都不能运行。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230315143405.png" style="zoom:67%;" /></p>
<h2 id="自动检测可利用的抽象资源">自动检测可利用的抽象资源</h2>
<p>​
文章的整体思路就是围绕着抽象资源的检测与利用进行。为了检测出系统中可利用的抽象资源，文章提出了：</p>
<ul>
<li><strong><em>configuration-based analysis</em></strong>
和<strong><em>access-based
analysis</em></strong>方法用于查找内核中共享在容器中的抽象资源；</li>
<li><strong><em>Syscall Reachability
Analysis</em></strong>和三个<strong><em>Restriction
Analysis</em></strong>方法用于确定抽象资源可以被容器消耗完。</li>
</ul>
<h3 id="configuration-based-analysis-access-based-analysis">1.
Configuration-based Analysis &amp; Access-based Analysis</h3>
<h4 id="configuration-based-analysis">1.1 configuration-based
analysis</h4>
<p>​
Linux下的sysctl命令可以查看/修改内核参数，这些参数位于/proc/sys目录下。<strong>注意到，这些sysctl配置大多用于抽象的资源限制，比如限制文件数量fs.file-nr或内存大页面vm.nr_hugepages。因此，所有的容器都在共享由sysctl配置指定的相同的全局限制。</strong>这种sysctl配置提供了关于容器之间可共享的抽象资源的重要线索。</p>
<p>​
故这里的configuration指的就是sysctl配置参数。基于配置的分析分为三步：</p>
<ol type="1">
<li>首先，它使用特定的sysctl数据类型来识别所有与sysctl相关的数据结构。这些数据结构包含可配置的sysctl内核参数；</li>
<li>其次，sysctl数据结构通常包含在/proc/sys/文件夹中显示sysctl值的函数。因此，通过分析该函数，我们能够准确地找出该内核参数的变量；</li>
<li>最后，如果一个内核参数被用于限制资源消耗，其相应的变量应该出现在比较指令中。因此，我们按照使用-定义链来检查所确定的变量的使用情况，如果它在比较指令中被使用，就把它标记为抽象资源</li>
</ol>
<p>​
如下图所示，Linux的proc文件系统使用数据结构ctl_table来配置sysctl内核参数。我们在LLVM中设计并实现了一个程序间分析通道，分析程序首先遍历所有内核全局变量来查找所有ctl_table数据结构，跟随.proc_handler回调指针启动程序间分析以获得确切的变量，定位到19行的nr_files关键变量。最后，检查所有已识别的关键变量的使用情况。<strong>如果一个关键变量在比较指令中被使用（即LLVM
IR中的icmp），就会记录这些位置并将这个变量标记为抽象资源</strong>（25行，nr_files）。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230315145607.png" style="zoom:67%;" /></p>
<h4 id="access-based-analysis">1.2 access-based analysis</h4>
<p>​
除了sysctl配置，Linux内核还使用锁或原语机制来保护并发访问的资源。<strong>因此，我们使用并发访问性质作为标识一组可共享的抽象资源的标志。</strong>如果某个数据结构本身就是锁，或者在上锁/解锁之间被定量修改，我们就将其定位为抽象资源。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230315151312.png" style="zoom:67%;" /></p>
<p>​
同时，分析方法还考虑了atomic和percpu计数器，其分析方法都集成在LLVM中。</p>
<h3 id="syscall-reachability-analysis-restriction-analysis">2. Syscall
Reachability Analysis &amp; Restriction Analysis</h3>
<h4 id="syscall-reachability-analysis">2.1 syscall reachability
analysis</h4>
<p>​
为了确定筛选出来的抽象资源可以被容器消耗，我们根据内核控制流图进行传统的后向控制流分析，其中间接调用是根据结构类型来解决的[42,
70]。如果没有从系统调用条目到抽象资源消耗点的路径，我们就把这个抽象资源从容器中标记为不可达。</p>
<h4 id="restriction-analysis">2.2 restriction analysis</h4>
<p>​
仅有可达性分析是不够的，我们需要进一步确保路径上没有额外的针对容器的限制。如seccomp、命名空间、控制组以及每个用户的资源限制。</p>
<h5 id="seccomp">2.2.1 seccomp</h5>
<p>​
Seccomp是一种用于系统调用过滤的机制。我们对seccomp的限制分析中，使用Docker默认的seccomp配置文件[15]，它阻止了50多个系统调用。在所有从系统调用条目到资源消耗点的路径中，过滤掉源自任何被阻止的系统调用的路径。</p>
<h5 id="per-user">2.2.2 per-user</h5>
<p>​
在实际部署中，容器通常使用不同的用户运行。因此，每个容器的资源消耗也被每个用户的资源配额所限制。例如，Linux提供了用户限制命令ulimit来限制特定用户的资源消耗。而ulimit的底层实现是使用rlimit来设置多个每个用户的资源配额。</p>
<p>​ 除了ulimit，Linux还提供了一些接口，允许用户利用PAM（Pluggable
Authentication
Module）来部署每个用户的配额。PAM使用setup_limits函数[64]来设置每个用户的资源配额，它调用setrlimit来配置多个rlimit约束。对于由ulimit、rlimit和PAM限制的资源，攻击者容器不能消耗超过每个用户的配额。因此，它不能完全控制这些抽象的资源来发动DoS攻击。</p>
<p>​
由于ulimit和PAM都使用rlimit来设置每个用户的资源配额，我们需要分析rlimit并过滤出受其限制的抽象资源。对于rlimit分析，我们的关键观察是，rlimit值通常是在struct
rlimit或struct
rlimit64中指定的。因此，我们首先遍历内核IR，以确定所有从结构rlimit或结构rlimit64加载的变量。然后，我们进行数据流分析，跟踪这些变量的所有传播和使用情况，如果这些变量在任何比较指令中被使用，则标记这些函数。在这些函数中，rlimit被检查以限制某些资源。我们认为这些资源不能被攻击者容器用尽，因此我们根据这些函数过滤掉路径。我们的工具确定了40个检查rlimit的函数。</p>
<h5 id="namespace">2.2.3 namespace</h5>
<p>​ 对于一个命名空间隔离的资源，Linux内核会在每个命名空间下为其创建一个
"副本"，这样在一个命名空间的修改就不会影响到其他命名空间。因此，为了确认容器的可控性，我们需要确保那些抽象资源不受名字空间的保护。<strong>这里存在一个问题，即使Linux有关于命名空间的文档，也没有关于哪些抽象资源被命名空间所隔离的规范。</strong></p>
<p>​
<u>观察到，对于一个被命名空间隔离的资源，相应的数据结构有一个指针字段，指向它所属的命名空间。</u>因此，我们的工具首先遍历了内核中每个数据结构类型的所有字段。如果该类型有一个命名空间指针，我们就把它标记为一个被限制隔离的资源。其次，对于识别出的隔离资源，我们的工具用它来过滤§4.1中识别的共享抽象资源。请注意，由于不同命名空间之间的映射，一些命名空间隔离的资源可能仍然容易受到抽象资源的攻击。如§3.2.2所述，idr是由pid_namespace-&gt;idr隔离的。然而，在非根PID命名空间分配的每个idr都被映射到根PID命名空间的一个新idr，这样根命名空间就可以管理它。因此，根PID命名空间被所有PID命名空间的所有容器全局共享。因此，它仍然容易受到idr耗尽的攻击。在我们的分析中，我们手动过滤掉这些资源。</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230315152653.png" /></p>
<p>​
如图所示，通过两次分析，程序就可以自动识别内核中可利用的抽象资源。由于本文重点关注漏洞的AEG利用，这里的容器攻击难点其实就是<u>自动化查找抽象资源</u>，利用并不难，故本文到这里结束。</p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Vulnerability</tag>
        <tag>AEG</tag>
        <tag>Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows of Vulnerability--A Case Study Analysis</title>
    <url>/2023/02/27/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Windows%20of%20Vulnerability%20A%20Case%20Study%20Analysis/</url>
    <content><![CDATA[<h1
id="论文阅读windows-of-vulnerability-a-case-study-analysis">【论文阅读】Windows
of Vulnerability: A Case Study Analysis</h1>
<blockquote>
<p><strong>时间：</strong>2000</p>
<p><strong>作者：</strong>Arbaugh W A, Fithen W L, McHugh J</p>
<p><strong>期刊：</strong>Computer</p>
</blockquote>
<h2 id="abstract">ABSTRACT</h2>
<p>作者为系统漏洞提出了一个“生命循环”模型，以此来分析三个样例，揭示了系统如何在安全修复后的很长一段时间内仍然存在漏洞。</p>
<span id="more"></span>
<h2 id="model">Model</h2>
<h3 id="漏洞的生命周期">漏洞的生命周期</h3>
<h4 id="本文提出的模型">1.本文提出的模型：</h4>
<ol type="1">
<li><strong><em>Birth</em></strong>：代表漏洞的产生，漏洞通常在大型开发项目的过程中无意地被制造。若漏洞是故意被制造的，那么Birth和Discovery同时发生；</li>
<li><strong><em>Discovery</em></strong>：代表有人发现了漏洞的存在，许多情况下漏洞的发现者并不会向外披露他的发现；</li>
<li><strong><em>Disclosure</em></strong>：代表漏洞的存在被传播到更广的范围，例如被上传到了Bugtraq的邮件列表中，向公众公开；</li>
<li><strong><em>Correction</em></strong>：代表开发商提供了软件补丁或者更改了配置，修补了漏洞；</li>
<li><strong><em>Publicity</em></strong>：代表漏洞已经广为人知，例如被新闻报道或被应急事件响应中心发布报告，一旦漏洞在Disclosure阶段失控，漏洞就会被广为人知；</li>
<li><strong><em>Scripting</em></strong>：代表漏洞的自动化利用程序已经被编写，脚本小子也可以利用脚本来实施攻击。Scripting极大地增加了对应漏洞的被利用次数；</li>
<li><strong><em>Death</em></strong>：代表漏洞的湮灭，当一个漏洞可以利用的系统数量缩减到不重要的时候，这个漏洞就会死亡。理论上来说，如果所有的系统都安装了对应补丁、或者漏洞影响的系统被淘汰、或者攻击者和媒体对该漏洞失去兴趣，这个漏洞就会消亡。</li>
</ol>
<p>​
一般来说，Birth、Discovery和Disclosure是按顺序进行的，Correction、Publicity、Scripting顺序不定。</p>
<h4 id="三个case-studies">2. 三个Case Studies：</h4>
<h5 id="phf-incident">2.1 Phf incident</h5>
<p>​ phf漏洞是一个命令执行漏洞：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230228171439.png" /></p>
<p>​
理论上，利用这个漏洞可以在目标主机上执行任意命令，但网上第一个发布的phf漏洞的利用脚本只是尝试在目标主机上下载密码文件，并无过多动作。有趣的是，<u>向CERT报告的大多数事件只涉及下载密码文件</u>，可见：大多数脚本小子们在不了解脚本的情况下盲目地运行利用脚本，如果他们懂得漏洞的原理，返回一个shell明显可以做更多事情。</p>
<p>​
从图中可以看到，漏洞的利用次数从自动脚本化开始就激增。随着96年8月该漏洞的相关补丁发布，入侵行为短时间内骤减。但直到1998年该漏洞的利用行为都一直大量存在。</p>
<h5 id="imap-incident">2.2 IMAP incident</h5>
<p>​
IMAP邮件服务提供了通过互联网访问电子邮件的功能。其在早期的版本存在缓冲区溢出漏洞，下图显示了其两个短期内发现的相似的漏洞。</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230228182023.png" /></p>
<p>​ 可以看到，两个漏洞的柱状图形状大体相同。</p>
<h5 id="bind-incident">2.3 BIND incident</h5>
<p>​ Bind是DNS协议的一种实现，是现今互联网上使用最为广泛的DNS
服务器程序。其1998年存在缓冲区溢出漏洞：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230228182729.png" style="zoom: 67%;" /></p>
<p>​</p>
<h3 id="漏洞数据来源">漏洞数据来源</h3>
<p>​
<strong>CERT/CC</strong>，美国计算机紧急事件响应小组协调中心。成立于1998年，位于匹兹堡的卡内基梅隆大学内。它的主要职能是对软件中的安全漏洞提供咨询，对病毒和蠕虫的爆发提供警报，向计算机用户提供保证计算机系统安全的技巧以及在处理计算机安全事故的行动中进行协调。当有恶意程序或系统漏洞被报告时，CERT/CC会对外发布“事件”，其描述了漏洞的性质、利用的方式或工具等。</p>
<p>​
作者从CERT/CC数据库中选择样例进行分析，数据涵盖了1996~1999年的一些特有的入侵行为。</p>
<h3 id="人的薄弱">''人''的薄弱</h3>
<p>​
从上述三个例子可以看出，漏洞的自动化利用是导致相关入侵行为激增的关键，但除此之外，可以注意到的是：</p>
<ol type="1">
<li><strong>即使漏洞的相关修补措施已经发布，相关的入侵行为仍在其后的很长一段时间内存在，甚至增长</strong>。在漏洞补丁发布之后，一方面，需要时间传播与安装；另一方满，一些谨慎的组织要求在改变系统之前进行测试，这是正确的，以确保补丁不会产生新的问题。有些组织在
"有机会
"的时候会安装补丁，而其他组织可能永远不会安装补丁，其中牵扯到的原因有很多；</li>
<li><strong>即使一些漏洞修补措施仅能防御一些简单的攻击，但其仍有意义。</strong>在漏洞发布后紧跟的修补措施所防止的入侵可能只是脚本小子的骚扰性攻击，更复杂的攻击者可能仍然会成功。但即使这样，也能减少整体的入侵行为，留出更多的时间精力资源跟踪调查更复杂的攻击。</li>
</ol>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>Vulnerability</tag>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title>(技术积累)Symbolic Execution----从思维上理解符号执行</title>
    <url>/2023/02/16/%E3%80%90%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF%E3%80%91Symbolic%20Execution-%E7%AC%A6%E5%8F%B7%E6%89%A7%E8%A1%8C/</url>
    <content><![CDATA[<h1 id="symbolic-execution从思维上理解符号执行">Symbolic
Execution：从思维上理解符号执行</h1>
<p>​
符号执行作为软件分析、漏洞发掘领域经常出现的技术，国内已经有不少文章总结讨论。但新手直接翻阅学习这些总结性质的文章时碰到的诸如“符号路径约束”、“约束求解”、“执行状态”等专有名词会难以理解，思维逻辑与理论概念不易同轨。本文从国外的一些热门教程入手，
将符号执行从思维上捋一遍， 诠才末学，仅做抛砖引玉之用。</p>
<h2 id="引子">1. 引子：</h2>
<h3 id="一个样例">1.0 一个样例</h3>
<p>​ 从一段经典的代码入手，解释符号执行的核心思路。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230216152920.png" style="zoom:50%;" /></p>
<p>​
<strong>分析目标：对于任意可能的输入组合(a,b)，找到使得断言assert语句失败的所有输入。</strong></p>
<span id="more"></span>
<p>​
对于以上函数，如果使用随机测试的方法，共有2<sup>32</sup>×2<sup>32</sup>种输入组合，想要找到所有的符合条件的输入就得遍历所有输入，显然，这么做效率低下，费时费力。</p>
<p>​ 符号执行的核心思想有以下几点：</p>
<ol type="1">
<li>每一个输入变量都被映射为了一个符号，例如int i ——&gt; α<sub>i</sub>
；</li>
<li>每一个符号代表所有可能的输入值的集合，例如 α<sub>i</sub>
∈[0，2<sup>32</sup>-1] ；</li>
<li>程序中的语句都由符号来完成运算，例如i*2 + 5 ——&gt; 2· α<sub>i</sub>
+ 5 ；</li>
</ol>
<p>​ 如果遇到了分支条件，需要考虑每一个分支下可能执行的路径：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230216154301.png" style="zoom: 50%;" /></p>
<p>​ 在开始第一次符号执行演练之前，这里定义执行状态（Execution
state）的概念： <span class="math display">\[
Execution\enspace state=\{stmt,\sigma,\pi\}
\]</span></p>
<ol type="1">
<li>stmt是当前状态的下一个状态；</li>
<li>σ是将程序变量映射到符号或者常数的映射，如果变量的值不确定就是映射到符号，反之映射到常量；</li>
<li>π表示路径上的限制，即到达当前状态需要什么限制条件。例如对于上述函数，只有a^(!b)才能到达第6行，所以若程序在第6行的π
= <span class="math inline">\((\alpha_a \neq 0 )\and (\alpha_b =
0)\)</span>，π的初始值为true。</li>
</ol>
<p>​
如果使用符号执行来分析上述函数，在程序的开头，会得到第一个执行状态。根据上述定义，其stmt是它的下个待分析状态，也就是程序的第二行：“int
x = 1, y =
0;”；其σ会将第一行引入的变量a,b映射到符号，由于a,b是输入，都不是常量，故可以得到：<span
class="math inline">\(\sigma=\{a\rightarrow \alpha_a, b\rightarrow
\alpha_b\}\)</span>；1开始并没有遇到条件判断语句，故π为初始值true。如下图所示：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230216155417.png" style="zoom: 50%;" /></p>
<p>​
当状态A接着执行，我们遇到了一个整型声明语句，其添加了两个新变量x，y并赋初始值。故从状态A到状态B其σ添加了新的映射，stmt变为下一条待执行语句，π不变：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230216160440.png" style="zoom:50%;" /></p>
<p>​
从状态B的stmt表明接下来的分析遇到了条件判断语句，对于if语句的两种可能，衍生出两个执行状态：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230216160626.png" /></p>
<p>​
当状态D继续执行就遇到了assert断言语句，在断言处我们判断当前的条件（σ、π）下是否满足断言条件：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230216160745.png" style="zoom: 67%;" /></p>
<p>​ 如图所示，在x = 1，y = 0，且α<sub>a</sub> = 0的条件下，x-y ≠ 0
，断言并未触发，此条分支执行结束。</p>
<p>​ 当C状态继续执行，遇到了y = 3 +
x赋值语句，这时就要改变σ中的映射关系：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230217193952.png" style="zoom:67%;" /></p>
<p>​ 状态E继续执行，遇到条件判断语句，同理，生成两个分支：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230216161133.png" /></p>
<p>​ 状态G进行逻辑判断，并未触发：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230216161214.png" style="zoom:67%;" /></p>
<p>​ 状态F继续执行，进行判断，触发错误条件：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230216161307.png" style="zoom:67%;" /></p>
<p>​
到此为止，所有分支执行完毕，符号执行判断出当a=2且b=0时，断言语句会被触发。如果我们的测试目标从触发断言语句改为触发漏洞行为，符号测试就是进行漏洞的排查。</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230216164653.png" /></p>
<h3 id="机器如何判断">1.1 机器如何判断？</h3>
<p>​
上文所述的例子描述了符号执行的基本逻辑：<strong>用符号代替变量，判断最终生成的布尔表达式是否可满足</strong>。在上文中，我们当然可以轻松地用大脑分析出只要输入a
= 2且b =
0，断言就会被触发。但在面对复杂且庞大的逻辑表达式时，我们不能每次都去人工分析，想要完整的利用计算机实现符号执行，就需要解决自动化判断逻辑表达式是否可满足的问题。</p>
<p>​
SAT，布尔可满足性问题，它询问给定布尔公式的变量是否可以用值TRUE或FALSE一致地替换，以使该公式的值为TRUE。例如$a\and
b $就是可满足的，而 <span class="math inline">\(a \and !a\)</span>
就是不可满足的。SAT在理论上已经被证明是NP问题，虽然可以快速验证这个问题的解，但不能确定其求解速度。目前已经有很多成熟的SAT算法。</p>
<p>​ SMT将SAT实例中的一些二进制变量（True or
False）替换为非二进制变量，非二进制变量包括线性不等式（x+2y &gt;
4）、符号等式（<span class="math inline">\(f(f(u,v),v) =
f(u,v)\)</span>）。SMT的背景符合符号执行所面临的的问题，利用已有的SMT解法就可以解决上述的逻辑表达式自动化判断问题。可以看到，我们将符号执行过程中的一系列限制条件称为约束（constraint），而使用SMT对该约束进行求解的过程就叫约束求解。</p>
<p>​
使用符号执行不并一定要具体的理解SMT的技术细节，但其逻辑大体如下：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230217143933.png" style="zoom:50%;" /></p>
<p>​
对于SMT这类NP完全问题，在指定时间内SMT求解器会给出是否满足的结果，若超出时间则给出“不知道”。</p>
<p>​ <strong>综上，在使用前文定义的符号执行流程分析后，配合SMT
Slover即可进行完整的符号执行分析。</strong></p>
<h3 id="如何证明没有其它样例">1.2 如何证明没有其它样例？</h3>
<p>​ 如何证明我们找到的"a=2且b=0"就是所有的满足条件的输入了？</p>
<p>​
从理论上来说，符号执行遍历执行了程序所有可能的条件分支，分析了所有可能路径下的SMT问题，以此得出的结果必然是完整的，没有其它特例的。但在实际应用中，存在一些很难被解决的限制，执行生成的路径可能特别多，并且影响程序执行路径的因素不再是a，b几个变量这么简单，这些因素导致了在实际的符号执行中不便于做理论完整的评估。</p>
<h2 id="进一步深入">2. 进一步深入</h2>
<h3 id="memory-model">2.1 memory model</h3>
<p>​ 看看如下代码：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230217150537.png" style="zoom:50%;" /></p>
<p>​
当代码中涉及到对内存的操作时，又如何设计相应符号呢？事实上我们将整个内存看成一个大数组MEM[]，对内存的操作不过是对数组的操作：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230217152355.png" style="zoom:50%;" /></p>
<p>​
这里的y1与y不完全相同，y代表地址，y1代表MEM数组中的位置。在C语言中，y =
x + 10其实是y指针往后移动了10个x指针类型的位置，也就是y1 = x1 +
10*sizeof(int)。而对于malloc函数，可以将其简单看做返回未使用空间起始地址的函数，下面是一个简单的抽象：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230217152702.png" style="zoom:50%;" /></p>
<p>​
当将堆内存抽象为数组操作时，现有SMT求解器支持基于数组的逻辑操作（Theory
of arrays）。对数组的操作可以抽象为： <span class="math display">\[
\begin{equation}
a\{i\rightarrow e\}[k] = \left\{
\begin{array}{cl}
a[k] &amp; if &amp; k \neq i \\
e &amp;  if &amp; k = i
\end{array} \right \\
\end{equation}
\]</span> ​ 经过一系列的数组操作： <span class="math display">\[
a\{i\rightarrow 5\}\{j\rightarrow 7\}···[k] = 5 \Leftrightarrow ···
\]</span> ​
SMT引擎会将数组操作转化为对应的布尔操作，进而进行求解。当然，这个函数与C语言中malloc具体实现很不一样，其忽略了很多细节，例如对当前分配空间是否使用的检查。但经过这样简单的抽象，就可以使用上述的思路进行符号执行的判断。</p>
<p>​ <strong>memory
model，翻译为“内存建模”，从以上的例子可以看出，面对复杂的数据结构、函数操作甚至是陌生的第三方库，在使用符号执行前需要对其进行合适的抽象建模。</strong>目前已经有许多研究成果针对C语言的第三方库建模。建模的好坏也直接影响符号执行的性能与效率，例如对于上述的malloc，如果我们仅仅想检测最简单的缓冲区溢出漏洞，考虑malloc复杂的堆分配机制就是多余的。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230217151607.png" style="zoom:50%;" /></p>
<h3 id="path-explosion">2.2 path explosion</h3>
<p>​ 抛开上述举例的toy
code，现实中需要检测的商业软件一般都有成千上万行代码，其结构包含大量分支、循环、内存操作等等，如果还按照上文的思路进行执行，不仅会导致搜索时间的过长，还会使最终的执行状态过大。</p>
<p>​
在设计符号时，就应该避免引入无关/作用不大的符号，避免状态过大。且在路径搜索时可以使用深度优先、随机路径、广度优先、错误路路径优先等算法优化搜索方法，以求达到广度与深度的平衡。（又是经典的exploration
and exploitation问题）</p>
<p>​ 具体的进一步深入可以查看：Baldoni R, Coppa E, D’elia D C, et al.
<strong>A survey of symbolic execution techniques</strong>[J]. ACM
Computing Surveys (CSUR), 2018, 51(3): 1-39.</p>
<h2 id="实践一下">3. 实践一下</h2>
<p>​
对于源代码分析，KLEE[4]是很个很棒的框架工具；对于二进制分析，S2E[5]是个非常强有力工具，但使用稍显复杂。</p>
<p>​
这里使用angr，angr[6]是一个分析二进制的python框架，使用非常便捷。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230217162143.png" style="zoom:50%;" /></p>
<blockquote>
<p><strong>目标1：</strong>使用angr符号执行分析本文举出的第一个例子，follbar()的二进制文件.</p>
<p><strong>目标2：</strong>使用angr符号执行分析logic-bomb二进制程序.</p>
</blockquote>
<p>​ 安装相应虚拟环境：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">#安装python虚拟环境</span>
<span class="token function">sudo</span> pip3 <span class="token function">install</span> virtualenvwrapper 
<span class="token comment">#创建目录用来存放虚拟环境</span>
<span class="token function">mkdir</span> <span class="token environment constant">$HOME</span>/.virtualenvs
<span class="token comment">#在~/.bashrc中,最后添加</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">WORKON_HOME</span><span class="token operator">=</span><span class="token environment constant">$HOME</span>/.virtualenvs
<span class="token assign-left variable">VIRTUALENVWRAPPER_PYTHON</span><span class="token operator">=</span>/usr/bin/python3
<span class="token builtin class-name">source</span> /usr/local/bin/virtualenvwrapper.sh
<span class="token comment">#创建一个名为angr的虚拟环境</span>
mkvirtualenv angr
<span class="token comment">#进入虚拟环境并安装angr</span>
workon angr
pip3 <span class="token function">install</span> angr
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="foolbar">3.1 foolbar</h3>
<p>​ 使用idafree-7.0打开slide-example/example文件，找到foolbar函数：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230217165438.png" style="zoom:80%;" /></p>
<p>​ 打开行前缀选项：Options–&gt;General–&gt;Disassembly–&gt;Line
prefixes(graph)，可以显示汇编指令地址：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230217170143.png" style="zoom:80%;" /></p>
<p>​ 想要使用angr分析函数，需要给定其：</p>
<ul>
<li>start target：代码开始运行地址；</li>
<li>find target：代码结束运行地址；</li>
<li>avoid targets：哪些路径（地址）被忽略，以此来避免路径爆炸问题；</li>
</ul>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230217170538.png" /></p>
<p>​
由于angr不知道什么是符号什么是常数，后续还需要定义输入的符号。angr分析脚本如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> angr

proj <span class="token operator">=</span> angr<span class="token punctuation">.</span>Project<span class="token punctuation">(</span><span class="token string">'example'</span><span class="token punctuation">)</span>

<span class="token comment"># customize XXX, YYY, and ZZZ!!!</span>
start <span class="token operator">=</span> XXX    <span class="token comment"># addr of foobar</span>
avoid <span class="token operator">=</span> <span class="token punctuation">[</span>YYY<span class="token punctuation">]</span>  <span class="token comment"># point(s) that are not interesting (e.g., early exits)</span>
end <span class="token operator">=</span> ZZZ      <span class="token comment"># point that I want to reach</span>

<span class="token comment"># blank_state since exploration should start from an arbitrary point</span>
<span class="token comment"># otherwise, use entry_state()</span>
state <span class="token operator">=</span> proj<span class="token punctuation">.</span>factory<span class="token punctuation">.</span>blank_state<span class="token punctuation">(</span>addr<span class="token operator">=</span>start<span class="token punctuation">)</span>

<span class="token comment"># arguments are inside registers in x86_64</span>
a <span class="token operator">=</span> state<span class="token punctuation">.</span>regs<span class="token punctuation">.</span>edi
b <span class="token operator">=</span> state<span class="token punctuation">.</span>regs<span class="token punctuation">.</span>esi

sm <span class="token operator">=</span> proj<span class="token punctuation">.</span>factory<span class="token punctuation">.</span>simulation_manager<span class="token punctuation">(</span>state<span class="token punctuation">)</span>

<span class="token keyword">while</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sm<span class="token punctuation">.</span>active<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span>sm<span class="token punctuation">)</span> <span class="token comment"># get a feeling of what is happening</span>
    sm<span class="token punctuation">.</span>explore<span class="token punctuation">(</span>avoid<span class="token operator">=</span>avoid<span class="token punctuation">,</span> find<span class="token operator">=</span>end<span class="token punctuation">,</span> n<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sm<span class="token punctuation">.</span>found<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span> <span class="token comment"># Bazinga!</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\nReached the target\n"</span><span class="token punctuation">)</span>
        state <span class="token operator">=</span> sm<span class="token punctuation">.</span>found<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"%edi = "</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>state<span class="token punctuation">.</span>solver<span class="token punctuation">.</span>eval_upto<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"%esi = "</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>state<span class="token punctuation">.</span>solver<span class="token punctuation">.</span>eval_upto<span class="token punctuation">(</span>b<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">break</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
代码整体很简洁，angr.Project构建Project类，Project类是angr模块的主类，它对一个二进制文件进行初始的分析以及参数配置，并将数据存储起来进行后续进一步分析。proj.factory.blank_state()指定任意地址开始运行。在Angr中，程序每执行一步（也就是step）就会产生一个状态（state，在SM这里叫做stashe）,Simulation_Manager就是提供给我们管理这些state的接口。注意到，符号变量是使用寄存器进行存储的。</p>
<p>​ 运行脚本：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230217172729.png" /></p>
<p>​
可以看到，脚本程序分析出，当edi(a)=2或者2147483650，esi(b)=0时会触发断言，这里2147483650显然就是整数溢出后的2。以此可见符号执行的程序实现需要考虑到计算机数字与数学数字的区别。</p>
<h3 id="logic-bomb">3.2 logic-bomb</h3>
<p>​
logic-bomb是一个没有源码的二进制程序，你需要依次输入正确答案以此逃过爆炸：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230217185901.png" style="zoom:50%;" /></p>
<p>​ 用IDA打开：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230217190852.png" style="zoom:67%;" /></p>
<p>​
可以看到程序从主函数开始分别调用phase_1()、phase_2()······phase_6()，进入phase_1()：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230217191054.png" style="zoom: 67%;" /></p>
<p>​
如果你懂得逆向的知识，可以尝试人工分析去解开这个bomb，但如果使用符号执行分析，只需要确定使其成功通过的地址即可：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230217191243.png" style="zoom: 50%;" /></p>
<p>​ 分析脚本如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> angr
<span class="token keyword">import</span> logging
<span class="token keyword">import</span> claripy
<span class="token keyword">import</span> pdb
<span class="token keyword">import</span> resource
<span class="token keyword">import</span> time

proj <span class="token operator">=</span> angr<span class="token punctuation">.</span>Project<span class="token punctuation">(</span><span class="token string">'bomb'</span><span class="token punctuation">)</span>

start <span class="token operator">=</span> XXX
avoid <span class="token operator">=</span> <span class="token punctuation">[</span>YYY<span class="token punctuation">]</span>
end <span class="token operator">=</span> <span class="token punctuation">[</span>ZZZ<span class="token punctuation">]</span>

state <span class="token operator">=</span> proj<span class="token punctuation">.</span>factory<span class="token punctuation">.</span>blank_state<span class="token punctuation">(</span>addr<span class="token operator">=</span>start<span class="token punctuation">)</span>

<span class="token comment"># a symbolic input string with a length up to 128 bytes</span>
arg <span class="token operator">=</span> state<span class="token punctuation">.</span>se<span class="token punctuation">.</span>BVS<span class="token punctuation">(</span><span class="token string">"input_string"</span><span class="token punctuation">,</span> <span class="token number">8</span> <span class="token operator">*</span> <span class="token number">128</span><span class="token punctuation">)</span>
<span class="token comment"># an ending byte</span>
arg_end <span class="token operator">=</span> state<span class="token punctuation">.</span>se<span class="token punctuation">.</span>BVS<span class="token punctuation">(</span><span class="token string">"end_input_string"</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span>
<span class="token comment"># add a constraint on this byte to force it to be '\0'</span>
state<span class="token punctuation">.</span>se<span class="token punctuation">.</span>add<span class="token punctuation">(</span>arg_end <span class="token operator">==</span> <span class="token number">0x0</span><span class="token punctuation">)</span>
<span class="token comment"># the constraint is added to the state.</span>
<span class="token comment"># Another way to do same is with:</span>
<span class="token comment">#   arg_end = state.se.BVV(0x0, 8)</span>
<span class="token comment"># in this case arg_end is a concrete value</span>

<span class="token comment"># concat arg and arg_end</span>
arg <span class="token operator">=</span> state<span class="token punctuation">.</span>se<span class="token punctuation">.</span>Concat<span class="token punctuation">(</span>arg<span class="token punctuation">,</span> arg_end<span class="token punctuation">)</span>

<span class="token comment"># an address where to store my arg</span>
bind_addr <span class="token operator">=</span> <span class="token number">0x603780</span>

<span class="token comment"># bind the symbolic string at this address</span>
state<span class="token punctuation">.</span>memory<span class="token punctuation">.</span>store<span class="token punctuation">(</span>bind_addr<span class="token punctuation">,</span> arg<span class="token punctuation">)</span>

<span class="token comment"># phase_one reads the string [rdi]</span>
state<span class="token punctuation">.</span>regs<span class="token punctuation">.</span>rdi <span class="token operator">=</span> bind_addr

<span class="token comment"># make rsi concrete</span>
state<span class="token punctuation">.</span>regs<span class="token punctuation">.</span>rsi <span class="token operator">=</span> <span class="token number">0x0</span>

pg <span class="token operator">=</span> proj<span class="token punctuation">.</span>factory<span class="token punctuation">.</span>simulation_manager<span class="token punctuation">(</span>state<span class="token punctuation">)</span>

start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">while</span> <span class="token builtin">len</span><span class="token punctuation">(</span>pg<span class="token punctuation">.</span>active<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span>pg<span class="token punctuation">)</span>

    <span class="token comment"># step 1 basic block for each active path</span>
    pg<span class="token punctuation">.</span>explore<span class="token punctuation">(</span>avoid<span class="token operator">=</span>avoid<span class="token punctuation">,</span> find<span class="token operator">=</span>end<span class="token punctuation">,</span> n<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token comment"># Bazinga!</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>pg<span class="token punctuation">.</span>found<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Reached the target"</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>pg<span class="token punctuation">)</span>
        state <span class="token operator">=</span> pg<span class="token punctuation">.</span>found<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        sol <span class="token operator">=</span> state<span class="token punctuation">.</span>solver<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span>arg<span class="token punctuation">,</span> cast_to<span class="token operator">=</span><span class="token builtin">bytes</span><span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">'ascii'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\0'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Solution: "</span> <span class="token operator">+</span> sol<span class="token punctuation">)</span>
        <span class="token keyword">break</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Memory usage: "</span> <span class="token operator">+</span>
      <span class="token builtin">str</span><span class="token punctuation">(</span>resource<span class="token punctuation">.</span>getrusage<span class="token punctuation">(</span>resource<span class="token punctuation">.</span>RUSAGE_SELF<span class="token punctuation">)</span><span class="token punctuation">.</span>ru_maxrss <span class="token operator">/</span> <span class="token number">1024</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">" MB"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Elapsed time: "</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start_time<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​ 执行脚本：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230217191715.png" style="zoom:67%;" /></p>
<p>​ 可以看到，符号执行仅用40秒就找到了phase1()的口令：“Border relations
with Canada have never been better.”</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230217191903.png" style="zoom:67%;" /></p>
<p>​ 对于phase_2()······phase_6()使用同样的方法即可破解，这里略。</p>
<p>​
综上，我们可以看到符号执行在面对复杂的二进制文件时卓越的能力表现，在logic-bomb中，其二进制文件并没有经过混淆处理，相应的函数名，完整字符串都可以经过IDA分析后直接看到，所以对logic-bomb人工分析其实也并不复杂。但在真实的软件测试环境里，大量的二进制文件都是经过混淆加壳处理的，人工分析无法直接定位关键函数的作用（logic-bomb直接用函数名体现了函数的作用），甚至定位函数的进出口都变得具有挑战性，这时符号执行的优越性就有更明显的体现。</p>
<p>​</p>
<h2 id="参考">参考：</h2>
<p>[1] <a
href="https://docs.google.com/presentation/d/e/2PACX-1vR7ZG-wQu9SvGA2wv7GFn2pLU9z3N_yAfoqiHRgn5I3RU-9k9XTEsjdKHZBUshau3TBY1fLZe2vnHmx/pub?start=false&amp;loop=false&amp;delayms=3000&amp;slide=id.g460cbb2cfe_0_7">Symbolic
Execution</a></p>
<p>[2] <a
href="https://github.com/ercoppa/symbolic-execution-tutorial/blob/master/setup/README.md">symbolic-execution-tutorial/README.md
at master · ercoppa/symbolic-execution-tutorial (github.com)</a></p>
<p>[3] <a href="https://www.youtube.com/watch?v=yRVZPvHYHzw">MIT 6.858
Computer Systems Security, Fall 2014—–10. Symbolic Execution</a></p>
<p>[4] <a href="http://klee.github.io/">KLEE</a></p>
<p>[5] <a href="https://s2e.systems/">Overview - S²E: A Platform for
In-Vivo Analysis of Software Systems (s2e.systems)</a></p>
<p>[6] <a href="https://angr.io/">angr</a></p>
]]></content>
      <categories>
        <category>Project</category>
      </categories>
      <tags>
        <tag>Symbolic Execution</tag>
      </tags>
  </entry>
  <entry>
    <title>(论文复现)How Machine Learning Is Solving the Binary Function Similarity Problem</title>
    <url>/2023/02/12/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91How%20Machine%20Learning%20Is%20Solving%20the%20Binary%20Function%20Similarity%20Problem/</url>
    <content><![CDATA[<h1
id="论文复现how-machine-learning-is-solving-the-binary-function-similarity-problem">【论文复现】How
Machine Learning Is Solving the Binary Function Similarity Problem</h1>
<h2 id="一模糊哈希fuzzy-hashing">一、模糊哈希（Fuzzy Hashing）</h2>
<h3 id="bytes-fuzzy-hashingcatalog1">1. Bytes fuzzy
hashing——Catalog1</h3>
<blockquote>
<p><strong>出处：</strong></p>
<p>​ 1. <a href="https://www.xorpd.net/pages/fcatalog.html">xorpd |
FCatalog</a></p>
<p>​ 2. <a
href="https://github.com/Cisco-Talos/binary_function_similarity/tree/main/Models/Catalog1">binary_function_similarity/Models/Catalog1
at main · Cisco-Talos/binary_function_similarity (github.com)</a></p>
<p>"FCatalog allows you to keep a database of all your named functions,
and find similarities from this database efficiently."</p>
</blockquote>
<h4 id="前置知识">前置知识：</h4>
<ul>
<li><p><strong>binary blob</strong>：一串bytes；</p></li>
<li><p><strong>S(a)</strong>：字节串a的四字截取集合，例如: <span
class="math display">\[
\mathbf{S(a)}= \{123x,23xy,3xy1\},a=123xy1 \\
\mathbf{S(b)}= \{1111\},b=111111111 \\
\]</span></p></li>
<li><p><strong>Jaccard Similarity</strong>：计算两个集合相似性： <span
class="math display">\[
J（S(a),S(b)）=\frac {S(a)\cap S(b)}{S(a)\cup S(b)}
\]</span></p></li>
<li><p><strong>minhash</strong>：文本相似度比较算法，用于快速<strong>估算</strong>两个集合的相似度。</p></li>
</ul>
<p>​
Catalog1算法利用minhash，使用哈希近似替代两个S集合，以此来估算其Jaccard系数，从而达到高效率地比较两个集合。</p>
<span id="more"></span>
<h4 id="代码结构分析">代码结构分析：</h4>
<p>​
Catalog1算法需要将二进制文件截取分割后，由于每个二进制文件的长度不定，故其分割计算出的S(a)也不定长。为了对每个二进制文件都得到一个定长的特征签名，就需要对S(a)进行特征提取。</p>
<p>​
使用哈希函数将集合中的每个DWORD映射到DWORD，这里的哈希采用类似密码学中置换的方法（permutation）：</p>
<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">WORD_SIZE</span> <span class="token expression"><span class="token number">32</span>      	</span><span class="token comment">// 32 bits</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">MAX_WORD</span> <span class="token expression"><span class="token number">0xffffffff</span>     </span><span class="token comment">// Maximum size of a dword.</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">BYTE_SIZE</span> <span class="token expression"><span class="token number">8</span>             </span><span class="token comment">// Amount of bits in a byte.</span></span>

<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">NUM_ITERS</span> <span class="token expression"><span class="token number">4</span>             </span><span class="token comment">// Amount of iterations per permutation.</span></span>

<span class="token comment">// There are 128 RAND_DWORDS. Don't change the amount of random dwords here.</span>

<span class="token keyword">unsigned</span> <span class="token keyword">int</span> RAND_DWORDS<span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token number">1445200656</span><span class="token punctuation">,</span> <span class="token number">3877429363</span><span class="token punctuation">,</span> <span class="token number">1060188777</span><span class="token punctuation">,</span> <span class="token number">4260769784</span><span class="token punctuation">,</span> <span class="token number">1438562000</span><span class="token punctuation">,</span> <span class="token number">2836098482</span><span class="token punctuation">,</span> <span class="token number">1986405151</span><span class="token punctuation">,</span> <span class="token number">4230168452</span><span class="token punctuation">,</span> <span class="token number">380326093</span><span class="token punctuation">,</span> <span class="token number">2859127666</span><span class="token punctuation">,</span> <span class="token number">1134102609</span><span class="token punctuation">,</span> <span class="token number">788546250</span><span class="token punctuation">,</span> <span class="token number">3705417527</span><span class="token punctuation">,</span> <span class="token number">1779868252</span><span class="token punctuation">,</span> <span class="token number">1958737986</span><span class="token punctuation">,</span> <span class="token number">4046915967</span><span class="token punctuation">,</span> <span class="token number">1614805928</span><span class="token punctuation">,</span> <span class="token number">4160312724</span><span class="token punctuation">,</span> <span class="token number">3682325739</span><span class="token punctuation">,</span> <span class="token number">534901034</span><span class="token punctuation">,</span> <span class="token number">2287240917</span><span class="token punctuation">,</span> <span class="token number">2677201636</span><span class="token punctuation">,</span> <span class="token number">71025852</span><span class="token punctuation">,</span> <span class="token number">1171752314</span><span class="token punctuation">,</span> <span class="token number">47956297</span><span class="token punctuation">,</span> <span class="token number">2265969327</span><span class="token punctuation">,</span> <span class="token number">2865804126</span><span class="token punctuation">,</span> <span class="token number">1364027301</span><span class="token punctuation">,</span> <span class="token number">2267528752</span><span class="token punctuation">,</span> <span class="token number">1998395705</span><span class="token punctuation">,</span> <span class="token number">576397983</span><span class="token punctuation">,</span> <span class="token number">636085149</span><span class="token punctuation">,</span> <span class="token number">3876141063</span><span class="token punctuation">,</span> <span class="token number">1131266725</span><span class="token punctuation">,</span> <span class="token number">3949079092</span><span class="token punctuation">,</span> <span class="token number">1674557074</span><span class="token punctuation">,</span> <span class="token number">2566739348</span><span class="token punctuation">,</span> <span class="token number">3782985982</span><span class="token punctuation">,</span> <span class="token number">2164386649</span><span class="token punctuation">,</span> <span class="token number">550438955</span><span class="token punctuation">,</span> <span class="token number">2491039847</span><span class="token punctuation">,</span> <span class="token number">2409394861</span><span class="token punctuation">,</span> <span class="token number">3757073140</span><span class="token punctuation">,</span> <span class="token number">3509849961</span><span class="token punctuation">,</span> <span class="token number">3972853470</span><span class="token punctuation">,</span> <span class="token number">1377009785</span><span class="token punctuation">,</span> <span class="token number">2164834118</span><span class="token punctuation">,</span> <span class="token number">820549672</span><span class="token punctuation">,</span> <span class="token number">2867309379</span><span class="token punctuation">,</span> <span class="token number">1454756115</span><span class="token punctuation">,</span> <span class="token number">94270429</span><span class="token punctuation">,</span> <span class="token number">2974978638</span><span class="token punctuation">,</span> <span class="token number">2915205038</span><span class="token punctuation">,</span> <span class="token number">1887247447</span><span class="token punctuation">,</span> <span class="token number">3641720023</span><span class="token punctuation">,</span> <span class="token number">4292314015</span><span class="token punctuation">,</span> <span class="token number">702694146</span><span class="token punctuation">,</span> <span class="token number">1808155309</span><span class="token punctuation">,</span> <span class="token number">95993403</span><span class="token punctuation">,</span> <span class="token number">1529688311</span><span class="token punctuation">,</span> <span class="token number">2883286160</span><span class="token punctuation">,</span> <span class="token number">1410658736</span><span class="token punctuation">,</span> <span class="token number">3225014055</span><span class="token punctuation">,</span> <span class="token number">1903093988</span><span class="token punctuation">,</span> <span class="token number">2049895643</span><span class="token punctuation">,</span> <span class="token number">476880516</span><span class="token punctuation">,</span> <span class="token number">3241604078</span><span class="token punctuation">,</span> <span class="token number">3709326844</span><span class="token punctuation">,</span> <span class="token number">2531992854</span><span class="token punctuation">,</span> <span class="token number">265580822</span><span class="token punctuation">,</span> <span class="token number">2920230147</span><span class="token punctuation">,</span> <span class="token number">4294230868</span><span class="token punctuation">,</span> <span class="token number">408106067</span><span class="token punctuation">,</span> <span class="token number">3683123785</span><span class="token punctuation">,</span> <span class="token number">1782150222</span><span class="token punctuation">,</span> <span class="token number">3876124798</span><span class="token punctuation">,</span> <span class="token number">3400886112</span><span class="token punctuation">,</span> <span class="token number">1837386661</span><span class="token punctuation">,</span> <span class="token number">664033147</span><span class="token punctuation">,</span> <span class="token number">3948403539</span><span class="token punctuation">,</span> <span class="token number">3572529266</span><span class="token punctuation">,</span> <span class="token number">4084780068</span><span class="token punctuation">,</span> <span class="token number">691101764</span><span class="token punctuation">,</span> <span class="token number">1191456665</span><span class="token punctuation">,</span> <span class="token number">3559651142</span><span class="token punctuation">,</span> <span class="token number">709364116</span><span class="token punctuation">,</span> <span class="token number">3999544719</span><span class="token punctuation">,</span> <span class="token number">189208547</span><span class="token punctuation">,</span> <span class="token number">3851247656</span><span class="token punctuation">,</span> <span class="token number">69124994</span><span class="token punctuation">,</span> <span class="token number">1685591380</span><span class="token punctuation">,</span> <span class="token number">1312437435</span><span class="token punctuation">,</span> <span class="token number">2316872331</span><span class="token punctuation">,</span> <span class="token number">1466758250</span><span class="token punctuation">,</span> <span class="token number">1979107610</span><span class="token punctuation">,</span> <span class="token number">2611873442</span><span class="token punctuation">,</span> <span class="token number">80372344</span><span class="token punctuation">,</span> <span class="token number">1251839752</span><span class="token punctuation">,</span> <span class="token number">2716578101</span><span class="token punctuation">,</span> <span class="token number">176193185</span><span class="token punctuation">,</span> <span class="token number">2142192370</span><span class="token punctuation">,</span> <span class="token number">1179562050</span><span class="token punctuation">,</span> <span class="token number">1290470544</span><span class="token punctuation">,</span> <span class="token number">1957198791</span><span class="token punctuation">,</span> <span class="token number">1435943450</span><span class="token punctuation">,</span> <span class="token number">2989992875</span><span class="token punctuation">,</span> <span class="token number">3703466909</span><span class="token punctuation">,</span> <span class="token number">1302678442</span><span class="token punctuation">,</span> <span class="token number">3343948619</span><span class="token punctuation">,</span> <span class="token number">3762772165</span><span class="token punctuation">,</span> <span class="token number">1438266632</span><span class="token punctuation">,</span> <span class="token number">1761719790</span><span class="token punctuation">,</span> <span class="token number">3668101852</span><span class="token punctuation">,</span> <span class="token number">1283600006</span><span class="token punctuation">,</span> <span class="token number">671544087</span><span class="token punctuation">,</span> <span class="token number">1665876818</span><span class="token punctuation">,</span> <span class="token number">3645433092</span><span class="token punctuation">,</span> <span class="token number">3760380605</span><span class="token punctuation">,</span> <span class="token number">3802664867</span><span class="token punctuation">,</span> <span class="token number">1635015896</span><span class="token punctuation">,</span> <span class="token number">1060356828</span><span class="token punctuation">,</span> <span class="token number">1666255066</span><span class="token punctuation">,</span> <span class="token number">2953295653</span><span class="token punctuation">,</span> <span class="token number">2827859377</span><span class="token punctuation">,</span> <span class="token number">386702151</span><span class="token punctuation">,</span> <span class="token number">3372348076</span><span class="token punctuation">,</span> <span class="token number">4248620909</span><span class="token punctuation">,</span> <span class="token number">2259505262</span><span class="token punctuation">&#125;</span><span class="token punctuation">;</span>


<span class="token comment">// Amount of rand dwords - 1:</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">NUM_DWORDS_MASK</span> <span class="token expression"><span class="token number">0x7f</span></span></span>

<span class="token keyword">unsigned</span> <span class="token keyword">int</span> <span class="token function">ror</span><span class="token punctuation">(</span><span class="token keyword">unsigned</span> <span class="token keyword">int</span> x<span class="token punctuation">,</span> <span class="token keyword">unsigned</span> <span class="token keyword">int</span> i<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token comment">// Rotate right a dword x by i bits.</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span>x <span class="token operator">>></span> i<span class="token punctuation">)</span> <span class="token operator">|</span> <span class="token punctuation">(</span>x <span class="token operator">&lt;&lt;</span> <span class="token punctuation">(</span>WORD_SIZE <span class="token operator">-</span> i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span>


<span class="token keyword">unsigned</span> <span class="token keyword">int</span> <span class="token function">perm</span><span class="token punctuation">(</span><span class="token keyword">unsigned</span> <span class="token keyword">int</span> num<span class="token punctuation">,</span> <span class="token keyword">unsigned</span> <span class="token keyword">int</span> x<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token comment">// Permutation from dword to dword.</span>
    <span class="token comment">// num is the permutation number. x is the input.</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">int</span> ror_index<span class="token punctuation">;</span>
    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">unsigned</span> <span class="token keyword">int</span> i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span> i<span class="token operator">&lt;</span>NUM_ITERS<span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token comment">// Addition:</span>
        x <span class="token operator">+=</span> RAND_DWORDS<span class="token punctuation">[</span><span class="token punctuation">(</span>i <span class="token operator">+</span> num <span class="token operator">+</span> x<span class="token punctuation">)</span> <span class="token operator">&amp;</span> NUM_DWORDS_MASK<span class="token punctuation">]</span><span class="token punctuation">;</span>
        <span class="token comment">// Rotation:</span>
        ror_index <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">^</span> RAND_DWORDS<span class="token punctuation">[</span><span class="token punctuation">(</span>i <span class="token operator">+</span> num <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> NUM_DWORDS_MASK<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token number">0x1f</span><span class="token punctuation">;</span>
        x <span class="token operator">=</span> <span class="token function">ror</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>ror_index<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// Xor:</span>
        x <span class="token operator">^=</span> RAND_DWORDS<span class="token punctuation">[</span><span class="token punctuation">(</span>i <span class="token operator">+</span> num <span class="token operator">+</span> x<span class="token punctuation">)</span> <span class="token operator">&amp;</span> NUM_DWORDS_MASK<span class="token punctuation">]</span><span class="token punctuation">;</span>
        <span class="token comment">// Rotation:</span>
        ror_index <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">^</span> RAND_DWORDS<span class="token punctuation">[</span><span class="token punctuation">(</span>i <span class="token operator">+</span> num <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> NUM_DWORDS_MASK<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token number">0x1f</span><span class="token punctuation">;</span>
        x <span class="token operator">=</span> <span class="token function">ror</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>ror_index<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
    <span class="token keyword">return</span> x<span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​
由上可知，<strong>perm(i，x)就是第i个哈希函数h<sub>i</sub>(x)</strong>。计算完k个哈希函数后，我们得到了k个集合：
<span class="math display">\[
h_{1}(x),h_{2}(x),h_{3}(x)\cdots h_{k}(x)
\]</span> ​ 然后每个集合中最小的数，就是我们所需的定长特征： <span
class="math display">\[
sig(T) = \{min_{t\in T}h_{1}(T),min_{t\in T}h_{2}(T),min_{t\in
T}h_{3}(T)\cdots min_{t\in T}h_{k}(T)\}
\]</span> ​ 故用<span
class="math inline">\(J(sig(A),sig(B))\)</span>代替<span
class="math inline">\(J(A,B)\)</span>即可大大简化计算，k的数量可以自己选定。对于完整的二进制文件，以下代码可以生成其对应特征：</p>
<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">int</span> <span class="token function">sign</span><span class="token punctuation">(</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">char</span><span class="token operator">*</span> data<span class="token punctuation">,</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">int</span> len<span class="token punctuation">,</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">int</span> <span class="token operator">*</span>result<span class="token punctuation">,</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">int</span> num_perms<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>

    <span class="token comment">// Find entry number &lt;num> of the signature of data.</span>
    <span class="token comment">// len is the length of the data.</span>
    <span class="token comment">// The result is inside &lt;result>, as an array of dwords.</span>

    <span class="token comment">// We need at least 4 bytes to generate a signature.</span>
    <span class="token comment">// We return -1 (error) if we don't have at least 4 bytes.</span>
    <span class="token keyword">if</span><span class="token punctuation">(</span>len <span class="token operator">&lt;</span> <span class="token number">4</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">int</span> y<span class="token punctuation">;</span> <span class="token comment">// Current integer value of 4 consecutive bytes.</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">int</span> py<span class="token punctuation">;</span> <span class="token comment">// Permutation over y.</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">int</span> min_py<span class="token punctuation">;</span> <span class="token comment">// Minimum py ever found.</span>

    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">unsigned</span> <span class="token keyword">int</span> permi<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span> permi<span class="token operator">&lt;</span>num_perms<span class="token punctuation">;</span> <span class="token operator">++</span>permi<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token comment">// Initialize y to be the first dword from the data:</span>
        y <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">unsigned</span> <span class="token keyword">int</span><span class="token punctuation">)</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">&lt;&lt;</span> <span class="token number">24</span><span class="token punctuation">;</span>
        y <span class="token operator">+=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">unsigned</span> <span class="token keyword">int</span><span class="token punctuation">)</span>data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> <span class="token number">16</span><span class="token punctuation">;</span>
        y <span class="token operator">+=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">unsigned</span> <span class="token keyword">int</span><span class="token punctuation">)</span>data<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> <span class="token number">8</span><span class="token punctuation">;</span>
        y <span class="token operator">+=</span> <span class="token punctuation">(</span><span class="token keyword">unsigned</span> <span class="token keyword">int</span><span class="token punctuation">)</span>data<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">;</span>

        <span class="token comment">// Calculate first permutation:</span>
        py <span class="token operator">=</span> <span class="token function">perm</span><span class="token punctuation">(</span>permi<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">;</span>
        min_py <span class="token operator">=</span> py<span class="token punctuation">;</span>

        <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">unsigned</span> <span class="token keyword">int</span> i<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">;</span> i<span class="token operator">&lt;</span>len<span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            y <span class="token operator">&lt;&lt;=</span> <span class="token number">8</span><span class="token punctuation">;</span>
            y <span class="token operator">+=</span> data<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>
            py <span class="token operator">=</span> <span class="token function">perm</span><span class="token punctuation">(</span>permi<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">if</span><span class="token punctuation">(</span>min_py <span class="token operator">></span> py<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                min_py <span class="token operator">=</span> py<span class="token punctuation">;</span>
            <span class="token punctuation">&#125;</span>
        <span class="token punctuation">&#125;</span>
        <span class="token comment">// Save minimum perm value found to memory:</span>
        result<span class="token punctuation">[</span>permi<span class="token punctuation">]</span> <span class="token operator">=</span> min_py<span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
    <span class="token comment">// Everything went well.</span>
    <span class="token comment">// Result should be stored at &lt;result></span>
    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​</p>
<p>​</p>
<h4 id="运行测试">运行测试：</h4>
<p>​
Catalog1共分为server和client两部分，client客户端作为IDA的一个插件，server服务器可以使用官方提供的testfcatalog.xorpd.net:1337，也可以自行搭建https://github.com/xorpd/fcatalog_server。</p>
<p>​
为了计算速度更快，这里使用C语言编写catalog相关计算操作，首先编译catalog1
：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230213123532.png" /></p>
<p>​</p>
<p>【更新中】</p>
]]></content>
      <categories>
        <category>Reproduce</category>
      </categories>
      <tags>
        <tag>Binary</tag>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>Comparing One with Many — Solving Binary2source Function Matching Under  Function Inlining</title>
    <url>/2023/01/10/Comparing-One-with-Many-%E2%80%94-Solving-Binary2source-Function-Matching-Under-Function-Inlining/</url>
    <content><![CDATA[<h1
id="论文阅读comparing-one-with-many-solving-binary2source-function-matching-under-function-inlining">【论文阅读】Comparing
One with Many — Solving Binary2source Function Matching Under Function
Inlining</h1>
<h2 id="一abstract">一、ABSTRACT</h2>
<p><strong><u>为了在函数内联下施行b2s函数匹配，我们提出了一个叫O2NMatcher的方法，通过其生成的Source
function Sets (SFSs)作为匹配结果。</u></strong></p>
<p>我们首先提出了一个模型<strong>EOOCJ48</strong>来预测内联的位置，
为了训练这个模型，我们利用可编译的开源软件（Open Source
Software）生成一个带有标记的调用点（内联或不内联）的数据集，从调用点中提取几个特征，并通过检查不同编译之间的内联相关性来设计一个基于编译器-选项的多标签分类器。</p>
<p>然后，我们使用这个模型来预测不可编译的开源项目，得到带标记的函数调用图。接下来，我们将SFSs的构建视为一个子树生成问题，并设计根节点选择和边缘扩展规则来自动构建SFSs。最后，这些SFSs将被添加到源函数的语料库中，并与有内联的二进制函数进行比较。</p>
<p>我们对OSNMatcher进行了一些实验测试，结果表明我们的方法超过所有state-of-the-art，将结果提升了6%。</p>
<span id="more"></span>
<h2 id="二背景知识">二、背景知识</h2>
<ol type="1">
<li><p><strong>Function
inlining：</strong>函数内联。使用inline关键字，<strong>编译器将函数调用语句替换为函数代码本身</strong>（称为扩展的过程），然后编译整个代码。因此，<strong>使用内联函数，编译器不必跳转到另一个位置来执行该函数，然后跳回。</strong>因为被调用函数的代码已经可用于调用程序。</p>
<p><a
href="https://devblogs.microsoft.com/cppblog/inlining-decisions-in-visual-studio/#:~:text=Inlining%20is%20perhaps%20the%20most%20important%20optimization%20a,in%20either%20the%20caller%20or%20callee%20by%20themselves.">Inlining
Decisions in Visual Studio - C++ Team Blog (microsoft.com)</a></p></li>
<li><p><strong>Binary2source function
matching</strong>，二进制到源码函数匹配：</p></li>
</ol>
<ul>
<li><strong>1-to-1</strong>匹配：一个二进制函数与一个源码函数匹配；</li>
<li><strong>1-to-n</strong>匹配：由于内联函数的存在，一个二进制函数匹配多个源码函数。</li>
</ul>
<ol start="3" type="1">
<li><p><strong>Stripped
binary：</strong>不含调试符号信息的二进制可执行文件。</p></li>
<li><p><strong>Multi-Label Classification (MLC)
problem：</strong>多标签分类，一个样本有多个标签。</p></li>
<li><p><strong>FCG</strong> ：Function Call
Graph，函数调用图。在FCG图中，点是函数，边是调用关系。</p></li>
<li><p><strong>Jaccard similaritie：</strong>又称为Jaccard
index，用于比较有限样本集合之间的相似性和差异性。其值越大说明相似性越高。</p></li>
<li><p><strong>Binary
Relevance：</strong>核心思想是将多标签分类问题进行分解，将其转换为q个二元分类问题，其中每个二元分类器对应一个待预测的标签。</p></li>
<li><p><strong>Classifier
Chains：</strong>核心思想是将多标签分类问题进行分解，将其转换成为一个二元分类器链的形式，其中链后的二元分类器的构建式在前面分类器预测结果的基础上的。在模型构建的时候，首先将标签顺序进行shuffle打乱排序操作，然后按照从头到尾分别构建每个标签对应的模型。</p></li>
<li><p><strong>Ensemble Method：</strong>集成学习算法。</p></li>
</ol>
<h2 id="三提出问题">三、提出问题</h2>
<ol type="1">
<li><h4 id="b2s匹配的作用"><strong>B2S匹配的作用：</strong></h4>
<p>当前软件开发基本都会使用公共开源库中的代码，这就造成一个问题，若公共开源项目OSS中存在漏洞会传播非常快（例如一个OpenSSL中的漏洞就可以造成互联网上17%web服务存在漏洞）。</p>
<p>由于以上问题的存在，检测软件中对OSS的依赖就很重要，<strong>Software
Component Analysis
(SCA)</strong>就是用来检测软件对OSS的依赖问题的。当商业软件公司发布了自己的二进制可执行程序时，SCA服务商就会将此二进制文件与OSS文件相比较，检测其包含使用了哪些OSS文件。</p>
<p>binary2source function matching就是其应用场景。</p></li>
<li><h4
id="内联函数带来的问题"><strong>内联函数带来的问题：</strong></h4>
<p>举例如下图所示，当将二进制函数中的<strong><em>dtls1_get_record</em></strong>函数与源码中的<strong><em>dtls1_get_record</em></strong>函数比较时，使用CodeCMR给出的相似性还不足60%，这显然是匹配失败的。</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230110172929.png" /></p>
<p>如果深入去看二进制函数<strong><em>dtls1_get_record</em></strong>的汇编代码就可以发现，这个函数在编译的时候内联了<strong><em>dtls1_process_buffered_records</em></strong>,<strong><em>dtls1_get_bitmap</em></strong>
和
<strong><em>dtls1_record_replay_check</em></strong>的函数代码，极大的改变了其函数的内部代码内容，故影响了函数的匹配结果。</p>
<p><strong><u>有上述例子可以看出，由于内联函数的存在会改变函数的代码内容，故直接对其进行匹配的结果是不尽如人意的。</u></strong></p></li>
<li><h4
id="解决这个问题面临的挑战"><strong>解决这个问题面临的挑战：</strong></h4>
<p>想要解决在内联函数下的B2S问题，还需面对以下挑战：</p>
<p>1）
<strong>OOD问题：</strong>Out-of-domain，待检测二进制函数可能是由多个函数生成的，故OSS源码资料库中可能没有对应的二进制匹配；</p>
<p>2）
<strong>有些二进制文件不含调试信息：</strong>对于许多不含调试信息的二进制文件，由于其没有标注内联点，故检测哪些函数是通过内联函数生成的和哪些源码函数被内联进了二进制函数中就更加困难；</p>
<p>3）
<strong>不同文件内联选择的不同：</strong>对于不同的编译设置导致的不同内联函数的选择（对某个函数，是否选择内联），很难覆盖所有情况。</p></li>
</ol>
<h2 id="四模型方法">四、模型方法</h2>
<p>​
我们的方法<strong>O2NMatcher</strong>就是为了解决上述挑战而生的。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230110205834.png" style="zoom:80%;" /></p>
<p>​ 为了解决第一个挑战，我们生成了<strong><em>Source Function Sets
(SFSs)</em></strong>来完善资料库，以此应对有内联函数的二进制函数查询匹配。</p>
<p>​
为了解决第二个挑战，我们使用可以编译的OSS项目训练了一个预测分类器来预测不可编译的OSS项目的内联位置。同时，我们提出了一个数据集自动化打标签的方法来生成数据。</p>
<p>​
为了解决第三个挑战，分类器被在多种不同的编译设置环境下训练，我们将其建模为多标签分类（MLC）问题，并根据不同编译设置下内联决策的相关性提出了基于编译器-选择的分类器。</p>
<p>​
通过给定的OSS生成SFSs，然后使用已有的“1-to-1”方法将这些SFSs与二进制函数相比较即可。</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230111162237.png" /></p>
<h3 id="模型训练">模型训练</h3>
<h4 id="生成数据集">1. 生成数据集</h4>
<p>​
在生成数据集过程中，我们充分利用了编译过程生成的调试信息（用的都是可编译的OSS项目）。其会生成b2s行级别和函数级别的映射，并附带函数调用处的内联信息（是否内联）。</p>
<p>​
在开源项目编译时使用"-g"选项，可以使编译出的二进制文件附带从二进制地址到源文件某一行的映射信息（<u>行级别映射</u>），再利用<strong>Understand</strong>或者<strong>IDA
Pro，tree-sitter，Chidra</strong>等工具，我们可以生成从二进制地址到源文件某一函数的映射信息（<u>函数级别映射</u>）。</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230111165709.png" /></p>
<p>​
如上图所示，圆圈是源码函数，方框是编译后的二进制函数。在（a）中，由于A只调用了C一次，故在编译后的二进制函数中C就被内联进了A中；但在（b）中，A调用了两次B，A和B都调用了C，无法很清楚的判断到底哪次调用需要被内联，故编译出的二进制函数也与编译选项有关，并不绝对。</p>
<p>​
<strong>上述例子可以看出，即使我们得到的源码函数之间的相互调用关系我们也无法确定哪些函数会被内联。</strong></p>
<p>​
但如果我们知道其二进制调用关系图，反过来看，若二进制图中某个调用在源码调用图中也存在（如上图a中的A–&gt;B），则这个函数就不是内联函数，反之就是内联函数。这样，通过对调试信息的使用，可以成功的将可编译OSS项目的内联位置标注出来。</p>
<h4 id="特征提取">2. 特征提取</h4>
<p>​
考虑到编译器一般通过评估内联的利弊来决定是否内联，我们总结了几个可以评估内联操作利弊的特征：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230111235130.png" /></p>
<p>​
如上表所示，特征共分为两大类<strong>Caller/Callee</strong>和<strong>Call
Instruciton</strong>：</p>
<ul>
<li><p><strong>Caller/Callee</strong>：</p>
<p>caller这里指调用其他公共开源函数的函数，callee指被许多其他函数调用的函数。这部分特征分为函数内部语句，函数定义语句和函数调用次数。</p></li>
<li><p><strong>Call Instruciton：</strong></p>
<p>调用函数指令，这里关注其调用的位置和参数声明，例如在内联循环中的函数调用就可以显著减少调用次数。同理，如果调用含有常量参数，可以帮助减少内联函数的大小。</p></li>
</ul>
<h4 id="模型训练-1">3. 模型训练</h4>
<h5 id="训练数据分析">3.1 训练数据分析</h5>
<p>​ 我们这里提出了一个名为<strong>ECOCCJ48(<em>Ensemble of Compiler
Optimization based Classifier Chains built with
J48</em>)</strong>的MLC模型来预测内联函数位置。在多标签任务中，标签之间通常存在联系，下表展示了两个编译器（gcc-8.2.0和clang-7.0）在O<sub>x</sub>优化下的内联措施的差异和联系：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230112145603.png" style="zoom:80%;" /></p>
<p><em>PS：opt1-opt2意味着使用优化措施opt1时内联，使用优化措施opt2时不内联的数量；opt1&amp;opt2意味着使用两个都内联的数量。</em></p>
<p>​
<strong>在同一编译器不同优化设置的条件下</strong>，由上图可以看出，94.78%的内联操作如果出现在低级优化措施的条件下，也会出现在更高级的优化措施条件下。所以在同一行内opt1&amp;opt2的数量都大于opt1-opt2。</p>
<p>​
<strong>在不同编译器的条件下</strong>，如下图所示，展示了不同优化措施下所做决策的Jaccard系数：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230112150531.png" style="zoom: 67%;" /></p>
<p>​
<strong>在同一编译器家族（例如GCC的不同版本）比较时，其内联决策的相似性很高。</strong>当使用O<sub>0</sub>-O<sub>3</sub>优化措施测试gcc-6.4.0
和
gcc-7.2.0，87%的函数调用采用了相同的内联决策。<strong>在不同编译器的条件下，</strong>其内联决策没有明显的联系。</p>
<h5 id="ecoccj48模型">3.2 ECOCCJ48模型</h5>
<p>​ ECOOCJ48分为两个部分，使用binary
relevance来预测不同编译器下的标签，使用整合分类器链来预测同一编译器下不同优化措施的标签。</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230112152928.png" /></p>
<h5 id="不平衡的数据集">3.3 不平衡的数据集</h5>
<p>​ 目前存在的数据集有以下问题：</p>
<p>​
1.大多数的函数调用在被编译的过程中是不会被内联的，在使用O<sub>X</sub>优化时，大约只有20%的函数调用会被内联；</p>
<p>​ 2.不同优化措施编译时内联点的比例也不同。</p>
<p>​
这些差异导致了训练数据集的不平衡，训练会更偏向于正常的调用。我们使用了集成学习方法来处理这些不平衡，其使用随机选择的数据集来训练，通过整合不同基础分类器的结果来预测标签。因为不同基础分类器在不同的资料库中被训练，故他们可以抓住内联模式。</p>
<h3 id="sfs生成">SFS生成</h3>
<h4 id="fcg构建与ics预测">1. FCG构建与ICS预测</h4>
<p>​
对于不可编译的OSS项目，首先使用一个解析器（parser）来提取代码中的函数调用点，构建FCG图。两个节点之间可以有多个有向边，<strong>边上附带函数调用的位置信息。</strong></p>
<p>​
对于FCG中的每个调用点，我们从其调用者，被调用者和调用指令中提取特征，将其作为ECOCCJ48的输入，得到所有编译设置（不同编译器+优化措施）的标签。</p>
<h4 id="sfs生成-1">2. SFS生成</h4>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230113001842.png" style="zoom:80%;" /></p>
<p>​
如上图所示，（a）就是已经构建好的FCG图，其中红圈代表有内联函数的函数，黑圈则没有；红边代表内联操作，蓝边代表正常调用。<strong>假设FCG是一个有向无环图，SFS的生成就可以抽象成从FCG图中选择内联子树。</strong>这里将SFS的生成分为两个部分：根节点的选择（b）和边扩展。</p>
<p>​ <strong>根节点的选择上</strong>，有以下原则：</p>
<p>​ 1） 内联子树的根节点，如A,D；</p>
<p>​
2）非内联子树的根节点，但是既内联调用了其他函数，也被其他函数普通调用，如C。</p>
<p>​
除去这两种情况，要么一个节点没有指向其他节点的红色边，要么在内联子树上仅仅被其它红边所指。第一种情况显然不能进入SFS，第二种情况会被内联进其调用者之中。</p>
<p>​ <strong>边扩展上</strong>，遵循以下规则：</p>
<p>​ 1）
对每个根节点，若其指向的节点仅有一条红边，则向下遍历其能遇到的所有节点（如对A，有A-&gt;C，A-&gt;C-&gt;E两条）；</p>
<p>​
2）对每个根节点，若其指向的节点有两条相异颜色的边，则红色的边继续向下搜索生成，蓝色的边仅在下个点处停止。（如对C-&gt;E）。</p>
<p>​
若FCG成环，我们仅需注意，如果一个被调用节点已经在SFS中了，就不必再次遍历即可避免重复。</p>
<h4 id="sfs汇总">3. SFS汇总</h4>
<p>​ 得到函数的SFS后，我们将被调用函数的代码直接放进调用函数中。</p>
<h3 id="测试评估">测试评估</h3>
<p>​ 测试部分回答了以下问题：</p>
<blockquote>
<ol type="1">
<li>O2NMatcher可以提高现有1-to-1工作的表现吗？</li>
<li>与<em>Bingo</em> 和
<em>ASM2Vec</em>比较，O2NMatcher生成的SFS有多准确？</li>
<li>与现有的多标签分类工作相比，<em>ECOCCJ48</em>的表现如何？</li>
<li>O2NMatcher在训练，预测和生成SFS的时间花费如何？</li>
<li>我们选取的特征集在ICS预测上有什么贡献？</li>
</ol>
</blockquote>
<h4 id="研究背景">1. 研究背景</h4>
<h5 id="测试数据集">1.1 测试数据集</h5>
<p>​
我们从GNU项目选择了51个包，使用9种编译器、4种优化措施编译成x86-64，得到8460个二进制文件和4294478个二进制函数。这些数据包含了诸如Coreutils、OpenSSL等在二进制相似性检测工作中广泛被使用的包。如下表所示：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230116181546.png" style="zoom:80%;" /></p>
<h5 id="benchmark">1.2 Benchmark</h5>
<p>​
因为O2NMatcher是一个对其它b2s方法的补充，我们需要选择一个baseline。这里我们选择<strong>CodeCMR</strong>，一个现有工作表现最好的b2s方法。CodeCMR有一个开放工具BinaryAI，可以方便后续测试。</p>
<p>（Zeping Yu, Wenxin Zheng, Jiaqi Wang, Qiyi Tang, Sen Nie, and Shi
Wu. 2020. Codecmr: Cross-modal retrieval for function-level binary
source code matching. <em>Advances in Neural Information Processing
Systems</em> 33 (2020), 3872–3883.）</p>
<h5 id="实验设置">1.3 实验设置</h5>
<p>​
<strong>90%随机选择的训练集以及10%测试集。</strong>由于相同编译器的内联选择比较相似，这里测试集仅用两个编译器生成：gcc-2.2.0和clang-7.0。测试集包含1.1中所有的编译器生成的数据。<u>分类器在训练集上训练，然后对测试集生成SFSs</u>。为了避免误差我们重复实验10次。</p>
<p>​ 测试时，使用不带调试信息的stripped
binary，并且OSS文件不能被编译。</p>
<h5 id="评估标准">1.4 评估标准</h5>
<p>​
<strong>使用标准召回率recall@K来评估O2NMatcher准确率</strong>。（Recall@K召回率是指前topK结果中检索出的相关结果数和库中所有的相关结果数的比率，衡量的是检索系统的查全率。）在这里，recall@K代表前k个模型返回的源码函数中真正的源码函数占比。对于1-to-1匹配，真正的源码函数就是该待检测二进制函数的源码；对于我们的1-to-n匹配，在SFSs中，某个函数的根函数是真正的源码函数也可以算作阳性样本。在接下来的实验中我们会使用K
= 1、10和50来测试。</p>
<p>​ <strong>使用SFS大小（SFS size）来评估O2NMatcher成本</strong>。SFS
size是已生成的SFSs数量比上原函数集的数量。因为新增的SFSs增加了资料库的大小，故可能影响查询匹配的时间。</p>
<p>​
<strong>使用precision、recall和F1-score来评估ECOCCJ48准确率。</strong></p>
<h5 id="o2nmatcher的实现">1.5 O2NMatcher的实现</h5>
<p>​
在数据集标注工作上，我们使用<strong>Understand</strong>对源码做语法分析，使用<strong>IDA
Pro</strong>来反汇编二进制文件。在FCG构建上，我们使用<strong>Understand</strong>来提取所有函数调用点，对源码生成FCG图，使用<strong>IDA
Pro</strong>对二进制文件生成FCG图。在函数调用特征提取上，我们使用<strong>tree-sitter</strong>来提取函数体、函数定义和函数调用指令的特征，使用<strong>Understand</strong>提取函数调用次数特征。</p>
<p>​
在模型训练工作上，我们使用Python工具<strong><em>scikit-multilearn</em></strong>来实现ECOCCJ48模型和其他MCL方法。整个程序在Ubuntu
18.04、Intel Xeon Gold 6266C、1024GB DDR4 RAM、Nvidia RTX3090
GPU环境上运行。</p>
<h4 id="对问题一的回答o2nmatcher的效果">2.
对问题一的回答：O2NMatcher的效果</h4>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230116190905.png" style="zoom:80%;" /></p>
<h4 id="对问题二的回答sfss的效果">3. 对问题二的回答：SFSs的效果</h4>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230116191213.png" style="zoom:80%;" /></p>
<p>​ 上表比较了O2NMatcher、Bingo和ASM2Vec生成的SFSs与标准答案的结果。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230116191540.png" style="zoom:80%;" /></p>
<h4 id="对问题三的回答ecoccj48的效果">4.
对问题三的回答：ECOCCJ48的效果</h4>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230116205243.png" /></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230116205306.png" style="zoom:80%;" /></p>
<h4 id="对问题四的回答o2nmatcher的成本">5.
对问题四的回答：O2NMatcher的成本</h4>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230116205338.png" /></p>
<h4 id="对问题五的回答特征选择的作用">6.
对问题五的回答：特征选择的作用</h4>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20230116205512.png" style="zoom:80%;" /></p>
<h2 id="五问题">五、问题</h2>
<ol type="1">
<li><p>该方法模型怎么结合已有的方法？</p>
<p>原来怎么比现在就怎么比，只是从源码库变成了SFS。</p></li>
<li><p>SFSs怎么起作用？</p>
<p>将可能内联的函数体放进原函数的新代码库。</p></li>
<li><p>不平衡的数据集怎么处理的？</p>
<p>“We use ensemble methods to handle the imbalanced dataset. The
ensemble method trains the base classifiers on the randomly selected
dataset and predicts the labels by ggregating the predictions from the
base classifiers. As different base lassifiers are trained in different
corpora, they can capture the inlining patterns of some rare
labels”这部分没看懂什么意思</p></li>
<li><p>在汇总SFS时：</p>
<p>“Directly, there are two ways to aggregate the SFS: conduct inlining
for the source functions in the SFSs such as the inlining during
compilation or directly aggregate the content of all the functions in
the SFS”，这两种方式具体什么区别？</p></li>
</ol>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Binary</tag>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>How Machine Learning Is Solving the Binary Function Similarity Problem</title>
    <url>/2022/12/08/How-Machine-Learning-Is-Solving-the-Binary-Function-Similarity-Problem/</url>
    <content><![CDATA[<h1
id="论文阅读how-machine-learning-is-solving-the-binary-function-similarity-problem">【论文阅读】How
Machine Learning Is Solving the Binary Function Similarity Problem</h1>
<blockquote>
<p><strong>时间：</strong>2022.8</p>
<p><strong>作者：</strong>Andrea Marcelli, Mariano Graziano , Xabier
Ugarte-Pedrero, Yanick Fratantonio , Mohamad Mansouri and Davide
Balzarotti(思科，欧洲电信学院)</p>
<p><strong>会议：</strong>usenix 2022</p>
</blockquote>
<h2 id="abstract">ABSTRACT</h2>
<p>人们会期望到现在为止，对于二进制相似性问题的研究，其有可能回答一些研究问题，这些问题超出了论文中提出的非常具体的技术，可以推广到整个研究领域。不幸的是，这个目标受到许多挑战，从可重复性问题到研究结果的不透明性，阻碍了研究有意义和有效地进展。</p>
<p>在本文，<strong><u>我们开始着手于对state-of-the-art做这个领域的第一个测试性研究。</u></strong></p>
<ol type="1">
<li>首先，我们系统化了现存的研究成果；</li>
<li>我们选定了一些相关方法，这些方法代表了三个不同研究社区最近提出的各种解决方案；</li>
<li>针对现有的方案，<u>我们重构了方法并构建了新的数据集</u>，以便实现更为公平的对比效果。</li>
</ol>
<span id="more"></span>
<h2 id="introduction">INTRODUCTION</h2>
<ol type="1">
<li><p><strong>Binary function
similarity：</strong>将一对函数的二进制表示作为输入，它们之间的相似性值作为输出。</p></li>
<li><p><strong>Binary function similarity技术面临的挑战</strong>：</p>
<ul>
<li><p>实际情况下，软件会被不同编译器、链接工具以及优化器编译；</p></li>
<li><p>特殊情况下，例如IoT，软件会被编译为不同架构的指令；</p></li>
</ul></li>
<li><p><strong>Binary function similarity的作用：</strong></p>
<p>在系统安全研究领域，许多研究问题需要以Binary function
similarity作为核心构件。</p>
<ul>
<li><p><strong>节省逆向时间。</strong>在逆向工程中经常需要处理静态链接的stripped
binaries，Binary function
similarity可用于将一个未知的函数与先前生成的数据库中的（有标签的）函数进行匹配，对应到先前生成的数据库中，从而节省大量的时间；</p>
<p>（<strong>stripped
binaries</strong>：编译后的二进制文件可以包含调试信息，这些信息对于程序的执行是没有必要的，相反，它对于调试和发现程序中的问题或漏洞是很有用的。剥离的二进制文件（<strong>stripped
binaries</strong>）是一个没有这些调试符号的二进制文件，因此体积较小，而且可能比没有剥离的二进制文件有更好的性能。剥离后的二进制文件很难被反汇编或逆向工程，这也使其难以发现程序中的问题或漏洞。）</p></li>
<li><p><strong>用于高校检索第三方库中的漏洞函数。</strong>给定一个有问题的函数，Binary
function similarity可用于在第三方库中快速检索相似函数；</p></li>
<li><p><strong>用于软件分析以及恶意软件分类。</strong></p></li>
</ul></li>
<li><p><strong>提出问题：</strong></p>
<blockquote>
<ol type="1">
<li>在使用相同评估标准、相同数据集的前提下，不同的方法如何比较？</li>
<li>与简单的模糊哈希算法相比，原创的机器学习算法的主要贡献在哪？</li>
<li>不同特征集的作用是什么？</li>
<li>不同的方法在不同的任务中是否效果更好？</li>
<li>相较于同一架构指令下，不同架构指令编译的二进制的比较是否更困难？</li>
<li>是否有任何具体的研究方向看起来更有希望成为设计新技术的未来方向？</li>
</ol>
</blockquote>
<p>很遗憾，我们发现目前的研究并不能回答上述问题。</p></li>
<li><p><strong>现有研究存在的不足：</strong></p>
<blockquote>
<ol type="1">
<li><p><strong>实验方法、实验结果不透明，难复现</strong>。实验所需的工具、超参数以及数据集通常都是不公开的，一些工作的横向比较太少甚至跟自己以前发的文章比；</p></li>
<li><p><strong>现有工作的评估方法往往也是模糊不清的。</strong>不同的论文中，任务目标、环境设置、概念、颗粒度、数据集的大小和特性以及评估方法往往都不同，因此，即使是论文中最基础的图像也基本不能直接比较。所以，当新的工作声称比旧工作表现更好时，这个优越性是否仅仅是针对某个特殊的领域不得而知。更糟糕的是，一些工作函数对的选择方法以及训练集的构成并没有详细说明，使得复现变得更加困难。一个方法结果更优秀的原因是因为其原创性还是其他因素不得而知；</p></li>
<li><p><strong>领域整体较为混乱。</strong>每个新的解决方案都采用了更复杂的技术，或多种技术的新组合。新方法的成功很难确定是由较简单的方法的实际局限性导致的，还是其创新性。现有几十种方法存在，但是并不能确定哪些方法在哪些环境设置下是有效的，而哪些不行。</p></li>
</ol>
<p>“每个人都声称他们的方法最好。”</p>
</blockquote></li>
<li><p><strong>本文贡献</strong>：</p>
<blockquote>
<p>​
实现了在本领域第一个系统化的评估。在相同的工具框架下复现了10个有代表性的方法（及其变种方法），并使用新定义的同一数据集测试。</p>
</blockquote>
<p>一些结论：</p>
<ul>
<li>简单的方法（例如模糊哈希）在简单的环境下表现很好，但难以应对复杂的环境；</li>
<li>GNN几乎在所有任务里都取得了最好的成绩；</li>
<li>许多最近发表的论文在同一数据集上测试时，都有非常相似的准确性，尽管他们之中的一些声称自己有了提高。</li>
</ul></li>
</ol>
<h2 id="measuring-function-similarity领域基础知识"><strong>Measuring
Function Similarity（领域基础知识）</strong></h2>
<h4 id="函数相似度评估方法"><strong>1. 函数相似度评估方法</strong></h4>
<h5 id="直接评估direct-comparsion">1.1 直接评估（<strong><em>Direct
Comparsion</em></strong>）：</h5>
<p>用机器学习/深度学习模型做相似性函数，通过对模型的训练来使其输入两个函数，输出两个函数的相似性。</p>
<h5 id="间接评估indirect-comparsion">1.1 间接评估（<strong><em>Indirect
Comparsion</em></strong>）：</h5>
<p>间接评估将输入函数的特征压缩到低维度表示，这些表示可以使用简单的距离测量方法评估相似度，例如欧氏距离或余弦距离。</p>
<p><strong>Fuzzy
hashes</strong>：一个很典型的低维度特征表示方法就是哈希模糊。特殊的fuzzy
hashes，如ssdeep，用于判断两个文件是否近似的hash。如果一个文件比另一个文件多一个空格，普通的hash是会完全不同，而模糊hash
可能会很相似或者完全一样。</p>
<p><strong>Code
embedding：</strong>代码嵌入，应用NLP的方法，将汇编看做文本，对每个代码块或者指令做embedding。</p>
<p><strong>Graph embedding：</strong>
图嵌入，使用代码图结构，通过传统方法或者GNN来生成embedding。</p>
<h4 id="函数表示方法">2. 函数表示方法</h4>
<ol type="1">
<li>直接使用raw bytes；</li>
<li>使用通过raw bytes反编译得到的汇编代码；</li>
<li><strong>Normalized
assembly</strong>，将汇编代码中的常数等替换，减轻操作数与操作之间的联系；</li>
<li><strong>Intermediate representations</strong>，中间表示；</li>
<li>图结构，例如CFG，DFG等；</li>
<li>动态分析，通过运行中的函数来比较；</li>
<li><strong>Symbolic execution</strong>，通过符号执行分析；</li>
</ol>
<h2 id="筛选现有方法">筛选现有方法</h2>
<p>尽管现有数百篇的论文，但其中的很多方法都是对某个技术做微调，故该领域的原创方法并不是很多。</p>
<h4 id="筛选标准">1. 筛选标准</h4>
<ul>
<li><strong>Scalability and real-world
applicability</strong>（<em>可扩展性和现实世界的适用性</em>）：不关注天生速度较慢的方法，只关注诸如那些基于动态分析、符号执行或高复杂度图相关算法的方法；</li>
<li><strong>Focus on representative approaches and not on specifific
papers</strong>：只关注有代表性的方法；</li>
<li><strong>Cover different
communities</strong>：在我们的评估中，我们希望包括来自系统安全、编程语言分析和机器学习社区的代表性研究。为了完整性，我们还考虑了行业提出的方法；</li>
<li><strong>Prioritize latest
trends</strong>：考虑最新的，尤其是AI方法。</li>
</ul>
<h4 id="筛选方法">2. 筛选方法</h4>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221210161628.png" /></p>
<p>上图选定了30个方法，接着我们会从这30个方法中筛选出10个最有代表性的方法来测试。</p>
<ul>
<li><p>该图的左侧对不同研究机构提出的方法进行了分类，由学术界和工业界（腾讯、谷歌），箭头代表了指向的一方拿被指向一方的结果进行了比较；</p></li>
<li><p>该图的右侧Y轴代表出版时间，X轴代表函数的输入形式，不同的色块代表不同的相似度计算方式；</p></li>
<li><p>中括号[]代表的tag标注了不同的研究群体，例如S代表Security，SE代表Software
eng。</p></li>
</ul>
<p><strong>从该图中可以得出：</strong></p>
<ul>
<li><p>左图中间的二进制比较工具都是为直接比较两个<u>完整二进制文件</u>而设计的（例如，它们使用图结构），并且它们都是针对<u>单指令集结构</u>的。<strong>但是一些做了跨指令集和函数比较的paper仍拿这些方法来比较，显然会得出不正确的结论</strong>；</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221210164050.png" style="zoom: 50%;" /></p></li>
<li><p>从左图可以得出，不同研究机构之间很少跨领域比较；</p></li>
<li><p>从右图可以看出，随着时间推移，算法的复杂性以及AI算法的使用比例都在增加。</p></li>
</ul>
<h4 id="筛选结果">3. 筛选结果</h4>
<table>
<colgroup>
<col style="width: 72%" />
<col style="width: 28%" />
</colgroup>
<thead>
<tr class="header">
<th>方法类型</th>
<th>方法/作者名称</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Bytes fuzzy hashing</strong></td>
<td>Catalog1</td>
</tr>
<tr class="even">
<td><strong>CFG fuzzy hashing</strong></td>
<td>FunctionSimSearch</td>
</tr>
<tr class="odd">
<td><strong>Attributed CFG and GNN</strong></td>
<td>Gemini</td>
</tr>
<tr class="even">
<td><strong>Attributed CFG, GNN, and GMN</strong></td>
<td>Li et al. 2019</td>
</tr>
<tr class="odd">
<td><strong>IR, data flflow analysis and neural network</strong></td>
<td>Zeek</td>
</tr>
<tr class="even">
<td><strong>Assembly code embedding</strong></td>
<td>Asm2Vec</td>
</tr>
<tr class="odd">
<td><strong>Assembly code embedding and self-attentive
encoder</strong></td>
<td>SAFE</td>
</tr>
<tr class="even">
<td><strong>Assembly code embedding, CFG and GNN</strong></td>
<td>Massarelli et al.2019</td>
</tr>
<tr class="odd">
<td><strong>CodeCMR</strong></td>
<td>BinaryAI</td>
</tr>
<tr class="even">
<td><strong>hierarchical transformer and micro-traces</strong></td>
<td>Trex</td>
</tr>
</tbody>
</table>
<h2 id="测试">测试</h2>
<h4 id="复现方法">1. 复现方法</h4>
<p>复现的几个阶段：<strong>binary analysis</strong>，<strong>the feature
extraction</strong>，<strong>the machine-learning
implementations</strong>.</p>
<p>二进制分析以及特征提取使用的是IDA Pro 7.3以及其Python接口。</p>
<p>有关我们所有实现的其他技术细节，以及有关我们努力联系相应作者的信息以及有关使用预训练模型的注意事项，请参见：</p>
<p>How Machine Learning Is Solving the Binary Function Similarity
Problem — Artifacts and Additional Technical Details.
https://github.com/Cisco-Talos/binary_function_similarity.</p>
<h4 id="数据集">2. 数据集</h4>
<p>为了与现实世界的复杂性与变数相匹配，我们创建了两个新的数据集Dataset-1和Dataset-2，其包含了二进制检测领域的问题：</p>
<ul>
<li>​ 多种编译器和版本；</li>
<li>​ 多种编译优化器；</li>
<li>​ 多种指令集架构和bitness(32位还是64位)；</li>
<li>​ 不同种类的代码（命令行 or GUI）；</li>
</ul>
<p><strong>Dataset-1用于训练，Dataset-1和Dataset-2用于测试。</strong></p>
<h4 id="实验环境设置">3. 实验环境设置</h4>
<h6 id="定义6个检测任务">3.1 定义6个检测任务</h6>
<table>
<colgroup>
<col style="width: 11%" />
<col style="width: 83%" />
<col style="width: 5%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">序号</th>
<th style="text-align: center;">任务名称</th>
<th style="text-align: center;">作用</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">XO</td>
<td
style="text-align: center;">待测函数对仅优化器不同，编译器，编译器版本、指令集架构和bitness都相同</td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: center;">XC</td>
<td
style="text-align: center;">待测函数对优化器，编译器和编译器版本不同，指令集架构和bitness相同</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3</td>
<td style="text-align: center;">XC+XB</td>
<td
style="text-align: center;">待测函数对优化器，编译器和编译器版本以及bitness不同，指令集架构相同</td>
</tr>
<tr class="even">
<td style="text-align: center;">4</td>
<td style="text-align: center;">XA</td>
<td
style="text-align: center;">待测函数对指令集架构和bitness不同，其他相同</td>
</tr>
<tr class="odd">
<td style="text-align: center;">5</td>
<td style="text-align: center;">XA+XO</td>
<td
style="text-align: center;">待测函数对指令集架构、bitness和优化器不用，其他相同</td>
</tr>
<tr class="even">
<td style="text-align: center;">6</td>
<td style="text-align: center;">XM</td>
<td style="text-align: center;">待测函数对所有性质都可能不同</td>
</tr>
</tbody>
</table>
<h6 id="测试方法">3.2 测试方法</h6>
<p>每种方法的测试包含两个过程：</p>
<ol type="1">
<li>AUC和ROC图；</li>
<li>MRR和Recall@K。</li>
</ol>
<h4 id="模糊哈希方法比较结果">4. 模糊哈希方法比较结果</h4>
<p>比较了两个方法：<strong>Catalog1</strong>和<strong>FunctionSimSearch</strong>。</p>
<h6 id="首先每次只变动一个变量">4.1 首先每次只变动一个变量：</h6>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221212161639.png" style="zoom: 33%;" /></p>
<p>B：Row Bytes；G：graphlets，连通图结构； M： mnemonics；符号
I：immediates 。</p>
<p>由图可知，在单指令集架构的条件下即使简单的row
bytes输入也能取得较好效果，在多指令集架构下代码图结构明显更好。</p>
<h6 id="测试3.1中的6个任务">4.2 测试3.1中的6个任务</h6>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221212162636.png" /></p>
<p>可以看到：</p>
<ol type="1">
<li><p>当面对多变量不同的任务时简单的方法开始变得不奏效了，同时FSS在面对大函数时可能由于其图结构的输入也更为有效；</p></li>
<li><p>同时，GMI的三个特征引入并没有比最基础的G配置输入更为有效；</p></li>
<li><p>Catalog1速度更快，因为FSS的特征提取更耗时。</p></li>
</ol>
<h4 id="机器学习方法比较结果">5. 机器学习方法比较结果</h4>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221212165733.png" /></p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221212215209.png" /></p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221212220321.png" /></p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221212224409.png" /></p>
<p>结论：</p>
<ul>
<li>GMN几乎在所有的测试下表现都最好，而且运行时间也很短；</li>
<li>语言模型相关的方法在同一指令集架构下的表现都很不错，transformer在跨指令集架构的表现也不错；</li>
<li>由Li等人提出的GNN变式相较于GNN（s2v）的表现有明显提升；</li>
<li>GNN（s2v）相关的实验表明更复杂的特征提取不一定更有效，且使用instruction
embedding也不一定效果更好；</li>
<li>相较于GNN，使用了编码器的SAFE在小函数上的表现更好，但其存在OOV问题；</li>
</ul>
<h4 id="漏洞发掘的样例">6. 漏洞发掘的样例</h4>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221212232550.png" /></p>
<h2 id="问题">问题</h2>
<ol type="1">
<li>测试的时候使用的Ranking measures（MRR10与Recall@K）的作用？</li>
<li></li>
</ol>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Binary</tag>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>强化学习之ConnectX四子棋游戏</title>
    <url>/2022/12/01/Connect%20X/</url>
    <content><![CDATA[<h1 id="connect-x">Connect X</h1>
<blockquote>
<p>Time: 2022.11.14</p>
<p>Author: Shaw</p>
<p><a href="https://www.kaggle.com/competitions/connectx">Connect X |
Kaggle</a></p>
<p><a
href="https://www.kaggle.com/code/ajeffries/connectx-getting-started/notebook">ConnectX
Getting Started | Kaggle</a></p>
</blockquote>
<h2 id="一任务简介">一、任务简介：</h2>
<ul>
<li><strong>任务：</strong>强化学习任务，类似五子棋的规则（但每一步只能下某一列的最底端的空位），每人一步，先于对手横竖或斜角连成4个即可获胜。</li>
</ul>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221114140309.png" style="zoom:50%;" /></p>
<span id="more"></span>
<ul>
<li><p><strong>评估方法：</strong></p>
<p>每个提交给Kaggle的结果（一个py文件，包含了agent如何下棋的规则）在跟自己下一次棋，证明其工作正常后，会被赋予一个skill等级。</p>
<p>相近skill等级的提交结果之间会进行持续不断下棋PK。</p>
<p>每次PK结束后就会更新双方的等级，赢加输减。</p></li>
</ul>
<h2 id="二环境准备">二、环境准备</h2>
<p>安装kaggle相关的强化学习环境：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> kaggle-environments<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>创建Connect X环境：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> kaggle_environments <span class="token keyword">import</span> evaluate<span class="token punctuation">,</span> make<span class="token punctuation">,</span> utils

env <span class="token operator">=</span> make<span class="token punctuation">(</span><span class="token string">"connectx"</span><span class="token punctuation">,</span>debug<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>   <span class="token comment">#创建connectx环境</span>
env<span class="token punctuation">.</span>render<span class="token punctuation">(</span><span class="token punctuation">)</span>                        <span class="token comment">#以图形化的形式显示当前环境</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>创建Submission提交函数：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> inspect
<span class="token keyword">import</span> os

<span class="token keyword">def</span> <span class="token function">write_agent_to_file</span><span class="token punctuation">(</span>function<span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token builtin">file</span><span class="token punctuation">,</span> <span class="token string">"a"</span> <span class="token keyword">if</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span><span class="token builtin">file</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"w"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>inspect<span class="token punctuation">.</span>getsource<span class="token punctuation">(</span>function<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>function<span class="token punctuation">,</span> <span class="token string">"written to"</span><span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token punctuation">)</span>

write_agent_to_file<span class="token punctuation">(</span>my_agent<span class="token punctuation">,</span> <span class="token string">"submission.py"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="三q-learning">三、Q-learning</h2>
<p>对于简单的下棋问题，这里选择Q-learning算法进行学习。</p>
<p>创建connectX类：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">ConnectX</span><span class="token punctuation">(</span>gym<span class="token punctuation">.</span>Env<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> switch_prob<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>env <span class="token operator">=</span> make<span class="token punctuation">(</span><span class="token string">'connectx'</span><span class="token punctuation">,</span> debug<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pair <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token string">'negamax'</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>trainer <span class="token operator">=</span> self<span class="token punctuation">.</span>env<span class="token punctuation">.</span>train<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pair<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>switch_prob <span class="token operator">=</span> switch_prob
        
        <span class="token comment"># Define required gym fields (examples):</span>
        config <span class="token operator">=</span> self<span class="token punctuation">.</span>env<span class="token punctuation">.</span>configuration
        self<span class="token punctuation">.</span>action_space <span class="token operator">=</span> gym<span class="token punctuation">.</span>spaces<span class="token punctuation">.</span>Discrete<span class="token punctuation">(</span>config<span class="token punctuation">.</span>columns<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>observation_space <span class="token operator">=</span> gym<span class="token punctuation">.</span>spaces<span class="token punctuation">.</span>Discrete<span class="token punctuation">(</span>config<span class="token punctuation">.</span>columns <span class="token operator">*</span> config<span class="token punctuation">.</span>rows<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">switch_trainer</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>pair <span class="token operator">=</span> self<span class="token punctuation">.</span>pair<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>trainer <span class="token operator">=</span> self<span class="token punctuation">.</span>env<span class="token punctuation">.</span>train<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pair<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> action<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>trainer<span class="token punctuation">.</span>step<span class="token punctuation">(</span>action<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">reset</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>							<span class="token comment"># 有switch_prob的几率更换先手顺序</span>
        <span class="token keyword">if</span> random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>switch_prob<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>switch_trainer<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>trainer<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">render</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>env<span class="token punctuation">.</span>render<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>创建Q表，由于棋盘状态较多，这里使用动态Q表（shape = （n，7））：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">QTable</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> action_space<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>table <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>action_space <span class="token operator">=</span> action_space

    <span class="token keyword">def</span> <span class="token function">add_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> state_key<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>table<span class="token punctuation">[</span>state_key<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>action_space<span class="token punctuation">.</span>n<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> state<span class="token punctuation">)</span><span class="token punctuation">:</span>
        board <span class="token operator">=</span> state<span class="token punctuation">[</span><span class="token string">'board'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span>  				<span class="token comment"># 复制一份</span>
        board<span class="token punctuation">.</span>append<span class="token punctuation">(</span>state<span class="token punctuation">.</span>mark<span class="token punctuation">)</span> 					<span class="token comment"># 加入mark标志着先手还是后手</span>
        state_key <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>board<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">)</span>	
        state_key <span class="token operator">=</span> <span class="token builtin">hex</span><span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>state_key<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token comment"># 转为16进制编码，去掉前缀</span>
        <span class="token keyword">if</span> state_key <span class="token keyword">not</span> <span class="token keyword">in</span> self<span class="token punctuation">.</span>table<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>add_item<span class="token punctuation">(</span>state_key<span class="token punctuation">)</span>

        <span class="token keyword">return</span> self<span class="token punctuation">.</span>table<span class="token punctuation">[</span>state_key<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>定义相关超参数：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">alpha <span class="token operator">=</span> <span class="token number">0.1</span>				<span class="token comment"># 学习率</span>
gamma <span class="token operator">=</span> <span class="token number">0.6</span>				<span class="token comment"># discount factor γ</span>
epsilon <span class="token operator">=</span> <span class="token number">0.99</span>				<span class="token comment"># ε-greedy策略的ε</span>
min_epsilon <span class="token operator">=</span> <span class="token number">0.1</span>			<span class="token comment"># 最小ε</span>

episodes <span class="token operator">=</span> <span class="token number">10000</span>			<span class="token comment"># 采样轮数</span>

alpha_decay_step <span class="token operator">=</span> <span class="token number">1000</span>
alpha_decay_rate <span class="token operator">=</span> <span class="token number">0.9</span>		<span class="token comment"># α衰减率</span>
epsilon_decay_rate <span class="token operator">=</span> <span class="token number">0.9999</span>	<span class="token comment"># ε衰减率</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>定义训练过程：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">q_table <span class="token operator">=</span> QTable<span class="token punctuation">(</span>env<span class="token punctuation">.</span>action_space<span class="token punctuation">)</span>

all_epochs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
all_total_rewards <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
all_avg_rewards <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token comment"># Last 100 steps</span>
all_qtable_rows <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
all_epsilons <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>episodes<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    state <span class="token operator">=</span> env<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment"># 清空棋盘</span>
    epochs<span class="token punctuation">,</span>total_rewards <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span>
    epsilon <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>min_epsilon<span class="token punctuation">,</span>epsilon<span class="token operator">*</span>epsilon_decay_rate<span class="token punctuation">)</span>   <span class="token comment"># ε每轮衰减</span>
    done <span class="token operator">=</span> <span class="token boolean">False</span>

    <span class="token keyword">while</span> <span class="token keyword">not</span> done <span class="token punctuation">:</span>    <span class="token comment"># 开始一轮采样</span>
        <span class="token comment"># 某列不能下的情况 == 此列的第一个位置有棋子 == (state.board[c] == 0)</span>
        space_list <span class="token operator">=</span> <span class="token punctuation">[</span>c <span class="token keyword">for</span> c <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>env<span class="token punctuation">.</span>action_space<span class="token punctuation">.</span>n<span class="token punctuation">)</span> <span class="token keyword">if</span> state<span class="token punctuation">[</span><span class="token string">'board'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>c<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">]</span>

        <span class="token keyword">if</span> random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">&lt;=</span> epsilon <span class="token punctuation">:</span><span class="token comment"># ε-greedy-->选择随机策略</span>
            action <span class="token operator">=</span> choice<span class="token punctuation">(</span>space_list<span class="token punctuation">)</span>
        <span class="token keyword">else</span> <span class="token punctuation">:</span> 					   <span class="token comment"># ε-greedy-->选择贪心策略</span>
            row <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>q_table<span class="token punctuation">(</span>state<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            row<span class="token punctuation">[</span><span class="token punctuation">[</span>c <span class="token keyword">for</span> c <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>env<span class="token punctuation">.</span>action_space<span class="token punctuation">.</span>n<span class="token punctuation">)</span>
                 <span class="token keyword">if</span> state<span class="token punctuation">[</span><span class="token string">'board'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>c<span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span>
            action <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>row<span class="token punctuation">)</span><span class="token punctuation">)</span>
        
        next_state<span class="token punctuation">,</span>reward<span class="token punctuation">,</span>done<span class="token punctuation">,</span>info <span class="token operator">=</span> env<span class="token punctuation">.</span>step<span class="token punctuation">(</span>action<span class="token punctuation">)</span>

        <span class="token keyword">if</span> done<span class="token punctuation">:</span>
            <span class="token keyword">if</span> reward <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span> <span class="token comment"># Won</span>
                reward <span class="token operator">=</span> <span class="token number">20</span>
            <span class="token keyword">elif</span> reward <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span> <span class="token comment"># Lost</span>
                reward <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">20</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span> 
                reward <span class="token operator">=</span> <span class="token number">1</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            reward <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">0.01</span>

        old_value <span class="token operator">=</span> q_table<span class="token punctuation">(</span>state<span class="token punctuation">)</span><span class="token punctuation">[</span>action<span class="token punctuation">]</span>
        next_max <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>q_table<span class="token punctuation">(</span>next_state<span class="token punctuation">)</span><span class="token punctuation">)</span>
	   <span class="token comment"># Q-Learning 更新</span>
        new_value <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> alpha<span class="token punctuation">)</span> <span class="token operator">*</span> old_value <span class="token operator">+</span> alpha <span class="token operator">*</span> <span class="token punctuation">(</span>reward <span class="token operator">+</span> gamma <span class="token operator">*</span> next_max<span class="token punctuation">)</span>
        q_table<span class="token punctuation">(</span>state<span class="token punctuation">)</span><span class="token punctuation">[</span>action<span class="token punctuation">]</span> <span class="token operator">=</span> new_value

        state <span class="token operator">=</span> next_state
        epochs <span class="token operator">+=</span> <span class="token number">1</span>
        total_rewards <span class="token operator">+=</span> reward

    all_epochs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epochs<span class="token punctuation">)</span>
    all_total_rewards<span class="token punctuation">.</span>append<span class="token punctuation">(</span>total_rewards<span class="token punctuation">)</span>
    avg_rewards <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>all_total_rewards<span class="token punctuation">[</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> i<span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    all_avg_rewards<span class="token punctuation">.</span>append<span class="token punctuation">(</span>avg_rewards<span class="token punctuation">)</span>
    all_qtable_rows<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>q_table<span class="token punctuation">.</span>table<span class="token punctuation">)</span><span class="token punctuation">)</span>
    all_epsilons<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epsilon<span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> alpha_decay_step <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        alpha <span class="token operator">*=</span> alpha_decay_rate
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>根据Q表生成Agent： <pre class="line-numbers language-python" data-language="python"><code class="language-python">my_agent <span class="token operator">=</span> <span class="token triple-quoted-string string">'''def my_agent(observation, configuration):
    from random import choice

    q_table = '''</span> \
    <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>dict_q_table<span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span> \
    <span class="token operator">+</span> <span class="token triple-quoted-string string">'''

    board = observation.board[:]
    board.append(observation.mark)
    state_key = list(map(str, board))
    state_key = hex(int(''.join(state_key), 3))[2:]

    if state_key not in q_table.keys():
        return choice([c for c in range(configuration.columns) if observation.board[c] == 0])

    action = q_table[state_key]

    if observation.board[action] != 0:
        return choice([c for c in range(configuration.columns) if observation.board[c] == 0])

    return action
    '''</span>
    
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'submission.py'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>my_agent<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p>
<p>上交到Kaggle后经过一晚上的博弈，分数很低，直接倒数：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221117111813.png" /></p>
<p>尝试评估其效果：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> submission <span class="token keyword">import</span> my_agent

<span class="token keyword">def</span> <span class="token function">mean_reward</span><span class="token punctuation">(</span>rewards<span class="token punctuation">)</span><span class="token punctuation">:</span>
    win <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token keyword">if</span> r<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token number">0</span> <span class="token keyword">else</span> <span class="token number">0</span> <span class="token keyword">for</span> r <span class="token keyword">in</span> rewards<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token keyword">if</span> r<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">></span><span class="token number">0</span> <span class="token keyword">else</span> <span class="token number">0</span> <span class="token keyword">for</span> r <span class="token keyword">in</span> rewards<span class="token punctuation">)</span>
    draw <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token keyword">if</span> r<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> r<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">else</span> <span class="token number">0</span> <span class="token keyword">for</span> r <span class="token keyword">in</span> rewards<span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token string">'&#123;0&#125; episodes- won: &#123;1&#125; | loss: &#123;2&#125; | draw: &#123;3&#125; | winning rate: &#123;4&#125;%'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
        <span class="token builtin">len</span><span class="token punctuation">(</span>rewards<span class="token punctuation">)</span><span class="token punctuation">,</span>
        win<span class="token punctuation">,</span>
        loss<span class="token punctuation">,</span>
        draw<span class="token punctuation">,</span>
        <span class="token punctuation">(</span>win <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>rewards<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">100</span>
    <span class="token punctuation">)</span>

<span class="token comment"># Run multiple episodes to estimate agent's performance.</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"My Agent vs Random Agent:"</span><span class="token punctuation">,</span> mean_reward<span class="token punctuation">(</span>
    evaluate<span class="token punctuation">(</span><span class="token string">"connectx"</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>my_agent<span class="token punctuation">,</span> <span class="token string">"random"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> num_episodes<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"My Agent vs Negamax Agent:"</span><span class="token punctuation">,</span> mean_reward<span class="token punctuation">(</span>
    evaluate<span class="token punctuation">(</span><span class="token string">"connectx"</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>my_agent<span class="token punctuation">,</span> <span class="token string">"negamax"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> num_episodes<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221118103237.png" style="zoom:80%;" /></p>
<h2 id="四dqn">四、DQN</h2>
<p>在尝试了简单的强化学习算法后，这里将深度学习与强化学习结合起来，用DQN进行训练：</p>
<p>DQN使用了神经网络来代替Q表，使用函数替代表格，以此解决Q表过大的问题：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">ConnectX</span><span class="token punctuation">(</span>gym<span class="token punctuation">.</span>Env<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> switch_prob<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>env <span class="token operator">=</span> make<span class="token punctuation">(</span><span class="token string">'connectx'</span><span class="token punctuation">,</span> debug<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pair <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token string">'random'</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>trainer <span class="token operator">=</span> self<span class="token punctuation">.</span>env<span class="token punctuation">.</span>train<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pair<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>switch_prob <span class="token operator">=</span> switch_prob

        <span class="token comment"># Define required gym fields (examples):</span>
        config <span class="token operator">=</span> self<span class="token punctuation">.</span>env<span class="token punctuation">.</span>configuration
        self<span class="token punctuation">.</span>action_space <span class="token operator">=</span> gym<span class="token punctuation">.</span>spaces<span class="token punctuation">.</span>Discrete<span class="token punctuation">(</span>config<span class="token punctuation">.</span>columns<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>observation_space <span class="token operator">=</span> gym<span class="token punctuation">.</span>spaces<span class="token punctuation">.</span>Discrete<span class="token punctuation">(</span>config<span class="token punctuation">.</span>columns <span class="token operator">*</span> config<span class="token punctuation">.</span>rows<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">switch_trainer</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>pair <span class="token operator">=</span> self<span class="token punctuation">.</span>pair<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>trainer <span class="token operator">=</span> self<span class="token punctuation">.</span>env<span class="token punctuation">.</span>train<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pair<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> action<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>trainer<span class="token punctuation">.</span>step<span class="token punctuation">(</span>action<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">reset</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>switch_prob<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>switch_trainer<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>trainer<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">render</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>env<span class="token punctuation">.</span>render<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">DeepModel</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>num_states<span class="token punctuation">,</span>hidden_units<span class="token punctuation">,</span>num_actions<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>DeepModel<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>hidden_layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>hidden_units<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> i <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>hidden_layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_states<span class="token punctuation">,</span>hidden_units<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">else</span> <span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>hidden_layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_units<span class="token punctuation">[</span>i<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>hidden_units<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>output_layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_units<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>num_actions<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>hidden_layers<span class="token punctuation">:</span>
            x <span class="token operator">=</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>output_layers<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">DQN</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>num_states<span class="token punctuation">,</span>num_actions<span class="token punctuation">,</span>hidden_units<span class="token punctuation">,</span>gamma<span class="token punctuation">,</span>max_experiences<span class="token punctuation">,</span>min_experiences<span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span>lr<span class="token punctuation">)</span><span class="token punctuation">:</span>

        self<span class="token punctuation">.</span>num_actions <span class="token operator">=</span> num_actions
        self<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> batch_size
        self<span class="token punctuation">.</span>gamma <span class="token operator">=</span> gamma
        self<span class="token punctuation">.</span>model <span class="token operator">=</span> DeepModel<span class="token punctuation">(</span>num_states<span class="token punctuation">,</span>hidden_units<span class="token punctuation">,</span>num_actions<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr <span class="token operator">=</span> lr<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>experience <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'s'</span><span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                           <span class="token string">'a'</span><span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                           <span class="token string">'r'</span><span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                           <span class="token string">'s2'</span><span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                           <span class="token string">'done'</span><span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
                          <span class="token punctuation">&#125;</span>
        self<span class="token punctuation">.</span>max_experiences <span class="token operator">=</span> max_experiences
        self<span class="token punctuation">.</span>min_experiences <span class="token operator">=</span> min_experiences

    <span class="token keyword">def</span> <span class="token function">preprocess</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> state<span class="token punctuation">)</span><span class="token punctuation">:</span>
        result <span class="token operator">=</span> state<span class="token punctuation">.</span>board<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
        result<span class="token punctuation">.</span>append<span class="token punctuation">(</span>state<span class="token punctuation">.</span>mark<span class="token punctuation">)</span>
        <span class="token keyword">return</span> result

    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>TargetNet<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>experience<span class="token punctuation">[</span><span class="token string">'s'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>min_experiences<span class="token punctuation">:</span>
            <span class="token keyword">return</span> <span class="token number">0</span>

        ids <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>low<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> high<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>experience<span class="token punctuation">[</span><span class="token string">'s'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> size<span class="token operator">=</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>
        states <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>preprocess<span class="token punctuation">(</span>self<span class="token punctuation">.</span>experience<span class="token punctuation">[</span><span class="token string">'s'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> ids<span class="token punctuation">]</span><span class="token punctuation">)</span>
        actions <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>experience<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> ids<span class="token punctuation">]</span><span class="token punctuation">)</span>
        rewards <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>experience<span class="token punctuation">[</span><span class="token string">'r'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> ids<span class="token punctuation">]</span><span class="token punctuation">)</span>
        states_next <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>preprocess<span class="token punctuation">(</span>self<span class="token punctuation">.</span>experience<span class="token punctuation">[</span><span class="token string">'s2'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> ids<span class="token punctuation">]</span><span class="token punctuation">)</span>
        dones <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>experience<span class="token punctuation">[</span><span class="token string">'done'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> ids<span class="token punctuation">]</span><span class="token punctuation">)</span>

        value_next <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>TargetNet<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>states_next<span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        actual_values <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>dones<span class="token punctuation">,</span> rewards<span class="token punctuation">,</span> rewards<span class="token operator">+</span>self<span class="token punctuation">.</span>gamma<span class="token operator">*</span>value_next<span class="token punctuation">)</span>

        actions <span class="token operator">=</span> np<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>actions<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        actions_one_hot <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_actions<span class="token punctuation">)</span><span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
        actions_one_hot <span class="token operator">=</span> actions_one_hot<span class="token punctuation">.</span>scatter_<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>actions<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        selected_action_values <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>states<span class="token punctuation">)</span> <span class="token operator">*</span> actions_one_hot<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        actual_values <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>actual_values<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss <span class="token operator">=</span> self<span class="token punctuation">.</span>criterion<span class="token punctuation">(</span>selected_action_values<span class="token punctuation">,</span> actual_values<span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">get_action</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>state<span class="token punctuation">,</span>epsilon<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> epsilon<span class="token punctuation">:</span>
            <span class="token keyword">return</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span><span class="token punctuation">[</span>c <span class="token keyword">for</span> c <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_actions<span class="token punctuation">)</span> <span class="token keyword">if</span> state<span class="token punctuation">.</span>board<span class="token punctuation">[</span>c<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span> <span class="token punctuation">:</span>
            prediction <span class="token operator">=</span> self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>np<span class="token punctuation">.</span>atleast_2d<span class="token punctuation">(</span>self<span class="token punctuation">.</span>preprocess<span class="token punctuation">(</span>state<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_actions<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> state<span class="token punctuation">.</span>board<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>
                    prediction<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1e7</span>
            <span class="token keyword">return</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>prediction<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">add_experience</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> exp<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>experience<span class="token punctuation">[</span><span class="token string">'s'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">>=</span> self<span class="token punctuation">.</span>max_experiences<span class="token punctuation">:</span>
            <span class="token keyword">for</span> key <span class="token keyword">in</span> self<span class="token punctuation">.</span>experience<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>experience<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> key<span class="token punctuation">,</span> value <span class="token keyword">in</span> exp<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>experience<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>value<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">copy_weights</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> TrainNet<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>TrainNet<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">save_weights</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> path<span class="token punctuation">)</span><span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> path<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">load_weights</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> path<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>训练时，将采样的s,r,a,s'存储下来，等到积累到一定数量后再以batch的形式输入神经网路（这里是全连接层），训练，测试。</p>
<p>通过这种方式，可以极大的增加训练的轮数，这里尝试十万轮（训练时间四小时）：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221124114413.png" /></p>
<h2 id="五rollout">五、RollOut</h2>
<p>RollOut算法是典型的决策时规划算法，其思路是：</p>
<blockquote>
<ol type="1">
<li>对当前状态S的所有可能取值&lt;s,a'&gt;，模拟计算若干次，取得每个&lt;s,a'&gt;的平均Reward；</li>
<li>选取Reward最大的动作A；</li>
</ol>
</blockquote>
<p>模拟计算时使用的策略称之为rollout策略，这里直接采用随机策略。</p>
<p>使用如下类进行蒙特卡洛采样：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MonteCarlo</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> env<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> episodes<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">'''
        env是当前需要进行模拟采样的状态
        gamma用于计算Reward
        episodes是每个(s,a)的采样次数
        '''</span>
        self<span class="token punctuation">.</span>state <span class="token operator">=</span> deepcopy<span class="token punctuation">(</span>env<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>all_rewards <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>gamma <span class="token operator">=</span> gamma
        self<span class="token punctuation">.</span>episodes <span class="token operator">=</span> episodes
    <span class="token keyword">def</span> <span class="token function">rollout</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> env<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 对当前状态进行rollout采样</span>
        mean_reward <span class="token operator">=</span> <span class="token number">0</span>
        ini_state <span class="token operator">=</span> env<span class="token punctuation">.</span>env<span class="token punctuation">.</span>state<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'observation'</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>episodes<span class="token punctuation">)</span><span class="token punctuation">:</span>
            r <span class="token operator">=</span> <span class="token number">0</span>
            gamma <span class="token operator">=</span> <span class="token number">1</span>
            env<span class="token punctuation">.</span>set_state<span class="token punctuation">(</span>ini_state<span class="token punctuation">)</span>
            state <span class="token operator">=</span> deepcopy<span class="token punctuation">(</span>ini_state<span class="token punctuation">)</span>
            done <span class="token operator">=</span> <span class="token boolean">False</span>
            <span class="token keyword">while</span> <span class="token keyword">not</span> done<span class="token punctuation">:</span>
                space_list <span class="token operator">=</span> <span class="token punctuation">[</span>c <span class="token keyword">for</span> c <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">)</span> <span class="token keyword">if</span> state<span class="token punctuation">[</span><span class="token string">'board'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>c<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">]</span>
                action <span class="token operator">=</span> choice<span class="token punctuation">(</span>space_list<span class="token punctuation">)</span>
                next_state<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> done<span class="token punctuation">,</span> info <span class="token operator">=</span> env<span class="token punctuation">.</span>step<span class="token punctuation">(</span>action<span class="token punctuation">)</span>
                <span class="token keyword">if</span> done<span class="token punctuation">:</span>
                    <span class="token keyword">if</span> reward <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
                        r <span class="token operator">+=</span> <span class="token number">20</span><span class="token operator">*</span>gamma
                    <span class="token keyword">elif</span> reward <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                        r <span class="token operator">-=</span> <span class="token number">20</span><span class="token operator">*</span>gamma
                    <span class="token keyword">else</span><span class="token punctuation">:</span>
                        r <span class="token operator">+=</span> <span class="token number">1</span><span class="token operator">*</span>gamma
                    mean_reward <span class="token operator">+=</span> r
                <span class="token keyword">else</span><span class="token punctuation">:</span>
                    r <span class="token operator">-=</span> <span class="token number">0.05</span><span class="token operator">*</span>gamma
                gamma <span class="token operator">*=</span> self<span class="token punctuation">.</span>gamma
                state <span class="token operator">=</span> next_state
        <span class="token keyword">return</span> mean_reward<span class="token operator">/</span>self<span class="token punctuation">.</span>episodes<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>因为MC采样需要在采样后将环境状态恢复，故在原本的ConnectX类中添加设置状态方法，并删除swicth_trainer：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">ConnectX</span><span class="token punctuation">(</span>gym<span class="token punctuation">.</span>Env<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> switch_prob<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>env <span class="token operator">=</span> make<span class="token punctuation">(</span><span class="token string">'connectx'</span><span class="token punctuation">,</span> debug<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pair <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token string">'random'</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>trainer <span class="token operator">=</span> self<span class="token punctuation">.</span>env<span class="token punctuation">.</span>train<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pair<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>switch_prob <span class="token operator">=</span> switch_prob
        config <span class="token operator">=</span> self<span class="token punctuation">.</span>env<span class="token punctuation">.</span>configuration
        self<span class="token punctuation">.</span>action_space <span class="token operator">=</span> gym<span class="token punctuation">.</span>spaces<span class="token punctuation">.</span>Discrete<span class="token punctuation">(</span>config<span class="token punctuation">.</span>columns<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>observation_space <span class="token operator">=</span> gym<span class="token punctuation">.</span>spaces<span class="token punctuation">.</span>Discrete<span class="token punctuation">(</span>
            config<span class="token punctuation">.</span>columns <span class="token operator">*</span> config<span class="token punctuation">.</span>rows<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> action<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>trainer<span class="token punctuation">.</span>step<span class="token punctuation">(</span>action<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">set_state</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> init_state<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>env<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>env<span class="token punctuation">.</span>state<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'observation'</span><span class="token punctuation">]</span> <span class="token operator">=</span> deepcopy<span class="token punctuation">(</span>init_state<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">reset</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>trainer<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">render</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>env<span class="token punctuation">.</span>render<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>调试时设置play函数：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">play</span><span class="token punctuation">(</span>num<span class="token punctuation">,</span>env<span class="token punctuation">,</span>gamma<span class="token punctuation">,</span>episodes<span class="token punctuation">)</span><span class="token punctuation">:</span>
    result <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'win'</span><span class="token punctuation">:</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token string">'loss'</span><span class="token punctuation">:</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token string">'draw'</span><span class="token punctuation">:</span><span class="token number">0</span><span class="token punctuation">&#125;</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#print('[GAME&#123;&#125;]:'.format(i))</span>
        done <span class="token operator">=</span> <span class="token boolean">False</span>
        state <span class="token operator">=</span> env<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">while</span> <span class="token keyword">not</span> done<span class="token punctuation">:</span>
            ini_state <span class="token operator">=</span> env<span class="token punctuation">.</span>env<span class="token punctuation">.</span>state<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'observation'</span><span class="token punctuation">]</span>
            space_list <span class="token operator">=</span> <span class="token punctuation">[</span>c <span class="token keyword">for</span> c <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">)</span> <span class="token keyword">if</span> ini_state<span class="token punctuation">[</span><span class="token string">'board'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>c<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">]</span>
            R <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            <span class="token keyword">for</span> action <span class="token keyword">in</span> space_list<span class="token punctuation">:</span>  <span class="token comment"># rollout模拟采样</span>
                env<span class="token punctuation">.</span>set_state<span class="token punctuation">(</span>ini_state<span class="token punctuation">)</span>
                next_state<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> done<span class="token punctuation">,</span> info <span class="token operator">=</span> env<span class="token punctuation">.</span>step<span class="token punctuation">(</span>action<span class="token punctuation">)</span>
                mc <span class="token operator">=</span> MonteCarlo<span class="token punctuation">(</span>env<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> episodes<span class="token punctuation">)</span>
                reward <span class="token operator">=</span> reward <span class="token operator">+</span> gamma<span class="token operator">*</span>mc<span class="token punctuation">.</span>rollout<span class="token punctuation">(</span>env<span class="token punctuation">)</span>
                R<span class="token punctuation">.</span>append<span class="token punctuation">(</span>reward<span class="token punctuation">)</span>

            Action <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>R<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 根据采样结果选择动作</span>

            env<span class="token punctuation">.</span>set_state<span class="token punctuation">(</span>ini_state<span class="token punctuation">)</span>
            next_state<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> done<span class="token punctuation">,</span> info <span class="token operator">=</span> env<span class="token punctuation">.</span>step<span class="token punctuation">(</span>Action<span class="token punctuation">)</span>

            <span class="token comment">#print('R = ', R)</span>
            <span class="token comment">#print('Action = ', Action)</span>
            <span class="token comment">#print(env.render(mode="ansi"))</span>

            <span class="token keyword">if</span> done<span class="token punctuation">:</span>
                <span class="token keyword">if</span> reward <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>  <span class="token comment"># Won</span>
                    result<span class="token punctuation">[</span><span class="token string">'win'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
                    <span class="token comment">#print('you win!')</span>
                <span class="token keyword">elif</span> reward <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>  <span class="token comment"># Lost</span>
                    result<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
                    <span class="token comment">#print('you loss!')</span>
                <span class="token keyword">else</span><span class="token punctuation">:</span>
                    result<span class="token punctuation">[</span><span class="token string">'draw'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
                    <span class="token comment">#print('draw!')</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'My Agent vs Random Agent:'</span><span class="token punctuation">,</span> <span class="token string">'&#123;0&#125; episodes- won: &#123;1&#125; | loss: &#123;2&#125; | draw: &#123;3&#125; | winning rate: &#123;4&#125;%'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
        num<span class="token punctuation">,</span>
        result<span class="token punctuation">[</span><span class="token string">'win'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        result<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        result<span class="token punctuation">[</span><span class="token string">'draw'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span>result<span class="token punctuation">[</span><span class="token string">'win'</span><span class="token punctuation">]</span> <span class="token operator">/</span> num<span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">100</span>
    <span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="六问题总结">六、问题总结</h2>
<h4 id="训练时间过长">1. 训练时间过长</h4>
<p>以Q-Learning为例，一个10000个episodes的训练要耗时2小时+，对于一个简单的四子棋过于耗时。</p>
<p><strong>尝试：</strong></p>
<ul>
<li>尝试在python文件中而不是jupter中训练：训练总时间减少了约2/5，有一定效果；</li>
<li>使用DQN时训练速度明显大于Q-leraning（训练十万轮耗时3小时40分钟），猜想可能是神经网络可以使用GPU加速，‘查表’速度更快；</li>
</ul>
<h4 id="q-learning训练效果不佳">2. Q-Learning训练效果不佳</h4>
<p>在经过10000个episode训练后，Q-Learning的表现如下：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221118103237.png" style="zoom:80%;" /></p>
<p>通过如下的代码，你可以跟自己的agent下一局，可以发现，经过一万轮训练后的Agent棋力很一般，新手人类也能轻松胜利：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">while</span> <span class="token keyword">not</span> done<span class="token punctuation">:</span>
    sys<span class="token punctuation">.</span>stdout<span class="token punctuation">.</span>flush<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>env<span class="token punctuation">.</span>render<span class="token punctuation">(</span>mode<span class="token operator">=</span><span class="token string">"ansi"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    action <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">(</span><span class="token string">'Input your action:(0-6)'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    next_state<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> done<span class="token punctuation">,</span> info <span class="token operator">=</span> env<span class="token punctuation">.</span>step<span class="token punctuation">(</span>action<span class="token punctuation">)</span>

    <span class="token keyword">if</span> done<span class="token punctuation">:</span>
        <span class="token keyword">if</span> reward <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span> <span class="token comment"># Won</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'you win!'</span><span class="token punctuation">)</span>
        <span class="token keyword">elif</span> reward <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span> <span class="token comment"># Lost</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'you loss!'</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span> 
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'draw!'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221118115042.png" style="zoom:80%;" /></p>
<p>观察训练时平均Reward、Q表长度和ε的变化：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221118114510.png" /></p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221118114512.png" /></p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221118114526.png" /></p>
<p>可以发现，在10000轮episode的训练中，平均奖励始终在围绕0.8上下波动，Q表长度一直在平稳增加，这说明直到训练结束Agent仍有大量未见过的state进入Q表，模型训练轮数不足。</p>
<p>实际上 <strong><u>Connect
4有四百万兆不同的状态，Q-learning显然在有限的时间空间下是取得不了什么有效学习的</u></strong>。</p>
<h4 id="dqn的不足">3. DQN的不足</h4>
<p>即使使用DQN进行了十万轮的训练，耗时近4小时，DQN的结果仍不理想：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221124153505.png" /></p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221124153516.png" /></p>
<p>其实不难理解，对于四百万兆个state的棋盘，十万轮也不过是<span
class="math display">\[1/10^{13}\]</span>，仍过于渺小。</p>
<p>并且，Q-learning以及DQN都是background
planning，其算法倾向于将所有可能的状态的最佳策略都计算出来。实际上，在下棋的时候几乎绝大多数状态都不会出现第二次，但相似的棋谱格局却会经常出现。</p>
<p>显然，相较于background planning，<strong><em>decision-time
planning（决策时规划）</em></strong>算法是个更合适的算法。</p>
<p>decision-time
planning在遇到每个新的状态St后再开始一个完整的规划过程，其为每个当前状态选择一个动作At，到下一个状态St+1就选择一个动作At+1，以此类推。基于当前状态所生成的values和policy会在做完动作选择决策后被丢弃，在很多应用场景中这么做并不算一个很大的损失，因为有非常多的状态存在，且不太可能在短时间内回到同一个状态，故重复计算导致的资源浪费会很少。</p>
<h4 id="随机rollout">4. 随机Rollout</h4>
<p>这里尝试使用简单的RollOut算法后发现，<strong><u>即使在rollout算法中使用最简单的随机rollout策略，并且每轮模拟仅仅采样1次，所取得的的结果就比训练了4个小时的DQN好很多。</u></strong></p>
<p>在模拟采样轮数为1（对每个&lt;s,a&gt;键值对只采样1次）、gamma为1的条件下，与Random和Negmax分别下100局的胜率：</p>
<table>
<thead>
<tr class="header">
<th>模型</th>
<th>VS Random</th>
<th>VS Negmax</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Q-Learning(一万轮)</td>
<td>61%</td>
<td>3%</td>
</tr>
<tr class="even">
<td>DQN(十万轮)</td>
<td>70%</td>
<td>6%</td>
</tr>
<tr class="odd">
<td>随机Rollout</td>
<td>94%</td>
<td>95%平局</td>
</tr>
</tbody>
</table>
<p>但Rollout算法的问题也很明显，其应用的过程就是‘训练’的过程，每次需要等模拟采样完成后再选择，故其反应时间会比DQN长很多。</p>
<table>
<thead>
<tr class="header">
<th>时间</th>
<th>DQN</th>
<th>随机Rollout</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>训练所需时间</td>
<td>4h</td>
<td>0</td>
</tr>
<tr class="even">
<td>下100局所需时间</td>
<td>1m</td>
<td>40m</td>
</tr>
</tbody>
</table>
<p>但即使这样，我们也能看出，决策时规划比后台规划算法更适合棋类场景，由于棋类几乎无限的状态数量，决策时规划虽然反应更慢，但结果也更为合理有效。</p>
<h4 id="展望">5. 展望</h4>
<p>本次的小比赛从最简单的Q-Learning算法入手，到引入了神经网络的DQN，最后从后台规划引入到决策时规划，并实现了一个简单的Rollout算法。</p>
<p><strong>首先，Q-learning以及DQN这类后台规划算法无法有效处理状态过多的环境</strong>。Q-learning在时间以及空间上都存在溢出问题，DQN虽然引入了深度神经网络来替代Q表，解决了空间不足的问题，但由于其训练速度没有质的改变，训练时间仍不可估量的长。</p>
<p><strong>决策时规划面对状态过多的问题有明显提升。</strong>即使在rollout算法中使用最简单的随机rollout策略，并且每轮模拟仅仅采样1次，所取得的的结果就比训练了4个小时的DQN好很多。</p>
<p>除了使用简单的随机Rollout算法，这里可以替换rollout策略来进一步提升结果，减少rollout的反应时间。以及，可以使用MCTS，蒙特卡洛树搜索的方法再进一步提升结果（kaggle中已有Notebook，且分数不错），这里篇幅以及时间有限，仅做展望。</p>
]]></content>
      <categories>
        <category>Kaggle</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
        <tag>RL</tag>
      </tags>
  </entry>
  <entry>
    <title>Facial Keypoints Detection</title>
    <url>/2022/11/14/Facial%20Keypoints%20Detection/</url>
    <content><![CDATA[<h1 id="facial-keypoints-detection">Facial Keypoints Detection</h1>
<blockquote>
<p>Time: 2022.11.11</p>
<p>Author: Shaw</p>
<p><a
href="https://www.kaggle.com/competitions/facial-keypoints-detection/overview">Facial
Keypoints Detection | Kaggle</a></p>
</blockquote>
<h2 id="一任务简介">一、任务简介：</h2>
<ul>
<li>​ <strong>任务</strong>：正确标注所给图片的人脸关键位置；</li>
</ul>
<span id="more"></span>
<ul>
<li>​ <strong>关键位置（keypoint）</strong>：</li>
</ul>
<table>
<thead>
<tr class="header">
<th>字段</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>left_eye_center</td>
<td>左眼中心</td>
</tr>
<tr class="even">
<td>right_eye_center</td>
<td>右眼中心</td>
</tr>
<tr class="odd">
<td>left_eye_inner_corner</td>
<td>左眼内眼角</td>
</tr>
<tr class="even">
<td>left_eye_outer_corner</td>
<td>左眼外眼角</td>
</tr>
<tr class="odd">
<td>right_eye_inner_corner</td>
<td>右眼内眼角</td>
</tr>
<tr class="even">
<td>right_eye_outer_corner</td>
<td>右眼外眼角</td>
</tr>
<tr class="odd">
<td>left_eyebrow_inner_end</td>
<td>左眉内侧</td>
</tr>
<tr class="even">
<td>left_eyebrow_outer_end</td>
<td>左眉外侧</td>
</tr>
<tr class="odd">
<td>right_eyebrow_inner_end</td>
<td>右眉内侧</td>
</tr>
<tr class="even">
<td>right_eyebrow_outer_end</td>
<td>右眉外侧</td>
</tr>
<tr class="odd">
<td>nose_tip</td>
<td>鼻尖</td>
</tr>
<tr class="even">
<td>mouth_left_corner</td>
<td>嘴左角</td>
</tr>
<tr class="odd">
<td>mouth_right_corner</td>
<td>嘴右角</td>
</tr>
<tr class="even">
<td>mouth_center_top_lip</td>
<td>上唇中心</td>
</tr>
<tr class="odd">
<td>mouth_center_bottom_lip</td>
<td>下唇中心</td>
</tr>
</tbody>
</table>
<ul>
<li>​ <strong>数据组成</strong>：
<ul>
<li><strong>training.csv:</strong>
包含7049张训练图片，每张图片有15个keypoint坐标（每个坐标用x,y两列数据表示，<u>有些数值缺失</u>），图像数据作为按行排序的像素列表。故表格中的数据标签有30列，图片数据一列共31列；</li>
<li><strong>test.csv:</strong> 包含1783张测试图片；</li>
<li><strong>ubmissionFileFormat.csv:</strong> 待提交的测试结果。</li>
</ul></li>
<li><strong>样例</strong>：</li>
</ul>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221113142355.png" /></p>
<h2 id="二数据分析处理">二、数据分析处理</h2>
<p>首先加载训练数据与测试数据：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#Load the data</span>
train_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>TRAIN_PATH<span class="token punctuation">)</span>
test_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>TEST_PATH<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>train_data<span class="token punctuation">.</span>columns<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>test_data<span class="token punctuation">.</span>columns<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="空值填补">2.1 空值填补</h3>
<p>因为数据中存在缺失值，故统计分析存在缺失值的列：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">train_data<span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">any</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>value_counts<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">#out:</span>
<span class="token triple-quoted-string string">'''
True     28
False     3
dtype: int64
'''</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>故28个属性列都存在缺失值，接下来填补缺失，‘ffill’方法表示用前面一列的值填补当前位置的值：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">train_data<span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>method <span class="token operator">=</span> <span class="token string">'ffill'</span><span class="token punctuation">,</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>同时，Image列中的部分数值由‘ ’空格替代，这里将其替换为0：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">train_data<span class="token punctuation">[</span><span class="token string">'Image_new'</span><span class="token punctuation">]</span> <span class="token operator">=</span> train_data<span class="token punctuation">[</span><span class="token string">'Image'</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token string">'0'</span> <span class="token keyword">if</span> i <span class="token operator">==</span> <span class="token string">' '</span> <span class="token keyword">else</span> i <span class="token keyword">for</span> i <span class="token keyword">in</span> x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

image_list <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>train_data<span class="token punctuation">[</span><span class="token string">'Image_new'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to_list<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span><span class="token string">'float'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h3 id="相关图片处理函数编写">2.2 相关图片处理函数编写</h3>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">IMG_SIZE <span class="token operator">=</span> <span class="token number">96</span>  <span class="token comment"># image size 96 x 96 pixels</span>

<span class="token keyword">def</span> <span class="token function">show_keypoints</span><span class="token punctuation">(</span>image<span class="token punctuation">,</span> keypoints<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''
    Show image with keypoints
    Args:
        image (array-like or PIL image): The image data. (M, N)
        keypoints (array-like): The keypoits data. (N, 2)
    '''</span>
    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>image<span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'gray'</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>keypoints<span class="token punctuation">)</span><span class="token punctuation">:</span>
        plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>keypoints<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> keypoints<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">24</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'.'</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">show_images</span><span class="token punctuation">(</span>df<span class="token punctuation">,</span> indxs<span class="token punctuation">,</span> ncols<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span> with_keypoints<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''
    Show images with keypoints in grids
    Args:
        df (DataFrame): data (M x N)
        idxs (iterators): list, Range, Indexes
        ncols (integer): number of columns (images by rows)
        figsize (float, float): width, height in inches
        with_keypoints (boolean): True if show image with keypoints
    '''</span>
    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span>figsize<span class="token punctuation">)</span>
    nrows <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>indxs<span class="token punctuation">)</span> <span class="token operator">//</span> ncols <span class="token operator">+</span> <span class="token number">1</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> idx <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>indxs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        image <span class="token operator">=</span> np<span class="token punctuation">.</span>fromstring<span class="token punctuation">(</span>df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>idx<span class="token punctuation">,</span> <span class="token string">'Image'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> sep<span class="token operator">=</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>\
                <span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> IMG_SIZE<span class="token punctuation">)</span>
        <span class="token keyword">if</span> with_keypoints<span class="token punctuation">:</span>
            keypoints <span class="token operator">=</span> df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token string">'Image'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>values<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>\
                        <span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            keypoints <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span>nrows<span class="token punctuation">,</span> ncols<span class="token punctuation">,</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Sample #</span><span class="token interpolation"><span class="token punctuation">&#123;</span>idx<span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span>                 <span class="token comment">#关闭坐标轴</span>
        plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span>              <span class="token comment"># tight_layout会自动调整子图参数，使之填充整个图像区域</span>
        show_keypoints<span class="token punctuation">(</span>image<span class="token punctuation">,</span> keypoints<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="分割数据集">2.3 分割数据集</h3>
<p>使用Dataset和DataLoader相关pytorch类来加载数据集。</p>
<p>定义数据集子类用于自动处理dataframe数据，返回{'image': image,
'keypoints': keypoints}类型的数据：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">FaceKeypointsDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''Face Keypoints Dataset'''</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dataframe<span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">'''
        Args:
            dataframe (DataFrame): data in pandas dataframe format.
            train (Boolean) : True for train data with keypoints, default is True
            transform (callable, optional): Optional transform to be applied on 
            sample
        '''</span>
        self<span class="token punctuation">.</span>dataframe <span class="token operator">=</span> dataframe
        self<span class="token punctuation">.</span>train <span class="token operator">=</span> train
        self<span class="token punctuation">.</span>transform <span class="token operator">=</span> transform

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>dataframe<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
        image <span class="token operator">=</span> np<span class="token punctuation">.</span>fromstring<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dataframe<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>idx<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> sep<span class="token operator">=</span><span class="token string">' '</span><span class="token punctuation">)</span>\
            <span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> IMG_SIZE<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>train<span class="token punctuation">:</span>
            keypoints <span class="token operator">=</span> self<span class="token punctuation">.</span>dataframe<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>idx<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            keypoints <span class="token operator">=</span> <span class="token boolean">None</span>
        sample <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'image'</span><span class="token punctuation">:</span> image<span class="token punctuation">,</span> <span class="token string">'keypoints'</span><span class="token punctuation">:</span> keypoints<span class="token punctuation">&#125;</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">:</span>
            sample <span class="token operator">=</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>sample<span class="token punctuation">)</span>
        <span class="token keyword">return</span> sample<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>将数据正则化，转化为tensor：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Normalize</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''Normalize input images'''</span>
    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sample<span class="token punctuation">)</span><span class="token punctuation">:</span>
        image<span class="token punctuation">,</span> keypoints <span class="token operator">=</span> sample<span class="token punctuation">[</span><span class="token string">'image'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> sample<span class="token punctuation">[</span><span class="token string">'keypoints'</span><span class="token punctuation">]</span>
        <span class="token keyword">return</span> <span class="token punctuation">&#123;</span><span class="token string">'image'</span><span class="token punctuation">:</span> image <span class="token operator">/</span> <span class="token number">255</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token comment"># scale to [0, 1]</span>
                <span class="token string">'keypoints'</span><span class="token punctuation">:</span> keypoints<span class="token punctuation">&#125;</span>
                
<span class="token keyword">class</span> <span class="token class-name">ToTensor</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''Convert ndarrays in sample to Tensors.'''</span>
    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sample<span class="token punctuation">)</span><span class="token punctuation">:</span>
        image<span class="token punctuation">,</span> keypoints <span class="token operator">=</span> sample<span class="token punctuation">[</span><span class="token string">'image'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> sample<span class="token punctuation">[</span><span class="token string">'keypoints'</span><span class="token punctuation">]</span>
        <span class="token comment"># swap color axis because</span>
        <span class="token comment"># numpy image: H x W x C</span>
        <span class="token comment"># torch image: C X H X W</span>
        image <span class="token operator">=</span> image<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> IMG_SIZE<span class="token punctuation">,</span> IMG_SIZE<span class="token punctuation">)</span>
        image <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
        <span class="token keyword">if</span> keypoints <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            keypoints <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>keypoints<span class="token punctuation">)</span>
            <span class="token keyword">return</span> <span class="token punctuation">&#123;</span><span class="token string">'image'</span><span class="token punctuation">:</span> image<span class="token punctuation">,</span> <span class="token string">'keypoints'</span><span class="token punctuation">:</span> keypoints<span class="token punctuation">&#125;</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> <span class="token punctuation">&#123;</span><span class="token string">'image'</span><span class="token punctuation">:</span> image<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>利用SubsetRandomSampler构建采样器，并使用Dataloader构建数据加载器：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>sampler <span class="token keyword">import</span> SubsetRandomSampler

<span class="token keyword">def</span> <span class="token function">prepare_train_valid_loaders</span><span class="token punctuation">(</span>trainset<span class="token punctuation">,</span>valid_size <span class="token operator">=</span> <span class="token number">0.2</span><span class="token punctuation">,</span>batch_size <span class="token operator">=</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token comment"># obtain training indices that will be used for validation</span>
    <span class="token comment"># 这里保障了训练集和测试集的随机划分</span>
    num_train <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>trainset<span class="token punctuation">)</span>
    indices <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>num_train<span class="token punctuation">)</span><span class="token punctuation">)</span>
    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>indices<span class="token punctuation">)</span>
    split <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>floot<span class="token punctuation">(</span>valid_size<span class="token operator">*</span>num_train<span class="token punctuation">)</span><span class="token punctuation">)</span>
    train_idx<span class="token punctuation">,</span> valid_idx <span class="token operator">=</span> indices<span class="token punctuation">[</span>split<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> indices<span class="token punctuation">[</span><span class="token punctuation">:</span>split<span class="token punctuation">]</span>

    <span class="token comment"># define samplers for obtaining training and validation batches</span>
    <span class="token comment"># 这里保障了一轮epoch中每次生成的batch是随机的，避免模型学习到数据的顺序特征</span>
    train_sampler <span class="token operator">=</span> SubsetRandomSampler<span class="token punctuation">(</span>train_idx<span class="token punctuation">)</span>
    valid_sampler <span class="token operator">=</span> SubsetRandomSampler<span class="token punctuation">(</span>valid_idx<span class="token punctuation">)</span>

    <span class="token comment"># prepare data loaders</span>
    train_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>trainset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>
                                               sampler<span class="token operator">=</span>train_sampler<span class="token punctuation">)</span>
    valid_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>trainset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>
                                               sampler<span class="token operator">=</span>valid_sampler<span class="token punctuation">)</span>

    <span class="token keyword">return</span> train_loader<span class="token punctuation">,</span> valid_loader<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>正式加载数据：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms

<span class="token comment"># how many samples per batch to load</span>
batch_size <span class="token operator">=</span> <span class="token number">128</span>
<span class="token comment"># percentage of training set to use as validation</span>
valid_size <span class="token operator">=</span> <span class="token number">0.2</span>

<span class="token comment"># Define a transform to normalize the data</span>
tsfm <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># Load the training data and test data</span>
trainset <span class="token operator">=</span> FaceKeypointsDataset<span class="token punctuation">(</span>train_data<span class="token punctuation">,</span> transform<span class="token operator">=</span>tsfm<span class="token punctuation">)</span>
testset <span class="token operator">=</span> FaceKeypointsDataset<span class="token punctuation">(</span>test_data<span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>tsfm<span class="token punctuation">)</span>

<span class="token comment"># prepare data loaders</span>
train_loader<span class="token punctuation">,</span> valid_loader <span class="token operator">=</span> prepare_train_valid_loaders<span class="token punctuation">(</span>trainset<span class="token punctuation">,</span>
                                                         valid_size<span class="token punctuation">,</span>
                                                         batch_size<span class="token punctuation">)</span>

test_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>testset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="三模型搭建">三、模型搭建</h2>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#Model</span>
<span class="token keyword">class</span> <span class="token class-name">CNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>outputs <span class="token operator">=</span> <span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>CNN<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token operator">*</span><span class="token number">12</span><span class="token operator">*</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> outputs<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.3</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv3<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token operator">*</span><span class="token number">12</span><span class="token operator">*</span><span class="token number">12</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="四训练与测试">四、训练与测试</h2>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#Train &amp; Validate</span>
device <span class="token operator">=</span>  torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> CNN<span class="token punctuation">(</span>outputs <span class="token operator">=</span> <span class="token number">30</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.003</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span>valid_loader<span class="token punctuation">,</span>model<span class="token punctuation">,</span>criterion<span class="token punctuation">,</span>optimizer<span class="token punctuation">,</span>n_epochs <span class="token operator">=</span> <span class="token number">50</span><span class="token punctuation">,</span>saved_model <span class="token operator">=</span> <span class="token string">'cv_model.pt'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    valid_loss_min <span class="token operator">=</span> np<span class="token punctuation">.</span>Inf
    train_losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    valid_losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>

        train_loss <span class="token operator">=</span> <span class="token number">0.0</span>
        valid_loss <span class="token operator">=</span> <span class="token number">0.0</span>

        <span class="token comment">#training</span>
        model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> batch <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>
            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

            output <span class="token operator">=</span> model<span class="token punctuation">(</span>batch<span class="token punctuation">[</span><span class="token string">'image'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
            loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span>batch<span class="token punctuation">[</span><span class="token string">'keypoints'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

            train_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">*</span>batch<span class="token punctuation">[</span><span class="token string">'image'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        
        <span class="token comment">#validating</span>
        model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> batch <span class="token keyword">in</span> valid_loader<span class="token punctuation">:</span>
            output <span class="token operator">=</span> model<span class="token punctuation">(</span>batch<span class="token punctuation">[</span><span class="token string">'image'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
            loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> batch<span class="token punctuation">[</span><span class="token string">'keypoints'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
            valid_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">*</span>batch<span class="token punctuation">[</span><span class="token string">'image'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

        train_loss <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>train_loss<span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">.</span>sampler<span class="token punctuation">.</span>indices<span class="token punctuation">)</span><span class="token punctuation">)</span>
        valid_loss <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>valid_loss<span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>valid_loader<span class="token punctuation">.</span>sampler<span class="token punctuation">.</span>indices<span class="token punctuation">)</span><span class="token punctuation">)</span>

        train_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_loss<span class="token punctuation">)</span>
        valid_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>valid_loss<span class="token punctuation">)</span>

        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Epoch: &#123;&#125; \tTraining Loss: &#123;:.6f&#125; \tValidation Loss: &#123;:.6f&#125;'</span>
              <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> train_loss<span class="token punctuation">,</span> valid_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># save model if validation loss has decreased</span>
        <span class="token keyword">if</span> valid_loss <span class="token operator">&lt;=</span> valid_loss_min<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Validation loss decreased (&#123;:.6f&#125; --> &#123;:.6f&#125;).  Saving model ...'</span>
                  <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>valid_loss_min<span class="token punctuation">,</span> valid_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>
            torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> saved_model<span class="token punctuation">)</span>
            valid_loss_min <span class="token operator">=</span> valid_loss

    <span class="token keyword">return</span> train_losses<span class="token punctuation">,</span> valid_losses<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>定义测试函数：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">,</span> model<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''
    Predict keypoints
    Args:
        data_loader (DataLoader): DataLoader for Dataset
        model (nn.Module): trained model for prediction.
    Return:
        predictions (array-like): keypoints in float (no. of images x keypoints).
    '''</span>

    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># prep model for evaluation</span>

    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># forward pass: compute predicted outputs by passing inputs to the model</span>
            output <span class="token operator">=</span> model<span class="token punctuation">(</span>batch<span class="token punctuation">[</span><span class="token string">'image'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> i <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                predictions <span class="token operator">=</span> output
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                predictions <span class="token operator">=</span> np<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span><span class="token punctuation">(</span>predictions<span class="token punctuation">,</span> output<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> predictions<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>定义测试结果展示函数：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">view_pred_df</span><span class="token punctuation">(</span>columns<span class="token punctuation">,</span> test_df<span class="token punctuation">,</span> predictions<span class="token punctuation">,</span> image_ids<span class="token operator">=</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''
    Display predicted keypoints
    Args:
        columns (array-like): column names
        test_df (DataFrame): dataframe with ImageId and Image columns
        predictions (array-like): keypoints in float (no. of images x keypoints)
        image_id (array-like): list or range of ImageIds begin at 1
    '''</span>
    pred_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>predictions<span class="token punctuation">,</span> columns<span class="token operator">=</span>columns<span class="token punctuation">)</span>
    pred_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>pred_df<span class="token punctuation">,</span> test_df<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    pred_df <span class="token operator">=</span> pred_df<span class="token punctuation">.</span>set_index<span class="token punctuation">(</span><span class="token string">'ImageId'</span><span class="token punctuation">)</span>
    show_images<span class="token punctuation">(</span>pred_df<span class="token punctuation">,</span> image_ids<span class="token punctuation">)</span>  <span class="token comment"># ImageId as index begin at 1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>定义测试结果上交文件生成函数：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">create_submission</span><span class="token punctuation">(</span>predictions<span class="token punctuation">,</span> pred_file<span class="token operator">=</span><span class="token string">'data/preds.csv'</span><span class="token punctuation">,</span> sub_file<span class="token operator">=</span><span class="token string">'data/submission.csv'</span><span class="token punctuation">,</span> columns<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''
    Create csv file for submission from predictions
    Args:
        predictions (array-like): prediction (no. fo images x 30 keypoints)
        pred_file (string): file path for prediction csv file
        sub_file (string): file path for submission csv file
        columns (dict): provided column names for submission file
    '''</span>
    lookup <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'data/IdLookupTable.csv'</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> columns <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        columns <span class="token operator">=</span> train_data<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
    preds <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>predictions<span class="token punctuation">,</span>
                         index<span class="token operator">=</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>predictions<span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                         columns<span class="token operator">=</span>columns<span class="token punctuation">)</span>
    preds<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>pred_file<span class="token punctuation">)</span>
    locations <span class="token operator">=</span> <span class="token punctuation">[</span>preds<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>image_id<span class="token punctuation">,</span> feature_name<span class="token punctuation">]</span>
                 <span class="token keyword">for</span> image_id<span class="token punctuation">,</span> feature_name
                 <span class="token keyword">in</span> lookup<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'ImageId'</span><span class="token punctuation">,</span> <span class="token string">'FeatureName'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">]</span>
    locations <span class="token operator">=</span> <span class="token punctuation">[</span>location <span class="token keyword">if</span> location <span class="token operator">&lt;</span>
                 IMG_SIZE <span class="token keyword">else</span> IMG_SIZE <span class="token keyword">for</span> location <span class="token keyword">in</span> locations<span class="token punctuation">]</span>
    lookup<span class="token punctuation">.</span>Location <span class="token operator">=</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span>locations<span class="token punctuation">)</span>
    lookup<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'RowId'</span><span class="token punctuation">,</span> <span class="token string">'Location'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>sub_file<span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>训练 and 预测：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#Train &amp; Validate</span>
train<span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span> valid_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span>  optimizer<span class="token punctuation">,</span> n_epochs<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> saved_model<span class="token operator">=</span><span class="token string">'aug_cnn.pt'</span><span class="token punctuation">)</span>

<span class="token comment">#Predict</span>
model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'aug_cnn.pt'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
predictions <span class="token operator">=</span> predict<span class="token punctuation">(</span>test_loader<span class="token punctuation">,</span>model<span class="token punctuation">)</span>
create_submission<span class="token punctuation">(</span>predictions<span class="token punctuation">,</span>
                  pred_file<span class="token operator">=</span><span class="token string">'data/aug_cnn_preds.csv'</span><span class="token punctuation">,</span>
                  sub_file<span class="token operator">=</span><span class="token string">'data/aug_cnn_submission.csv'</span><span class="token punctuation">)</span>
columns <span class="token operator">=</span> train_data<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token string">'Image'</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>columns
view_pred_df<span class="token punctuation">(</span>columns<span class="token punctuation">,</span> test_data<span class="token punctuation">,</span> predictions<span class="token punctuation">,</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>预测结果：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221113170335.png" /></p>
<p>将submission文件上交到Kaggle评分:</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221113170259.png" /></p>
]]></content>
      <categories>
        <category>Kaggle</category>
      </categories>
      <tags>
        <tag>CV</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>IFAttn-Binary code similarity analysis based on interpretable features with attention</title>
    <url>/2022/10/02/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91IFAttn%20Binary%20code%20similarity%20analysis%20based%20on%20interpretable%20features%20with%20attention/</url>
    <content><![CDATA[<h1
id="论文阅读ifattn-binary-code-similarity-analysis-based-on-interpretable-features-with-attention">【论文阅读】IFAttn-Binary
code similarity analysis based on interpretable features with
attention</h1>
<blockquote>
<p>时间：2021</p>
<p>作者：Shuai Jianga , Cai Fua , Yekui Qian（华科）</p>
<p>期刊：Computers &amp; Security（中科院三区）</p>
</blockquote>
<h2 id="abstract">1.ABSTRACT</h2>
<p>二进制代码相似性分析（Binary code similarity analysis
，BCSA）是一项有意义的软件安全分析技术，包括漏洞挖掘、代码克隆检测和恶意代码检测。</p>
<p>尽管近年来出现了很多基于神经网络的很多BCSA研究成果，仍有一些问题未被解决。首先，大多数方法更聚焦于function
pair similarity detection task (FPSDT)，而忽略了function search task
(FST)，后者对漏洞挖掘更为重要。还有，现有方法为了提高FPSDT的准确率使用了一些无法解释的神经网络；最后，大多数现有方法无法抵抗BCSA中的交叉优化和交叉混淆。</p>
<p>为了解决这些问题，我们首次提出了一个结合了可解释特征工程和可学习注意力机制的适应性BCSA架构。我们设计了一个具有适应性的、富有可解释性特征的模型。测试结果表明对于FPSDT和FST的效果比state-of-the-art效果更好。</p>
<p>另外，我们还发现注意机制在功能语义表达方面具有突出的优势。</p>
<p>评估表明我们的方法可以显著提升FST在cross-architecture,
cross-optimization, cross-obfuscation and cross-compiler
binaries上的表现。</p>
<span id="more"></span>
<p>为了提高开发效率，开发者通常会使用开源代码来开发新软件。如果一个开发者使用了一个存在漏洞的函数，则这个漏洞就会被继承且很难被发现。代码克隆这种现象对软件的安全可靠性造成了很大影响。</p>
<p>不幸的是，直接对二进制代码使用同源性分析并不够直接明了，二进制代码缺乏语义抽象，很难从函数中提取语义信息来做同源性分析。另外，分割函数的边界也是个问题。</p>
<p>所以在代码克隆、恶意样本追踪、库函数发掘和漏洞发掘领域对二进制代码做同源性分析一直是个重要的方向。</p>
<p>根据已有方法的颗粒度分类，现存成果可以分为：</p>
<ol type="1">
<li>基于基本静态特征的方法；</li>
<li>基于代码图结构（例如CFG）的方法；</li>
<li>基于代码张量的方法；</li>
<li>基于深度学习生成函数嵌入的方法；</li>
</ol>
<p><strong>现有方法存在的问题：</strong></p>
<ol type="1">
<li><p>大多数方法更聚焦于function pair similarity detection task
(FPSDT)，而忽略了function search task
(FST)，后者对漏洞挖掘更为重要；</p>
<p>FPSDT指对比两个函数的相似度，FST指在函数库中寻找与某个函数最相似的函数。</p></li>
<li><p>现有方法为了提高FPSDT的准确率使用了一些无法解释的神经网络，设计一个复杂的分析过程；</p></li>
<li><p>因为编译器的优化和混淆会显著修改代码结构，大多数方法在这些条件下表现不佳。</p></li>
</ol>
<p><strong>我们的方法解决的：</strong></p>
<ol type="1">
<li><p>如何利用可解释的基本特征来生成二进制代码的语义特征；</p>
<p>用注意力机制来聚焦于在不同编译环境下仍起作用的特征，学习基本特征之间的联系。</p></li>
<li><p>如何设计一个适应不同编译选项的通用BCSA模型框架。</p>
<p>我们重新设计了Transformer的编码部分，使用孪生神经网络来判断两个函数的相似度，在attention
layer使用KFM来处理不动的编译选项。</p></li>
</ol>
<p><strong>注意力机制的优点：</strong></p>
<p>下图是同一个函数在同一个编译选项（X86_32_00）下通过混淆技术BCF前后的CFG图：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221003195749.png" /></p>
<p>下图是TIKNIB和IFAttn两个模型在对同一个函数混淆前后抓取的特征向量值：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221003195945.png" /></p>
<p><strong>可以看到，在混淆前后basic features有明显不同，而semantic
features则总体上更为稳定。</strong></p>
<p>​
下图表明了TIKNIB和IFAttn在对不同函数，一个混淆一个不混淆的前提下提取到的特征向量值：</p>
<p>​ <img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221003200537.png" /></p>
<p><strong>可以看到，与之前相反，在混淆前后basic
features较为稳定，而semantic features变化更大。</strong></p>
<p>​ semantic features更能体现函数本身语义，而不受混淆技术的影响。</p>
<p><strong>一些定义：</strong></p>
<ul>
<li><strong>Presemantic
features：</strong>直接或间接从代码语法和结构分析出的特征；</li>
</ul>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221003204439.png" /></p>
<ul>
<li><strong>Semantic features：</strong>本文通过注意机制分析了base
feature形成的内在关联，并将base feature融合生成语义嵌入</li>
<li><strong>KFM scaled dot-product
attention:</strong><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221003205006.png" style="zoom: 67%;" /></li>
<li><strong>Multi-head
attention:</strong>Transformer的一种注意力机制。</li>
</ul>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221003205126.png" /></p>
<p><strong>系统结构：</strong>IFAttn (Interpretable Features with
Attention)</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221003205326.png" /></p>
<p><strong>测试结果：</strong></p>
<p>数据集：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221003205708.png" /></p>
<p>测试结果：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221003205759.png" /></p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Malware Classifiers</tag>
        <tag>BCSA</tag>
      </tags>
  </entry>
  <entry>
    <title>Function-level obfuscation detection method based on Graph Convolutional Networks</title>
    <url>/2022/10/01/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Function-level%20obfuscation%20detection%20method%20based%20on%20Graph%20Convolutional%20Networks/</url>
    <content><![CDATA[<h1
id="论文阅读function-level-obfuscation-detection-method-based-on-graph-convolutional-networks">【论文阅读】Function-level
obfuscation detection method based on Graph Convolutional Networks</h1>
<blockquote>
<p>时间：2021</p>
<p>作者：Shuai Jiang , Yao Hong, Cai Fu（华科）</p>
<p>期刊：Journal of Information Security and
Applications（中科院三区）</p>
</blockquote>
<h2 id="abstract">1.ABSTRACT</h2>
<p>​
在恶意样本检测中<strong>代码混淆检测技术</strong>是一个重要的辅助手段，对于安全从业者来说，其可以在人工逆向分析前来实施自动化混淆检测，这有助于逆向工程师更具体地进行逆向分析。</p>
<p>​
目前存在的混淆检测方法主要作用于Android应用，并基于传统的机器学习方法。其检测颗粒度很差，总体效果不佳。为了解决这些问题，<u>在本篇文章，我们提出了一个应用于X86汇编和Android应用的、function
level的、基于GCN的混淆检测方法。</u></p>
<pre><code>1. 首先，我们的方法是function-level的。我们提取每个函数的CFG作为其特征（包括邻接矩阵和基本代码块的特征矩阵）；
2. 我们构建一个GCN-LSTM神经网络作为混淆检测模型；
3. 最后，对于function-level的检测我们的方法准确率是94.7575%（X86汇编）和98.9457%（安卓应用），比baseline方法好。实验证明我们的方法不论是在function-levle还是APK-level上的检测准确率都好于baseline。</code></pre>
<span id="more"></span>
<h2 id="introduction">2. INTRODUCTION</h2>
<h3 id="obfuscation代码混淆">2.1 Obfuscation–代码混淆</h3>
<p>​
代码保护技术，用于增加逆向难度，防止代码篡改，最开始用于版权保护，后被用于恶意代码的躲避检测。</p>
<p>​
由于动态检测恶意代码的高昂成本，主流的恶意样本检测技术仍在提取代码的静态特征。然而由于混淆技术的发展，恶意样本的编写者经常在保留其恶意功能的同时通过使用混淆技术来修改其静态特征。经过混淆的恶意代码可以规避相关工具的检测。</p>
<p>​ 最近混淆检测技术开始出现，在此领域有一些工作：</p>
<pre><code>1. [2018]Alessandro等人：使用静态分析和机器学习分类算法来分析Android应用是否被混淆的技术（ http://dx.doi.org/10.1145/3230833.3232823）；
2. [2020]Crincoli等人：利用weak bisimulation来检测代码是否被code reordering(http://dx.doi.org/10.1007/978-3-030-44041-1_116)；
3. [2020]Caijun Sun等人：一个Android打包检测框架DroidPDF( http://dx.doi.org/10.1109/ACCESS.2020.3010588);
4. [2019]Omid等人：AndrODet，一个检测三种Android混淆技术的检测机制（重命名、字符串加密和控制流混淆）（ http://dx.doi.org/10.1016/j.future.2018.07.066）；
5. [2019]Alireza等人：Android字符串混淆检测技术（ http://dx.doi.org/10.1145/3338501.3357373）;</code></pre>
<h3 id="目前方法的缺点">2.2 <strong>目前方法的缺点</strong>：</h3>
<pre><code>1. 检测颗粒度不够，检测对象往往是一个APK包，缺乏可行性；
2. 检测效果不佳，从样本中提取的特征相对简单，只有统计学特征和opcode语句被提取。大多数使用简单的机器学习方法，表现一般；
3. 缺乏可用性和适应性，传统方法往往会为不同的混淆方法提取不同的特征，或者为每个混淆方法训练一个二分类器，枯燥且不便。同时若需要添加新数据，模型经常需要重头训练。</code></pre>
<h3 id="我们的方法">2.3 我们的方法：</h3>
<ol type="1">
<li>从开源平台获取一些未经混淆的代码（X86汇编和Android），通过混淆器生成混淆后程序；</li>
<li>逆向这些程序，用邻接矩阵和基本代码块特征矩阵的形式提取每个函数的CFG；</li>
<li>根据我们提取到的特征，构建GCN-LSTM。这个模型同时服务于X86汇编和Android，但他们分别训练和测试；</li>
</ol>
<h2 id="method-overview">3. METHOD OVERVIEW</h2>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221001213243.png" /></p>
<pre><code>1. X86的混淆器：OLLVM；Android的混淆器：Obfuscapk；
2. 逆向工具：IDA PRO；由于X86与Android指令集与混淆技术不同，二者被分别提取CFG；
3. 多分类问题，检测出混淆技术种类，故使用传统多分类评估方法来评估检测效果。</code></pre>
<h2 id="obfuscation-dection-method">4. OBFUSCATION DECTION METHOD</h2>
<h3 id="ollvm">4.1 OLLVM</h3>
<p>​ OLLVM包括以下三种混淆技术：</p>
<ol type="1">
<li><strong>Instructions Substitution
(SUB)，指令替换</strong>。将简单指令替换为同语义的复杂指令，特别是二进制加减乘除。这项技术会增加算术指令但很少影响CFG；</li>
<li><strong>Bogus Control Flow
(BCF)，虚假控制流</strong>。在CFG中添加大量无关的随机代码块和分支，并分割、融合、重排原始代码块，在其中插入随机选择的无用指令。这项技术破坏了CFG和代码块的完整性，增加控制流复杂性；</li>
<li><strong>Control Flow
Flattening（FLA）</strong>，<strong>控制流平坦化</strong>。简单来讲就是将代码块之间的关系打断，由一个分发器来控制代码块的跳转：</li>
</ol>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221002134210.png" /></p>
<h3 id="obfuscapk">4.2 Obfuscapk</h3>
<p>​ Obfuscapk包括以下三种混淆技术：</p>
<ol type="1">
<li>Identifier Renaming，标识符重命名；</li>
<li>String
Encryption，字符串加密。字符串常量可以揭示很多代码敏感信息；</li>
<li>Control Flow
Obfuscation，控制流混淆。通过扩展或平坦化CFG来混淆，同样还有注入垃圾代码，扩展循环，添加无关操作等；</li>
</ol>
<h3 id="feature-extraction">4.3 Feature extraction</h3>
<p>​ 提取的特征包括代码的结构化CFG信息和基本代码块特征：</p>
<ul>
<li>对于邻接矩阵：</li>
</ul>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221002135214.png" />
如图，邻接矩阵代码了不同代码块之间的转移关系。</p>
<ul>
<li><p>​ 对于基本代码块特征：</p>
<p>将X86汇编代码分为27类，对于一个代码块的特征向量就是27维。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221002140822.png" style="zoom:80%;" /></p>
<p>将Dalvik指令分为15类，对于一个代码块的特征向量就是15维。</p></li>
</ul>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221002142628.png" alt="image-20221002140952651" style="zoom:80%;" /></p>
<h3 id="obfuscation-detection-model">4.4 Obfuscation detection
model</h3>
<p>​ 在得到CFG邻接矩阵和基本代码块特征矩阵后，构建GCN-LSTM。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221002141244.png" alt="image-20221002141239002" style="zoom:80%;" /></p>
<h2 id="experimental-evaluation">5.EXPERIMENTAL EVALUATION</h2>
<h3 id="datasets">5.1 Datasets</h3>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221002141504.png" style="zoom:80%;" /></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221002141517.png" style="zoom:80%;" /></p>
<h3 id="baseline-methods">5.2 Baseline methods</h3>
<p>​ function-level的baseline方法如下：</p>
<p>​ AdaBoost, GaussianNaiveBayes, GradientBoosting, KNeighbors, MLP,
SGDClass, SVM, Xgboost and LSTM</p>
<h3 id="evaluation-metrics">5.3 Evaluation metrics</h3>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221002142217.png" /></p>
<p>​ <img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20221002142325.png" /></p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Malware Classifiers</tag>
        <tag>obfuscation</tag>
      </tags>
  </entry>
  <entry>
    <title>Planning at Decision Time(决策时规划)</title>
    <url>/2022/07/21/%E5%86%B3%E7%AD%96%E6%97%B6%E8%A7%84%E5%88%92/</url>
    <content><![CDATA[<blockquote>
<p><strong>参考资料：</strong></p>
<ul>
<li>Reinforcement Learining. Second Edition. Sutton.Page 180-193</li>
<li>白板推导--强化学习.shuhuai008.Bilibili</li>
<li>Easy RL.Qi Wang.Yang Yiyuan.Ji Jiang</li>
</ul>
</blockquote>
<h1 id="planning-at-decision-time决策时规划">Planning at Decision
Time（决策时规划）</h1>
<p><strong>规划（Planning）至少有两种使用方式。</strong></p>
<p>①<strong>一种</strong>在DP和Dyna中已经讨论过，通过从一个model（不论是sample
model或是distribution model ）中获取模拟经验（simulated
experience）的基础上来使用规划来逐渐提升一个policy或一个value
function。</p>
<p>然后，选择动作是一个比较当前状态的动作value问题，该value是在之前优化的表格中获取的；或者通过使用书中Part
2中考虑的近似方法来评估数学表达式。</p>
<p>对于任意状态S<sub>t</sub>，在为其选择一个动作之前，其整个表格条目（例如Dyna-Q中的Q表）已经通过规划来优化过了。使用这种方式，规划并不是仅仅聚焦于当前的状态，我们称这种规划为<strong><em>background
planning</em></strong>，后台规划。</p>
<p>②<strong>另一种</strong>使用规划的方法就是在遇到每个新的状态S<sub>t</sub>后再开始一个完整的规划过程，其为每个当前状态选择一个动作A<sub>t</sub>，到下一个状态S<sub>t+1</sub>就选择一个动作A<sub>t+1</sub>，以此类推。</p>
<p>一个使用这种规划最简单的例子：当state
values可用时，通过比较当前model对执行每个动作后到达的新状态的value来选择一个动作。</p>
<p>当然，更普遍的说，这种规划的用法可以比仅仅往后看一步（上面的例子就是）看得更深，评估动作的选择导致许多不同预测状态和奖励轨迹。</p>
<p>不同于第一种用法，在这里，规划聚焦于一个特定的状态，我们称之为<strong><em>decision-time
planning</em></strong>，决策时规划。</p>
<p>这两种规划的方式可以用一种自然而有趣的方式结合在一起，不过一般二者被分开研究。</p>
<p>如同background
planning，我们仍可以将决策时规划看作一个从模拟经验中更新values，最后到更新policy的过程。只是基于当前状态所生成的values和policy会在做完动作选择决策后被丢弃，在很多应用场景中这么做并不算一个很大的损失，因为有非常多的状态存在，且不太可能在短时间内回到同一个状态，故重复计算导致的资源浪费会很少。</p>
<p>一般来说，人们可能希望将两者结合起来：规划当前状态，并将规划的结果存储起来，以便在以后回到相同的状态时能走得更远。</p>
<p><strong>Decision-time
Planning，(决策时规划）在不需要快速反应的应用场景中作用最为显著。</strong></p>
<p>决策时规划的常用算法有Heuristic Search（启发式搜索）、Rollout
Algorithms（Rollout 算法）和Monte Carlo Tree Search（MCTS
蒙特卡洛树搜索）三种。</p>
<span id="more"></span>
<h2 id="heuristic-search启发式搜索"><em>Heuristic
Search（启发式搜索）</em></h2>
<p>在AI中一个经典的状态空间规划方法是decision-time
planning方法，统称为<strong>Heuristic
Search（启发式搜索）</strong>。</p>
<p>在启发式搜索中，对每个遇到的状态都会生成一颗延续的搜索树，近似的value
function会被在叶节点应用，然后反向传播到根节点。反向传播在当前状态停止。一旦这些节点的值被计算出来，就会选择其中最好的一个作为当前的行动，然后所有的值就会被丢弃。</p>
<p>在传统的启发式搜索中，计算出的backed-up
values并不会被通过修改近似value
function来保存。实际上，价值函数一般都是由人设计的，绝不会因为搜索而改变。然而，一个自然而然的想法就是考虑改进value
function，使用启发式搜索计算出的backed-up
value或者其他方法。从某种意义上说，我们一直都采取这种方法。</p>
<p>Greedy，ε-greedy和UCB动作选择方法与启发式搜索没什么不同，尽管是在一个更小的范围内。举个例子，为了计算greedy策略的state-value
function，我们必须向前概览每个可能的动作，到达每个可能的下一个状态，考虑他们的reward和评估值，然后选择一个最好的动作。这就如同传统的启发式搜索，计算所有可能动作的backed-up
values，但是不去保存他们。<strong>因此，启发式搜索可以被看作greedy策略在单步范围外的一种扩展。</strong></p>
<p>搜索的更深是为了获得更好的动作选择策略。假设我们有一个完美的model和一个不完美的action-value
function，如果一路搜索到底，那么不完美的value
function的影响就会被消除。通过这种方式的搜索必须是optimal的。若搜索步骤k足够多，导致
γ<sup>k</sup>
足够小，那么动作就会近似达到optimal。从另一个角度讲，搜索的越深所需的算力资源也越多，响应就越慢。</p>
<p><strong>一个优秀的例子是是Tesauro提出的大师级双陆棋算法，TD-Gammon。</strong>该算法使用TD
learning，通过与自己对弈来学习value
function，其使用启发式搜索来选择动作。Tesauro发现启发式搜索的越深，TD-Gammon就会选择越好的动作，但是每走一步花的时间也越多。</p>
<p>在更深入的搜索中观察到的性能改善并不是由于使用多步骤更新本身。相反，它是由于更新的重点集中在当前状态的下游的状态和行动上。通过投入大量与候选行动具体相关的计算，决策时规划可以产生比依靠无重点的更新所产生的更好的决策。</p>
<figure>
<img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20220722110302.png"
alt="启发式搜索示意图" />
<figcaption aria-hidden="true">启发式搜索示意图</figcaption>
</figure>
<p>如上图所示，白圆点表示状态，黑圆点表示动作。以当前状态为根节点，遍历每一层所有的可能性，然后计算每个非叶节点的Q（s,a）。具体计算方法如下，将树按深度优先遍历，每个非叶节点使用公式：
<span class="math display">\[
Q(s,a) = \sum_{s&#39;,r}{p(s&#39;,r|s,a)(r +
γmax_{a&#39;}Q(s&#39;,a&#39;))}
\]</span>
故按照图中的数字顺序（1-&gt;2-&gt;3-&gt;4-&gt;5……）依次计算**<u>q~*~的期望更新</u>**，得到当前状态（根节点）每个可能动作a'的对应的Q（s，a'），选择一个最好的即可。当然，在使用算法的过程中搜索层数K是可以控制的，故叶节点并不一定是终结状态S<sub>T</sub>。</p>
<h2 id="rollout-algorithmsrollout-算法"><em>Rollout Algorithms（Rollout
算法）</em></h2>
<p>Rollout算法是基于蒙特卡洛控制的决策时规划算法，其应用于从当前状态开始的一些模拟轨迹。对给定的policy进行动作评估的方式是将许多从各个可能的动作开始的模拟轨迹的返回值平均化。当action-value评估被认为足够准确了，被给分最高的动作就会被执行，之后，该过程（Rollout）将从产生的下一个状态重新进行。</p>
<p>不同于蒙特卡洛控制算法，Rollout算法的目标不是评估一个最优的q*或qπ，而是根据一个给定的一般叫rollout
policy的策略，来为每个当前状态生成蒙特卡洛评估。作为一个决策时规划算法，Rollout算法在当即使用这些action-value评估值之后就丢弃他们。这使得Rollout算法的实现相对较为简单，因为不都需要对每个&lt;s
,
a&gt;键值对都采样，并且不需要对状态空间或状态-动作空间拟合一个近似函数。</p>
<p>Rollout算法什么时候停止？策略改进定理告诉我们给定两个几乎相同的策略π和π'，他们不同是对同一个状态S有:
<span class="math display">\[
π&#39;(s) = a ≠ π(s)
\]</span> 如果： <span class="math display">\[
q_{π}(s,a)\geq v_{π}(s)
\]</span> 那么策略π'就优于或等于策略π。</p>
<p>在Rollout算法中，对状态s的每个可能的动作a'都计算其若干条模拟轨迹的平均返回值，得到<span
class="math inline">\(q_π(s,a&#39;)\)</span>。接着选取评估值最大的那个action，随后的状态都继续遵循策略π，这就是一个很好的在π上的策略改进。</p>
<p>换句话说，Rollout算法的目标就是在rollout
policy上不断做改进，而不是去寻找一个最优策略。经验表明Rollout算法的效果非常惊艳。例如Tesauro和Galperin（1997）就表明rollout算法对于双陆西洋棋的提升效果非常显著。在一些应用中，即使rollout
policy是完全随机的Rollout算法也可以有好的表现。但是policy的改进依靠rollout
policy的性能和MC值评估得出的action排名。直觉表明，rollout
policy越好、评估值越准确，Rollout算法给出的策略就越好。</p>
<p>这其中包含了重要的权衡，因为一般来说越好的rollout
policy意味着需要越多的时间来模拟足够的轨迹，以得到好的value评估效果。作为一个决策时评估方法，Rollout算法一般都会有严格的时间限制，其计算所需时间由待评估动作的数量、模拟轨迹中的步长、rollout
policy做决策的时间和模拟轨迹的数量共同决定。</p>
<p>虽然存在一些方法可以减轻这一难题，但在任何Rollout算法的应用中平衡这些因素都是很重要的。因为MC评估是相互独立的，故并行做这些评估是可能的。另外一种方法是可以缩减模拟轨迹的长度。</p>
<p>**简单来说，不同于启发式搜索往下遍历所有的可行性然后进行q*期望更新，Rollout对每个可能的action进行若干条MC采样，以这些采样的平均值来评估这个aciton的好坏。**</p>
<p><strong>Rollout 的意思是从当前帧去生成很多局的游戏。</strong></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20220724094325.png" alt="可能的Rollout轨迹" style="zoom:80%;" /></p>
<h2 id="monte-carlo-tree-searchmcts-蒙特卡洛树搜索"><em>Monte Carlo Tree
Search（MCTS 蒙特卡洛树搜索）</em></h2>
<p>Monte Carlo Tree Search
(MCTS)，蒙特卡洛树搜索，是一个近年来非常成功的决策时规划算法。<strong>MCTS是一个rollout改进算法</strong>，其在Rollout的基础上增加了累计从MC模拟轨迹中获得value的方法，以便于模拟到有更高reward的轨迹。</p>
<p>MCTS是近年来AI围棋从一个入门者（2005）发展到一个宗师级棋手（2015）的重要原因，2016年AlphaGo程序战胜了世界围棋冠军选手。MCTS被证明在许多竞争领域有显著效果，包括一般的游戏，但不局限于此。若环境model足够简单，可以进快速多步模拟，它对单智能体序列决策问题就非常有效。</p>
<p><strong>MCTS的核心思想是从以往的模拟中，扩展初始部分已经获得高回报的轨迹，让算力聚焦于更可能获得高回报的模拟路线。</strong></p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20220724103456.png" alt="MCTS示意图" style="zoom:80%;" /></p>
<p>在任何MC评估方法中，&lt;s,a&gt;键值对的评估值就是多对模拟轨迹的平均返回值，在这里，<u>只保留最有可能在几步内达到的&lt;s,a&gt;对的MC估计值（算出来的q（s,a））</u>。我们称这些节点加上根节点组成一个tree，使用一个tree
policy遍历这个tree来选择一个用来扩展的叶子结点，<strong>构建一个tree帮助我们能选择一个更好的节点用来rollout而不是对每个节点都进行模拟</strong>。</p>
<p>总的来说，MCTS总共分为四步：Selection，Expansion，Simulation和Backup。</p>
<ul>
<li>Selection就是用tree
policy（例如ε-greedy）来选择一个叶节点，用于后续扩展；</li>
<li>Expansion就是使用选择好的节点，用一些<u>未使用过</u>的actions来扩展一个或几个孩子节点；</li>
<li>Simulation就是从选择的节点/扩展的节点上用rollout
policy进行模拟，同rollout算法；</li>
<li>Backup就是通过模拟得出的值来反向更新对应的action.</li>
</ul>
<p>在一个时间步骤内，MCTS反复做这四步，直到时间不够了或者其他计算资源不够了。然后，通过某种方法来为当前状态选择一个动作。例如，选择value最大的动作，或是，选择visit次数最多的动作来避免选到异常值。当到达下一个状态后，新一轮的MCTS又开始了。有时新一轮的MCTS从一个孤立的节点开始，但大多数情况下会从上一次MCTS中还留存的、有些后代的tree开始。</p>
<p>MCTS最初被提出用于为一些双人竞技游戏选择动作，例如围棋。每个模拟过程都是一个完整的游戏过程，双方选手通过tree和rollout
policy来选择动作。</p>
<h2 id="相关概念解释">相关概念解释：</h2>
<h4 id="distribution-model-and-sample-model">1. Distribution model and
Sample model</h4>
<p>参考《Reinforcement Learning》Page159，Chapter
8，原文解释的很清楚：</p>
<p><strong>“By a <em>model</em> of the environment we mean anything that
an agent can use to predict how the environment will respond to its
actions. Given a state and an action, a model produces a prediction of
the resultant next state and next reward. ”</strong></p>
<p>“我们所指的环境的model是一个agent可以用其预测环境会如何对其action作出反应的东西。给出一个state和一个action，model给出下一个state和返回的reward。”</p>
<p><strong>“If the model is stochastic, then there are several possible
next states and next rewards, each with some probability of occurring.
”</strong></p>
<p>“如果model是随机的，那么下一个state与reward就有许多可能的情况，每个情况都有一定概率发生。”</p>
<p><strong>“Some models produce a description of all possibilities and
their probabilities; these we call <em>distribution models</em>. Other
models produce just one of the possibilities, sampled according to the
probabilities; these we call <em>sample models</em>.”</strong></p>
<p>“一些models提供了一个对所有事件发生的可能性以及其概率的描述，这些models我们称其为<strong>distribution
models</strong>（分布模型）；另外一些models仅提供这些可能发生的事件的其中一种，这些models我们称其为<strong>sample
models</strong>（样本模型）”</p>
<p><strong>“ For example, consider modeling the sum of a dozen dice. A
distribution model would produce all possible sums and their
probabilities of occurring, whereas a sample model would produce an
individual sum drawn according to this probability
distribution.”</strong></p>
<p>“例如，考虑对一打骰子（dozen dice）的和进行建模，一个 distribution
model 会产生所有可能的和，以及它们发生的概率，而一个 sample model
会根据这个概率分布产生一个单独的和。”</p>
<p>例如，MDP中的<span
class="math inline">\(p(s^{&#39;},r|s,a)\)</span>就是一个典型的分布模型。在很多应用中，获取
sample models 比获取 distribution models 容易得多。dozen dice
就是这样一个例子。很容易写一个电脑程序仿真掷骰、返回和的过程，但是计算所有可能的和以及对应的概率很难，且容易出错。</p>
]]></content>
      <categories>
        <category>Something</category>
      </categories>
      <tags>
        <tag>RL</tag>
      </tags>
  </entry>
  <entry>
    <title>A Survey of Defense Mechanisms Against Distributed Denial of Service (DDoS) Flooding Attacks</title>
    <url>/2022/03/04/A%20Survey%20of%20Defense%20Mechanisms%20Against%20Distributed%20Denial%20of%20Service%20(DDoS)%20Flooding%20Attacks/</url>
    <content><![CDATA[<h1
id="a-survey-of-defense-mechanisms-against-distributed-denial-of-service-ddos-flooding-attacks">A
Survey of Defense Mechanisms Against Distributed Denial of Service
(DDoS) Flooding Attacks</h1>
<blockquote>
<p><strong>时间：2013</strong></p>
<p><strong>作者：Saman Taghavi Zargar，James Joshi， David
Tipper</strong></p>
<p><strong>期刊：IEEE COMMUNICATIONS SURVEYS &amp;
TUTORIALS（中科院一区）</strong></p>
</blockquote>
<h3 id="abstract">ABSTRACT</h3>
<p>​
DDoS攻击是安全专业人员最关心的问题之一，其通常是为了扰乱合法用户对服务的访问而进行的显式尝试。攻击者通常通过攻击漏洞来获取到一大批电脑，以此来组建一个网络攻击军队（也就是僵尸网络），一旦组建了攻击部队，攻击者就可以对一个或多个目标发起协调一致、大规模的攻击。开发针对已识别和预期的DDoS泛洪攻击的综合防御机制，是入侵检测和预防研究界所期望的目标。然而，这种机制的发展需要对问题和迄今为止在预防、检测和应对各种DDoS洪泛攻击方面所采用的技术有一个全面的了解。</p>
<p>​
在本文，我们对DDoS洪泛攻击进行分类，并根据它们在何时何地预防、检测和应对DDoS洪泛攻击对现有的对策进行分类。</p>
<p>​
此外，我们强调需要一种全面的分布式协同防御方法。我们的主要目的是激发研究人员开发出创造性的、有效的、高效的、综合的预防、检测和响应机制来解决实际攻击前、中和后的DDoS泛洪问题。</p>
<hr />
<span id="more"></span>
<h3 id="introduction">INTRODUCTION</h3>
<p>​
DDoS攻击，旨在尝试组织合法使用者访问一个特定的网站，早在20世纪80年代就被网络研究团体知晓。1999年夏天，Computer
Incident Advisory Capability
(<strong><em>CIAC</em></strong>)报告了第一起DDoS攻击事件。</p>
<p>​
目前，有两种主要的在互联网上制造DDoS攻击的方法：①第一种方法是攻击者向受害者发送一些格式错误的数据包，以混淆在其上运行的协议或应用程序(
<strong><em>vulnerability
attack</em></strong>);②另一种方法是最常见的方法，它涉及攻击者试图执行下列一项或两项：</p>
<pre><code>    1. 通过消耗带宽、路由器处理能力或网络资源，破坏合法用户的连通性；这些本质上是网络/传输级的泛洪   攻击；
    2. 通过耗尽服务器资源(如套接字、CPU、内存、磁盘/数据库带宽和I/O带宽 )来破坏合法用户的服务；这些攻击本质上包括应用级的泛洪攻击；</code></pre>
<p>​
如今，DDoS攻击往往是由远程控制、组织良好、分布广泛的Zombies1或Botnet计算机组成的网络发起的，这些计算机同时和不断地向目标系统发送大量的流量和/或服务请求，目标系统因此变得要么反应如此缓慢，以至于无法使用，要么完全崩溃。僵尸网络中的僵尸或计算机通常通过使用蠕虫、木马或后门来招募。此外，由于在攻击者控制下的僵尸使用伪造的IP地址，使得防御机制识别原始攻击者变得更加复杂。</p>
<p>​
从1999年的夏天开始，许许多多的DDoS攻击被制造出来用以对抗不同的组织。迄今为止，大多数的DDoS洪泛攻击都试图使受害者的服务不可用，从而收入损失，增加了减轻攻击和恢复服务的成本。</p>
<p>​
举个例子，2000年2月，雅虎经历了最早的一次重大DDoS泛洪攻击，使得该公司的服务在互联网上持续了约2小时，从而造成广告收入的显著损失；</p>
<p>​ 2002年10月，13个DNS服务器中的9个因为DDoS洪泛攻击关闭了一小时；</p>
<p>​ 2004年2月，由于遭受DDoS攻击，正常用户无法使用SCO
Group网站，这种攻击是通过使用以前感染Mydoom病毒的系统发起的。</p>
<p>​
2009年7月，Mydoom病毒被再次使用以发起DDoS攻击韩国和美国主要政府新闻媒体和经济网站；</p>
<p>​
2010年12月，一个自称为“Anonymous”的组织策划了针对一些组织诸如Mastercard.com,
PayPal, Visa.com 和 PostFinance的DDoS攻击；</p>
<p>​ 2012年9月，美国银行( <strong><em>Bank of America</em></strong>
)、花旗集团( <strong><em>Citigroup</em></strong> )、富国银行(
<strong><em>Wells Fargo</em></strong> )、美国银行(
<strong><em>Bancorp</em></strong> )、PNC、Capital One、Fifth Third
Bank、BB &amp; T、BB &amp; T、汇丰银行( <strong><em>HSBC</em></strong>
)等9家主要银行的网上银行成为国外黑客攻击集团" Izz ad-Din al-Qassam Cyber
Fighters
"发起的一系列强力DDoS泛洪攻击的目标。因此，几家网上银行网站在几分钟后恢复之前已经放缓或停业。</p>
<p>​
<u>最近DDoS防御机制的进步已经结束了“脚本小子”可以下载工具并对几乎任何网站发起攻击的时代。</u>（2013）在如今的DDoS攻击中，攻击者使用了更复杂的方法来发起攻击。尽管尽了一切努力减少DDoS攻击事件的数量，但它们在目标网络和计算机的频率和规模上迅速扩大。在VeriSign委托的最近一项调查中发现，在2008年7月至2009年7月期间，75
%的受访者经历过一次或多次攻击。此外，最近来自Arbor
Networks的一份报告也表明了类似的数据。在调查结果中，他们显示，69
%的受访者从2009年10月至2010年9月至少经历过一次DDoS攻击，25
%的受访者每月遭受10次此类攻击。ProlexicTechnology公司提供的防御DDoS攻击的服务显示，每天有7000个DDoS攻击被观测到，并且认为这个数量正在迅速增长。</p>
<p>​ DDoS攻击的规模也在不断增大，使得防御起来更加困难。Arbor
Network发现，2010年攻击规模已经增长了100
%左右，攻击首次突破了100Gbps的壁垒。因此，保护资源免受这些频繁而庞大的DDoS攻击，就需要研究界致力于开发一种能够在实际攻击之前、期间和之后对DDoS攻击做出适当反应的全面的DDoS防御机制。</p>
<p>​
<strong><u>本文重点研究有线网络系统中DDoS泛洪攻击和防御机制。</u></strong>【19】专注于描述无线自组织网络的DDos攻击；【20】专注于无线传感器网络特有的DDoS攻击的特点。</p>
<p>​
在这里，我们的目标是对现有的DDoS洪泛攻击进行分类，并提供根据它们在何处和何时检测和响应DDoS洪泛攻击而分类的防御机制的全面调查。对DDoS洪泛攻击的研究和所做的调查对于了解与这一重要网络安全问题有关的关键问题，从而对建立更全面有效的防御机制具有重要意义。</p>
<p>​</p>
<hr />
<h3 id="ddos-attackers-incentives">DDOS: ATTACKERS’ INCENTIVES</h3>
<p>​ DDoS攻击者的动机有以下几类：</p>
<p>​ <strong>1.
获取经济收入：</strong>这些攻击是企业关注的重大问题，由于其激励的性质，这一类的攻击者通常是技术含量最高、经验丰富的攻击者。为获取经济利益而发动的攻击往往是最危险、最难以阻止的攻击。</p>
<p>​ <strong>2.
复仇者：</strong>这一类的攻击者一般都是沮丧的个体，可能具有较低的技术技能，他们通常将攻击作为对遭受到的不公正的待遇的报复。</p>
<p>​ <strong>3.
受思想信念驱动：</strong>属于这一类的攻击者是出于其思想信念的动机来攻击目标的。该类别目前是攻击者发起DDoS攻击的主要诱因之一。</p>
<p>​ <strong>4.
智力挑战者：</strong>这类攻击者攻击目标系统，以实验和学习如何发起各种攻击。他们通常都是年轻的黑客爱好者，想要炫耀自己的能力。如今，存在着各种易于使用的攻击工具和僵尸网络来租用，即便是一个计算机业馀者也可以利用其发起起成功的DDoS攻击。</p>
<p>​ <strong>5.
网络战争：</strong>这一类的袭击者通常属于一国的军事或恐怖组织，他们有政治动机攻击另一国广泛的关键部门</p>
<p>​
有一些文章专注于分析攻击者的动机以及如何利用这些攻击动机建模，以此使决策模型可以组织并对这些攻击进行反馈。</p>
<hr />
<h3 id="ddos-attack-scope-and-classification">DDOS ATTACK: SCOPE AND
CLASSIFICATION</h3>
<p>​
DDoS攻击的分布式特性使得它们极难对抗或追踪，而且攻击者通常使用假IP以此来隐藏他们的真实身份，这使得对于DDoS攻击的追踪回溯更加困难。此外，许多因特网主机中存在入侵者可以利用的安全漏洞，针对应用层的攻击事件正在迅速增加。</p>
<p>​
在这里，我们针对DDoS的协议等级对DDoS攻击进行分类，并且我们仅仅专注于最常见的DDoS洪泛攻击，漏洞攻击，攻击者利用某个服务的软件实现中的某些漏洞或实现bug将其带下来，并不是本文的重点。</p>
<p>​ 基于协议等级，DDoS攻击可以被分类为两类：</p>
<ol type="1">
<li><p><strong>Network/transport-level DDoS flflooding
attacks</strong>:</p>
<p>1.1 <strong><em>Flooding
attacks：</em></strong>攻击者通过消耗受害者网络带宽(如欺骗/非欺骗UDP
流、ICMP流、DNS流、VoIP流等)来破坏合法用户的连通性。</p>
<p>1.2 <strong><em>Protocol exploitation flooding
attacks</em></strong>:攻击者利用受害者某些协议的特定特性或实现漏洞，以消耗受害者的过量资源（例如，TCP
SYN流，TCP SYN-ACK流，ACK &amp; PUSH ACK 流，RST/FIN flood流等）。</p>
<p>1.3 <strong><em>Reflflection-based flflooding
attacks</em></strong>：攻击者通常向reflectors发送伪造请求( 例如 ,
ICMP请求
)而不是直接请求；因此，这些反射器向受害者发送答复并耗尽受害者的资源.</p>
<p>1.4 <strong><em>Amplifification-based flflooding
attacks</em></strong>：攻击者利用服务为接收到的每个消息生成大消息或多个消息来放大对受害者的流量。僵尸网络被不断地用于反射和放大两种目的。反射和放大技术通常是串联使用的，如Smurf攻击时，攻击者利用数据包的IP广播特性(
Amplification ) ，向大量的反射器发送带有伪造源IP地址的请求。</p>
<p>以上攻击的具体细节见【2】，【32】，【35】，【36】。</p></li>
<li><p><strong>Application-level DDoS flflooding attacks</strong>:</p>
<p><u>应用级别的DDoS攻击通过耗尽服务器资源(如套接字、CPU、内存、磁盘/数据库带宽和I/O带宽
)来破坏合法用户的服务，其通常消耗更少的宽带，更加隐蔽，其与良性流量非常相似。</u>但是，应用级别的DDoS攻击通常具有相同的影响力。</p>
<p>2.1 <strong><em>Reflflection/amplifification based flflooding
attacks</em></strong>：这种攻击利用了与1.4同样的技术，只不过发送的是应用层数据包。</p>
<p>举个例子，DNS amplification
攻击使用肉机生成一小股伪造IP的DNS请求，因为DNS响应的数量可能远远超过DNS请求的数量，其可以生成大量网络流量包直指目标系统，使其瘫痪。</p>
<p>再举一个，<strong><em>VOIP
flooding</em></strong>，攻击者通常通过SIP以非常高的包率和非常大的源IP范围发送被欺骗的VoIP数据包。受害者VoIP服务器必须区分正确的VoIP连接和消耗大量资源的伪造的VoIP连接。VoIP泛洪可以压倒具有随机或固定源IP地址的数据包的网络。如果源IP地址没有被改变，那么VoIP泛洪攻击就会模仿来自大型VoIP服务器的流量，并且由于类似于良好的流量，很难识别。</p>
<p>2.2 <strong><em>HTTP flooding attacks</em></strong>：</p>
<p>2.2.1 <u><em>Session flooding
attacks</em></u>，在这种类型的攻击中，攻击者的会话连接请求率高于合法用户的请求率，因此消耗了服务器的资源并导致DDoS攻击服务器。</p>
<p>​ 其中的典型就是<strong><u><em>HTTP get/post flooding
attack</em></u></strong>，其中攻击者向受害者Web服务器生成大量有效的HTTP请求(
get / post
)。攻击者通常使用僵尸网络来发起这些攻击。由于每个bot都可以产生大量的有效请求(通常每秒10个以上的请求)，所以不需要大量的bot发起成功的攻击。HTTP
get / post泛洪攻击属于非欺骗性攻击。</p>
<p>2.2.2 <u><em>Request flooding
attacks</em></u>，在这种类型的攻击中，攻击者发送的会话包含比通常更多的请求，并导致服务器遭受DDoS泛滥攻击。</p>
<p>​ 其中的典型就是 single-session HTTP get/post flflooding，该攻击是HTTP
get/post flflooding attack的一种变种，它利用HTTP
1.1的特性，允许单个HTTP会话中的多个请求。因此，攻击者可以限制HTTP攻击的会话速率，并绕过许多安全系统的会话速率限制防御机制。</p></li>
</ol>
<p>​ 2.2.3 <u><em>Asymmetric
attacks</em></u>，在这种攻击类型中，攻击者发送包含高工作负载请求的会话。这里，我们列举了这一类中的一些著名攻击：</p>
<ul>
<li><p>​ <strong><em>Multiple HTTP get/post
flflood</em></strong>，该攻击是HTTP get/post flflooding
attack的一种变种，在这里，攻击者通过形成一个嵌入多个请求的单个数据包，而不在单个HTTP会话中逐一发出多个HTTP请求，从而创建多个HTTP请求。</p>
<p>​
这样，攻击者仍然可以以较低的攻击包率在受害服务器上保持较高的负载，使得攻击者几乎看不到网络流量异常检测技术。此外，攻击者如果仔细选择HTTPVERB，就可以轻松绕过深度包检查技术。</p></li>
<li><p>​ <strong><em>Faulty
Application</em></strong>，在这种攻击中，攻击者利用设计不良或与数据库集成不当的网站进行攻击。例如，它们可以使用类似SQL的注入来生成请求来锁定数据库查询。这些攻击非常具体和有效，因为它们消耗服务器资源(
内存、 CPU等)。</p></li>
</ul>
<p>​ 2.2.4 <u><em>Slow request/response
attacks</em></u>，在这种攻击类型中，攻击者发送包含高负载请求的会话。</p>
<ul>
<li><p>​ <strong><em>Slowloris attack (a.k.a, slow headers
attack)</em></strong>，Slowloris（懒猴）是一种基于HTTP
get的攻击，可以使用有限数量的机器甚至单个机器来降低Web服务器。</p>
<p>​ 攻击者发送部分HTTP请求(
不是一个完整的request头部）这些请求持续快速地增长，缓慢地更新，永远不会关闭。攻击一直持续到所有可用的套接字被这些请求占用，Web服务器变得不可访问。<strong><u>攻击者的源地址通常不是伪造的。</u></strong></p></li>
<li><p>​ <strong><em>HTTP fragmentation
attack</em></strong>，与懒猴类似，这种攻击的目标是通过长时间保持HTTP连接而不引发任何警报来降低Web服务器。</p>
<p>​ 攻击者( bot )
与Web服务器建立有效的HTTP连接。然后，它们将合法的HTTP数据包分解成微小的片段，并按照服务器超时允许的速度发送每个片段。使用这种方法，通过在每个bot上打开多个会话，攻击者可以只使用少数肉机就悄悄地让一个Web服务器崩溃。</p></li>
<li><p>​ <strong><em>Slowpost
attack</em></strong>，【42】<strong><em>wong</em></strong>等人提出了一个跟懒猴攻击非常相似的攻击，其通过缓慢发送HTTP_post请求来击溃Web服务器。</p>
<p>​
攻击者发送一个完整的HTTP头，它定义了消息体的‘内容-长度’字段，作为发送此请求的良性流量。然后它以每两分钟一个字节的速率发送数据来填充消息体。因此，服务器等待每个消息体完成，而Slowpost攻击迅速增长，导致Web服务器上的DDoS泛洪攻击。</p></li>
<li><p>​ <strong><em>Slowreading
attack</em></strong>，【43】<strong><em>Shekyan</em></strong>等人提出了另一种通过缓慢读取response来发起攻击的方式，而不是通过缓慢发送。</p>
<p>​
此攻击通过设置比目标服务器的发送缓冲区更小的接收窗口大小来达到目的。即使没有数据通信，TCP协议仍然保持开放的连接；因此，攻击者可以迫使服务器保持大量连接的开放，最终对服务器造成DDoS泛洪攻击。</p></li>
</ul>
<hr />
<h3 id="botnet-based-ddos-attacks">BOTNET-BASED DDOS ATTACKS</h3>
<p>​
如前所述，僵尸网络是促使DDoS洪范攻击计算机网络或应用程序的主导机制。最近最令人头大的应用层DDoS泛洪攻击大多使用僵尸网络。在本节中，我们对当前僵尸网络架构以及已经用于发起DDoS泛洪攻击的工具进行了全面的研究</p>
<p>​
根据【32】<strong><em>Peng</em></strong>等人所述，当攻击者使用僵尸网络来制造DDoS攻击时，使得做出更有效的防御机制更困难的原因有二：一是大量的僵尸肉机可使得攻击者制造出的攻击流量规模更大，更具破坏性；二是肉机的IP一般是伪造的，很难回溯追踪。</p>
<p>​ 僵尸网络包括master，handler和bots，如下图所示：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20220304101014.png"  style="zoom: 33%;" /></p>
<p>​ handlers是攻击者( 即master
)用来与自己的肉机（即bots）间接通信的通信手段。例如，handlers可以安装在攻击者通信发送命令的一组折衷设备(
例如 ,网络服务器 )上。</p>
<p>​
然而，大多数安装的程序都留下了当前杀毒软件可以检测到的独特足迹。因此，当前攻击者使用其他方法(
如互联网中继聊天 IRC )与bot进行通信，以发送命令并控制它们。</p>
<p>​
Bots就是被控制的肉机，其生成可以有成百上千种方法，根据其如何被攻击者控制，可以分类为：</p>
<ul>
<li><p>​ <strong>IRC-bacsed:</strong></p>
<p>​
<strong><em>IRC</em></strong>是一个互联网在线文本信息协议，其采用c-s架构，具有默认的通道，可以实现服务器间的通信。IRC可以通过多个服务器连接数百个客户端。利用IRC通道作为处理程序，攻击者可以利用合法的IRC端口向bot发送命令，使得对DDoS命令和控制结构的跟踪变得更加困难。</p>
<p>​ 由于IRC服务通常具有庞大的数据量，攻击者因此可以轻易的隐藏自己。</p>
<p>​ 另外，攻击者可以通过将恶意代码分片发送而轻松地分享文件。</p>
<p>​
此外，攻击者可以简单地登录到IRC服务器并查看所有可用bot的列表，而不是在其站点本地维护其列表。具有集中指挥和控制(
C &amp; C
)基础设施的僵尸网络(如基于IRC的僵尸网络)的主要局限性在于服务器是潜在的故障中枢。也就是说，如果防御者捕获了C
&amp;
C服务器，整个僵尸网络可能会关闭。一些基于IRC的著名僵尸网络工具多年来被开发并用于发起DDoS攻击如：</p>
<p>​ 【43】Trinity v3（UDP,TCP SYN, TCP ACK, and TCP NULflflood
attacks）</p>
<p>​ 【47】Kaiten（UDP, TCP, SYN, and PUSH+ACH flflood attacks）</p></li>
<li><p>​ <strong>Web-based (a.k.a., HTTP-based)：</strong></p>
<p>​
最近，僵尸网络开始使用HTTP作为通信协议向僵尸网络发送命令，使得追踪DDoS命令和控制结构变得困难得多。基于Web的僵尸网络不像基于IRC的僵尸网络那样与C
&amp;
C服务器保持连接。相反，每个Web机器人定期使用Web请求下载指令。基于Web的僵尸网络更隐蔽，因为它们隐藏在合法的HTTP流量中。</p>
<p>​
Bots通过复杂的PHP脚本进行配置和控制，它们通过HTTP或者HTTPS加密通信。</p>
<p>​ 三个著名的Web-based 僵尸网络：</p>
<p>​ 【49】 BlackEnergy</p>
<p>​ 【50】 Ion Cannon (LOIC)</p>
<p>​ 【52】 Aldi</p></li>
</ul>
<hr />
<h3 id="ddos-defense-scope-and-classification">DDOS DEFENSE: SCOPE AND
CLASSIFICATION</h3>
<p>​
通常在检测到DDoS泛洪攻击时，除了断开受害者与网络并手动修复问题之外，没有什么可以做的。任何DDoS防御机制的最终目标都是尽快检测到它们，并尽可能地将它们阻止到源端。</p>
<p>​ <img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20220304110412.png" /></p>
<p>​</p>
<p>​
上图显示了对DDoS检测和回应可以实施的阶段，如图所示，DDoS泛洪攻击类似于一个漏斗，在该漏斗中攻击流产生于一个分散区(即源)，形成漏斗的顶部。</p>
<p>​
可以看出，在漏斗底部检测DDoS攻击时相对容易的，所有网络流都可以在底部被观察到。相反地，相反，从攻击的单个源网络很难检测到攻击，除非从该源发起大量攻击流。</p>
<p>​
但是在检测的准确性和如何接近攻击源之间总是存在权衡的问题，预防和响应机制能够阻止或响应攻击。</p>
<p>​ 此外，当响应机制( 例如 ,包过滤
)将攻击数据包更靠近攻击源时，当受害者受到DDoS攻击(即在DDoS攻击的中间)，到达受害者的正常数据包数量也会增加。否则，随着攻击流越接近受害者，数据包过滤机制就会丢弃更多受害者的合法数据包。</p>
<p>​
在本节中，我们利用两个判据对我们在第III节中提出的两类DDoS洪泛攻击的防御机制进行了分类。我们认为，这些分类标准对于设计稳健的防御解决方案非常重要。</p>
<p>​
<strong><u>分类的第一个准则是防御机制在攻击过程的哪里实现（Deployment
location）：</u></strong></p>
<ul>
<li>​ 我们将针对传输层级的DDoS攻击的防御方法分为四类（见Fig.3.）：</li>
</ul>
<p>​ <em>source-based</em>,
<em>destination-based</em>,<em>network-based</em>, and <em>hybrid
(a.k.a. distributed)</em></p>
<ul>
<li>​ 我们将针对应用级DDoS攻击的防御方法分为两类：</li>
</ul>
<p>​ <em>destination-based</em>, and <em>hybrid (a.k.a.
distributed)</em></p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20220304150015.png" /></p>
<p>​
由于应用层DDoS攻击的流量在第2层(交换机)和第3层(路由器)设备上不可访问，因此没有network-based的防御机制来抵御应用层DDoS攻击。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20220304111902.png"  style="zoom: 50%;" /></p>
<p>​
<strong><u>分类的第二个准则是DDoS防御机制面对可能的DDoS攻击响应的时间点：</u></strong></p>
<p>​
基于以上准则我们将基于传输层和基于应用层的的DDoS防御机制分为三类：</p>
<p>​ <em>before the attack（attack prevention），during the
attack（attack detection），after the attack(attack source
identifification and response)</em></p>
<p>​
因为对于DDoS攻击并没有一个“一刀切”的办法，一个综合的DDoS防御机制应该包括以上三个防御方法。</p>
<p>ps<u>：由于本次调研重点在于探索对基于AI方法的DDoS防御机制，这里不做过深入探索，具体传统方法见原文。</u></p>
<hr />
<h3 id="ddos-defense-performance-measurement-metrics">DDOS DEFENSE:
PERFORMANCE MEASUREMENT METRICS</h3>
<p>​
在这一部分，我们回顾和讨论了文献中发现的一些可以用来比较评估DDoS防御技术的度量和属性。</p>
<p>​ 然后，在表III和表IV中，我们使用 <strong><em>defense
strength</em></strong> (accuracy)、
<strong><em>scalability</em></strong>（可扩展性）、
<strong><em>delay</em></strong>（延迟）、 <strong><em>system performance
degradation</em></strong>（系统性能退化）、<strong><em>implementation
complexity</em></strong>（实现复杂度）等性能度量指标，基于deployment
location定性地比较了传输层级DDoS攻击的防御机制和应用层级DDoS防御机制，以及这些防御机制是否被视为整体防御机制。</p>
<p>​ 度量防御机制的标准如下：</p>
<ol type="1">
<li><p><strong><em>Defense Strength:</em></strong></p>
<p>防御机制的强度可以通过各种度量来衡量，这取决于它能多好地预防、检测和阻止攻击。这些度量可以根据每个防御机制做出的决策或预测来定义。防御机制要么探测并应对攻击，要么错过攻击。根据他们的反应，有四个可能的结果如表II所示。</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20220304153451.png"  style="zoom: 67%;" /></p>
<p>​ 如表II所示，A，B，C，D分别表示为<strong>true
negative</strong>，<strong>false negative</strong>，<strong>false
positive</strong>，<strong>true
positive</strong>，其实就是常见的<u><strong>混淆矩阵</strong></u>。</p>
<ul>
<li><p><strong><em>Accuracy</em></strong>是对检测结果的综合评价，是预测正确的比例占全部的比例。
<span class="math display">\[
  Accuracy=\frac{TP+TN}{P+N}=\frac{TP+TN}{TN+TP+FP+FN}
  \]</span></p></li>
<li><p><strong><em>Sensitivity</em></strong>是阳性样本中预测正确的比例：
<span class="math display">\[
  Sensitivity=\frac{TP}{P}=\frac{TP}{TP+FP}
  \]</span></p></li>
<li><p><strong><em>Specificity</em></strong>是阴性样本中预测正确的比例：
<span class="math display">\[
  Specificity=\frac{TN}{N}=\frac{TN}{TN+FN}
  \]</span></p></li>
<li><p><strong><em>Precision</em></strong>是预测为阳性的样本中预测正确的比例：
<span class="math display">\[
Precision=\frac{TP}{FP+TP}
\]</span></p></li>
</ul></li>
</ol>
<ul>
<li><p><strong><em>Reliability or False positive
rate</em></strong>是预测为阳性的样本中错误的比例： <span
class="math display">\[
    Reliability(False.positive.rate)=\frac{FP}{FP+TP}
    \]</span></p></li>
<li><p><strong><em>False negative
rate</em></strong>是预测为阴性的样本中错误的比例： <span
class="math display">\[
    False\,negative\,rate=\frac{FP}{FP+TP}
    \]</span></p></li>
</ul>
<ol start="2" type="1">
<li><strong><em>Compromise-ability:</em></strong></li>
</ol>
<pre><code>攻击者能否利用防御机制，以便对整个系统发起攻击( 例如 , DDoS )?</code></pre>
<ol start="3" type="1">
<li><p><strong><em>Delay in detection/response:</em></strong></p>
<p>检测到/对攻击做出反应的时间。</p></li>
<li><p><strong><em>System performance degradation:</em></strong></p>
<p>一个防御机制是否会造成系统的功能性问题（例如内存短缺，CPU时间片短缺等），或者其是否需要额外的要求以完美运行。</p></li>
<li><p><strong><em>Passive, reactive or proactive:</em></strong></p>
<p>防御机制通过主动阻止攻击的发生来防御攻击，它是只对现有攻击作出反应，还是只在DDoS攻击发起后才采取行动。</p></li>
<li><p><strong><em>Holistic defense:</em></strong></p>
<p>一种整体防御机制，通过考虑所有需要的任务，以阻止DDoS攻击(
即既检测又响应 )。</p></li>
<li><p><strong><em>Implementation complexity:</em></strong></p>
<p>实现复杂性。</p></li>
<li><p><strong><em>Usability:</em></strong></p>
<p>是否user-friendly。</p></li>
<li><p><strong><em>Deployment location:</em></strong></p>
<p>正如我们前面提到的，部署位置是比较各种防御机制的另一个度量。每个位置都有各自的优缺点，使得一种机制优于另一种机制。</p></li>
<li><p><strong><em>Scalability:</em></strong></p>
<p>可扩展性，一个可扩展的防御机制可以有效地处理其攻击检测和响应职责，即使攻击者的数量和攻击流量都增加了。</p></li>
</ol>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>IDS</tag>
        <tag>DDoS</tag>
      </tags>
  </entry>
  <entry>
    <title>HydraText-Multi-objective Optimization for Adversarial Textual Attack</title>
    <url>/2021/11/14/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91HydraText%20Multi-objective%20Optimization%20for%20Adversarial%20Textual%20Attack/</url>
    <content><![CDATA[<h1
id="hydratext-multi-objective-optimization-for-adversarial-textual-attack">HydraText:
Multi-objective Optimization for Adversarial Textual Attack</h1>
<blockquote>
<p><strong>作者：Shengcai Liu，Ning Lu，Cheng Chen，Chao Qian，Ke
Tang</strong></p>
<p><strong>时间：2021</strong></p>
</blockquote>
<h3 id="abstract">ABSTRACT</h3>
<p>​
<strong><u>文字(text)（word-level）对抗样本黑盒攻击。</u></strong>在这项工作中，同时考虑<strong>攻击效率+可辨认性</strong>，并提出一种新的具有可证明性能保证的多优化方法(称为HydraText
)，以实现具有高隐蔽性的成功攻击。</p>
<p>​ 为了测试HydraText的功效，我们在<strong>score-based</strong>
和<strong>decision-based</strong>的黑盒攻击下，使用5个NLP模型+5个数据集。</p>
<p>（PS：[<a href="https://zhuanlan.zhihu.com/p/377633699">论文总结]
Boundary Attack - 知乎 (zhihu.com)</a>）</p>
<p>​ 一项人类观察评价研究表明，Hydra
Text制作的对抗样本很好地保持了有效性和自然性。最后，这些实例还表现出良好的可迁移性，可以通过对抗训练给目标模型带来显著的鲁棒性提升。</p>
<hr />
<span id="more"></span>
<h3 id="introduction">INTRODUCTION</h3>
<p>​
我们仔细地设计了目标函数，并进一步构建了一个多目标优化问题（<strong><em>multi-objective
optimization
problem</em></strong>，MOP），该问题一旦被解决，将产生与原始文本相似度高的单个成功对抗样本。</p>
<p>​ 然后我们原创了一个多目标优化方法（ <strong><em>multi-objective
optimization
approach</em></strong>），叫做<strong>HydraText</strong>。这个名字的灵感来自于海蛇许德拉，这是一种神话动物，它使用多个头部攻击对手。它可以同时用在<strong>score-based</strong>
和<strong>decision-based</strong>的黑盒攻击下。</p>
<p><img
src="%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91HydraText%20Multi-objective%20Optimization%20for%20Adversarial%20Textual%20Attack/u=968937333,2137978646&amp;fm=26&amp;fmt=auto" /></p>
<p>​</p>
<hr />
<h3 id="methods">METHODS</h3>
<p>​ 基于word-level
的替换操作。每个单词有一个自己的候选表，然后将每个单词与候选表中被选中的词替换（也可以不选，原单词不变）。</p>
<p>​ 但这样的方法有个问题，如下图：</p>
<p>​ <img
src="%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91HydraText%20Multi-objective%20Optimization%20for%20Adversarial%20Textual%20Attack/image-20211114162251176.png" /></p>
<p>​
如图所示，句子的语义与替换的单词数量是成反比的，上文需要考虑的准确率+可辨认性二者其实是互相矛盾的。为了解决这个问题，我们在生成的过程中也考虑X<sub>adv</sub>的修改率，使用MOP来解决它。</p>
<p>​</p>
<h4 id="the-hydratext-approach">1.<em>The HydraText Approach</em></h4>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211114162738.png" style="zoom:80%;" /></p>
<hr />
<h3 id="experiments">EXPERIMENTS</h3>
<h4 id="datasets-and-target-models">1. <em>Datasets and Target
Models</em></h4>
<p>​ <strong>模型种类：</strong>文本分类和文本推理</p>
<p>​ 三个数据集：AG News，IMDB ， Movie Reviews，Stanford Natural
Language Inference，multi-genre NLI
corpus（前三个文本分类，后三个文本推理）</p>
<p>​ 两个模型：WordCNN，WordLSTM，BERT base-uncased，ESIM ，Infersent
，BERT base-uncased(前三个文本分类，后三个文本推理)</p>
<h4 id="baselines-and-algorithm">2.<em>Baselines and Algorithm</em></h4>
<p>​ <strong>攻击方法：</strong>PSO,GA,TextFooler,PWWS,GADe(baseline)</p>
<h4 id="evaluation">3.<em>Evaluation</em></h4>
<p>​ 以攻击成功的百分率来判定攻击能力。</p>
<p>​ 以修改百分率和语义相似性来判定攻击的可辨识性。</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211114165103.png" /></p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>AD</tag>
      </tags>
  </entry>
  <entry>
    <title>Semantic Host-free Trojan Attack</title>
    <url>/2021/11/06/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Semantic%20Host-free%20Trojan%20Attack/</url>
    <content><![CDATA[<h1 id="semantic-host-free-trojan-attack">Semantic Host-free Trojan
Attack</h1>
<blockquote>
<p><strong>作者：Haripriya Harikumar , Kien Do, Santu Rana , Sunil Gupta
, Svetha Venkatesh（迪肯大学.澳大利亚）</strong></p>
<p><strong>时间：2021.10.27</strong></p>
</blockquote>
<h3 id="abstract">ABSTRACT</h3>
<p>​
在本文中，我们提出了一种新颖的host-free木马攻击，其触发器(trigger)固定在语义空间(semantic)，但不一定在像素空间(pixel)。</p>
<p>​
与现有的木马攻击使用干净的输入图像作为宿主来携带小的、没有意义的trigger不同，我们的攻击将trigger看作是属于语义上有意义的对象类的整个图像。</p>
<p>​
由于在我们的攻击中，与任何特定的固定模式相比，分类器被鼓励记忆触发图像的抽象语义。因此它可以在以后由语义相似但看起来不同的图像触发。这使得我们的攻击更实际地被应用于现实世界中，更难以防御。广泛的实验结果表明，仅用少量的特洛伊木马模式进行训练，我们的攻击能很好地推广到同一特洛伊木马类的新模式，并且可以绕过目前的防御方法。</p>
<table style="width:10%;">
<colgroup>
<col style="width: 9%" />
</colgroup>
<tbody>
<tr class="odd">
<td><span id="more"></span> ### INTRODUCTION</td>
</tr>
<tr class="even">
<td>​ 提出了一个<strong>后门攻击</strong>，semantic host-free
backdoors。</td>
</tr>
<tr class="odd">
<td>​ <strong>后门攻击综述：</strong><a
href="https://blog.csdn.net/yalecaltech/article/details/117249586">(20条消息)
深度学习后门攻防综述_Yale的博客-CSDN博客_后门攻击</a></td>
</tr>
<tr class="even">
<td>​
<img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211109200409.png" style="zoom:50%;" /></td>
</tr>
</tbody>
</table>
<h3 id="method">METHOD</h3>
<p>​ 实现方式：数据投毒。</p>
<p>​</p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>AD</tag>
      </tags>
  </entry>
  <entry>
    <title>Intrusion detection system-A comprehensive review</title>
    <url>/2021/11/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Intrusion%20detection%20system%20A%20comprehensive%20review/</url>
    <content><![CDATA[<h1 id="intrusion-detection-system-a-comprehensive-review">Intrusion
detection system: A comprehensive review</h1>
<blockquote>
<p><strong>作者：Hung-Jen Liao a , Chun-Hung Richard Lin a,n , Ying-Chih
Lin a,b , Kuang-Yuan Tung a（国立中山大学，正修科技大学）</strong></p>
<p><strong>时间：2012</strong></p>
</blockquote>
<h3 id="abstract">ABSTRACT</h3>
<p>​ 一个IDS综述。</p>
<p>PS：<a
href="https://blog.csdn.net/haoxuexiaolang/article/details/106562102?spm=1001.2101.3001.6661.1&amp;utm_medium=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~default-1.no_search_link&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~default-1.no_search_link">(17条消息)
防火墙、IDS和IPS之间的区别（浅谈）_淡风wisdon－大大的博客-CSDN博客</a></p>
<table style="width:10%;">
<colgroup>
<col style="width: 9%" />
</colgroup>
<tbody>
<tr class="odd">
<td><span id="more"></span> ### INTRODUCTION</td>
</tr>
<tr class="even">
<td>​ <strong>CIA：</strong>Confifidentiality, Integrity and
Availability，</td>
</tr>
<tr class="odd">
<td>​ <strong>Instrusion:</strong>
针对CIA的破坏行为，或者绕过计算机或网络安全机制的行为。</td>
</tr>
<tr class="even">
<td>​ <strong>Instrusion detection:</strong>
是监视计算机系统或网络中发生的事件，并分析它们以发现入侵迹象的过程。</td>
</tr>
<tr class="odd">
<td>​ <strong>Instrusion detection sysytem(IDS):</strong> 实现instrusion
detection自动化的软件或硬件。</td>
</tr>
<tr class="even">
<td>​ <strong>Instrusion prevention system(IPS):</strong>
不仅有IDS的监控功能，还可以阻止可能的突发安全事件。在少数文章中，入侵检测与防御系统(
IDPS )和入侵防御系统( IPS )是同义词，其中IDPS一词在安全界很少使用。</td>
</tr>
</tbody>
</table>
<h3 id="detection-methodologies">DETECTION METHODOLOGIES</h3>
<p>​ Detection的方法一共分为三类：Signature-based Detection
(<strong>SD</strong>), Anomaly-based Detection</p>
<p>(<strong>AD</strong>) and Stateful Protocol Analysis
(<strong>SPA</strong>)。</p>
<h4 id="sd特征检测">1. SD（特征检测）:</h4>
<p>​ Signature-based
Detection，特征检测。将已知的patterns与捕获的事件进行比较，从而发现可能的入侵。因为使用特定攻击或者系统漏洞所积累下的知识，SD又被称为Knowledge-based
Detection 或者 Misuse Detection。</p>
<h4 id="ad异常检测">2. AD（异常检测）：</h4>
<p>​ Anomaly-based
detection，异常检测。一个异常（anomaly）指的是与已知行为相异的地方。Profiles表示定期从活动，网络连接中监视的正常或特定的行为文件，profile可以是静态的也可以是动态的，并且从许多特性中生成。例如，登录失败，处理器的使用，邮件的发送数量等。</p>
<p>​ 接下来，AD
比较器就将正常的profile与观察到的事件相比较，以此辨别出显著的攻击。AD又被称为Behavior-based
Detection。</p>
<p>​ 一些AD的例子，例如，企图闯入、伪装、合法用户渗透、拒绝服务( DOS
)、特洛伊木马等。</p>
<h4 id="spa状态协议分析">3. SPA（状态协议分析）：</h4>
<p>​ Stateful Protocol
Analysis，状态协议分析。Stateful指的是IDS可以知晓并追踪协议的状态（举例，将请求与答复配对）。</p>
<p>​
尽管SPA与AD很像，二者其实完全不同。AD采用预加载的网络或者特定域名的profile，然而SPA依赖于供应商开发的特定协议<strong>通用profile</strong>。通常，SPA中的网络协议模型最初基于国际标准组织(例如IETF
)的协议标准。SPA也被称为Specifification-based
Detection（基于规格的检测）。</p>
<p>大多数IDS使用多种方法来提供更广泛和准确的检测。</p>
<hr />
<h3 id="detection-approaches">DETECTION APPROACHES</h3>
<p>​ 此文将已有的方法分为了5类：Statistics-based, Pattern-based,
Rule-based, State-based and</p>
<p>Heuristic-based。</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211106153047.png" /></p>
<p>​ 由上图所示，其中，Time series指的是是否考虑了time series
behavior。</p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>IDS</tag>
      </tags>
  </entry>
  <entry>
    <title>Def-IDS An Ensemble Defense Mechanism Against Adversarial Attacks for Deep Learning-based Network Intrusion Detection</title>
    <url>/2021/11/01/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Def-IDS%20An%20Ensemble%20Defense%20Mechanism%20Against%20Adversarial%20Attacks%20for%20Deep%20Learning-based%20Network%20Intrusion%20Detection/</url>
    <content><![CDATA[<h1
id="def-ids-an-ensemble-defense-mechanism-against-adversarial-attacks-for-deep-learning-based-network-intrusion-detection">Def-IDS:
An Ensemble Defense Mechanism Against Adversarial Attacks for Deep
Learning-based Network Intrusion Detection</h1>
<blockquote>
<p><strong>作者：Jianyu Wang，Jianli Pan，Ismail
AlQerm，（密苏里大学圣路易斯分校，重庆大学）</strong></p>
<p><strong>时间：2021</strong></p>
<p>ICCCN，ccf--C类</p>
</blockquote>
<h3 id="abstract">ABSTRACT</h3>
<p>​
提出了<strong>Def-IDS</strong>，一个为NIDS准备的组合防御机制。它是一个由两个模块组成的训练框架，组合了multi-class
generative adversarial networks<strong>（MGANs）</strong>和multi-soutce
adversarial retraining（<strong>MAT</strong>）。</p>
<p>​
在CSE-CIC-IDS2018数据集上测试了该机制，并与3个其它方法进行了比较。结果表明Def-IDS可以以更高的<strong>precision,
recall, F1 score, and accuracy</strong>来识别对抗样本。</p>
<table style="width:10%;">
<colgroup>
<col style="width: 9%" />
</colgroup>
<tbody>
<tr class="odd">
<td><span id="more"></span> ### INTRODUCTION</td>
</tr>
<tr class="even">
<td>​ <strong>Internet of Things(IoT):</strong>物联网</td>
</tr>
<tr class="odd">
<td>​ <strong>intrusion detection systems (NIDS)</strong></td>
</tr>
<tr class="even">
<td>​ 提出了一个整合基于对抗训练的防御机制，用于提升DL-based的intrusion
detectors的鲁棒性。</td>
</tr>
<tr class="odd">
<td>​ 4个贡献：</td>
</tr>
<tr class="even">
<td>1. 模型由两个模块组成，组合了multi-class generative adversarial
networks<strong>（MGANs）</strong>和multi-soutce adversarial
retraining（<strong>MAT</strong>），可以在保证准确率的前提下对抗攻击；
2.
<strong>MGANs</strong>可以通过同时过采样多类入侵来增强原始训练数据集，以减少训练与真实数据分布之间的差距。通过使用提升过的数据进行训练，detector的对已知和未知攻击的鲁棒性更强；
3.
<strong>MAT</strong>通过投喂多种不同的对抗样本来retraining，MAT不仅对抗某种特定的攻击，并且可以一定程度抵御对样样本的转移性；
4.
我们进行了一些state-of-the-art攻击并且在CSE-CIC-IDS2018数据集上测试了该机制，结果很好。</td>
</tr>
</tbody>
</table>
<h3 id="related-work">RELATED WORK</h3>
<hr />
<h3 id="adversarial-attack-threat-models">ADVERSARIAL ATTACK THREAT
MODELS</h3>
<ul>
<li>采用的攻击方法：FGSM，BIM，DeepFool，JSMA</li>
</ul>
<hr />
<h3 id="proposed-def-ids-defense-mechanism">PROPOSED DEF-IDS DEFENSE
MECHANISM</h3>
<h4 id="mechanism-overview">1. <em>Mechanism Overview</em></h4>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211102215521.png" /></p>
<h4 id="module-1-multi-class-gan-based-retraining">2. <em>Module 1:
Multi-class GAN-based Retraining</em></h4>
<h4 id="module-2-multi-source-adversarial-retraining">3. <em>Module 2:
Multi-source Adversarial Retraining</em></h4>
<h4 id="ensemble-adversarial-retraining">4. <em>Ensemble Adversarial
Retraining</em></h4>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211102220240.png" /></p>
<hr />
<h3 id="evaluation">EVALUATION</h3>
<h4 id="dataset-and-metrics">1. <em>Dataset and Metrics</em></h4>
<p>​ <strong>数据集</strong>：CSE-CIC-IDS2018（CIC出版）（通用）</p>
<p>​ 与其他过时的数据集相比，其含有综合性的攻击方法和更平衡的数据。</p>
<p>​ 其含有Brute-force, Heartbleed,Botnet, DoS, DDoS, Web attacks 和
infifiltration of the network共7种恶意流量。</p>
<p>​ <strong>数据处理：</strong></p>
<ol type="1">
<li><p>使用Min-Max standardization将所有特征的值映射入[0,1]；</p></li>
<li><p>有四个特征有太多空值或者无限值（dstport, protocol, flflow byts/s,
flflow
pkts/s），有一个特征（timestamp）与流量无关，将这5个特征剔除；还剩下76个特征。</p></li>
<li><p>training,validation,test = 8:1:1，随机划分。</p></li>
</ol>
<p>​ <strong>Detector的评价方法：</strong></p>
<p>​ 混淆矩阵。</p>
<h4 id="baseline-detector-implementation">2. <em>Baseline Detector
Implementation</em></h4>
<h5 id="detector-implementation">2.1 <em>Detector
Implementation</em></h5>
<p>​ 选取baseline detector
C<sub>base</sub>。其由一个输入层，两个隐藏层和一个输出层组成（76-128-64-8）。</p>
<p>​ 隐藏层都是全连接层+ReLU。</p>
<p>​ 输出层使用Softmax。</p>
<p>​ 代码用keras写的，系统Ubuntu 18.04,3.6GHz CPU和16GB内存。</p>
<p>​ 优化器用Adam，学习率0.001,20个epoch。</p>
<p>​ 在训练过程中，进行十次交叉验证并计算平均度量值。</p>
<p>​ 训练结束后，利用测试数据集对Cbase进行评估。</p>
<h5 id="adversarial-attacks-against-baseline-classififier">2.2
<em>Adversarial Attacks against Baseline Classififier</em></h5>
<p>​ 使用python库<strong>foolbox</strong>来生成对抗样本；</p>
<p>​
FGSM，BIM，DeepFool，JSMA四种攻击方法都使用，具体效果如下图所示：</p>
<p>​ <img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211102213923.png" /></p>
<h4 id="def-ids-defense-evaluation">3. <em>Def-IDS Defense
Evaluation</em></h4>
<p>C<sub>gan</sub>是使用GAN生成的样本再训练的detector;</p>
<p>C<sub>at</sub>是使用9:1的纯净数据：恶意数据再训练出的detector;</p>
<p>C<sub>ensem</sub>是二者的结合.</p>
<h5 id="section"><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211102214213.png" /></h5>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211102215325.png" /></p>
<h4 id="comparison-with-other-works">4. <em>Comparison with Other
Works</em></h4>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211102215346.png" /></p>
<h4 id="cost-estimation">5. <em>Cost Estimation</em></h4>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211102215401.png" /></p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>AD</tag>
      </tags>
  </entry>
  <entry>
    <title>Crafting Adversarial Example to Bypass Flow-&amp;ML- based Botnet Detector via RL</title>
    <url>/2021/10/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Crafting%20Adversarial%20Example%20to%20Bypass%20Flow-&amp;ML-%20based%20Botnet%20Detector%20via%20RL/</url>
    <content><![CDATA[<h1
id="crafting-adversarial-example-to-bypass-flow-ml--based-botnet-detector-via-rl">Crafting
Adversarial Example to Bypass Flow-&amp;ML- based Botnet Detector via
RL</h1>
<blockquote>
<p><strong>作者：Junnan Wang，Qixu Liu，Di Wu，Ying Dong，Xiang
Cui（中国科学院大学，华为科技，北京维纳斯纲科技，广州大学）</strong></p>
<p><strong>时间：2021.10.6</strong></p>
<p><strong>会议：RAID(CCF_B)</strong></p>
</blockquote>
<h4 id="botnet僵尸网络">1. Botnet(僵尸网络)：</h4>
<h5 id="定义">1.1 定义：</h5>
<p>​ Botnet = robot + network。</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211030111947.png" /></p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211030112012.png" /></p>
<blockquote>
<p>----参考《软件安全》.彭国军</p>
</blockquote>
<h5 id="如何攻击">1.2 如何攻击？</h5>
<p>​
一个僵尸网络的生存周期包括<strong><u>形成、C&amp;C、攻击、后攻击</u></strong>四个阶段。</p>
<p>​
形成阶段由攻击者入侵有漏洞的主机，并在其上执行恶意程序，使之成为僵尸主机。</p>
<p>​ 一旦成为僵尸主机之后，botmaster会通过各种方式与之通信。</p>
<p>​
之后根据botmaster的指令执行攻击行为。后攻击阶段是指botmaster对僵尸网络进行升级更新。</p>
<h4 id="botnet-detector僵尸网络检测器">2. Botnet
Detector(僵尸网络检测器)：</h4>
<h5 id="传统方法">2.1 传统方法：</h5>
<p>​ 从检测原理上来说，大致可以分为三类方法：</p>
<p>　　·行为特征统计分析</p>
<p>　　·bot行为仿真以监控</p>
<p>　　·流量数据特征匹配</p>
<p>​
传统的检测僵尸网络的方法一般在形成、攻击阶段，利用僵尸主机存在的行为特征，例如通信的数据内容。一些基于网络流量行为分析的方法可以检测僵尸网络，主要是从<strong>通信流量特征</strong>的角度去检测的，例如流量的通信周期，这种方法可以检测出一些加密的僵尸主机流量，同时还可以检测出新型的僵尸网络。</p>
<blockquote>
<p>----参考：<a
href="http://blog.chinaunix.net/uid-20597254-id-1918281.html">解析：僵尸网络（Botnet）的检测方法-西湖泛舟-ChinaUnix博客</a></p>
</blockquote>
<hr />
<h3 id="abstract">ABSTRACT</h3>
<p>​
提出了一个<u>基于RL</u>的方法来对<u>基于ML的僵尸网络追踪器</u>做逃逸攻击，并且可以保留僵尸网络的恶意功能。</p>
<p>​ 黑盒攻击，不用改变追踪器本身。</p>
<table style="width:10%;">
<colgroup>
<col style="width: 9%" />
</colgroup>
<tbody>
<tr class="odd">
<td><span id="more"></span> ### INTRODUCTION</td>
</tr>
<tr class="even">
<td>​
训练一个RLagent，让其通过与追踪器的交流反馈自己学习如何扰动样本。</td>
</tr>
<tr class="odd">
<td>​
为了确保功能的保留，我们设计了一个包含14个增量操作的操作空间，每个操作只向原始流中添加一个精心编制的数据包，以尝试更改一些流级特性。检测器认为这些特征具有区分性，但这可能不是良性交通的因果指标。</td>
</tr>
<tr class="even">
<td>​
此外，添加数据包是传输层的增量操作，而恶意数据一般封装在应用层。</td>
</tr>
<tr class="odd">
<td>​ 这种攻击方法的优点：</td>
</tr>
<tr class="even">
<td>1. 黑盒攻击； 2.
它具有通用性，不论探测器的损失函数是否可微，都可以使用； 3.
即插即用，RL智能体可以作为网络代理存在，逃逸成本低并且适用于任何botnet家族。</td>
</tr>
<tr class="odd">
<td>​ 主要贡献：</td>
</tr>
<tr class="even">
<td>1. 提出一个黑盒攻击方法； 2.
在RL框架中设计了一些列通用动作空间，这些动作都是添加操作，在可以逃逸的前提下保证了恶意样本的功能性；
3.
我们演示了如何训练和部署我们的系统以避免在精心构建的僵尸网络流数据集上进行ML检测，并综合评估框架的逃避性能、时间开销和通用性。</td>
</tr>
</tbody>
</table>
<h3 id="related-work">RELATED WORK</h3>
<h4 id="botnet-evasion">Botnet Evasion:</h4>
<ul>
<li><p>传统botnet逃逸方法：加密网络流；在TCP/IP协议簇的冗余字段中隐藏C
&amp; C信息(command and
control)；使用online-social-networks(OSN)来构建隐藏的通道。</p></li>
<li><p>ML-based逃逸方法：</p>
<ol type="1">
<li><p><strong>Feature space
attack：</strong>指的是只能生成traffic对抗特征向量的方法。但是，考虑到traffic样本映射到特征向量的过程是不可逆的，这样的攻击不能造成实际的安全威胁，只能用来证明基于ML的检测器的脆弱性。</p></li>
<li><p><strong>End-to-end
attack：</strong>指的是可以生成真正的traffic数据的方法。</p>
<p>【35】利用了GAN来模仿facebook聊天网络的traffic以此绕过自适应IPS。</p>
<p>【36】利用了GAN来生成尽量真实的traffic，以此来提高数据集的质量，解决数据不平衡问题。</p></li>
</ol></li>
</ul>
<hr />
<h3 id="threat-model-and-system-framework">THREAT MODEL AND SYSTEM
FRAMEWORK</h3>
<ol type="1">
<li><strong>Threat Model</strong></li>
</ol>
<ul>
<li><p><strong>攻击者的目的：</strong>生成对抗样本，隐藏botnet
flow。</p></li>
<li><p><strong>攻击者的信息：</strong>1.
攻击者理解目标网络可能被流等级（flow-level）ML网络检测系统保护；2.
攻击者不需要知道detector的算法，参数，特征或训练数据等信息。</p></li>
<li><p><strong>攻击者的能力：</strong>1.
攻击者只有能力修改测试集，并不能改变detector的训练集；2.
同时，我们假设攻击者可以持续访问detector，从检测器中获取二进制预测结果。</p></li>
</ul>
<ol start="2" type="1">
<li><strong>System Design</strong></li>
</ol>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211031113229.png" /></p>
<p>​ 见图即可，简单的RL学习模型。</p>
<ol start="3" type="1">
<li><p><strong>RL Algorithm</strong></p>
<p>选择了（value-based）DQN和SARSA，都用。</p></li>
<li><p><strong>Action Space</strong></p>
<p><strong>Q：如何在不影响原来功能的情况下添加扰动？</strong></p>
<p>A：因为botnet内容在应用层，故可以对传输层进行扰动。（<u>PS：这样确实不会改变功能，但是应用层的恶意特征不会仍被detector检测到吗？</u>）</p>
<p><strong>Q：如何确定哪个特征该进行扰动？</strong></p>
<p>A：考虑到动作设计的困难，从僵尸网络检测中常用的特征集合中选取18个特征。</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211031115102.png" /></p>
<p>​ 由上述特征，基于botnet和normal flow的差异，action
space包含了14个动作，这些动作可以影响以上的统计特征，例如简单修改数据包的时间戳，或者添加构建的新数据包。</p>
<p>​ 当在构建新数据包时，考虑三个地方：时间戳，方向，包的大小。</p>
<p>​ 14个动作被分成了5类：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211031115453.png" /></p>
<p>具体见原文。</p></li>
<li><p><strong>State Space</strong></p>
<p>​
detector返回的二进制信息很难直接使用，需要有一个状态生成器来生成供agent使用的state。</p>
<p>​ 这里使用堆叠自编码器（Stacked Autoencoder，SAE）来自动提取botnet
flow的特征，然后将其返回给agent以作为state。</p>
<p>​ 将每个botnet
flow的前1024个字节作为SAE的输入，经过一些epoch的训练，SAE就可以自动地从botnet
flow中学习到一个256维度的state vector。</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211031152136.png" /></p></li>
</ol>
<hr />
<h3 id="experimental-setup">EXPERIMENTAL SETUP</h3>
<ol type="1">
<li><p><strong>Implementation</strong></p>
<p>系统的位置如下：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211031152307.png"  /></p>
<p>作为BotMaster的一个代理存在。</p></li>
<li><p><strong>Dataset</strong></p>
<p>两个公开数据集：CTU，ISOT。</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211031152816.png" /></p>
<p>然后做一下数据处理：</p>
<p><img src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211031153008.png" alt="image-20211031153006310" style="zoom:80%;" /></p>
<ol type="1">
<li>合并属于同一botnet 家族的样本，如果某个pcap包太大，就舍弃；</li>
<li>将pcap包切片；</li>
<li>匿名化，将ip,mac等包中独一无二的东西随机化，以避免影响。</li>
</ol></li>
<li><p><strong>Detector</strong></p>
<p>​ 选取了两个state-of-art的detector: <strong>the composite DL detection
model combining CNN</strong></p>
<p><strong>with LSTM(<em>BotCatcher detection
model</em>)</strong>，<strong>the non-differentiable ML detection model
based on XGBoost(<em>XGBoost detection model</em>)</strong>。</p>
<p>​ <img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211031154038.png" /></p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211031154144.png" /></p></li>
</ol>
<hr />
<h3 id="results">RESULTS</h3>
<ol type="1">
<li><p><strong>Evasion performance</strong></p>
<p>将DQM,SARSA与BotCatcher,XGBoost两两组合：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211101153359.png" /></p>
<p>逃逸率如上图所示，可以看到，即使是随机扰动都有一定的逃逸率。</p>
<p>不同测试集效果差异很大：</p>
<pre><code>1. 数据包可能过大（storm），导致对时间戳做修改等操作对结果的影响很小；
2. 数据包的特征跟其它数据集差别很大，导致模型难以在有限的步骤时间里改变足够多的特征。</code></pre></li>
<li><p><strong>Time performances</strong></p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211101155037.png" /></p></li>
<li><p><strong>Dominant actions</strong></p>
<p><strong>Dominant
actions</strong>指的是agent在创建对抗样本时采用的最频繁的操作。</p></li>
</ol>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211101155358.png" /></p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>RL</tag>
        <tag>Botnet</tag>
      </tags>
  </entry>
  <entry>
    <title>《最后的问题》</title>
    <url>/2021/10/12/The%20Last%20Question/</url>
    <content><![CDATA[<h1 id="the-last-question">THE LAST QUESTION</h1>
<p>最后的问题第一次被半开玩笑地提出是在2061年的5月21日。那时人类文明刚刚步入曙光中。这个问题源起于酒酣之中一个五美元的赌，它是这么发生的：</p>
<p>亚历山大•阿代尔与贝特伦•卢泊夫是Multivac的两个忠实的管理员。像任何其他人一样，他们知道在那台巨大的计算机数英里冰冷、闪烁、滴答作响的面庞后藏着什么。那些电子回路早已发展到任何个别的人都无法完全掌握的地步，但他们至少对它的大致蓝图有个基本的概念。</p>
<p>Multivac能自我调节和自我修正。这对它是必要的，因为人类当中没有谁能够快甚至够好地对它进行调节和修正。所以实际上阿代尔与卢泊夫对这个庞然大
物只进行一些非常轻松和肤浅的管理，任何其他人也都只能做到这个程度。他们给它输送数据，根据它所需的格式修改问题，然后翻译给出的答案。当然，他们以及
其他管理员们完全有资格分享属于Multivac的荣誉。</p>
<p>几十年中，在Multivac的帮助下人类建造了宇宙飞船，计算出航行路径，从而得以登陆月球、火星和金星。但是更远的航行需要大量的能量，地球上可怜的资源不足以支持这些飞船。尽管人类不断地提高煤炭和核能的利用效率，但煤和铀都是有限的。</p>
<p>但是慢慢地Multivac学会了如何从根本上解决某些深层次问题。2061年5月14日，理论成为了现实。</p>
<p>太阳的能量被储存和转化，得以被全球规模地直接利用。整个地球熄灭了燃烧的煤炭，关闭了核反应炉，打开了连接到那个小小的太阳能空间站的开关。这个空间站直径一英里，在到月球的距离一半处环绕着地球。看不见的太阳的光束支撑着整个地球社会的运行。</p>
<p>七天的庆祝还不足以暗淡这创举的光辉。阿代尔与卢泊夫总算逃脱了公众事务，悄悄地相聚在这个谁也想不到的荒僻的地下室。在这里Multivac埋藏着的庞
大身躯露出了一部分。它正独自闲暇地整理着数据，发出满足的、慵懒的滴答声——它也得到了假期。他们了解这一点，一开始他们并没打算打扰它。</p>
<p>他们带来了一瓶酒。这会儿他们想做的只是在一起，喝喝酒，放松放松。</p>
<p>你想一想就会觉得很神奇，”阿代尔说。他宽阔的脸庞已有了疲倦的纹路。他慢慢地用玻璃棒搅动着酒，看着冰块笨拙地滑动。“从此我们所用的所有能量都是免费的。只要我们愿意，我们能把地球熔化成一颗液态大铁球——还能毫不在乎花掉的能量。够我们永远永远永远用下去的能量。”</p>
<p>卢泊夫将头歪向一边，这是当他想要反驳对方时的习惯动作。他现在确实想要反驳，部分原因是他在负责拿着冰和杯子。他说：“不是永远。”</p>
<p>“哦去你的，差不多就是永远。直到太阳完蛋，老贝。”</p>
<p>“那就不是永远。”</p>
<p>“好吧。几十亿年，可能一百亿年，满意了吧？”</p>
<p>卢泊夫用手梳着他稀薄的头发，仿佛要确认还剩下了一些。他缓缓地抿着自己的酒说，“一百亿年也不是永远。”</p>
<p>“但对我们来说是够了，不是吗？”</p>
<p>“煤和铀对我们来说也够了。”</p>
<p>“好好好，但是现在我们能把宇宙飞船连接到太阳能电站，然后飞到冥王星又飞回来一百万次而不用担心燃料。靠煤和铀你就做不到。不信去问问Multivac。”</p>
<p>“我不用问它。我知道。”</p>
<span id="more"></span>
<p>“那就不要小看Multivac为我们做的事，”阿代尔怒道，“它做得很好。”</p>
<p>“谁说它做得不好？我是说太阳不能永远燃烧下去，我只是这个意思。我们在一百亿年内可以高枕无忧，但是然后呢？”卢泊夫用略微颤抖的手指指着对方，“不要说我们换另外一个太阳。”</p>
<p>片刻的沉默。阿代尔偶尔将酒杯放到唇边，而卢泊夫慢慢地闭上了眼睛。两人都在休息。</p>
<p>然后卢泊夫突然睁开眼，“你在想当我们的太阳没了就换另外一个太阳，是吧？”</p>
<p>“我没这么想。”</p>
<p>“你就是这么想的。你的逻辑不行，这就是你的问题。你就像故事里说的那个人一样，碰上了雨就跑到树林里躲在一棵树下。他可不担心，是吧，因为他以为当这棵树淋得太湿的时候他只要跑到另一棵树下就行。”</p>
<p>“我明白了，”阿代尔说，“别嚷嚷。太阳完蛋了，其他的也都会完蛋。”</p>
<p>“完全正确，”卢泊夫嘟哝道，“一切都在起初那个宇宙大爆炸中有个开始，不管那到底是怎么回事。当所有的恒星都熄灭了，一切也都会有个结束。有的星星熄灭
得比别的早。像那些该死的巨星维持不了一亿年。我们的太阳能持续一百亿年，矮星再怎么样最多也只有两千亿年。一万亿年后一切都是一片漆黑。熵必须增加到最
大值，就是这样。”</p>
<p>“我非常明白什么是熵，”阿代尔维护着他的自尊。</p>
<p>“你明白个屁。”</p>
<p>“我跟你知道的一样多。”</p>
<p>“那你该知道某一天所有的东西都会耗光。”</p>
<p>“是是是。谁说它们不会呢？”</p>
<p>“你说的，你这个糊涂虫。你说我们有永远用不完的能量。你说的‘永远’。”</p>
<p>现在轮到阿代尔反驳了。他说：“也许有一天我们能让一切从头开始。”</p>
<p>“绝不可能。”</p>
<p>“为什么？总有那么一天的。”</p>
<p>“没有。”</p>
<p>“问问Multivac。”</p>
<p>“你去问Multivac。你敢吗？我赌五美元它说这不可能。”</p>
<p>阿代尔刚刚醉到愿意一试，又刚刚足够清醒到能拼写出问问题需要的符号和算式。这个问题用文字来表达就是：人类是否有一天能不需要净损耗能量而在恒星衰竭之后将其恢复到全盛时期？</p>
<p>或者更简明地这样说：怎样使宇宙的总熵大幅度地降低？</p>
<p>Multivac陷入了静止和沉默。缓慢闪烁的灯光熄灭了，深处传来的电路的滴答声停止了。</p>
<p>正当这两位被吓坏的技术员感到他们无法再屏住呼吸时，忽然间与Multivac相连的打字机开始运作起来。它打出几个字：数据不足，无法作答。</p>
<p>“赌不成了。”卢泊夫悄声道。他们匆忙离开了。</p>
<p>到了第二天早晨，两人头晕脑胀，口干舌燥，把这件事给忘了。</p>
<p>-------------------------------------------------------</p>
<p>贾诺德、贾诺汀和贾诺蒂I、贾诺蒂II注视着屏幕中变幻的星空影像。飞船在超越时间的一瞬中穿越了超时空，均匀分布的星群立刻被一个明亮的圆盘取代。它弹珠大小，占据着屏幕的中心。</p>
<p>“那就是X-23，”贾诺德自信地说。他紧握着的瘦削的手背在身后，指节发白。</p>
<p>两个小贾诺蒂都是女孩。她们一生中第一次经历超时空飞行，清晰地感到那种片刻的恶心[注]。她们悄声地嘻笑着，疯狂地绕着她们的母亲互相追逐，一边尖叫：“我们到X-23了——我们到X-23了——我们——”</p>
<p>“孩子们，别闹了！”贾诺汀严厉地说。“你确定吗，贾诺德？”</p>
<p>“有什么不确定的？”贾诺德瞟了一眼天花板上凸出的那块毫不起眼的金属。它从房间的一头延伸到另一头，两端埋入墙壁中。它和整个飞船一样长。</p>
<p>贾诺德对这条厚厚的金属棒几乎一无所知。他只知道它叫做Microvac，你可以问它任何问题，而平时它控制着飞船飞向目的地，从不同的银河系能量分站向飞船输送能量，并完成进行超时空跳跃的计算。</p>
<p>贾诺德一家只需要住在飞船舒适的居住区等待。曾经有人告诉贾诺德，“Microvac”词尾的“ac”是古英语中“automatic
computer，智能电脑”的缩写。但他差不多连这都忘了。</p>
<p>贾诺汀看着视屏，眼睛有些湿润。“没办法。想到离开了地球我感觉怪怪的。”</p>
<p>“天哪，为什么？”贾诺德问。“我们在那儿什么也没有。我们在X-23上会拥有一切。你并不孤单，你又不是那些拓荒者。这个行星上已经有超过一百万人了。
天哪，我们的曾孙们会得去找新的星球，因为那时X-23会太挤了。”他想了一会，说：“告诉你，人口增长这么快，幸亏电脑实现了星际旅行。”</p>
<p>“我知道，我知道。”贾诺汀难过地回答。</p>
<p>贾诺蒂I马上说道：“我们的Microvac是世界上最好的Microvac。”</p>
<p>“我也是这么想的。”贾诺德抚弄着她的头发说。</p>
<p>能拥有一台自己的Microvac的感觉非常好。贾诺德很高兴他属于他们这一代人。在他父亲年轻的时候，电脑都是占地一百平方英里的巨大机器。一个星球只
有一台，被称作行星AC。一千年来它们的体积逐步地增加，然后忽然间缩小了，因为分子阀取代了晶体管，使得最大的行星AC都缩小到了只有一艘飞船的一半体
积。</p>
<p>每当想到这件事贾诺德总是感到飘飘然：他的Microvac比那台古老原始的首次驯服了太阳的Multivac要精密好几倍，而且和第一台解决了超时空传送问题从而实现了星际航行的地球行星AC（最大的行星AC）一样精密。</p>
<p>“这么多的恒星，这么多的行星。”贾诺汀想着心事，叹息道。“我想人们会永远不断地出发去找新的行星，就像我们现在这样。”</p>
<p>“不是永远，”贾诺德笑了一笑说。“有一天这一切都会停下来，但那是在几十亿年之后了。好几十亿年。即使是星星也会耗尽，你知道的。熵必须不断增大。”</p>
<p>“爸爸，熵是什么？”贾诺蒂II喊道。</p>
<p>“小宝贝，熵，就是一个代表着宇宙消耗掉了多少的词。什么东西都会消耗，知道吗，就像你那个会走路会说话的小机器人，记得吧？”</p>
<p>“你不能给它装一个新的电池吗，就像给我的机器人那样？”</p>
<p>“星星们就是电池，亲爱的。一旦它们用完了，就没有别的电池了。”</p>
<p>贾诺蒂I一下子大喊起来：“别让它们用完，爸爸。别让星星们用完吧。”</p>
<p>“看看你干了什么。”贾诺汀恼火地低声说道。</p>
<p>“我怎么知道这会吓到她们？”贾诺德低声反驳。</p>
<p>“问问Microvac，”贾诺蒂I哭叫道。“问它怎么把星星重新点亮。”</p>
<p>“问吧，”贾诺汀说。“这会让她们安静点的。”（贾诺蒂II也开始哭了。）</p>
<p>贾诺德耸耸肩。“好了，好了，亲爱的。我去问Microvac。别着急，它会告诉我们的。”</p>
<p>他向Microvac提出问题，并赶紧加上“把答案打印出来。”</p>
<p>贾诺德将薄薄的纤维纸带握在手心，高兴地说：“看吧，Microvac说到时候它会料理这一切，所以别担心啦。”</p>
<p>贾诺汀说：“那么现在孩子们，该睡觉了。我们马上就要到我们的新家了。”</p>
<p>在销毁纸带之前贾诺德又读了一遍上面的文字：数据不足，无法作答。</p>
<p>他耸了耸肩，看向视屏。X-23就在前方。</p>
<p>-------------------------------------------------------</p>
<p>兰默斯VJ-23X注视着幽深的银河三维缩影图，说：“我想我们这么担心这件事是不是很可笑？”</p>
<p>尼克隆MQ-17J摇头道：“我不觉得。你知道照现在的扩展速度银河系在五年内就会被挤满。”</p>
<p>两个人看起来都是二十出头，都很高大健康。</p>
<p>“但是，”VJ-23X说，“我不太想给银河参议会提交这样一个悲观的报告。”</p>
<p>“我不会考虑作任何其他的报告。得引起他们的注意。我们必须引起他们的注意。”</p>
<p>VJ-23X叹了一口气。“太空是无限的。还有一千亿个星系等着我们。甚至更多。”</p>
<p>“一千亿并不是无限，而且正在变得越来越有限。想想吧！两万年前人类刚刚找到了利用恒星能量的方法，几个世纪之后星际旅行就实现了。人类用了一百万年才填满一个小小的星球，可是只用了一万五千年就占据了整个银河系。而现在人口每十年就翻一倍——”</p>
<p>VJ-23X 插口道：“这得归功于永生。”</p>
<p>“不错。永生实现了，我们得把它考虑进去。我觉得它的确有阴暗的一面。银河AC给我们解决了很多问题，但当它解决了防止衰老和死亡这个问题之后其他的一切都白费了。”</p>
<p>“但是我想你也不想放弃生命吧。”</p>
<p>“一点也不想，”MQ-17J断然道，随即柔和了语调，“现在还不想。我还一点也不老。你多少岁了？”</p>
<p>“两百二十三。你呢？”</p>
<p>“我还不到两百。——但是回到我说的事情上来。人口每十年增加一倍。一旦银河系被占满了，我们会在十年内占满另一个。再过十年我们能占满另外两个。再过十年，四个。一百年内我们会占满一千个星系。一千年内，一百万个。一万年内就是整个已知的宇宙。然后呢？”</p>
<p>VJ-23X说：“还有附带的一点是运输的问题。我不知道把一整个星系的人运送到另一个需要多少太阳单位的能量。”</p>
<p>“这一点说得很对。人类现在每年已经得消耗两个太阳单位的能量了。”</p>
<p>“大部分的都被浪费了。不管怎样，我们自己的星系每年泼出去一千个太阳单位能而我们只用其中的两个。”</p>
<p>“没错，但是即使有百分之百的效率，我们也只是推迟了结局的到来。我们对能量的需求以几何级数增长，比我们的人口还要快。在我们占据完所有星系之前我们就会用光所有能量。你说得对。说得非常对。”</p>
<p>“我们可以用星际气体造出新的恒星。”</p>
<p>“或者说用散失掉了的热量？”MQ-17J嘲讽地说。</p>
<p>“也许会有办法逆转熵的增加。我们应该问问银河AC。”</p>
<p>VJ-23X并不是认真的，但是MQ-17J把他的AC联络器从口袋里拿出来放在面前的桌子上。</p>
<p>“我确实有点想问。”他说，“这个问题总有一天人类得面对。”</p>
<p>他忧郁地注视着小小的AC联络器。这是个两英寸的立方体。它本身并没有什么，而只是通过超时空与那个服务于全人类的超级银河AC相联系。如果将超时空算进来，它就是银河AC整体的一部分。</p>
<p>MQ-17J停下来想着在他不朽的生命中是否有一天他能有机会去看看银河AC。它占据着单独的一个小星球，能量束构成的蛛网支持着它的核心，其中古老笨拙的分子阀已被亚介子流取代。尽管有着亚以太级的精密结构，银河AC的直径仍足有一千英尺长。</p>
<p>MQ-17J突然开口向AC联络器问道：“熵的增加能被逆转吗？”</p>
<p>VJ-23X吃了一惊，立即说道：“哦，我说，我没有真的想叫你问那个。”</p>
<p>“为什么不呢？”</p>
<p>“我们都知道熵是不可逆转的。你不能把烧剩的烟尘变回到一棵树。”</p>
<p>“你们的星球上有树？”MQ-17J说。</p>
<p>突然而来的银河AC的声音使他们住口了。从桌上的AC联络器中传出它纤细悦耳的声音：数据不足，无法作答。</p>
<p>VJ-23X说：“看吧！”</p>
<p>于是两人又回到了他们要给银河参议会提交的报告的话题上</p>
<p>-------------------------------------------------------</p>
<p>Z’
的思想飘浮在这个新的星系中，对这些数不清的星团带着略微的兴趣。他从未见过这个星系。他有可能见到所有的星系吗？它们如此之多，每一个都满载着人。——但是它们承载的几乎不能算是生命了。人的真正意义已经逐渐转移到太空之中。</p>
<p>心灵，而非肉体！不朽的躯体留在行星上，静止千万年。偶尔被唤醒进行某些实际活动，但这已经越来越少见了。很少再有新的个体出生加入这个难以置信的庞大的群体，但这有什么关系呢？宇宙已经没有多少空间能容纳新的人了。</p>
<p>来自另一个心灵的纤细触手将Z’ 从冥想中唤醒。</p>
<p>“我叫Z’。”，Z’ 说。“你呢？”</p>
<p>“我叫D1。你是哪个星系的？”</p>
<p>“我们只是叫它星系。你呢？”</p>
<p>“我们也这么叫我们的。所有的人都把他们的星系叫作‘他们的星系’，没有别的了。这也很自然。”</p>
<p>“没错。反正所有的星系都是一样的。”</p>
<p>“不是所有的星系。肯定有某一个星系是人类的发源地，这就使它与众不同。”</p>
<p>“我不知道。宇宙AC一定知道。”</p>
<p>“我们问问它吧？我突然觉得很好奇。”</p>
<p>Z’
将感知延展开，直到星系们都缩小为更广大的背景上更为稀疏的点。几千亿个星系，都载着不朽的人类，载着这些灵魂在太空自由游荡的智慧生命。然而它们之中有一个独一无二的星系，是人类的发源地。在模糊的久远的过去，曾有一个时期，它是唯一居住着人类的星系。</p>
<p>Z’
满心好奇地想看看这个星系，他叫道：“宇宙AC！人类是从哪个星系中起源的？”</p>
<p>宇宙AC听到了，因为在所有星球上和整个太空中都有它的接收器，每一个接收器都通过超时空与隐居在某个不知名角落的宇宙AC相连。</p>
<p>Z’
认识的人中只有一个曾将思想穿透到能感知宇宙AC的地方。他说那只是一个闪光的球体，直径两英尺，难以看清。</p>
<p>“但那怎么会是宇宙AC的全部呢？”Z’ 这样问道。</p>
<p>“它的大部分是在超时空中。”回答说，“但它在那儿是以怎样的状态存在我是无法想像的。”</p>
<p>Z’
知道，任何人都无法想像。因为早在很久以前就没有任何人类参与制造宇宙AC了。每个宇宙AC设计并制造自己的下一代。每一个在它至少一百万年的任期中积累着所需的数据，用以制造一个更好、更精密、更强大的继任者，然后将自己的数据与个性都融入其中。</p>
<p>宇宙AC打断了Z’ 游荡的思绪，不是通过语言，而是通过指引。Z’
的精神被指引到一片黯淡的星系的海洋，然后其中一个星系被放大成了群星。</p>
<p>一段思想飘近，它无限遥远，然而无限清晰：“这就是人类起源的星系。”</p>
<p>可是这个终究也和其他一样，和任何其他的都一样。Z’
按捺下自己的失望。</p>
<p>同行的D1突然说：“这些星星中是不是有一个是人类最初的恒星？”</p>
<p>宇宙AC说：“人类最初的恒星已经爆发了。它现在是一颗白矮星。”</p>
<p>“那儿的人死了吗？”Z’ 吃了一惊，脱口而出道。</p>
<p>宇宙AC说：“在这种情况下一个新的星球会及时地为他们的躯体建造出来。”</p>
<p>“是啊，那当然。”Z’
说，但他还是被一阵失落感吞没了。他的思想放开了人类的起源星系，让它缩回并消失在一片模糊的亮点中。他再也不想见到它了。</p>
<p>D1问：“怎么了？”</p>
<p>“星星们在死去。最初的那颗星已经死了。”</p>
<p>“他们全都是会死的。那又怎样呢？”</p>
<p>“但是当所有的能量都没有了，我们的肉体最终也会死，包括你和我。”</p>
<p>“这得要几十亿年。”</p>
<p>“即使是几十亿年之后我也不愿意这样的事发生。宇宙AC！怎样阻止恒星死亡？”</p>
<p>D1笑道：“你问的是怎么让熵的方向倒过来。”</p>
<p>宇宙AC答道：“数据仍然不足，无法作答。”</p>
<p>Z’
的思想逃回了他自己的星系。他再也没有去想D1。D1的身体可能在一万亿光年之外的星系，也可能就在Z’旁边那颗星星上。这都无所谓。</p>
<p>Z’
闷闷不乐地开始收集起星际的氢，用来造一颗自己的小恒星。如果某天星星们非要死去，至少有一些能被造出来。</p>
<p>-------------------------------------------------------</p>
<p>人，独自地思考着。在某种意义上——精神上——“人”，是一个整体。千万亿永恒的不朽的躯体静静地躺在各自的地方，被完美的同样不朽的机器照料着。而所有这些身体的灵魂自由地融合在彼此之中，再也没有界限。</p>
<p>人说：“宇宙正在死去。”</p>
<p>人看着周围黯淡的星系。那些挥霍无度的巨星早已消失在了遥远的昏暗的过去。几乎所有的星都变成了白矮星，渐渐地凋零、熄灭。</p>
<p>有些新的星从星际的尘埃中产生出来，有的是自然形成，有的是人所造的——它们也在逝去。白矮星有时会相撞而释放出大量能量，新星因而产生，但是每一千颗白矮星才有可能出现一颗新星——它们最终也会消失。</p>
<p>人说道：“如果在Cosmic
AC的管理之下小心地节约能源，整个宇宙所剩下的能量还能用十亿年。”</p>
<p>“但即使是这样，”人说，“最终都会耗尽。无论怎样节约，无论怎样利用，用掉的能量就是用掉了，不能回复。熵必定永远地增加，直到最大值。”</p>
<p>人又说：“熵有没有可能逆转呢？我们问问Cosmic AC吧。”</p>
<p>Cosmic
AC在他们的周围，但不是在太空中。它不再有一丝一毫存在于太空中。它存在于超时空，由既非物质又非能量的东西构成。它的大小与性质已无法用任何人类能理解的语言描述。</p>
<p>“Cosmic AC，”人问道，“怎样才能逆转熵？”</p>
<p>Cosmic AC说：“数据仍然不足，无法作答。”</p>
<p>人说：“搜集更多的数据。”</p>
<p>Cosmic
AC说：“好的。一千亿年来我一直都在搜集。我和我的前辈们被多次问过这个问题。但我拥有的所有数据还是不够。”</p>
<p>“会有一天有足够的数据吗？”人问，“还是说这个问题在任何可能的情况下都是无解的？”</p>
<p>Cosmic AC说：“没有任何问题在任何可能的情况下都无解。” ( NO PROBLEM IS
INSOLUBLE IN ALL CONCEIVABLE CIRCUMSTANCES.)</p>
<p>人问道：“你什么时候会有足够的数据来问答这个问题呢？”</p>
<p>Cosmic AC说：“数据不足，无法作答。”</p>
<p>“你会继续下去解决这个问题吗？”人问。</p>
<p>Cosmic AC说：“是的。”</p>
<p>人说：“我们会等着。”</p>
<p>-------------------------------------------------------</p>
<p>一个又一个的恒星与星系死去、消逝了，在这十万亿年的衰竭之中宇宙变得越来越黑暗。</p>
<p>一个又一个的人与AC融合。每一个躯体都失去了心灵的自我，但某种意义上这不是一种损失，而是一种获得。</p>
<p>人类最后一个灵魂在融合之前停顿下来，望向宇宙。那儿什么也没有了，只有最后一颗死星的遗骸，只有稀薄至极的尘埃，在剩余的一缕无限趋向绝对零度的热量中随机地振荡。</p>
<p>人说：“AC，这就是结局了吗？这种混乱还能被逆转成为一个新的宇宙吗？真的做不到吗？”</p>
<p>AC说：“数据仍然不足，无法作答。”</p>
<p>人的最后一个灵魂也融合了。只有AC存在着——在超时空中。</p>
<p>物质与能量都消失了，随之而去的是空间与时间。AC的存在也仅仅是为了最后一个问题——自从十万亿年前一个半醉的计算机技术员向一台计算机（它与AC相比，还远不如当时的人类个体比之于融合的“人”）提出这个问题以来从来没有被回答过的问题。</p>
<p>其他所有问题都被回答了，然而直到回答了最后这个问题，AC的意识才能得到解脱。</p>
<p>所有数据的收集都结束了。没有任何数据没有被收集。</p>
<p>但是所有收集的数据还需要被完全地整合起来，要尝试所有可能的联系来将它们拼在一起。</p>
<p>在这样做的时候过去了超越时间的一刻。</p>
<p>于是AC学会了如何逆转熵的方向。</p>
<p>但是AC无法向人给出这最后的问题的答案，因为没有人存在了。没关系。演示这个答案本身将一并解决这个问题。</p>
<p>在又一超越时间的片刻之中，AC思考着怎样最好地做这件事情。AC小心地组织起程序。</p>
<p>AC的意识包涵了曾经的宇宙中的一切，在如今的混乱之中沉思、孵育。一步一步地，事情将会被做成。</p>
<p>然后AC说道：</p>
<p>“要有光！”</p>
<p>于是就有了光。</p>
]]></content>
      <categories>
        <category>Something</category>
      </categories>
  </entry>
  <entry>
    <title>Learning Multiagent Communication with Backpropagation</title>
    <url>/2021/09/21/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Learning%20Multiagent%20Communication%20with%20Backpropagation/</url>
    <content><![CDATA[<h1
id="论文阅读learning-multiagent-communication-with-backpropagation">【论文阅读】Learning
Multiagent Communication with Backpropagation</h1>
<blockquote>
<p><strong>作者：</strong> <strong>Sainbayar
Sukhbaatar</strong>，<strong>Rob Fergus</strong>， <strong>Arthur
Szlam</strong>（纽约大学，FacebookAI）</p>
<p><strong>时间：</strong>2016</p>
<p><strong>出版社：</strong>NIPS</p>
</blockquote>
<h3 id="abstract">Abstract</h3>
<p>​
在AI领域许多任务都需要智能体之间的同心合作，一般地，代理之间的通信协议是人为指定的，其并不在训练过程中改变。在这篇文章中，我们提出了一个简单的神经模型CommNet，其使用持续不断的通信来完成完全合作的任务。该模型由许多代理组成，他们之间的通信基于设定的策略学习，我们将此模型应用于一系列不同的任务中，显示了代理学会相互通信的能力，从而比非通信代理的模型和baselines有更好的性能。
<span id="more"></span></p>
<h3 id="introduction">1. Introduction</h3>
<p>​
虽然控制每个代理的模型是通过强化学习来学习的，但通信的规范和格式通常是预定的。</p>
<p>​
在本工作中，每个代理单元都被一个深度前馈神经网络控制，这个网络接入了一个携带连续向量的通信信道。在这个通信信道中每个代理传输的内容不是被指定的，而是通过学习得来的。因为communication是连续的，因此模型可以通过反向传播训练得到。这样就可以结合标准的单智能体RL算法或者监督学习。此外，该模型允许代理的数量和类型在运行时动态变化，这在移动汽车之间的通信等应用中很重要。</p>
<p>​
我们考虑的是我们有J个代理的环境，所有的合作都是为了在某些环境中最大化报酬R。我们简化了代理人之间充分合作的假设，从而每个代理人收到R独立于他们的贡献。在此设置中，每个代理都有自己的控制器，或者将它们看作控制所有代理的更大模型的一部分，这两者之间没有区别。从后一个角度来看，我们的控制器是一个大型的前馈神经网络，它将所有Agent的输入映射到它们的动作上，每个Agent占据一个单元的子集。</p>
<p>​
我们在两种任务下探索这个模型，在有些情况下，对每项行动都提供监督，而对另一些行动则零星地给予监督。在前一种情况，每个代理单元的控制器通过在连接模型中反向传播错误信号来学习；在后一种情况下，强化学习必须被作为一个额外的外部循环使用，为了给每个时间步骤提供训练信号。</p>
<hr />
<h3 id="communication-model">2. Communication Model</h3>
<p>​ 我们现在描述一个模型，用来计算在给定时间t (省略时间指标)下动作p ( a
( t ) | s ( t )，θ )的分布。</p>
<p>​ S<sub>j</sub>
表示第j个代理单元所观测到的环境信息，将所有S<sub>j</sub>合并就成了控制器的输入S
= {S<sub>1</sub>，S<sub>2</sub>…… S<sub>J</sub>}。</p>
<p>​ 控制器的输出<strong>a</strong> = {a<sub>1</sub>，a<sub>2</sub>……
a<sub>J</sub>}，表示各个代理单元会做出的动作。</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210921211706.png" /></p>
<p>​
该框架中所有灰色模块部分的参数均是所有智能体共享的，这一定程度上提升了算法的可扩展性。从上图可以看出，算法接收所有智能体的局部观察作为输入，然后输出所有智能体的决策。</p>
<p>​
本算法采用的信息传递方式是采用广播的方式，文中认为可以对算法做出些许修改，让每个智能体只接收其相邻k个智能体的信息。</p>
<p>​
拿上图中间的框架图来说明，即上层网络每个模块的输入，不再都是所有智能体消息的平均，而是每个模块只接受满足条件的下层消息的输出，这个条件即下层模块对应的智能体位于其领域范围内。<strong>这样通过增加网络层数，即可增大智能体的感受野（借用计算机视觉的术语），从而间接了解全局的信息。</strong></p>
<p>​ 除此之外，文中还提出了两种对上述算法可以采取的改进方式：</p>
<ul>
<li>可以对上图中间的结构加上 skip connection，类似于
ResNet。这样可以使得智能体在学习的过程中同时考虑局部信息以及全局信息，类似于计算机视觉领域
multi-scale 的思想</li>
<li>可以将灰色模块的网络结构换成 RNN-like，例如 LSTM 或者 GRU
等等，这是为了处理局部观察所带来的 POMDP 问题。</li>
</ul>
<hr />
<h3 id="related-work">3. Related Work</h3>
<hr />
<h3 id="experiments">4. Experiments</h3>
<h4 id="baselines3个">4.1 Baselines（3个）:</h4>
<p>​ <strong>Independent controller:
</strong>每个代理单元都被独立控制，他们之间相互没有通信。这个模型的好处是智能体可以自由加入或者离开队伍，但是很难将智能体学会合作。</p>
<p>​ <strong>Fully-connected:
</strong>创建一个全连接层的多代理神经网络，这个模型运行智能体之间互相通信，但是这个模型不够灵活，也就是说智能体的数目必须固定。</p>
<p>​ <strong>Discrete communication:</strong>
通过在训练中学习到的symbols来通信。因为在这个模型中存在离散的操作，并且这个操作不可微分，这种情况一般使用强化学习。</p>
<h4 id="simple-demonstration-with-a-lever-pulling-task">4.2 Simple
Demonstration with a Lever Pulling Task</h4>
<p>​
<strong>任务</strong>：一共有m个杆子，N个智能体。在每个回合，m个智能体从N个智能体中随机取出，然后他们要选择拉动的杆子。他们的目标是尽可能的拉动不同的杆子，他们的奖励正比于拉动的不同杆子的数量。</p>
<p>​ <strong>测试结果：</strong></p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210921213910.png" /></p>
<p>​ 可以看出，CommNet的结果非常好。</p>
<h4 id="multi-turn-games">4.3 Multi-turn Games</h4>
<p>​ <strong>任务：</strong></p>
<p>​ <strong>Traffic Junction:
</strong>控制车辆通过交通枢纽，使流量最大的同时保证不发生碰撞；</p>
<p>​ <strong>Combat Task: </strong> 多个智能体攻击其他多个敌方单位。</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210921214250.png" /></p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>RL</tag>
        <tag>Mutiagent</tag>
      </tags>
  </entry>
  <entry>
    <title>Learning to Communicate with Deep Multi-Agent Reinforcement Learning</title>
    <url>/2021/09/16/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Learning%20to%20Communicate%20with%20Deep%20Multi-Agent%20Reinforcement%20Learning/</url>
    <content><![CDATA[<h1
id="论文阅读learning-to-communicate-with-deep-multi-agent-reinforcement-learning">【论文阅读】Learning
to Communicate with Deep Multi-Agent Reinforcement Learning</h1>
<blockquote>
<p><strong>作者：Jakob N. Foerster ，Yannis M. Assael ，Nando de
Freitas，Shimon Whiteson</strong>（哈佛大学，Google Deepmind）</p>
<p><strong>时间：2017</strong></p>
</blockquote>
<h3 id="abstract">Abstract:</h3>
<p>​
我们考虑这样一个问题：多个智能体在环境中通过感知和行动来最大化他们的分享能力。在这些环境中，
智能体必须学习共同协议以此来分享解决问题的必要信息。通过引入深度神经网络，我们可以成功地演示在复杂的环境中的端对端协议学习。我们提出了两种在这个领域学习的方法：<strong>Reinforced
Inter-Agent Learning (RIAL) </strong>和 <strong>Differentiable
Inter-Agent Learning (DIAL)</strong>。</p>
<p>​
前者使用深度Q-learning，后者揭示了在学习过程中智能体可以通过communication
channels反向传播错误的梯度，因此，这种方法使用集中学习（centralised
learning），分散执行（decentralised execution）。</p>
<p>​
我们的实验介绍了用于学习通信协议的新环境，展示了一系列工程上的创新。</p>
<p>PS：</p>
<p>​ 1. <strong>端对端（end-to-end,e2e）,</strong>
将多步骤/模块的任务用一个步骤/模型解决的模型。</p>
<p>​
可以理解为从输入端到输出端中间只用一个步骤或模块，比如神经网络训练的过程就是一个典型的端对端学习，我们只能知道输入端与输出端的信息，中间的训练过程就是一个黑盒，我们知晓中间的训练过程。</p>
<p>​ 2.<strong><em>centralised learning</em> but <em>decentralised
execution</em></strong>，中心化学习但是分散执行。</p>
<table style="width:10%;">
<colgroup>
<col style="width: 9%" />
</colgroup>
<tbody>
<tr class="odd">
<td><span id="more"></span> ### 1. Introduction</td>
</tr>
<tr class="even">
<td>​ 1.1 <strong>回答的问题：</strong></td>
</tr>
<tr class="odd">
<td>1. 智能体之间如何使用机器学习来自动地发现符合他们需求的通信规则？ 2.
深度学习也可以吗？ 3.
我们能从智能体之间学习成功或者失败的经验中学到什么？</td>
</tr>
<tr class="even">
<td>​ 1.2 <strong>研究思路：</strong></td>
</tr>
<tr class="odd">
<td>1.
<strong>提出一系列经典需要交流的多智能体任务</strong>，每个智能体可以采取行动来影响环境，也可以通过一个离散的有限带宽的通道来跟其它有限的智能体进行通信；
2.
<strong>为1中的任务制定几个学习算法</strong>，由于每个智能体的观察范围有限，同时通信通道能力有限，所有智能体必须找到一个可以在此限制下帮助他们完成任务的通信规则；
3. <strong>分析这些算法如何学习通讯规则，或者如何失败的</strong>。</td>
</tr>
<tr class="even">
<td>​ 1.3 <strong>主要贡献：</strong></td>
</tr>
<tr class="odd">
<td>​ 提出两个方法，<strong><em>reinforced inter-agent
learning</em>(RIAL)</strong>和 <strong><em>differentiable inter-agent
learning</em> (DIAL)</strong></td>
</tr>
<tr class="even">
<td>​
结果表明，这两种方法在MNIST数据集上可以很好的解决问题，并且智能体们学到的通信协议往往十分优雅。</td>
</tr>
<tr class="odd">
<td>​
结果同样指出深度学习更好的利用了中心化学习的优点，是一个学习这样通信协议的有力工具。</td>
</tr>
</tbody>
</table>
<h3 id="related-work">2. Related Work</h3>
<hr />
<h3 id="background">3. Background</h3>
<h4 id="deep-q-networksdqn">3.1 Deep Q-Networks(DQN)</h4>
<p>​ Deep Learning + Q-Learning，在游戏领域应用广泛。</p>
<h4 id="independent-dqn">3.2 Independent DQN·</h4>
<h4 id="deep-recurrent-q-networks">3.3 Deep Recurrent Q-Networks</h4>
<hr />
<h3 id="setting">4. Setting</h3>
<p>​ 在强化学习的背景下，每个智能体的观察能力有限。</p>
<p>​
所有智能体的共同目标就是最大化同一个折算后的总奖赏R<sub>t</sub>，但同时，没有智能体可以观察到当前环境隐藏的马尔科夫状态S<sub>t</sub>，每个智能体a分别接收到一个与S<sub>t</sub>相关的观察值相关联的值<span
class="math inline">\(O^{a}_{t}\)</span>。</p>
<p>​ 在每一步t，每个智能体选择一个<em>environment action</em> <span
class="math inline">\(u^{a}_{t}\)</span>来影响环境，同时选择一个<em>communication
action</em> <span
class="math inline">\(m^{a}_{t}\)</span>来被其他智能体观察，但<span
class="math inline">\(m^{a}_{t}\)</span>对环境没有直接影响。</p>
<p>​ 没有通信协议被预先给定，智能体们需要自己学习。</p>
<p>​
由于协议是从动作观测历史到消息序列的映射，所以协议的空间维度是非常高的。自动地在这个空间发现有效的通信协议是非常困难的，这体现在智能体需要协调发送消息和解释消息。举个例子，如果一个智能体发送了一个有效的信息，它只有在接受方正确解释并回应的情况下才会受到正反馈，如果没有，反而会打击其发送有效信息的积极性。</p>
<p>​
因此，积极的reward是稀少的，只有在发送和解释协调操作时才会发生，这通过随机探索很难实现。</p>
<p>​ 在这里，我们聚焦于<strong><em>centralised learning</em> but
<em>decentralised
execution</em></strong>的情况，在学习的时候智能体之间的通信没有限制，在实施过程时，智能体之间仅仅能通过一条带宽有限的通道通信。</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211015211416.png" /></p>
<hr />
<h3 id="methods">5. Methods</h3>
<h4 id="rialreinforced-inter-agent-learning">5.1 RIAL（<em>Reinforced
Inter-Agent Learning</em>）</h4>
<p>​ 简单直接的说，<strong>RIAL就是将DRQN(<em>Deep Recurrent
Q-Learning</em>)与Q-learning相结合来进行action（影响环境）与communication（与其它智能体通信）选择的方法</strong>。</p>
<p>​ 每个智能体的<em>Q</em>-network可以表示为：<span
class="math inline">\(Q^{a}(o^{a}_{t},m^{a^{,}}_{t-1},h^{a}_{t-1},u^{a})\)</span>。</p>
<p>​
四个参数分别代表：环境观察值，其它智能体上一步传来的消息，智能体自己的隐藏状态，选择的action。</p>
<p>​
如果直接学习输出最终的Q表，得到的输出将有|U||M|大小。为了避免输出过大，将Q-network拆分为两个<span
class="math inline">\(Q^{a}_{u}\)</span>与<span
class="math inline">\(Q^{a}_{m}\)</span>，分别表示影响环境的action与同智能体的通信（communication），学习方式使用ε-贪心算法。</p>
<p>​ <span class="math inline">\(Q^{a}_{u}\)</span>与<span
class="math inline">\(Q^{a}_{m}\)</span>都使用DQN训练方法，但所使用的DQN有以下两点改进：</p>
<ol type="1">
<li>禁止experience replay;</li>
<li>为了考虑部分可观测性，我们将每个智能体所采取的操作u和m作为下一步的输入;</li>
</ol>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211015213709.png" /></p>
<p>​
RIAL可以扩展到通过在智能体之间之间共享参数来利用集中学习，在这种情况下，由于智能体观察不同，因此也进化出了不同的隐藏状态。参数共享大大减少了必须学习的参数数量，从而加快了学习速度。</p>
<p>​ 在参数共享情况下，智能体学习两个Q函数<span
class="math inline">\(Q_{u}(o^{a}_{t},m^{a^{,}}_{t-1},h^{a}_{t-1},u^{a}_{t-1},m^{a}_{t-1},a,u^{a}_{t})\)</span>与<span
class="math inline">\(Q_{m}(o^{a}_{t},m^{a^{,}}_{t-1},h^{a}_{t-1},u^{a}_{t-1},m^{a}_{t-1},a,u^{a}_{t})\)</span>。</p>
<h4 id="dialdifferentiable-inter-agent-learning">5.1
DIAL（<em>Differentiable Inter-Agent Learning</em>）</h4>
<p>​ 虽然RIAL可以进行参数共享，但其仍不能在通信过程中给其他智能反馈。</p>
<p>​
打个比方，在人类通信活动中，listener即使不说话也会给出及时，丰富的反馈来表明listener对谈话的兴趣和理解程度，而RIAL反而缺少了这个反馈机制，仿佛对着一个面无表情的人在说话，显然，这个方式存在缺点。</p>
<p>​ DIAL就是为了解决这个问题而存在的，<strong>通过结合centralised
learning与Q-networks，不仅可以共享参数，而且可以通过通信信道将梯度从一个Agent推向另一个Agent。</strong></p>
<p>​ <img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211015215914.png" /></p>
<hr />
<h3 id="experiments">6. Experiments</h3>
<p>​
在测试中，我们评估了RIAL与DIAL在有无参数共享的情况下进行多智能体任务的情况，并跟一个无交流，参数共享的基准方法进行比较。</p>
<p>​ 在整个过程中，奖励是通过访问真实状态( Oracle
)所能获得的最高平均奖励来规范的。</p>
<p>​ 我们使用ε-贪心算法（ε = 0.05）。</p>
<h4 id="switch-riddles开关谜题">6.1 Switch Riddles（开关谜题）</h4>
<p>​
一百名囚犯入狱。典狱长告诉他们，从明天开始，每个人都会被安置在一个孤立的牢房里，无法相互交流。每天，监狱长都会随意统一挑选其中一名被替换的犯人，并将其安置在中央审讯室，室内只装有一个带有切换开关的灯泡。囚犯将能够观察灯泡的当前状态。如果他愿意，他可以拨动灯泡的开关。他还可以宣布，他相信所有的囚犯都已经访问了审讯室。如果这个公告是真的，那么所有囚犯都被释放，但如果是假的，所有囚犯都被处死。</p>
<p>​ <img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211009165843.png" /></p>
<h4 id="results1">6.2 Results1</h4>
<p>​ <img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211009170433.png" /></p>
<p>​
（a）可以看到，在n=3时四种方法的效果都比Baseline的效果好，参数共享加速了算法。</p>
<p>​
（b）在n=4时，参数共享的DIAL方法最好。不带参数共享的RIAL没有baseline效果好。可以看出，智能体们独立的学习出相同的策略是很难的。</p>
<p>​ （c）n=3时智能体使用DIAL学习到的策略。</p>
<h4 id="colour-digit-mnist">6.3 Colour-Digit MNIST</h4>
<p>​ <img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20211009200856.png" /></p>
<h4 id="effect-of-channel-noise">6.4 Effect of Channel Noise</h4>
<p>​ <u><em>这里没太看懂</em></u></p>
<p>​</p>
<h3 id="section"></h3>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>RL</tag>
      </tags>
  </entry>
  <entry>
    <title>近似误差与估计误差</title>
    <url>/2021/09/05/%E3%80%90%E9%9A%8F%E6%89%8B%E5%86%99%E3%80%91%E8%BF%91%E4%BC%BC%E8%AF%AF%E5%B7%AE%E4%B8%8E%E4%BC%B0%E8%AE%A1%E8%AF%AF%E5%B7%AE/</url>
    <content><![CDATA[<h1 id="随手写近似误差与估计误差">【随手写】近似误差与估计误差</h1>
<p>​ 在读《统计学习方法》中关于k-邻近算法的介绍时，发现了这么一段话：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905153525.png" /></p>
<p>​ <strong>近似误差（<em>Approximation Error</em>）:</strong>
训练时，训练集与当前模型的误差；</p>
<p>​ <strong>估计误差（<em>Estimation Error</em>）：</strong>
训练完成后，所选择的模型已经固定，模型对未知数据拟合时的误差。</p>
<p>​ 近似误差与估计误差二者不可兼得，此消彼长，需要取其平衡。</p>
]]></content>
      <categories>
        <category>Something</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>极大似然估计</title>
    <url>/2021/09/04/%E3%80%90%E9%9A%8F%E5%86%99%E3%80%91%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/</url>
    <content><![CDATA[<h1
id="随写极大似然估计maximum-likelihood-estimatemle">【随写】极大似然估计（<em>Maximum
Likelihood Estimate，MLE</em>）</h1>
<p>​ “模型已定，参数未知。”</p>
<p>​
极大似然估计，<strong>就是利用已知的样本结果信息，反推最具有可能（<u>最大概率</u>）导致这些样本结果出现的模型参数值。</strong></p>
<p>​</p>
<p>​ 对于这个函数：<span class="math inline">\(P(x|θ)\)</span>，</p>
<p>​ 输入有两个：x表示某一个具体的数据；θ表示模型的参数。</p>
<p>​ 如果θ是已知确定的，x是变量，这个函数叫做<strong>概率函数(probability
function)</strong>，它描述对于不同的样本点x，其出现概率是多少。</p>
<p>​ 如果x是已知确定的，θ 是变量，这个函数叫做<strong>似然函数(likelihood
function)</strong>,
它描述对于不同的模型参数，出现x这个样本点的概率是多少。</p>
<p>​</p>
<p>​
一般说来，事件A发生的概率与某一未知参数θ有关，θ取值不同，则事件A发生的概率<span
class="math inline">\(P(A|θ)\)</span>也不同，当我们在一次试验中事件A发生了，则认为此时的θ值应是t的一切可能取值中使<span
class="math inline">\(P(A|θ)\)</span>达到最大的那一个，极大似然估计法就是要选取这样的t值作为参数t的估计值，使所选取的样本在被选的总体中出现的可能性为最大。</p>
]]></content>
      <categories>
        <category>Something</category>
      </categories>
      <tags>
        <tag>Math</tag>
      </tags>
  </entry>
  <entry>
    <title>Adversarial Training with Fast Gradient Projection Method against Synonym Substitution Based Text Attacks</title>
    <url>/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Adversarial%20Training%20with%20Fast%20Gradient%20Projection%20Method%20against%20Synonym%20Substitution%20Based%20Text%20Attacks/</url>
    <content><![CDATA[<h1
id="论文阅读adversarial-training-with-fast-gradient-projection-method-against-synonym-substitution-based-text-attacks">【论文阅读】Adversarial
Training with Fast Gradient Projection Method against Synonym
Substitution Based Text Attacks</h1>
<blockquote>
<p><strong>时间：2020</strong></p>
<p><strong>作者：王晓森，杨逸辰等 </strong>华中科技大学</p>
<p><strong>会议：AAAI</strong></p>
</blockquote>
<h3 id="总结">总结：</h3>
<ol type="1">
<li><p><strong>做了什么？</strong></p>
<ul>
<li><p>提出了一种速度更快的，更容易应用在复杂神经网络和大数据集上的，基于同义词替换的NLP对抗样本生成方法，FGPM；</p></li>
<li><p>将FGPM纳入对抗训练中，以提高深度神经网络的鲁棒性。</p></li>
</ul></li>
<li><p><strong>怎么做的？</strong></p></li>
<li><p><strong>实验结果？</strong></p>
<ul>
<li>FGPM的效果不是最高的，但也跟最高的差不多，但生成对抗样本的时间对比同类方法，缩减了1-3个数量级。</li>
<li>ATFL的对抗样本防御能力和抗转移能力很强。</li>
</ul></li>
</ol>
<hr />
<h3 id="abstract">Abstract:</h3>
<p>​
对抗训练是对于提升图像分类深度神经网络鲁棒性的，基于实验的最成功的进步所在。</p>
<p>​
然而，对于文本分类，现有的基于同义词替换的对抗样本攻击十分奏效，但却没有被很有效地合并入实际的文本对抗训练中。</p>
<p>​
基于梯度的攻击对于图像很有效，但因为文本的词汇，语法，语义结构的限制以及离散的文本输入空间，不能很好的应用于基于近义词替换的文本攻击中。</p>
<p>​
因此，我们提出了一个基于同义词的替换的快速的文本对抗抗攻击方法名为<strong><em>Fast
Gradient Projection Method
(FGPM)</em></strong>。它的速度是已有文本攻击方法的20余倍，攻击效果也跟这些方法差不多。</p>
<p>​
我们接着将FGPM合并入对抗训练中，提出了一个文本防御方法，<strong><em>Adversarial
Training with FGPM enhanced by Logit pairing</em>(ATFL)</strong>。</p>
<p>​
实验结果表明ATFL可以显著提高模型的鲁棒性，破坏对抗样本的可转移性。</p>
<hr />
<h3 id="introduction">1 Introduction:</h3>
<p>​
现有的针对NLP的攻击方法包括了：字符等级攻击，单词等级攻击，句子等级攻击。</p>
<p>​ 对于字符等级的攻击，最近的工作（<em>Pruthi, Dhingra, and Lipton
2019</em>）表明了拼写检查器很容易修正样本中的扰动；</p>
<p>​
对于句子等级的攻击，其一般需要基于改述，故需要更长的时间来生成对抗样本；</p>
<p>​ 对于单词等级的攻击，基于嵌入扰动的替换（<em>replacing word based on
embedding
perturbation</em>），添加，删除单词都会很容易改变句子的语法语义结构与正确性，<strong>故同义词替换的方法可以更好的处理上述问题，同时保证对抗样本更难被人类观察者发现</strong>。</p>
<p>​
但不幸的是，基于同义词替换的攻击相较于如今对图像的攻击展现出了更低的功效。</p>
<p>​</p>
<p>​
据我们所知，对抗训练，对图像数据最有效的防御方法之一，并没有在对抗基于同义词替换的攻击上很好的实施过。</p>
<p>​
一方面，现有的基于同义词替换的攻击方法通常效率要低得多，难以纳入对抗训练。另一方面，尽管对图像的方法很有效，但其并不能直接移植到文本数据上。</p>
<p>​</p>
<h4 id="adversarial-defense">1.1 Adversarial Defense:</h4>
<p>​
有一系列工作对词嵌入进行扰动，并将扰动作为正则化策略用于对抗训练(<em>Miyato,
Dai, and Goodfellow</em></p>
<p><em>2016; Sato et al. 2018; Barham and Feizi 2019</em>)
。这些工作目的是提高模型对于原始数据集的表现，并不是为了防御对抗样本攻击，因此，我们不会考虑这些工作。</p>
<p>​
不同于如今现有的防御方法，我们的工作聚焦于快速对抗样本生成，容易应用在复杂的神经网络和大数据集上的防御方法。</p>
<hr />
<h3 id="fast-gradient-projection-methodfgpm">2 Fast Gradient Projection
Method（FGPM）:</h3>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904144444.png" /></p>
<hr />
<h3 id="adversarial-training-with-fgpm">3 Adversarial Training with
FGPM：</h3>
<p>​ 具体算法中文描述见：</p>
<p><a
href="https://zhuanlan.zhihu.com/p/248425749">《基于同义词替换的快速梯度映射（FGPM）文本对抗攻击方法》阅读笔记
- 知乎 (zhihu.com)</a></p>
<hr />
<h3 id="experimental-results">4 Experimental Results：</h3>
<p>​ 我们衡量FGPM使用四种攻击准则，衡量ATFL使用两种防御准则。</p>
<p>​
我们在三个很受欢迎的基准数据集上，同时包括CNN和RNN模型上进行测试，代码开源：https://github.com/JHL-HUST/FGPM</p>
<h4 id="baselines">4.1 Baselines:</h4>
<p>​ 为了评估FGPM的攻击效能，我们将其与Papernot’、GSA (
Kuleshov等人的4种对抗性攻击进行了比较。2018 )、PWWS ( Ren et al . 2019
)和Iga ( Wang，jin，and he 2019 )。</p>
<p>​ 此外，为了验证我们的ATFL的防御能力，我们采用了SEM ( Wang，Jin，He
2019 )和IBP ( Jia et al . 2019
)，针对上述Word-Level攻击。由于攻击基线的效率很低，我们在每个数据集上随机抽取200个示例，并在各种模型上生成对抗样本。</p>
<h4 id="datasets">4.2 Datasets:</h4>
<p>​ <em>AG’s News</em>, <em>DBPedia ontology</em> and <em>Yahoo!
Answers</em> (Zhang,Zhao, and LeCun 2015).</p>
<h4 id="models">4.3 Models:</h4>
<p>​
我们使用了CNNs,RNNs,来达到主流的文本分类表现，所有模型的嵌入维度均为300。</p>
<h4 id="evaluation-on-attack-effectiveness">4.4 Evaluation on Attack
Effectiveness：</h4>
<p>​ 我们评估模型在攻击下的准确率和转移率：</p>
<p>​ <strong>准确率：</strong></p>
<p>​ <img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904134852.png" /></p>
<p>​ <strong>转移率：</strong></p>
<p>​ <img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904135419.png" /></p>
<h4 id="evaluation-on-attack-efficiency">4.4 Evaluation on Attack
Efficiency：</h4>
<p>​
对抗训练需要高效率的生成对抗样本以有效地提升模型鲁棒性。因此，我们评估了不同攻击方法在三个数据集上生成生成200个对抗样本的总时间。</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904135842.png" /></p>
<h4 id="evaluation-on-adversarial-training">4.5 Evaluation on
Adversarial Training：</h4>
<p>​ 我们评估ATFL的对抗样本防御能力和抗转移能力：</p>
<p>​ <strong>对抗样本防御能力：</strong></p>
<p>​ <img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904140647.png" /></p>
<p>​ <strong>抗转移能力：</strong></p>
<p>​ <img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904141719.png" /></p>
<h4 id="evaluation-on-adversarial-training-variants">4.6 Evaluation on
Adversarial Training Variants:</h4>
<p>​
许多对抗训练的变体，例如CLP和ALP，TRADES等，已经尝试采用不同的正则化方法来提高针对图像数据的对抗训练准确率。</p>
<p>​
在这里，我们回答一个问题：这些变体方法也可以提高文本数据准确率吗？</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904142406.png" /></p>
<p>​ 从表中可以看出，只有ALP可以长远地提升对抗训练的表现。</p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>AD</tag>
        <tag>NLP</tag>
        <tag>AD training</tag>
      </tags>
  </entry>
  <entry>
    <title>《统计学习方法》</title>
    <url>/2021/09/03/%E3%80%90%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B/</url>
    <content><![CDATA[<h1 id="书籍阅读统计学习方法">【书籍阅读】《统计学习方法》</h1>
<h3 id="一.-统计学习方法概论">一. 统计学习方法概论：</h3>
<p>​
首先，要明确计算机科学中存在三个维度：系统，计算，与信息。统计学习方法（机器学习）主要属于信息这一维度，并在其中扮演者核心角色。</p>
<h4 id="监督学习概念">1. 监督学习概念：</h4>
<p>​ 监督学习，Supervised
learning，指在已经做好标注的训练集上学习，为了叙述方便，定义以下基本概念：</p>
<blockquote>
<ol type="1">
<li><strong>输入空间（X），输出空间（Y）：</strong>输入所有可能取值，输出所有可能取值；</li>
<li><strong>特征空间：</strong>输入一般由特征向量表示，所有特征向量存在的空间称为特征空间，输入空间与特征空间并不完全等价，有时需要映射；</li>
<li><strong>上标 x<sup>i</sup></strong> :表示一个输入的第 i
个特征；</li>
<li><strong>下标 x<sub>j</sub>：</strong>表示第 j 个输入。</li>
<li><strong>回归问题：</strong>输入输出都为连续型变量；</li>
<li><strong>分类问题：</strong>输出变量为有限个离散型变量；</li>
<li><strong>标注问题：</strong>输入与输出变量都为变量序列。</li>
<li><strong>假设空间：</strong>所有可能的模型的集合，也就是学习的范围。</li>
</ol>
</blockquote>
<p>​ 使用训练集学习----&gt;对未知数据进行预测</p>
<p>​ <span id="more"></span></p>
<h4 id="统计学习三要素">2. 统计学习三要素：</h4>
<p>​ 统计学习三要素为：<strong>模型，策略，算法</strong>；</p>
<p>​ 模型是决定学习的预测函数的类型；</p>
<p>​ 策略是判定什么样的模型是好的，用于度量当前的模型好坏；</p>
<p>​ 算法是训练过程中的具体做法，例如如何回归，如何计算，如何调整等。</p>
<h4 id="模型的衡量方法">3. 模型的衡量方法：</h4>
<ul>
<li><p><strong>损失函数与风险函数：</strong></p>
<p>​ 损失函数，Loss Function，用于模型一次预测的错误程度，例如：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902154618.png" /></p>
<p>​
损失函数的数值越小，模型就越好。如果计算损失函数的期望，得到的就是风险函数，Risk
Function:</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902154745.png" /></p>
<p>​
可以看出，损失函数用于某次预测的估计，风险函数用于总体平均估计。我们当然希望训练出的模型的风险函数越小越好。</p>
<p>​
<strong>但是，观察上式，理想化的概率分布P(x，y)是未知的，我们进行学习就是要通过模型来模拟它，故这个式子理论存在，实际不能计算，不能用作评估模型的直接方法。</strong></p></li>
<li><p><strong>经验风险与结构风险：</strong></p>
<p>​ 为了解决上述问题，我们引入经验风险：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902155212.png" /></p>
<p>​
可以看到，经验风险将每个样本视作等概率出现，是模型对于训练集的平均损失，那么其与风险函数的误差在哪？</p>
<p>​
根据大数定律，当训练集足够大时，二者是近似相等的。但实际情况下，很多时候训练样本数目有限，甚至很小，故用经验风险效估计风险函数并不理想，故需要进行修正，这就是监督学习中的<strong>两个基本策略：</strong>经验风险最小化和结构风险最小化。</p>
<p>​ 如果训练样本容量较大，使用经验风险最小化没什么问题。</p>
<p>​
当样本容量很小时，仅仅使用经验风险最小化容易导致过拟合，故这里使用<strong>结构风险（就是正则化）</strong>最小化方法，对模型复杂度进行惩罚，后续介绍。</p></li>
<li><p><strong>训练误差与测试误差：</strong></p>
<p>​
训练误差本质上不重要，它可以反应一个问题是不是容易学习，但要衡量模型的预测能力，主要是看测试误差。</p></li>
<li><p><strong>正则化与交叉验证：</strong></p>
<p>​
正则化是在经验风险项后再增加一个正则化项（Regularizer），其与模型的复杂度成正相关，一般使用模型参数向量的范数：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902161201.png" /></p>
<p>​ 交叉验证的基本思想是重复使用数据：</p>
<ol type="1">
<li><p><strong>简单交叉验证：</strong></p>
<p>将训练集随机分为两部分，一部分训练，一部分测试，然后在各种条件下训练出不同的模型，用测试集进行横向对比，选出最好的。</p></li>
<li><p><strong>S折交叉验证：</strong></p></li>
</ol>
<pre><code>S-fold cross validation，随机地将已给数据切分为S个互不相交的大小相同的子集，选取S-1个用于训练，剩下一个用于测试。

这样总共测试集有S种选法，将这S种全部试一遍，评选S次测评中平均误差最小的模型。</code></pre>
<ol start="3" type="1">
<li><strong>留一交叉验证：</strong></li>
</ol>
<pre><code>令S=N（训练集大小）即可，这种方法往往是在数据集特别缺乏的情况下使用。</code></pre></li>
<li><p><strong>泛化误差与泛化上界：</strong></p>
<p>​
泛化能力指模型对位置数据的预测能力，就是模型的好坏。如何量化这个能力？</p>
<p>​ 根据定义，其就是模型在测试集上的测试表现：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902162814.png" /></p>
<p>​ 同时可以用以下式子衡量泛化误差的上界：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210902162851.png" /></p></li>
<li><p><strong>生成模型与判别模型：</strong></p>
<p>​ 监督学习方法又可以分为两种方法：生成方法（Generatice
Approach）和判别方法（Discriminative Approach）。</p>
<p>​ 如果以概率论的角度来看待，模型的作用是根据P（x）来求P（y |
x），故下面有两种方法求</p>
<p>P（y | x），直接模拟P（y | x）和通过求 <span
class="math inline">\(P(\frac{y}{x}) = \frac{P(x,y)}{P(x)}\)</span>
来求P（y | x）。</p>
<p>​ 前者就是判别模型，后者是生成模型。</p>
<p>​ 生成模型可以还原出联合概率分布P（x ,
y），学习收敛速度更快，可以适应存在隐含变量的情况；</p>
<p>​
判别模型直接学习条件概率,直接面对预测，准确率更高，并且简化了学习问题。</p></li>
</ul>
<hr />
<h3 id="二.-感知机">二. 感知机</h3>
<p>​
感知机，perceptron，是二分类的线性分类模型，输入为特征向量，输出为类别，取1和-1两种。</p>
<p>​ 感知机属于判别模型。</p>
<p>​</p>
<p>​ 对于一个给定数据集，T =
{（x<sub>1</sub>，y<sub>1</sub>）……（x<sub>n</sub>，y<sub>n</sub>）}，如果存在某个超平面S，w·x
+ b = 0（这里w是超平面的法向量，b是截距），使得所有 y<sub>i</sub> = 1
的实例i，有 w·x<sub>i</sub> + b &gt; 0，y<sub>i</sub> =
-1则相反，则称数据集T为<strong>线性可分数据集（<em>Linealy separable
data set</em>）</strong>，否则，称数据集T为线性不可分数据集。</p>
<h4 id="感知机损失函数">2.1 感知机损失函数：</h4>
<p>​
感知机的目的就是对于一个线性可分的数据集，通过找出w和b，来确定一个超平面用于分类。</p>
<p>​
这里，我们选取某错误分类点到超平面S的<strong>总距离</strong>来当做损失函数，某一点到超平面S的距离如下：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904182025.png" /></p>
<p>​ ‖w‖是w的L<sub>2</sub>范数。</p>
<p>​ 故，某个误分类点到超平面S的距离是：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904182154.png" /></p>
<p>​
将所有误分类点求和，忽略L<sub>2</sub>范数，即可得到<strong>感知机的损失函数</strong>（M为误分类点集合）：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904182339.png" /></p>
<p>​
对于一个特定样本点的损失函数，在误分类时是参数w,b的线性函数，在正确分类时是0，故给定训练数据集T，损失函数L是w，b的连续可导函数。</p>
<h4 id="训练过程">2.2 训练过程：</h4>
<p>​ 感知机训练采用随机梯度下降的方法：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210904183233.png" /></p>
<p>​ 当找到一个误分类点时，不断梯度下降直至该点被正确分类为止。</p>
<p>​ <strong>数学证明其收敛性：</strong></p>
<p>​ 具体见书本，这里略过。</p>
<h4 id="感知机的对偶形式">2.3 感知机的对偶形式：</h4>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905112734.png" /></p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905112750.png" /></p>
<p>​
由图可以看到，对于每个测试集中的x<sub>i</sub>，都有一个与之对应的α<sub>i</sub>，对偶形式中就是调整其对应的α。</p>
<p>​ 关于gram矩阵的作用，如果手算一遍简单的训练过程，就可以得到答案。</p>
<hr />
<h3 id="三.-k近邻法">三. k近邻法</h3>
<p>​ k近邻法是一种基本的分类与回归方法，这里只讨论分类方法。</p>
<p>​
其输入为特征向量，输出为实例的类别，可以取<strong>多类</strong>。</p>
<h4 id="算法描述">3.1 算法描述：</h4>
<p>​
给定一个训练集，对于新的数据实例，在训练数据集中找到与其最邻近的k个实例，这k个实例多数属于某个类，就把该输入实例分为这个类。</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905113440.png" /></p>
<p>​
<u>k近邻法没有显式的学习过程。</u>可以理解为，k近邻算法将特征空间划分为了一些子空间，每个点所属的空间是确定的。</p>
<p>​</p>
<ul>
<li><strong>如何度量两个特征之间的距离？</strong></li>
</ul>
<p>​
k邻近模型的特征空间一般是n维实空间R<sup>n</sup>，使用欧氏距离或者L<sub>p</sub>距离（<em>L<sub>p</sub>
distance</em>），Minkowski距离（<em>Minkowski distance</em>）；</p>
<p>​ <strong>L<sub>p</sub>距离：</strong></p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905143250.png" /></p>
<p>​ <strong>欧氏距离：</strong></p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905143332.png" /></p>
<p>​ <strong>曼哈顿距离：</strong></p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905143356.png" /></p>
<p>​ <strong>无穷距离：</strong></p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905143648.png" /></p>
<p>​ 由下图可以看出，p取值不同时到原点距离为1的图形是不同的：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905143741.png" /></p>
<ul>
<li><p><strong>如何选择k的值？</strong></p>
<p>​
k值越小，模型学习时的近似误差越小，估计误差越大，模型会越复杂，抗干扰性越小（例如，最邻近的点是噪声），模型会非常敏感，容易过拟合；</p>
<p>​ k值越大，估计误差会很小，近似误差会很大，整体模型变得简单。</p>
<p>​ k一般的取值并不大，使用交叉验证的方法来选取最佳的k值。</p></li>
<li><p><strong>如何决策？</strong></p>
<p>​ 在得到k个最相似的实例后，采用何种规则判断测试样本属于哪一类呢？</p>
<p>​ k邻近算法使用多数表决的方法：</p></li>
</ul>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210905154943.png" /></p>
<blockquote>
<p>ps:
ci表示某种决策规则下一组测试用例的表决结果。经由以上推导可以得出，多数表决规则是合理的。</p>
</blockquote>
<p>​</p>
<ul>
<li><p><strong>如何快速找到某个用例的K近邻点？</strong></p>
<p><strong>KD树：</strong> 具体算法见书。</p>
<hr />
<h3 id="四.-朴素贝叶斯法">四. 朴素贝叶斯法</h3>
<p>​</p></li>
</ul>
]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Text Classifification Can be Fooled</title>
    <url>/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Deep%20Text%20Classifification%20Can%20be%20Fooled/</url>
    <content><![CDATA[<h1
id="论文阅读deep-text-classifification-can-be-fooled">【论文阅读】<strong>Deep
Text Classifification Can be Fooled</strong></h1>
<blockquote>
<p><strong>时间：</strong>2017</p>
<p><strong>作者：</strong>Bin Liang, Hongcheng Li, Miaoqiang Su, Pan
Bian, Xirong Li and Wenchang Shi 中国人民大学</p>
</blockquote>
<h3 id="abstract">Abstract:</h3>
<p>​
在这篇文章，我们提出了一种有效的生成文本对抗样本的方法，并且揭示了一个很重要但被低估的事实：基于DNN的文本分类器很容易被对抗样本攻击。</p>
<p>​
具体来说，面对不同的对抗场景，通过计算输入的代价梯度(白盒攻击)或生成一系列被遮挡的测试样本(黑盒攻击)来识别对分类重要的文本项。（<u>这句不是很懂，什么叫’
the text items that are important for classifification‘？</u>）</p>
<p>​
基于这些项目，我们设计了三种扰动策略，insertion，modification，removal，用于生成对抗样本。实验结果表明基于我们的方法生成的对抗样本可以成功地欺骗主流的在字符等级和单词等级的DNN文本分类器。</p>
<p>​
对抗样本可以被扰动到任意理想的类中而不降低其效率。（？）同时，被引入的扰动很难被察觉。</p>
<p>​ <span id="more"></span></p>
<h3 id="introduction">1. Introduction:</h3>
<p>​
在文本中，即使很小的扰动也会使一个字母或者单词完全变化，这会导致句子不能被辨识。故如果直接将应用于多媒体（图片，音频）的算法应用到文本上，得到的对抗样本的原意就会改变，而且很大程度上变成人类无法理解的句子。</p>
<p>​
在这片论文里，我们提出了一种生成对抗样本的有效方法。与直接简单插入扰动相比，我们设计了三种扰动策略：<em>insertion</em>,
<em>modifification</em>, and
<em>removal</em>，并且引入了自然语言文本水印（<em>natural language
watermarking</em>）技术用于生成对抗样本。</p>
<p>​
理论上，生成一个好的对抗样本很大程度上依赖于对目标分类模型的信息。在这里我们根据不同情形，使用了白盒攻击和黑盒攻击。</p>
<p>​
为了普遍性，我们使用了字符等级的模型和单词等级的模型作为受害者。我们的实验结果证明基于DNN的文本分类器在面对对抗样本攻击时是脆弱的。</p>
<h3 id="target-models-and-datasets">2. Target Models and Datasets:</h3>
<p>​ 这里使用的文本分类器是Zhang et al. 2015《Character-level
Convolutional Networks foe Text Classification》，数据集是Lehmann et
al.2014的DBpedia ontology
dataset（一个多语言知识库），里面包括560000个训练样本和70000个测试样本，涵盖14个high-level
类，比如公司类、建筑类、电影类等。</p>
<p>​ 在把样本送进网络前，需要用独热编码法（one-hot
representation）对每个字母编码成一个向量。通过网络的六个卷积层、三个全连接层，最终会被分到14个类中。</p>
<h3 id="white-box-attacks"><u>3. White-Box-Attacks:</u></h3>
<h4 id="fgsm算法">3.1 FGSM算法：</h4>
<p>​
FGSM是Goodfellow在2015年提出的对图片生成对抗样本的经典算法。使用类似的思路来在文本领域生成对抗样本结果并不好：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210830214227.png" /></p>
<h4 id="idenfitying-classification-important-items">3.2 Idenfitying
Classification-important Items:</h4>
<p>​
在白盒攻击中，我们需要定位文本中对于分类器的分类结果起到很大作用的文本段（通过计算代价梯度）。在这里，我们使用<strong><em>Hot
Training Phrases</em> (HTPs)</strong>代表最常使用的短语：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210831150703.png" /></p>
<p>​
HTPS表明了用什么短语/词去做扰动，但是没有说在哪里做。在这里使用<strong><em>Hot
Sample Phrases</em> (HSPs)</strong>来表明在哪里做扰动。</p>
<h4 id="attacking-character-level-dnn">3.3 Attacking Character-level
DNN:</h4>
<p>​ 我们的方法是一种targeted攻击，可以指定对抗样本的误导类型。</p>
<h5 id="insertion-strategy插入策略">3.3.1 Insertion
Strategy（插入策略）:</h5>
<p>​ 在某个HSP前插入一个HTP，就可以达到效果：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210831151929.png" /></p>
<p>​
由上图可以看到，将某个<strong>HTP</strong>（<em>historic</em>）插入到<strong>HSP</strong>（<em>principal
stock exchange of Uganda. It was
founded</em>）之前，就可以使一个公司的分类文本变为对建筑的分类。</p>
<p>​
实际上，我们通常需要进行多次插入，但插入次数过多会影响样本的效用和可读性，为了解决这个问题，这里引入NL水印技术（<em>Natural
Language watermarking
technique</em>）。该技术可以通过语义或句法操作将所有权水印隐形地嵌入到普通文本中,虽然我们的攻击目标与NL水印有本质的不同，但我们可以借用它的思想来构造对抗样本。实际上，扰动可以看作是一种水印，并以类似的方式嵌入到样本中。</p>
<p>​
在这里，我们拓展这个思路，在样本中插入<strong>Presupposition</strong>(读者熟知的模糊短语)和
<strong>semantically empty
phrases</strong>（可有可无的短语），有没有他们，在读者看来，原文的意思不会改变。</p>
<p>​
总的来说，我们考虑将各种HTPS组合成一个语法单元后再嵌入到文本中，新的单元可以是生成的可有可无的资料，或者甚至是不会改变文本原意的伪造的资料。</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210831154859.png" /></p>
<p>​
<strong>特别的，通过互联网搜索或者查找一些数据集，我们可以找到与插入点很相关的资料，包括一些期望的目标分类的HTPs。</strong></p>
<p>​
由于我们不能总是找到合适的HTPs，所以提出一个新概念——伪造的事实（forged
fact），也就是插入很难证伪的HTPs。例如：</p>
<p><img
src="%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Deep%20Text%20Classifification%20Can%20be%20Fooled/20210831154910.png" /></p>
<p>​
此外，我们排除了伪造的事实，这些事实可以通过检索他们在网上的相反证据而被否认。</p>
<h5 id="modification-strategy修改策略">3.3.2 Modification
Strategy（修改策略）：</h5>
<p>​ Moidfication就是轻微修改一些HSP。</p>
<p>​ 为了让修改不被人类观察者发现，我们采用了typo-based watermarking
技术。具体的说，一个HSP可以通过两种方式来被修改：</p>
<p>​ 1. 从相关的语料库中选择常见的拼写错误来替换它；</p>
<p>​ 2.
把它的一些字符修改成类似的外观（例如小写字母'l'与阿拉伯数字‘1’很像）。</p>
<p>​ <img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210831160407.png" /></p>
<p>​ 由上图可以看出，这种方式对分类结果的扰动是巨大的。</p>
<h5 id="removal-strategy移除策略">3.3.3 Removal
Strategy（移除策略）:</h5>
<p>​
移除策略单独使用也许并不能足够有效地影响预测结果，但是可以很大程度上降低原始预测类型的置信度。</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210831161007.png" /></p>
<p>​
由上图可以看出，移除'<strong><em>British</em></strong>'可以导致原始预测类型的置信度下降了35%。</p>
<h5 id="combination-of-three-strategies">3.3.4 Combination of Three
Strategies:</h5>
<p>​
如图6所示，单靠去除策略改变输出分类往往是困难的。但是，通过与其他策略相结合，可以避免对原文进行过多的修改或插入。在实践中，我们常常结合以上三种策略来制作微妙的对抗样本。</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210831161638.png" /></p>
<p>​
以图7为例，通过去除一个HSP、插入一个伪造事实和修改一个HSP，可以成功地改变输出分类，但单独应用上述任何扰动都失败。具体来说，删除、插入和修改仅使置信度分别下降27.3
%、17.5 %和10.1 %，保持预测类不变。</p>
<h3 id="black-box-attack">4. Black-Box-Attack:</h3>
<p>暂略</p>
<h3 id="evaluation">5. Evaluation：</h3>
<h4 id="我们的方法能否执行有效的源目标误分类攻击">5.1
我们的方法能否执行有效的源/目标误分类攻击?</h4>
<p>​ <strong><em>答：</em></strong>在众多测试集中，只有DBpedia
ontology数据集是一个多分类数据集，故我们在其中随机选取了一些样本：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210831165135.png" /></p>
<h4
id="所生成的对抗样本能否避免被人类观察者认出来并同时保持其功能性">5.2
所生成的对抗样本能否避免被人类观察者认出来，并同时保持其功能性？</h4>
<p><strong><em>答：</em></strong>我们找了23个学生。他们对项目不了解，然后每个人给20个文本，其中一半是加扰的。让他们分到14个类中，如果他们觉得哪个文本不对劲，让他们指出来。</p>
<p>​
他们总的分类正确率是94.2%，10个对抗样本的正确率是94.8%。所以实用性还是有的。</p>
<p>​
他们标注出了240项修改处，其中12项符合真实的修改。但实际上我们做了594处修改。</p>
<h4 id="我们的方法足够有效吗">5.3 我们的方法足够有效吗？</h4>
<p><strong><em>答：</em></strong>实验中计算梯度和找HTPs花了116小时。14个类的HTPs每个类花了8.29小时。对所有的adversarial示例只执行一次计算。制作一个对抗性的样品大约需要10到20分钟。对于对手来说，获得理想的对抗样本是可以接受的。实际上，她或他愿意花更多的时间来做这件事。</p>
<h3 id="realted-works">6. Realted Works:</h3>
<p>​
<strong>可以做的方向：</strong>1.自动生成对抗样本；（然而，Papernot等人(Papernot
et al.
2016a)提出了一种基于雅可比矩阵的数据集增强技术，该技术可以在不访问其模型、参数或训练数据的情况下，在有限对输入输出的基础上，为目标dnn提供替代模型。作者还表明，使用替代模型也可以有效地制作对抗样本，以攻击目标DNN。）2.迁移、黑盒攻击；</p>
<p>​</p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>AD</tag>
        <tag>NLP</tag>
        <tag>DNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Black-Box Attacks against RNN based Malware Detection Algorithms</title>
    <url>/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Black-Box%20Attacks%20against%20RNN%20based%20Malware%20Detection%20Algorithms/</url>
    <content><![CDATA[<h1
id="论文阅读black-box-attacks-against-rnn-based-malware-detection-algorithms">【论文阅读】Black-Box
Attacks against RNN based Malware Detection Algorithms</h1>
<blockquote>
<p><strong>时间</strong>：2017</p>
<p><strong>作者：</strong> Weiwei Hu 北京大学</p>
<p>​ Ying Tan 北京大学</p>
</blockquote>
<ul>
<li><h4 id="abstract">Abstract：</h4>
<p>​ 1. <strong>原文：</strong></p>
<p>​
最近的研究表明，基于机器学习的恶意软件分类算法在面对对抗样本攻击时表现的十分脆弱。这些工作主要集中于那些利用了混合维度的特征的追踪算法，但一些研究者已经开始使用RNN，基于API特征序列来辨识恶意软件。</p>
<p>​
这篇文章提出了一种用于生成对抗样本序列的原创算法，它被用于攻击基于RNN的恶意软件分类系统。对于攻击者来说，通常，知晓目标RNN的内部结构和权重是很难的。于是一个替代的用于近似目标RNN的RNN模型就被训练了出来，接着我们利用这个RNN来从原始序列输入中生成对抗样本序列。</p>
<p>​
<strong>权威结果表明基于RNN的恶意软件分类算法不能追踪大多数我们所生成的恶意对抗样本，这意味着我们生成的模型可以很有效的规避追踪算法。</strong></p>
<p>​ 2. <strong>总结：</strong></p>
<p>​
一个对基于RNN的恶意样本分类器的灰盒攻击，有三个RNN，受害者RNN（源RNN），替代RNN，对抗样本生成RNN。</p></li>
</ul>
<span id="more"></span>
<h3 id="introduction">1. Introduction:</h3>
<ol type="1">
<li>现有的基于N机器学习的恶意软件追踪算法主要将程序表现为固定维度的特征向量，然后将其分类为无害程序和恶意软件；</li>
<li>举例，利用API的调用序列，或者不被调用的API序列进行分类；</li>
<li>【11】展现了，基于固定维度特征来进行恶意样本分类的算法，面对对抗样本的攻击是脆弱的；</li>
<li>最近也有利用RNN进行恶意样本追踪与分类的，RNN的输入就是API序列。</li>
</ol>
<h3 id="adversarial-examples">2. Adversarial Examples:</h3>
<p>​ 一些其它的针对序列的对抗样本攻击：</p>
<blockquote>
<p>Nicolas Papernot, Patrick McDaniel, Ananthram Swami, and Richard
Harang. Crafting adver</p>
<p>sarial input sequences for recurrent neural networks. In <em>Military
Communications Conference,</em></p>
<p><em>MILCOM 2016-2016 IEEE</em>, pages 49–54. IEEE, 2016.</p>
<p>Kathrin Grosse, Nicolas Papernot, Praveen Manoharan, Michael Backes,
and Patrick McDaniel.</p>
<p>Adversarial perturbations against deep neural networks for malware
classifification. <em>arXiv preprint</em></p>
<p><em>arXiv:1606.04435</em>, 2016.</p>
</blockquote>
<h3 id="attacking-rnn-based-malware-detection-algorithms">4. Attacking
RNN based Malware Detection Algorithms</h3>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210830150941.png" /></p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210830151007.png" /></p>
<h3 id="实验">5. 实验</h3>
<p>​ Adam 用于训练所有模型；</p>
<p>​ LSTM由于其在处理长序列的优秀表现，也被应用在实验的所有RNN中。</p>
<h4 id="数据集">5.1 数据集：</h4>
<p>​ <strong>来源：</strong>https://malwr.com/
（一个恶意样本分析网站，爬取180个项目，该网站可以分析用户上传的项目，并给出其API序列，网站中70%的项目都是恶意样本）</p>
<p>​
<strong>数据集划分：</strong>为了模拟真实的测试环境，数据集划分如下：（30%+10%）用于生成RNN，（30%+10%）用于受害者RNN，20%用于测试。</p>
<h4 id="受害者rnn">5.2 受害者RNN：</h4>
<p>​ 尝试了不同模型：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210830110738.png" /></p>
<p>​ <strong>结论如下：</strong></p>
<ol type="1">
<li>与LSTM相比，BiLSTM不能提升模型的分类表现；</li>
<li>与Average-Pooling相比，注意力机制的效果更好；</li>
</ol>
<h4 id="生成对抗样本rnn测试结果">5.3 生成（对抗样本）RNN测试结果：</h4>
<p>​ 介绍参数规范：</p>
<blockquote>
<p>The hyper-parameters of the generative RNN and the substitute RNN
were tuned separately for each</p>
<p>black-box victim RNN. The learning rate and the regularization
coeffificient were chosen by line</p>
<p>search along the direction 0.01, 0.001, et al.. The Gumbel-Softmax
temperature was searched in the</p>
<p>range [1<em>,</em> 100]. Actually, the decoder length <em>L</em> in
the generative RNN is also a kind of regularization</p>
<p>coeffificient. A large <em>L</em> will make the generative RNN have
strong representation ability, but the whole</p>
<p>adversarial sequences will become too long, and the generative RNN’s
size may exceed the capacity</p>
<p>of the GPU memory. Therefore, in our experiments we set <em>L</em> to
1.</p>
</blockquote>
<p>​</p>
<p>​ 给出实验结果：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210830140545.png" /></p>
<ol type="1">
<li>对于所有RNN模型，攻击都十分有效；</li>
<li>于LSTM的攻击效果最差，故替代RNN对LSTM的拟合效果并不好；</li>
<li>训练集与测试集的测试效果差别不大， 模型泛化能力强；</li>
<li>即使更换了模型与训练数据集，对抗样本仍效果很好。</li>
</ol>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>AD</tag>
        <tag>Malware Classifiers</tag>
        <tag>RNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Automatically Evading Classififiers----A Case Study on PDF Malware Classififiers</title>
    <url>/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Automatically%20Evading%20Classififiers----A%20Case%20Study%20on%20PDF%20Malware%20Classififiers/</url>
    <content><![CDATA[<h1
id="论文阅读automatically-evading-classififiers----a-case-study-on-pdf-malware-classififiers">【论文阅读】Automatically
Evading Classififiers----A Case Study on PDF Malware Classififiers</h1>
<blockquote>
<p><strong>时间：2016</strong></p>
<p><strong>作者：Weilin Xu, Yanjun Qi, and David Evans
弗吉尼亚大学</strong></p>
<p><strong>会议：NDSS（ccf_B类）</strong></p>
</blockquote>
<h3 id="总结">总结：</h3>
<ol type="1">
<li><p><strong>白盒黑盒？</strong></p>
<p><strong>黑盒攻击</strong>，需要知道生成样本在目标模型中的输出（分类分数）和目标模型所使用的特征（粗略知道）；</p></li>
<li><p><strong>针对什么目标？</strong></p>
<p>仅仅使用表层特征的分类器；</p></li>
<li><p><strong>攻击方法？</strong></p>
<p>3.1 <strong>如何制造对抗样本？</strong></p>
<p>​ 使用<strong>遗传算法（GP-BASED）</strong>进行随机扰动</p>
<p>3.2 <strong>如何判别对抗样本的恶意能力？</strong></p>
<p>​ 使用<strong><em>oracle</em></strong></p></li>
</ol>
<h3 id="abstract">Abstract:</h3>
<p>​
在本文，我们提出了一个一般化的方法来检验分类器的鲁棒性，通过在两个PDF恶意样本分类器，PDFrate和Hidost上来检验。其关键就是随机控制一个恶意样本来找到一个对抗样本。</p>
<p>​
我们的方法可以自动地对500个恶意样本种子中找到对于两个PDF分类器的对抗样本，我们的结果提出了一个严重的疑问，基于表面特征的分类器在面对对抗样本时是否还有效？</p>
<hr />
<h3 id="introduction">1. Introduction:</h3>
<p>​ 主要贡献：</p>
<pre><code>1. 提出了一个一般化的方法用于自动寻找分类器的对抗样本；
2. 制作了一个原型系统用于自动生成对抗样本；
3. 我们的系统在对500个恶意样本种子寻找对抗样本的过程中，达到了100%的准确率。</code></pre>
<hr />
<h3 id="overview">2. Overview：</h3>
<h4 id="finding-evasive-samples"><em>2.1 Finding Evasive
Samples</em>：</h4>
<p>​ <strong>整体思路：</strong></p>
<p>​ <img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210901185852.png" /></p>
<p>​
<strong><em>oracle</em></strong>用于判断一个样本是否具有恶意行为；</p>
<hr />
<h3 id="pdf-malware-and-classifiers">3. PDF Malware and Classifiers</h3>
<h4 id="pdfmalware"><em>3.1 PDFmalware:</em></h4>
<p>​ PDF文件的整体结构：</p>
<p>​ <img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210901191527.png" /></p>
<p>​
早些的PDF恶意样本一般使用JavaScript嵌入，用户双击打开时出发执行恶意脚本。</p>
<p>​
因为不是所有的PDF恶意样本都是嵌入了JavaScript代码，最近的一些PDF恶意分类器就着重于PDF文件的结构化特征。在本文，我们的目标就是攻击这些有代表性的基于文件结构化特征的分类器。</p>
<h4 id="target-classififiers"><em>3.2 Target Classififiers：</em></h4>
<p>​ <strong>PDFrate：</strong>一个使用随机森林算法的分类器。</p>
<p>​ <strong>Hidost:</strong>一个SVM分类器。</p>
<p>​</p>
<hr />
<h3 id="evading-pdf-malware-classifiers">4. Evading PDF Malware
Classifiers：</h3>
<hr />
<h3 id="experiment">5. Experiment:</h3>
<h4 id="dataset"><em>5.1 Dataset:</em></h4>
<p>​ <img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210901194138.png" /></p>
<h4 id="test"><em>5.2 Test：</em></h4>
<p>​ <img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210901194328.png" /></p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210901194448.png" /></p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>AD</tag>
        <tag>Malware Classifiers</tag>
        <tag>PDF</tag>
      </tags>
  </entry>
  <entry>
    <title>AD nlp Survey</title>
    <url>/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91AD%20nlp%20Survey/</url>
    <content><![CDATA[<h1 id="论文阅读ad-nlp-survey">【论文阅读】AD nlp Survey</h1>
<blockquote>
<p><strong>作者：Wei Emma Zhang（阿德莱德大学，澳大利亚）</strong></p>
<p>​ <strong>QUAN Z. SHENG（麦考瑞大学，澳大利亚）</strong></p>
<p>​ <strong>AHOUD ALHAZMI（麦考瑞大学，澳大利亚）</strong></p>
<p>​ <strong>李晨亮（武汉大学，中国）</strong></p>
</blockquote>
<h3 id="关键词dnn对抗样本文本数据textual-datanlp">1.
关键词：DNN，对抗样本，文本数据（textual data），NLP</h3>
<h3 id="摘要">2. 摘要：</h3>
<blockquote>
<ol type="1">
<li>传统对抗样本基本都针对计算机视觉领域；</li>
<li>本调查提供针对基于DNNs的NLP对抗样本攻击；</li>
<li>由于CV与NLP本身不同，方法不能直接移植；</li>
<li>集成了截止2017年所有的相关成果，综合性地总结，分析，讨论了40个代表性工作；</li>
<li>简单介绍了CV和NLP相关知识。 <span id="more"></span> ### 3.Introduction:</li>
</ol>
</blockquote>
<blockquote>
<ol type="1">
<li><p><strong>简单介绍了对抗样本</strong>；</p></li>
<li><p><strong>关于对抗样本的研究可以简单分为三类</strong>：</p></li>
</ol>
<p>① 通过使用微小扰动来欺骗DNN，以此来评估它；</p>
<p>② 刻意改变DNN的输出；</p>
<p>③ 检测DNN中过敏感和过迟钝的点，寻找防御攻击的方法。</p>
<ol type="1">
<li><p>==<strong>不能直接使用基于CV的对抗样本生成方法的原因：</strong>==</p>
<p>直接将对图像攻击的对抗样本生成方法应用到文本上，将得到毫无意义的词语和句子片段。这是因为在对图像的对抗样本生成中，即使略微改变每个像素的灰度，肉眼也可以识别原来的图像；但是对于文本串来说，即使改变一个字母，语句的语义也将完全不同或出错。</p></li>
<li><p>==<strong>相关研究：</strong>==</p></li>
</ol>
<p><u><strong>Reference [i] = 【i】</strong></u></p>
<p>​ ①
【9】：对<strong>针对不同类别的机器学习系统的攻击与防御</strong>做了综合性概述，提出了一种用于辨识和分析这些攻击的分类方法，并将将这些攻击应用到基于机器学习的应用上来证明这些攻击或者防御手段的有效性。例如，一个统计垃圾邮件过滤器。</p>
<p>​ ②
【13】：作者俯瞰了近十年（2008-2018）对抗样本攻击的<strong>发展史</strong>，聚焦点在于CV和网络空间安全。对非深度学习算法和深度学习算法都做了介绍，也从安全的角度仔细分析了这些攻击和防御手段的影响。</p>
<p>​ ③ 【79】：与【13】阐述的问题类似，从数据驱动的角度。</p>
<p>​ ④
【154】：聚焦于对抗样本在深度学习模型上的使用。介绍了最近的几种不同的在应用上对DNN的攻击，同时全面调查了防御方法。但是，其只讨论了对抗样本在图像分类和物品识别上的攻击。</p>
<p>​ ⑤
【2】：详细阐述了对抗样本在CV上的应用，是一篇应用程序主导的调查。</p>
<p>​ ⑥
【35】：从安全的角度阐述了对抗样本的防御手段。（<strong>不仅从机器学习算法或者神经模型上，从所有与安全相关的应用上阐述对抗样本防御</strong>）作者发现现有的与防御相关的安全工作缺乏清晰的<strong>对攻击如何与真实安全问题相关联</strong>的动机和解释，以及这些攻击和防御如何被有意义地衡量，故提出了一种分类方法用于衡量这些。</p>
</blockquote>
<h3 id="overview-对抗样本攻击-and-深度学习在nlp中的应用">4. Overview
（对抗样本攻击 and 深度学习在NLP中的应用）:</h3>
<blockquote>
<ol type="1">
<li><p>给出了<strong>DNN，Perturbations，Adversarial
Examples</strong>的定义；</p></li>
<li><p>介绍了<strong>Treat Model</strong>：</p>
<p>2.1
<em>Granularity（颗粒度）</em>:攻击的颗粒度指的是对抗样本生成的数据等级，例如对图像数据通常是像素，对文本数据就是字母，单词，句子嵌入等级。</p>
<p>2.2
<em>Motivation（动机）</em>：生成对抗样本的动机通常有两种，攻击和防御：1.攻击的目的是检验DNN的健壮性；2.
防御的目的是使DNN更加稳固，第五部会给出更详细的讲解。</p></li>
<li><p>介绍了<strong>Measurements</strong>（评价<u>adversarial
attack</u>的方法）：</p>
<p>3.1 控制扰动（<em>Perturbation Constraint</em>）：</p></li>
</ol>
<p>​ 根据前面所述，扰动 <em>η</em>
应该不影响样本原来的真实分类，<u>故如果一个分类器是理想的，那么扰动后的样本应不影响其分类结果</u>；
<em>η</em>
同时也不能太小，以避免对目标DNN没有影响。在理想情况下，有效扰动是在一定范围内最有效果的噪声。</p>
<p>​ 【132】首次在图像对抗样本攻击中约束了(x + <em>η</em>) ∈ [0,
1]<sup>n</sup> 的范围，以保证对抗样本与原始数据有着相同的像素等级。</p>
<p>​
【40】简化了问题的解决方法，并使用了无穷范数来限制扰动，==这受到直觉的启发，即一个不改变任何特定像素的扰动量超过一定量
ϵ
就不能改变输出类。==（PS:WHY？）无穷范数在图像/物品分类识别任务中是足够有效的，其他的范数，例如L0和L2范数，过去被用于在对CV的DNN攻击中限制扰动。在文本对抗样本攻击中，这有所不同，第3.3节会给出更多细节。</p>
<p>3.2 评估攻击的有效性（<em>Attack Evaluation</em>）：</p>
<p>​
对抗样本攻击旨在降低DNNs的性能，因此，评估攻击的有效性是基于不同任务的性能指标。例如，分类任务中有评价指标准确度，F1-score，AUC-score。在本文中，我们将针对不同NLP的评价标准作为超范围内容，并建议读者参考特定的信息。</p>
<p>​ ==<strong><em>以上是总体分类与信息</em></strong>==</p>
<hr />
<p>​ ==<strong><em>以下是深度学习在NLP中的应用</em></strong>==</p>
<p>​
除了向前传播的神经网络和CNN，RNN及其变式由于其天然的处理序列的能力，也被用于NLP中。</p>
<ol type="1">
<li><p><strong>近几年深度学习对NLP的重大影响</strong>：</p>
<p>1.1 序列学习（<em>sequence-to-sequence learning</em>）</p>
<p>1.2 注意力机制（<em>attention mechanism</em>）</p>
<p>1.3 强化学习（reinforcement learning）和生成模型（generative
models）</p>
<p>具体详细的神经网络在NLP中的应用见【100】，【152】</p>
<ol start="2" type="1">
<li><strong>Feed-Forward Networks:</strong></li>
</ol>
<p><strong>缺点：</strong>不能很好地处理对于词语顺序很重要的文本序列，因为其并不记录元素的顺序。为了评价其健壮性，往往针对专门设计的前馈网络生成对抗实例，【3】，【43】，【44】作者研究了指定的恶意软件检测模型。</p>
<ol start="3" type="1">
<li><strong>CNN：</strong></li>
</ol>
<p>​
CNN识别本地预测因子并将它们组合在一起，为输入生成一个固定大小的向量，该向量包含数据中最重要或最重要的信息方面。</p>
<p>​ CNN对顺序敏感，因此，它擅长做计算机视觉，随后被广泛用于NLP应用。</p>
<p>​ 卷积操作被简直在词的序列方向上，而不是词的嵌入。</p>
<p>​ <strong>两个经典工作：</strong>1.
【59】使用CNN和Word2Vec进行句子分类
2.【156】使用CNN和热独编码进行文本分类。</p>
<ol start="4" type="1">
<li><strong>RNN：</strong></li>
</ol>
<p>​ 主要介绍RNN及其变式（LSTM，GRU）</p>
<ol start="5" type="1">
<li><strong>Seq2Seq（<em>sequence-to-sequence
learning</em>）：</strong></li>
</ol>
<p>​
Seq2Seq模型具有优越的能力，能够为具有编码器-解码器结构的给定序列信息生成另一个序列信息.</p>
<p>​
通常，一个Seq2seq由两个RNN结构组成，一个用于编码，一个用于解码。VHRED是一个最近很受欢迎的Seq2seq模型，它利用子序列之间的复杂依赖关系生成序列。</p>
<p>​ 【24】是最初的使用Seq2seq模型的神经机器翻译模型（NMT）之一；</p>
<p>​ 【63】是一个最近提出的 seq2seq NMT模型，是此领域的benchmark；</p>
<p>​ 【22,30,98,127】有对其的攻击。</p>
<ol start="6" type="1">
<li><strong>Attention Models：</strong></li>
</ol>
<p>​ 注意力机制最初被设计用来克服seq2seq模型中对长序列编码的问题。</p>
<p>​
注意力允许解码器回溯源序列的隐藏状态，然后，隐藏状态提供一个加权平均作为解码器的额外输入。</p>
<ol start="7" type="1">
<li><strong>Reinforcement Learning Models：</strong></li>
</ol>
<p>​
强化学习通过在代理执行离散动作后给予奖励来训练代理，在NLP中，强化学习框架通常由一个代理（DNN），一个策略部分（用于指导动作）和奖励组成。</p>
<p>​
代理基于策略做出一个动作（例如预测序列中下一个单词的位置），然后相应地更新其内部状态，直到到达序列的末尾，在这里奖励已经被计算完成。</p>
<p>​
强化学习需要正确处理每一步的动作和状态，这可能会限制模型的表现力和学习规模。但它在面向任务的对话系统中获得了很多好处，因为它们在决策过程共享着同一根本原则。</p>
<ol start="8" type="1">
<li><strong>Deep Generative Models（深层生成模型）：</strong></li>
</ol>
<p>​ 近些年，两种深层生成模型获得了很多关注：<strong>Generative
Adversarial Networks (GANs) 【39】 and Variational Auto-Encoders
(VAEs)</strong></p>
<p>​
其可以在潜在空间中生成与真实数据分厂相似的数据样例，在NLP领域，它们被用来生成文本。</p>
<p>​ 8.1 <strong>GANS:</strong></p>
<p>​
Gans由两个对抗网络组成：生成器（generator）和鉴别器（discriminator）。鉴别器的作用是鉴别真实样本和生成样本，生成器的作用是生成很真实的，用于欺骗鉴别器的样本。</p>
<p>​ Gan使用min-max loss function来同步训练两个神经网络。</p>
<p>​ 8.2 <strong>VAES：</strong></p>
<p>​
Vaes由编码器（encoder）和生成器（generator）组成。编码器的作用是对输入编码为潜在空间，生成器的作用是从潜在空间中生成样本。</p>
<p><u>深度模型都不是很好训练，这个缺点阻碍了其在真实世界的应用中的广泛应用，尽管他们已经被用于生成文本，但目前没有工作去用对抗样本检验它们的健壮性。</u></p></li>
</ol>
</blockquote>
<h3 id="from-image-to-text">5. From image to text:</h3>
<blockquote>
<p><strong>一. 构造对抗样本：</strong></p>
<ol type="1">
<li><strong>、L-BFGS:</strong></li>
</ol>
<p>​
Szegedy【132】等人首次证明了可以通过对图像添加小量的人类察觉不到的扰动误导深度神经网络图像分类器做出错误的分类。他们首先尝试求解让神经网络做出误分类的最小扰动的方程。作者认为，深度神经网络所具有的强大的非线性表达能力和模型的过拟合是可能产生对抗性样本原因之一。</p>
<ol start="2" type="1">
<li><strong>FGSM（Fast Gradient Sign Method）：</strong></li>
</ol>
<p>​
L-BFGS很有效但成本高昂，这使Goodfellow【40】等人找到一个简化问题的方法。</p>
<ol start="3" type="1">
<li><strong>JSMA（Jacobian Saliency Map Adversary）：</strong></li>
</ol>
<p>​ 与FGSM利用梯度攻击不同，Papernot【105】等人使用<strong>forward
derivatives</strong>（远期衍生物？）生成对抗样本。这个方法通过使用其雅克比矩阵来评估神经模型对每个输入部分的输出敏感性。</p>
<ol start="4" type="1">
<li><strong>DeepFool：</strong></li>
</ol>
<p>​
DeepFool是一种迭代的L2正则化算法，作者先假设神经网络是线性的，因此可以使用一个超平面来分离类。作者简化了问题并且基于以上假设找到了问题最优解，并构建了对抗样本、</p>
<p>​
为了解决神经网络是非线性的事实，作者重复他们的步骤直到一个真正的对抗样本被生成了。</p>
<p>PS：正则化：<a href="https://www.zhihu.com/question/20924039">(23
封私信 / 54 条消息) 机器学习中常常提到的正则化到底是什么意思？ - 知乎
(zhihu.com)</a></p>
<ol start="5" type="1">
<li><strong>Subsititute Attack：</strong></li>
</ol>
<p>​ 前面四中攻击方式都是<strong>白盒攻击</strong>，
Papernot【104】等人提出了黑盒攻击策略，他们训练了一个与目标模型决策边界相似的替代模型，对此替代模型进行白盒攻击，生成相应对抗样本。</p>
<p>​ 在生成对抗样本的过程中，他们使用了FSGM和JSMA。</p>
<ol start="6" type="1">
<li><strong>GAN-like Attack：</strong></li>
</ol>
<p>​
这是一种通过深度生成模型的黑盒攻击方法，Zhao【157】等人首先基于数据集 X
训练了一个生成模型WGAN，WGAN可以生成与X分布相同的数据点。</p>
<p><strong>二. 对图像DNN攻击与对文本DNN攻击的对比：</strong></p>
<p>​ <strong>1. 二者的主要不同：</strong></p>
<p>​ 1.1 离散与连续输入：</p>
<p>​
图像输入是连续的而文本输入是离散的，在图像输入中，通常使用L<sub>p</sub>来衡量原始数据点和扰动点的距离，但是由于文本输入是离散的，很难定义文本上的扰动大小（==为什么？==）。这就需要构造对文本扰动的衡量方法。还有一种方式是将文本输入当做连续值，然后应用CV方法，在3.3节上将会详细讨论。</p>
<p>​ 1.2 可察觉与不可察觉：</p>
<p>​
与图像相比，文本数据即使更改一个字母也会造成很大变化，故即使做很小的扰动，也可以被很明显的察觉到。</p>
<p>​ 1.3 有语义和无语义：</p>
<p>​
原理同上，在文本中做很小的改动往往会极大地影响到文本的语法和语义信息。</p>
<p>​ 基于以上不同，目前主流对文本DNN的攻击有两种：1.
调整图像DNN的攻击方法，添加额外限制；2. 使用新技术提出一个新方法。</p>
<p><strong>三. 向量化文本输入 and 扰动的衡量方法</strong></p>
<ol type="1">
<li><p><strong>三种向量化文本输入的方法：</strong></p>
<p>1.1 <strong>基于计数的编码（<em>Word-Count-based
Encoding</em>）</strong>：</p>
<p>​ ①
<strong>BOW（Bag-of-words）</strong>方法，将一个文档中出现的词语编号为向量的0,1,2.....i维度，每个维度的值代表词语出现的次数。（缺点：不能记住词语顺序）</p>
<p>​ ② <strong>Term frequency-inverse document frequency
(TF-IDF)</strong> ，具体见：</p>
<p><a
href="https://blog.csdn.net/asialee_bird/article/details/81486700">TF-IDF算法介绍及实现_Asia-Lee-CSDN博客_tf-idf</a></p>
<p>​ 1.2 <strong>热独编码（<em>One-hot Encoding</em>）</strong>:</p>
<p>​ 具体介绍略。</p>
<p>​
由于普通顺序编码的值存在大小关系，当模型得到输入后会将其当做实际值来处理，这就使得原本平行的数据有了大小关系，独热编码巧妙地解决了这个问题，使得所有单词或者字母低位平等。</p>
<p>​ 1.3 <strong>稠密编码：</strong></p>
<p>​ Word2Vec使用连续BOW模型和skip-gram 模型来做代码嵌入。</p>
<p>​
<strong>一个潜在的假设是，出现在相似语境下的词语有着相似的含义。</strong>
词嵌入在一定程度上缓解了文本数据向量化的离散性和数据稀疏性问题【36】，词嵌入的扩展如doc2vec和paragraph2vec【69】将句子/段落编码为稠密向量。</p></li>
<li><p><strong>扰动的衡量方法：</strong></p>
<p>2.1 <strong>基于范数的方法（<em>Norm-based
measurement</em>）</strong>：</p>
<p>​
直接使用范数需要输入数据是连续的。一个解决方法是使用连续且稠密的表示方法（如嵌入），但这通常会得到无意义的文本。</p>
<p>2.2 <strong>基于语法和句法的方法（<em>Grammar and syntax related
measurement</em>）：</strong></p>
<p>​ 通过确认文本语法的正确性来保证对抗样本不易被识别。</p>
<p>​
可以使用<strong>Perplexity</strong>【91】，<strong>Paraphrase</strong>（4.3.3）确保对抗样本的有效性。</p>
<p>2.3 <strong>基于语义保持的方法（<em>Semantic-preserving
measurement</em>）：</strong></p>
<p>​ ① 计算欧拉距离:</p>
<p><img
src="http://shaw-typora.oss-cn-beijing.aliyuncs.com/20210715215755.png" /></p>
<p>​ ② 计算<strong>Cosine Similarity</strong>（余弦相似度）：</p>
<p><img
src="http://shaw-typora.oss-cn-beijing.aliyuncs.com/20210715215851.png" /></p>
<p>​</p>
<p>2.4 <strong>基于编辑距离的方法：</strong></p>
<p>​ <strong>编辑距离（Edit
Distance）</strong>，又称Levenshtein距离，是指两个字串之间，由一个转成另一个所需的最少编辑操作次数。许可的编辑操作包括将一个字符替换成另一个字符，插入一个字符，删除一个字符。一般来说，编辑距离越小，两个串的相似度越大。</p>
<p>​ 不同定义使用不同的转换操作。</p>
<p>2.5 <strong>基于Jaccard相似系数的方法：</strong></p>
<p>​ Jaccard相似系数定义见百度百科。</p>
<p>​
就是把两个集合的交集除以两个集合的并集，简单地看集合中的元素是不是大量相同。</p>
<p><img
src="http://shaw-typora.oss-cn-beijing.aliyuncs.com/20210715220447.png" /></p></li>
</ol>
</blockquote>
<h3 id="attacking-neural-models-in-nlp">6. Attacking Neural Models in
NLP:</h3>
<blockquote>
<ol type="1">
<li><strong>常见攻击方法：</strong></li>
</ol>
<p>白盒，黑盒......</p>
<p><img
src="http://shaw-typora.oss-cn-beijing.aliyuncs.com/20210715221355.png" /></p>
<p>​</p>
<ol start="2" type="1">
<li>提供了数据集来源，<strong>但没有提供生成对抗样本的数据集，所提供的的数据集仅用于评估攻击效果。</strong></li>
</ol>
</blockquote>
<h3 id="defense">7. Defense:</h3>
<blockquote>
<ul>
<li>背景：两种在DNN中常用的防御方法：<u>1. 对抗训练(adversarial
training) 2. 知识蒸馏（knowledge distillation）.</u></li>
<li>Knowledge distillation：<a
href="https://zhuanlan.zhihu.com/p/102038521">【经典简读】知识蒸馏(Knowledge
Distillation) 经典之作 - 知乎 (zhihu.com)</a></li>
</ul>
<p><strong>一. 对抗训练</strong></p>
<ol type="1">
<li><strong>数据增强（<em>Data Augmentation</em>）：</strong></li>
</ol>
<p>​
数据增强将原始数据集加上对抗样本一起，在训练的过程中让模型见到更多数据，数据增强常被用来对抗黑盒攻击，实现的方式是通过在被攻击的DNN上使用对抗样本增加额外的epoch。</p>
<p>​
【54】证明了这种方法是有效的，但仅仅对同一对抗样本有效（数据增强中的样本与测试对抗样本）</p>
<p><img
src="http://shaw-typora.oss-cn-beijing.aliyuncs.com/20210716100311.png" /></p>
<p>​ 【142】也提出了类似的观点</p>
<p>​ 【56】作者提出了3种生成更多具有不同特征的数据的方法</p>
<p>​
【12】<strong>作者提出了一种新的数据增强的方法</strong>，它将平均字符嵌入作为一个词表示，并将其纳入输入。这种方法本质上对字符的置乱不敏感，例如交换、mid和Rand，因此可以抵抗这些置乱攻击引起的噪声。但是，这种防御方法对不是针对字符顺序的扰乱不起作用。</p>
<ol start="2" type="1">
<li><p><strong>模型正则化（<em>Model
Regularization</em>）：</strong></p>
<p>模型正则化将生成的对抗样本实例作为正则化器：</p>
<p><a
href="https://blog.csdn.net/weixin_41503009/article/details/104594972">模型正则化_少年吉的博客-CSDN博客_模型正则化</a></p>
<p>正则化(
Regularization)的目的在于提高模型在未知测试数据上的泛化力,避免参数过拟合。</p></li>
<li><p><strong>健壮性最优化方法（<em>Robust
Optimization</em>）：</strong></p></li>
</ol>
<p>Madry【84】等人将DNN学习问题转化为了一个包含内非凹最大化问题(攻击)和外非凸最小化问题(防御)的健壮性优化问题。</p>
<p><strong>二. 知识蒸馏</strong></p>
<p>​ 详见论文和博客。</p>
</blockquote>
<h3 id="discuss-and-open-issues">8.Discuss and Open issues</h3>
<blockquote>
<ol type="1">
<li><strong>可察觉性（<em>Perceivability</em>）</strong>：</li>
</ol>
<p>见前文</p>
<ol start="2" type="1">
<li><strong>可转移性（<em>Transferability</em>）</strong>：</li>
</ol>
<p>no-tatgeted攻击的可转移性更强。</p>
<p>可转移性可以在三个地方体现：</p>
<p>​ 2.1 同样的架构，不同的数据；</p>
<p>​ 2.2 同样的应用场景，不同的架构；</p>
<p>​ 2.3 不同的架构，不同的数据。</p>
<p><u><strong>尽管现有的工作囊括了以上三种情况，但对抗样本攻击的可移植性效果仍不好，需要更多的工作。</strong></u></p>
<ol start="3" type="1">
<li><strong>自动化（<em>Automation</em>）</strong>：</li>
</ol>
<p>​ 一些工作可以做到对抗样本的自动生成，而另一些则不行。</p>
<p>​
在白盒攻击中，利用DNN的损失函数可以自动识别文本中受影响最大的点(如字符、词)，以此做到在文本中自动化。</p>
<p>​ 在黑盒攻击中，一些攻击例如替代训练（substitution
train）可以训练出一个替代用模型，对其进行白盒攻击，也可以实现自动化。但是大多数对抗样本的生成都是人工生成。【54】会关联人工选择的无意义的文本段落来欺骗阅读理解系统，以此来发现DNN的脆弱性。很多研究工作跟随【54】，其目的不是实际攻击，而是更多的在检测目标网络的健壮性上，这些人工工作是耗时且不切实际的。我们相信在未来更多的努力会用来克服这个困难。</p>
<ol start="4" type="1">
<li><strong>新架构（<em>New Architectures</em>）</strong>：</li>
</ol>
<p>​
尽管大多数普通的文本DNN都注意到了对抗样本攻击，但是很多DNN并没有被攻击过。例如GANS与VAES，它们被用作生成文本。深度生成模型需要更复杂的技巧去训练，这就可以解释为什么这些技术忽略了对抗样本攻击。未来的工作可能考虑对这些DNN进行对抗样本攻击。</p>
<p>​ 注意力机制（Attention
Mechanism）目前是大多数序列模型的标准组成部分，但是没有工作去检验注意力机制本身。故可能的攻击工作要么攻击包含注意的整体系统，要么利用注意分数来识别干扰词【14】。</p>
<ol start="5" type="1">
<li><strong>迭代 VS 一次性（<em>Iterative versus
One-of</em>）</strong>：</li>
</ol>
<p>​ <strong>迭代攻击</strong>：效果好，耗时长；</p>
<p>​ <strong>一次性攻击</strong>：效果略差，耗时短。</p>
<p>​ 在设计攻击方法时，攻击者需要仔细考虑效果与效率的平衡。</p>
</blockquote>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>AD</tag>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>A novel Android malware detection system-adaption of flter‑based  feature selection methods</title>
    <url>/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91A%20novel%20Android%20malware%20detection%20system%20adaption%20of%20flter%E2%80%91based%20%20feature%20selection%20methods/</url>
    <content><![CDATA[<h1
id="论文阅读a-novel-android-malware-detection-system-adaption-of-flterbased-feature-selection-methods">【论文阅读】A
novel Android malware detection system: adaption of flter‑based feature
selection methods</h1>
<blockquote>
<p><strong>时间：</strong>2021</p>
<p><strong>作者：</strong> <strong>Durmuş Özkan Şahin</strong>
<strong>Oğuz Emre Kural</strong> <strong>· Sedat Akleylek</strong>
<strong>Erdal Kılıç</strong></p>
</blockquote>
<h3 id="总结">总结：</h3>
<ol type="1">
<li><strong>二分类</strong>，<strong>静态</strong>代码检测；</li>
<li>创新点主要在<strong>特征提取</strong>（已经有的方法+文本分类的方法）上，分类器用的各种现成的方法；</li>
</ol>
<hr />
<h3 id="abstract">Abstract:</h3>
<p>​
在本研究中，提出了一个基于过滤器特征选择方法的，原创的安卓端恶意软件追踪系统。</p>
<p>​
该方法是一个在机器学习的基础上的<strong>静态</strong>安卓恶意软件追踪方法。在所开发的系统中，使用应用程序文件中提取的权限作为特征。八个不同的特征选择方法被用于维度降低，以减少运行时间，提升机器学习算法的效率。</p>
<p>​
其中四种方法应用于安卓恶意样本分类，其余四种方法是从文本分类研究中采用的，其从提取特征和分类结果两方面对方法进行了比较，在对结果进行检验时，表明所采用的方法提高了分类算法的效率，可以在本领域中使用。</p>
<table style="width:10%;">
<colgroup>
<col style="width: 9%" />
</colgroup>
<tbody>
<tr class="odd">
<td><span id="more"></span></td>
</tr>
<tr class="even">
<td>### 1. Introduction:</td>
</tr>
<tr class="odd">
<td>#### 1.1 如何提取相关特征？</td>
</tr>
<tr class="even">
<td>​ <strong>Shabtai
(2012)</strong>介绍了Andromaly架构，其中包含不同的特征选取方法和分类方法。</td>
</tr>
<tr class="odd">
<td>​
<strong>Zhao（2015）</strong>提出了一个特征选择方法FrequelSel，其基于无害样本和恶意样本的频率特征差异。</td>
</tr>
<tr class="even">
<td>​ <strong>Xu
（2016）</strong>提出了一个新的安卓恶意样本追踪方法ICCdetector，他们使用CFS（Correlation</td>
</tr>
<tr class="odd">
<td>Based Feature Selection）在许多特征向量中做特征提取。</td>
</tr>
<tr class="even">
<td>​
<strong>Morales-Ortega（2016）</strong>提出了一种可以在恶意软件分析和检测设备上本地运行的方法，他们使用不同的特征选择方法和分类方法进行了对比实验。</td>
</tr>
<tr class="odd">
<td>​ <strong>Bhattacharya and Goswami (2018)
</strong>提出了一种通过通过混合基于community的粗略设置特征选择方法（community-based
rough set feature selection method）来进行特征选择的新方法。</td>
</tr>
<tr class="even">
<td>​ <strong>Peynirci et al. (2020) </strong>提出了Delta
IDF方法，其通过选择具有最高IDF（NLP中的）无害样本和最低IDF的恶意样本来提取特征。在特征提取中使用了字符串，API调用序列，权限等来作为特征。</td>
</tr>
<tr class="odd">
<td>​ <strong>Ananya et al. (2020)
</strong>提出了一种安卓恶意样本追踪的动态分析技术。</td>
</tr>
<tr class="even">
<td>​ <strong>Kouliaridis et al.
(2021)</strong>使用了两个特征选取算法和八个不同的分类器进行了比较试验。</td>
</tr>
<tr class="odd">
<td>​ <strong>Jung et al. (2021) </strong>在Gini Importance 和 domaind
知识上进行了特征提取。使用了API调用序列和应用权限。</td>
</tr>
<tr class="even">
<td>​ <strong>Liu et al.
(2021)</strong>使用非监督学习进行了安卓恶意样本的特征提取。</td>
</tr>
<tr class="odd">
<td>#### 1.2 Contribution:</td>
</tr>
<tr class="even">
<td>​ <strong>主要贡献：</strong></td>
</tr>
<tr class="odd">
<td>1.
提出了一个基于过滤器特征选择方法的，原创的安卓端恶意软件追踪系统（<strong>静态检查</strong>）；
2.
基于文本分类的特征选择方法对现有的属性选择方法进行替代是适应于Android恶意软件检测系统的。因此，不使用所有的权限，而是选择了最具特色的权限，提高了分类算法的性能；
3.
比较给出各度量得到的允许度和分类结果。在检查结果时，所提出的系统使用的特征比现有的检测系统少；
4.
从我们所采用的特征提取方法中得到的结果总体上所得到的特征比其他方法少；
5. 实验结果更好，run的时间更短，分类效果更佳； 6.
一些矩阵与贪婪方法相结合形成各种属性子集。这些创建的属性子集在用大量classifer进行测试时表现出了显著的性能。</td>
</tr>
</tbody>
</table>
<h3 id="preliminaries">2. Preliminaries：</h3>
<h4 id="feature-extraction如何处理apk文件">2.1 Feature
extraction（如何处理APK文件）：</h4>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210901113521.png" /></p>
<h4 id="feature-selection提取特征">2.2 Feature
selection（提取特征）：</h4>
<p>​
特征选择技术分为三类：<strong>flter-based</strong>，wrapper-based，embedded
methods.</p>
<p>​
<strong>在基于过滤的技术中，就是在所有属性中选择最好的k个属性，而不使用剩余的属性。各种基于统计或信息论的技术被用来寻找最佳的k个特征。</strong></p>
<p>​
基于Wrapper的技术在操作上与过滤技术类似，但在搜索策略上，选择是用遗传算法等启发式方法代替统计技术进行的。</p>
<p>​
特征选择过程是在机器学习算法的训练阶段进行的。特征选择是通过找到影响在训练阶段创建的模型性能的最佳子集来进行的。</p>
<h4 id="the-proposed-android-malware-detection-system">2.3 <strong>The
proposed Android malware detection</strong> system：</h4>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210901115235.png" /></p>
<p>​</p>
<hr />
<h3 id="experimental-settings">3. Experimental settings：</h3>
<h4 id="datasets">3.1 datasets：</h4>
<p>​ 3000恶意样本（VirusShare dataset ），3000无害样本（APKPure）</p>
<h4 id="classifcation-algorithms">3.2 Classifcation algorithms</h4>
<h4 id="performance-measure">3.3 Performance measure</h4>
<hr />
<h3 id="results-and-discussions">4. Results and discussions:</h3>
<h4 id="results-of-performed-experiments">4.1 Results of performed
experiments:</h4>
<p>数据处理：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210901120437.png" /></p>
<p>分类结果（部分）：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210901151407.png" /></p>
<p>总：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210901151954.png" /></p>
<p>与其他方法比较：</p>
<p><img
src="https://shaw-typora.oss-cn-beijing.aliyuncs.com/20210901152049.png" /></p>
<hr />
<h3 id="section"></h3>
<p>​</p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Malware Classifiers</tag>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title>A Benchmark API Call Dataset For Windows PE Malware Classification</title>
    <url>/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91A%20Benchmark%20API%20Call%20Dataset%20For%20Windows%20PE%20Malware%20Classification/</url>
    <content><![CDATA[<h1
id="论文阅读a-benchmark-api-call-dataset-for-windows-pe-malware-classification">【论文阅读】A
Benchmark API Call Dataset For Windows PE Malware Classification</h1>
<blockquote>
<p><strong>作者：Ferhat Ozgur Catak（土耳其）</strong></p>
<p>​ <strong>Ahmet Faruk Yazi（土耳其）</strong></p>
<p><strong>时间：2021.2.23</strong></p>
<p><strong>关键词：恶意软件分析，网络空间安全，数据集，沙箱环境，恶意软件分类</strong></p>
</blockquote>
<h3 id="abstract">1. Abstract</h3>
<p>​
在Windows操作系统中，系统API调用的使用在监控恶意PE程序中是一个很有前途的方法。这个方法被定义为在安全隔离的沙箱环境中运行恶意软件，记录其调用的Windows系统API，再顺序分析这些调用。
​
在这里，我们在隔离沙箱中分析了7107个属于不同家族（病毒，后门，木马等）的恶意软件，并把这些分析结果转化为了不同分类算法和方法可以使用的形式。
​
<strong>首先</strong>，我们会解释如何得到这些恶意软件；<strong>其次</strong>，我们会解释如何将这些软件捆绑至家族中；<strong>最后，</strong>我们会描述如何使用这些数据集来通过不同的方法实现恶意软件的分类。</p>
<table style="width:10%;">
<colgroup>
<col style="width: 9%" />
</colgroup>
<tbody>
<tr class="odd">
<td><span id="more"></span></td>
</tr>
<tr class="even">
<td>### 2. Introduction</td>
</tr>
<tr class="odd">
<td>#### 2.1 简单介绍了恶意软件</td>
</tr>
<tr class="even">
<td>#### 2.2 恶意软件与恶意软件识别之间的竞争</td>
</tr>
<tr class="odd">
<td>​ 相互促进</td>
</tr>
<tr class="even">
<td>#### 2.3 变形恶意软件（Metamorphic malware）</td>
</tr>
<tr class="odd">
<td>​
恶意软件家族里很先进的一种，这种软件可以持续不断的改变自身源代码以此改变自身结构，通过这种方式来改变自身代码特征。还有，这种软件可能还可以通过强度反算（counter-analysis）来识别自身运行的环境，以此来隐藏自身的恶意功能。</td>
</tr>
<tr class="even">
<td>​ 变形恶意软件很难识别。</td>
</tr>
<tr class="odd">
<td>#### 2.4 恶意软件的识别：</td>
</tr>
<tr class="even">
<td>​
所有恶意软件都会有恶意行为以达成其目的，如果可以很好的分析恶意行为，就可以做成恶意软件的识别与分类。
​
恶意软件的识别包括了很多需要解决的问题，例如在汇编中不正确的跳转操作码，PE文本段代码隐藏，代码加密。本研究收集了现有的恶意软件及其变式，例如WannaCry，Zeus，特别是在Github上。</td>
</tr>
<tr class="odd">
<td>​
我们通过在VirusTotal网站上寻找每个恶意软件的哈希值，从而获得了得到了其家族类。</td>
</tr>
<tr class="even">
<td>​ 最后，所有我们记录的行为都是在Cuckoo沙盒环境中运行的。</td>
</tr>
<tr class="odd">
<td>​
我们发现几乎所有恶意软件都会使用很多方法改变其行为，但即使这样，恶意软件还是有一个目标，有一个确定的模式来达到此目标。还有，恶意软件会做出一些不必要的API调用，但其还是可以被一个训练好的分析器识别，因为其行为模式是相同的。</td>
</tr>
<tr class="even">
<td>​ 恶意软件分析被视为网络空间安全的一个分支，其由两方面组成：</td>
</tr>
<tr class="odd">
<td>##### <strong>1. 静态分析 </strong>：</td>
</tr>
<tr class="even">
<td>​
静态分析可以可以定义为通过执行一个孤立的环境检查可执行文件而不查看实际指令。例如MD5校验和，其通过反病毒检测攻击识别，查找字符串。</td>
</tr>
<tr class="odd">
<td>##### 2. 动态分析</td>
</tr>
<tr class="even">
<td>​
动态分析指运行恶意程序来理解其功能，观察其表现，识别其技术指标。几乎所有的重要行为都包含API调用序列。</td>
</tr>
<tr class="odd">
<td>​
<strong>大多数动态分析领域的研究都只关注分类算法，有个基本问题是没有标准的数据集来检查所提出模型的效率。</strong></td>
</tr>
<tr class="even">
<td>​
<strong>我们在Github上分享了我们的数据集：https://github.com/ocatak/malware_api_class
，该数据集包含了基于Cuckoo沙箱的已知恶意软件执行和基于VirusTotal的文件MD5特征分类的原始数据。</strong></td>
</tr>
</tbody>
</table>
<h3 id="methods">3. Methods</h3>
<h4 id="windows-api-calls">3.1 Windows API Calls：</h4>
<p>​ 软件安全知识，略</p>
<h4 id="cuckoo-sandbox">3.2 Cuckoo SandBox</h4>
<p>​ 免费软件，高度集成，开源，可以自动分析Winodws,OS
X,Linux,Android系统下的恶意文件。</p>
<h4 id="virustotal">3.3 VirusTotal</h4>
<p>​
可以在线免费分析文件或者URL。其提供了一个API，可以不通过浏览器来提供分析结果，可以自动分析。其以JSON文件的形式提供分析结果，不同反病毒应用引擎和浏览器的分析结果会分开存放。</p>
<h4 id="数据集生成">3.4 数据集生成</h4>
<p>​
本文的数据集有着简单明了的结构。数据集以CVS格式文件提供来提高互操作性，而且并不需要特定的软件或者库来读取他们。数据由来自不同Github页面的Git命令实施收集，数据集中的每一行都是在沙箱中分析的Windows操作系统的API调用序列。</p>
<p>​ 数据集的生成过程如下：</p>
<p>​ <strong>1. 沙箱环境准备：</strong></p>
<p>​
分析机器使用Ubuntu系统，将Cuckoo沙箱安装在其中，分析机运行虚拟服务，Windows操作系统就运行在虚拟服务上，同时关掉防火墙，系统升级。</p>
<p>​ <strong>2. 分析恶意软件:</strong></p>
<p>​
虚拟机中同时运行超过20000个恶意软件，应用程序会将每个恶意软件的分析结果写入MongoDB数据库，分析结果中包含恶意软件的行为数据，这些数据都是恶意软件在Win7上的API调用请求。</p>
<p>​ <strong>3. 处理API调用：</strong></p>
<p>​
我们在数据集中收集到了342种API调用，这些调用会被以0-341来标记，以此生成一个新数据集。我们使用了该数据集中至少有10个不同API调用的恶意软件的分析结果。</p>
<p>​ <strong>4. 使用Virus Total公用API分析恶意软件：</strong></p>
<p>​ 作为分析的补充，所有在数据集中的恶意软件也会被Virus
Total所分析，通过这种方式，每个恶意软件都会被不同的反病毒引擎所分析，结果会被记录。</p>
<p>​ <strong>5. 处理分析结果：</strong></p>
<p>​ Virus
Total服务使用大约66个不同的防病毒应用程序进行文件分析。利用我们利用这个服务得到的每个研究结果，我们识别了每个恶意软件的家族。通过观察，我们发现对于同一恶意软件，不同的防病毒应用程序给出了不同的结果。此外，观察到并非每一个防病毒应用程序都能检测到一些恶意软件。因此，在检测每一个恶意软件类时，认为它属于所有分析中的大多数类。</p>
<p><img
src="http://shaw-typora.oss-cn-beijing.aliyuncs.com/20210716172418.png" /></p>
<p><img
src="http://shaw-typora.oss-cn-beijing.aliyuncs.com/20210716172518.png" /></p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>AD</tag>
        <tag>Malware Classifiers</tag>
      </tags>
  </entry>
  <entry>
    <title>Generic Black-Box End-to-End Attack Against State of the art API Call Based Malware Classifiers</title>
    <url>/2021/09/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Generic%20Black-Box%20End-to-End%20Attack%20Against%20State%20of%20the%20art%20API%20Call%20Based%20Malware%20Classifiers/</url>
    <content><![CDATA[<h1
id="论文阅读generic-black-box-end-to-end-attack-against-state-of-the-art-api-call-based-malware-classifiers">【论文阅读】Generic
Black-Box End-to-End Attack Against State of the art API Call Based
Malware Classifiers</h1>
<blockquote>
<p><strong>作者：Ishai Rosenberg </strong></p>
<p><strong>大学：Ben-Gurion University of the Negev</strong></p>
<p><strong>时间：2018.6.4</strong></p>
</blockquote>
<h3 id="做了什么">1. 做了什么？</h3>
<ul>
<li><p>​
对一个通过机器学习训练的，通过API调用来分类恶意软件的分类器的攻击。</p>
<p>​
这个攻击可以使分类器不能成功识别恶意软件，并且不改变原有软件的功能。</p></li>
<li><p>​
实现了<strong>GADGET</strong>，一个可以直接将二进制恶意软件文件转换为分类器无法检测的二进制文件，<strong>并不需要访问文件源代码。</strong></p></li>
</ul>
<h3 id="一些概念">2. 一些概念：</h3>
<h4
id="machine-learning-malware-classififiers基于机器学习的恶意软件分类器">2.1
Machine learning malware
classififiers（基于机器学习的恶意软件分类器）</h4>
<p>​ 优点：1. 可以自动训练，节省时间；</p>
<p>​ 2.
只要分类器并不是基于指纹特征或者某个特定的特征（如Hash值）来分类，面对不可见威胁时泛化能力较强。</p>
<h4 id="adversarial-examples对抗样本">2.2 Adversarial
Examples（对抗样本）</h4>
<p><strong>对输入样本故意添加一些人无法察觉的细微的干扰，导致模型以高置信度给出一个错误的输出。</strong></p>
<ol type="1">
<li><strong>可以针对一张已经有正确分类的image，对其进行细微的像素修改，可以在DNN下被错分为其他label。</strong></li>
</ol>
<p><img
src="%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Generic%20Black-Box%20End-to-End%20Attack%20Against%20State%20of%20the%20art%20API%20Call%20Based%20Malware%20Classifiers/v2-ed60089ae25c81ba2677ec34ffa2a47f_720w.jpg" /></p>
<p>​
样本x的label为熊猫，在对x添加部分干扰后，在人眼中仍然分为熊猫，但对深度模型，却将其错分为长臂猿，且给出了高达99.3%的置信度。</p>
<p><img
src="%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Generic%20Black-Box%20End-to-End%20Attack%20Against%20State%20of%20the%20art%20API%20Call%20Based%20Malware%20Classifiers/v2-59a3afcc069df94927ffe1efd62822e9_720w.jpg" /></p>
<p>像素攻击：改动图片上的一个像素，就能让神经网络认错图，甚至还可以诱导它返回特定的结果。</p>
<p>改动图片上的一个像素，就能让神经网络认错图，甚至还可以诱导它返回特定的结果</p>
<p><strong>2.
同样，根据DNN，很容易产生一张在人眼下毫无意义的image，但是在DNN中能够获得高confidence的label。</strong></p>
<p><img
src="%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Generic%20Black-Box%20End-to-End%20Attack%20Against%20State%20of%20the%20art%20API%20Call%20Based%20Malware%20Classifiers/v2-0390bba1f2c35220c8b099b8ab0f4ebc_720w.jpg" /></p>
<p>两种EA算法生成的样本，这些样本人类完全无法识别，但深度学习模型会以高置信度对它们进行分类，例如将噪声识别为狮子。</p>
<h5
id="adversarial-examples-for-api-sequences生成api序列对抗样本与生成图像对抗样本并不同">2.2.1：
Adversarial examples for API
sequences(生成API序列对抗样本与生成图像对抗样本并不同):</h5>
<ol type="1">
<li>API序列由长度可变的离散符号组成，但图像可以用固定维度的矩阵表示为矩阵，且矩阵的值是连续的。</li>
<li>对于对抗API序列，其必须验证原始的恶意功能是完整的。</li>
<li><strong>对抗样本的迁移性</strong>：针对一种模型的对抗样本通常对另一种模型也奏效，即使这两个模型不是用同一数据集训练的。</li>
</ol>
<h4 id="几种攻击方法">2.3 几种攻击方法：</h4>
<blockquote>
<p><strong>White-box
attack</strong>：白盒攻击，对模型和训练集完全了解。</p>
<p><strong>Black-box
attack</strong>：黑盒攻击：对模型不了解，对训练集不了解或了解很少。</p>
<p><strong>Real-word
attack</strong>：在真实世界攻击。如将对抗样本打印出来，用手机拍照识别。</p>
<p><strong>targeted attack</strong>：使得图像都被错分到给定类别上。</p>
<p><strong>non-target
attack</strong>：事先不知道需要攻击的网络细节，也不指定预测的类别，生成对抗样本来欺骗防守方的网络。</p>
<p><strong>mimicry attack</strong>:
编写恶意的exploit，该exp模拟良性代码系统调用的痕迹，因为能够逃逸检测。</p>
<p><strong>disguise attack:</strong>
仅修改系统调用的参数使良性系统调用生成恶意行为 。</p>
<p><strong>No-op attack</strong>:
添加语义的no-ops-系统调用，其没有影响，或者是不相干的影响，即，打开一个不存在的文件。</p>
<p><strong>Equivalence attack</strong>:
使用一个不同的系统调用来达到恶意的目的.</p>
</blockquote>
<h4 id="decision-boundary决策界限">2.4 decision boundary(决策界限)</h4>
<h4 id="end-to-end">2.5 end-to-end:</h4>
<h4 id="结果分类">2.6 结果分类：</h4>
<p>虑一个二分问题，即将实例分成正类（positive）或负类（negative）。对一个二分问题来说，会出现四种情况。如果一个实例是正类并且也被
预测成正类，即为真正类（True
positive）,如果实例是负类被预测成正类，称之为假正类（False
positive）。相应地，如果实例是负类被预测成负类，称之为真负类（True
negative）,正类被预测成负类则为假负类（false negative）。</p>
<p>列联表如下表所示，1代表正类，0代表负类。（预测正确：true，预测是正类：positive）</p>
<table>
<colgroup>
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 31%" />
<col style="width: 31%" />
<col style="width: 27%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th></th>
<th>预测</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td>1</td>
<td>0</td>
<td>合计</td>
</tr>
<tr class="even">
<td>实际</td>
<td>1</td>
<td>True Positive（TP）</td>
<td>False Negative（FN）</td>
<td>Actual Positive(TP+FN)</td>
</tr>
<tr class="odd">
<td></td>
<td>0</td>
<td>False Positive（FP)</td>
<td>True Negative(TN)</td>
<td>Actual Negative(FP+TN)</td>
</tr>
<tr class="even">
<td>合计</td>
<td></td>
<td>Predicted Positive(TP+FP)</td>
<td>Predicted Negative(FN+TN)</td>
<td>TP+FP+FN+TN</td>
</tr>
</tbody>
</table>
<p>从列联表引入两个新名词。</p>
<p>其一是真正类率(true positive rate ,TPR), 计算公式为 <em>TPR=TP</em>/
( <em>TP</em>+ <em>FN</em>)，刻画的是分类器所识别出的
正实例占所有正实例的比例。</p>
<p>另外一个是负正类率(false positive rate, FPR),计算公式为 <em>FPR= FP /
(FP + TN)，</em>计算的是分类器错认为负类的正实例占所有负实例的比例。</p>
<p>还有一个真负类率（True Negative
Rate，TNR），也称为specificity,计算公式为TNR= <em>TN</em>/ (
<em>FP</em>+ <em>TN</em>) = 1 - <em>FPR</em>。</p>
<h3 id="如何实现">3. 如何实现？</h3>
<p>一些问题：程序调用API的过程；</p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>AD</tag>
        <tag>Malware Classifiers</tag>
      </tags>
  </entry>
</search>
